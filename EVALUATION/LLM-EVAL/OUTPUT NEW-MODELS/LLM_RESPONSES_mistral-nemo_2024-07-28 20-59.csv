,MODEL_NAME,filename,original text,expected_json,llm_full_response,llm_json_extracted,time_taken_seconds
0,mistral-nemo,../IMAGES NEW/Azure/14 Azure Call Center Analytics.txt,"
    A phone call between an agent and a customer is recorded and stored in Azure Blob Storage. Audio files are uploaded to an Azure Storage account via a supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API.

    Azure AI Speech is used to transcribe audio files in Batch mode asynchronously with speaker diarization enabled. The transcription results are persisted in Blob Storage.

    Azure AI Language is used to detect and redact personal data in the transcript.

    For batch mode transcription and personal data detection and redaction, use the AI services Ingestion Client tool. The Ingestion Client tool uses a no-code approach for call center transcription.

    Azure OpenAI is used to process the transcript and extract entities, summarize the conversation, and analyze sentiments. The processed output is stored in Blob Storage and then analyzed and visualized by using other services. You can also store the output in a datastore for keeping track of metadata and for reporting. Use Azure OpenAI to process the stored transcription information.

    Power BI or a custom web application that's hosted by App Service is used to visualize the output. Both options provide near real-time insights. You can store this output in a customer relationship management (CRM), so agents have contextual information about why the customer called and can quickly solve potential problems. This process is fully automated, which saves the agents time and effort.

","{""entities"": [[""phone call"", ""component"", ""A phone call between an agent and a customer is recorded""], [""agent"", ""person"", ""A phone call between an agent and a customer is recorded""], [""customer"", ""person"", ""A phone call between an agent and a customer is recorded""], [""Azure Blob Storage"", ""system"", ""is recorded and stored in Azure Blob Storage""], [""Audio files"", ""system"", ""Audio files are uploaded to an Azure Storage account via a supported method""], [""supported method"", ""component"", ""Audio files are uploaded to an Azure Storage account via a supported method""], [""UI-based tool"", ""component"", ""supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""Azure Storage Explorer"", ""component"", ""supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""Storage SDK"", ""component"", ""supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""API"", ""component"", ""supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""Azure AI Speech"", ""component"", ""transcribe audio files in Batch mode asynchronously""], [""transcription results"", ""component"", ""The transcription results are persisted in Blob Storage.""], [""Azure AI Language"", ""component"", ""Azure AI Language is used to detect and redact personal data in the transcript.""], [""AI services Ingestion Client tool"", ""component"", ""For batch mode transcription and personal data detection and redaction, use the AI services Ingestion Client tool""], [""Azure OpenAI"", ""component"", ""Azure OpenAI is used to process the transcript and extract entities, summarize the conversation, and analyze sentiments.""], [""Azure OpenAI output"", ""component"", ""The processed output is stored in Blob Storage and then analyzed and visualized by using other services.""], [""other services"", ""component"", ""The processed output is stored in Blob Storage and then analyzed and visualized by using other services.""], [""App Service"", ""system"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""Power BI"", ""system"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""custom web application"", ""system"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""Azure OpenAI output 2"", ""component"", ""You can also store the output in a datastore for keeping track of metadata and for reporting""], [""datastore"", ""component"", ""You can also store the output in a datastore for keeping track of metadata and for reporting""], [""customer relationship management (CRM)"", ""system"", ""You can store this output in a customer relationship management (CRM)""], [""Azure OpenAI output 3"", ""component"", ""You can store this output in a customer relationship management (CRM)""]], ""relationships"": [[""agent"", ""calls"", ""phone call"", ""A phone call between an agent and a customer is recorded""], [""customer"", ""calls"", ""phone call"", ""A phone call between an agent and a customer is recorded""], [""phone call"", ""part-of"", ""Azure Blob Storage"", ""is recorded and stored in Azure Blob Storage""], [""Audio files"", ""part-of"", ""Azure Blob Storage"", ""Audio files are uploaded to an Azure Storage account via a supported method""], [""supported method"", ""calls"", ""Audio files"", ""Audio files are uploaded to an Azure Storage account via a supported method""], [""supported method"", ""contains"", ""UI-based tool"", ""upported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""supported method"", ""contains"", ""Azure Storage Explorer"", ""upported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""supported method"", ""contains"", ""Storage SDK"", ""upported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""supported method"", ""contains"", ""API"", ""supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""Azure AI Speech"", ""calls"", ""Audio files"", ""transcribe audio files in Batch mode asynchronously""], [""Azure Blob Storage"", ""contains"", ""transcription results"", ""The transcription results are persisted in Blob Storage.""], [""Azure AI Speech"", ""calls"", ""transcription results"", ""The transcription results are persisted in Blob Storage.""], [""Azure AI Language"", ""calls"", ""transcription results"", ""Azure AI Language is used to detect and redact personal data in the transcript.""], [""AI services Ingestion Client tool"", ""calls"", ""transcription results"", ""For batch mode transcription and personal data detection and redaction, use the AI services Ingestion Client tool""], [""Azure OpenAI"", ""calls"", ""transcription results"", ""Azure OpenAI is used to process the transcript and extract entities, summarize the conversation, and analyze sentiments.""], [""Azure OpenAI"", ""calls"", ""Azure OpenAI output"", ""The processed output is stored in Blob Storage and then analyzed and visualized by using other services.""], [""Azure Blob Storage"", ""contains"", ""Azure OpenAI output"", ""The processed output is stored in Blob Storage and then analyzed and visualized by using other services.""], [""other services"", ""calls"", ""Azure OpenAI output"", ""The processed output is stored in Blob Storage and then analyzed and visualized by using other services.""], [""Power BI"", ""part-of"", ""App Service"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""custom web application"", ""part-of"", ""App Service"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""custom web application"", ""calls"", ""Azure OpenAI output"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""Power BI"", ""calls"", ""Azure OpenAI output"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""agent"", ""calls"", ""customer relationship management (CRM)"", ""You can store this output in a customer relationship management (CRM), so agents have contextual information about why the customer called and can quickly solve potential problems""], [""Azure OpenAI output 2"", ""part-of"", ""datastore"", ""You can also store the output in a datastore for keeping track of metadata and for reporting""], [""Azure OpenAI output 3"", ""part-of"", ""customer relationship management (CRM)"", ""You can also store the output in a datastore for keeping track of metadata and for reporting""], [""Azure OpenAI output"", ""calls"", ""Azure OpenAI output 2"", ""You can also store the output in a datastore for keeping track of metadata and for reporting""], [""Azure OpenAI output"", ""calls"", ""Azure OpenAI output 3"", ""You can store this output in a customer relationship management (CRM), so agents have contextual information about why the customer called and can quickly solve potential problems""]]}","Based on the provided context, here's the extracted entities and their relationships in JSON format:

```json
{
  ""entities"": [
    [""Azure Blob Storage"", ""system"", ""A storage system for recording and storing phone calls.""],
    [""Audio files"", ""component"", ""Files containing recorded phone calls.""],
    [""Azure AI Speech"", ""system"", ""Service used for transcribing audio files.""],
    [""AI services Ingestion Client tool"", ""system"", ""Tool used for batch mode transcription and personal data detection and redaction.""],
    [""Azure AI Language"", ""system"", ""Service used for detecting and redacting personal data in transcriptions.""],
    [""Azure OpenAI"", ""system"", ""Service used for processing transcripts, extracting entities, summarizing conversations, and analyzing sentiments.""],
    [""Power BI / App Service"", ""system"", ""Tools used for visualizing the output and providing insights.""],
    [""CRM system"", ""system"", ""Customer relationship management system for storing contextual information about customer calls.""]
  ],
  ""relationships"": [
    [""Azure Blob Storage"", ""contains"", ""Audio files""],
    [""Azure AI Speech"", ""calls"", ""Azure Blob Storage""],
    [""AI services Ingestion Client tool"", ""called-from"", ""Azure AI Speech""],
    [""AI services Ingestion Client tool"", ""calls"", ""Azure AI Language""],
    [""Azure OpenAI"", ""called-from"", ""AI services Ingestion Client tool""],
    [""Power BI / App Service"", ""called-from"", ""Azure OpenAI""],
    [""CRM system"", ""part-of"", ""Power BI / App Service""]
  ]
}
```","Based on the provided context, here's the extracted entities and their relationships in JSON format:

```json
{
  ""entities"": [
    [""Azure Blob Storage"", ""system"", ""A storage system for recording and storing phone calls.""],
    [""Audio files"", ""component"", ""Files containing recorded phone calls.""],
    [""Azure AI Speech"", ""system"", ""Service used for transcribing audio files.""],
    [""AI services Ingestion Client tool"", ""system"", ""Tool used for batch mode transcription and personal data detection and redaction.""],
    [""Azure AI Language"", ""system"", ""Service used for detecting and redacting personal data in transcriptions.""],
    [""Azure OpenAI"", ""system"", ""Service used for processing transcripts, extracting entities, summarizing conversations, and analyzing sentiments.""],
    [""Power BI / App Service"", ""system"", ""Tools used for visualizing the output and providing insights.""],
    [""CRM system"", ""system"", ""Customer relationship management system for storing contextual information about customer calls.""]
  ],
  ""relationships"": [
    [""Azure Blob Storage"", ""contains"", ""Audio files""],
    [""Azure AI Speech"", ""calls"", ""Azure Blob Storage""],
    [""AI services Ingestion Client tool"", ""called-from"", ""Azure AI Speech""],
    [""AI services Ingestion Client tool"", ""calls"", ""Azure AI Language""],
    [""Azure OpenAI"", ""called-from"", ""AI services Ingestion Client tool""],
    [""Power BI / App Service"", ""called-from"", ""Azure OpenAI""],
    [""CRM system"", ""part-of"", ""Power BI / App Service""]
  ]
}
```",9.132477435021428
1,mistral-nemo,../IMAGES NEW/Azure/07 Azure internal APIs original.txt,"
The data flows as follows:

    Developers check in code to a GitHub repository that's connected to a CI/CD pipeline agent that's installed on an Azure VM.
    The agent pushes the build to the API application that's hosted on ILB ASE.
    Azure API Management consumes the preceding APIs via HOST headers that are specified in API Management policy.
    API Management uses the App Service Environment's DNS name for all the APIs.
    Application Gateway exposes API Management's developer and API portal.
    Azure Private DNS is used to route the traffic internally between ASE, API Management, and Application Gateway.
    External users utilize the exposed developer portal to consume the APIs via Application Gateway's public IP.

","{""entities"": [[""GitHub repository"", ""system"", """"], [""Developers"", ""person"", """"], [""External users"", ""person"", """"], [""CI/CD pipeline agent"", ""system"", """"], [""Azure VM"", ""system"", """"], [""ILB ASE"", ""system"", """"], [""API application"", ""component"", """"], [""Azure API Management"", ""system"", ""consumes the preceding APIs via HOST headers""], [""App Service Environment"", ""component"", """"], [""Application Gateway"", ""component"", ""exposes API Management's developer and API portal""], [""Developer portal"", ""component"", ""API Management's developer and API portal""], [""API portal"", ""component"", ""API Management's developer and API portal""], [""Application Gateway"", ""component"", ""exposes API Management's developer and API portal""], [""Azure Private DNS"", ""component"", ""used to route the traffic internally between ASE, API Management, and Application Gateway""]], ""relationships"": [[""Azure VM"", ""contains"", ""CI/CD pipeline agent"", ""installed on an Azure VM""], [""API application"", ""part-of"", ""ILB ASE"", ""API application that's hosted on ILB ASE""], [""GitHub repository"", ""calls"", ""CI/CD pipeline agent"", ""GitHub repository that's connected to a CI/CD pipeline agent""], [""CI/CD pipeline agent"", ""calls"", ""API application"", ""agent pushes the build to the API application""], [""Azure API Management"", ""calls"", ""App Service Environment"", ""uses the App Service Environment's DNS name for all the APIs""], [""External users"", ""calls"", ""Application Gateway"", """"], [""Application Gateway"", ""calls"", ""API application"", ""to consume the APIs via Application Gateway's public IP""], [""Azure API Management"", ""contains"", ""Developer portal"", ""API Management's developer and API portal""], [""Azure API Management"", ""contains"", ""API portal"", ""API Management's developer and API portal""], [""Application Gateway"", ""calls"", ""API portal"", ""exposes API Management's developer and API portal.""], [""Application Gateway"", ""calls"", ""Developer portal"", ""exposes API Management's developer and API portal.""], [""Azure Private DNS"", ""calls"", ""Azure API Management"", ""route the traffic internally between ASE, API Management, and Application Gateway""], [""Azure Private DNS"", ""calls"", ""Application Gateway"", ""route the traffic internally between ASE, API Management, and Application Gateway""]]}","Here's the JSON response based on the provided text:

```json
{
  ""entities"": [
    [""Developers"", ""person""],
    [""GitHub repository"", ""system""],
    [""CI/CD pipeline agent"", ""component""],
    [""Azure VM"", ""system""],
    [""API application"", ""component""],
    [""ILB ASE"", ""system""],
    [""Azure API Management"", ""system""],
    [""HOST headers"", ""component""],
    [""API Management policy"", ""component""],
    [""App Service Environment's DNS name"", ""component""],
    [""Application Gateway"", ""system""],
    [""Azure Private DNS"", ""system""],
    [""External users"", ""person""]
  ],
  ""relationships"": [
    [""Developers"", ""checks in code to"", ""GitHub repository""],
    [""CI/CD pipeline agent"", ""is installed on"", ""Azure VM""],
    [""CI/CD pipeline agent"", ""pushes build to"", ""API application""],
    [""API application"", ""is hosted on"", ""ILB ASE""],
    [""Azure API Management"", ""uses"", ""App Service Environment's DNS name""],
    [""Application Gateway"", ""exposes"", ""Azure API Management developer portal""],
    [""External users"", ""consume APIs via"", ""Application Gateway public IP""]
  ]
}
```","Here's the JSON response based on the provided text:

```json
{
  ""entities"": [
    [""Developers"", ""person""],
    [""GitHub repository"", ""system""],
    [""CI/CD pipeline agent"", ""component""],
    [""Azure VM"", ""system""],
    [""API application"", ""component""],
    [""ILB ASE"", ""system""],
    [""Azure API Management"", ""system""],
    [""HOST headers"", ""component""],
    [""API Management policy"", ""component""],
    [""App Service Environment's DNS name"", ""component""],
    [""Application Gateway"", ""system""],
    [""Azure Private DNS"", ""system""],
    [""External users"", ""person""]
  ],
  ""relationships"": [
    [""Developers"", ""checks in code to"", ""GitHub repository""],
    [""CI/CD pipeline agent"", ""is installed on"", ""Azure VM""],
    [""CI/CD pipeline agent"", ""pushes build to"", ""API application""],
    [""API application"", ""is hosted on"", ""ILB ASE""],
    [""Azure API Management"", ""uses"", ""App Service Environment's DNS name""],
    [""Application Gateway"", ""exposes"", ""Azure API Management developer portal""],
    [""External users"", ""consume APIs via"", ""Application Gateway public IP""]
  ]
}
```",4.686186745995656
2,mistral-nemo,../IMAGES NEW/Azure/16 Azure automate-pdf-forms.txt,"
    A designated Outlook email account receives PDF files as attachments. The arrival of an email triggers a logic app to process the email. The logic app is built by using the capabilities of Azure Logic Apps.
    The logic app uploads the PDF files to a container in Azure Data Lake Storage.
    You can also manually or programmatically upload PDF files to the same PDF container.
    The arrival of a PDF file in the PDF container triggers another logic app to process the PDF forms that are in the PDF file.
    The logic app sends the location of the PDF file to a function app for processing. The function app is built by using the capabilities of Azure Functions.
    The function app receives the location of the file and takes these actions:
        It splits the file into single pages if the file has multiple pages. Each page contains one independent form. Split files are saved to a second container in Data Lake Storage.
        It uses HTTPS POST, an Azure REST API, to send the location of the single-page PDF file to AI Document Intelligence for processing. When Azure AI Document Intelligence completes its processing, it sends a response back to the function app, which places the information into a data structure.
        It creates a JSON data file that contains the response data and stores the file to a third container in Data Lake Storage.
    The forms processing logic app receives the processed response data.
    The forms processing logic app sends the processed data to Azure Cosmos DB, which saves the data in a database and in collections.
    Power BI obtains the data from Azure Cosmos DB and provides insights and dashboards.
    You can implement further processing as needed on the data that's in Azure Cosmos DB.

","{""entities"": [[""designated Outlook email account"", ""component"", ""A designated Outlook email account receives PDF files as attachments""], [""logic app"", ""component"", ""The arrival of an email triggers a logic app to process the email.""], [""Azure Logic Apps"", ""system"", ""The logic app is built by using the capabilities of Azure Logic Apps.""], [""Container"", ""component"", ""The logic app uploads the PDF files to a container in Azure Data Lake Storage""], [""Azure Data Lake Storage"", ""system"", ""The logic app uploads the PDF files to a container in Azure Data Lake Storage""], [""logic app 2"", ""system"", ""The arrival of a PDF file in the PDF container triggers another logic app to process the PDF forms""], [""function app"", ""component"", ""The logic app sends the location of the PDF file to a function app for processing.""], [""Azure Functions"", ""system"", ""The function app is built by using the capabilities of Azure Functions""], [""Azure REST API"", ""component"", ""It uses HTTPS POST, an Azure REST API, to send the location of the single-page PDF file""], [""Container 2"", ""component"", ""Split files are saved to a second container in Data Lake Storage""], [""AI Document Intelligence"", ""component"", ""It uses HTTPS POST, an Azure REST API, to send the location of the single-page PDF file to AI Document Intelligence for processing""], [""Container 3"", ""component"", ""JSON data file that contains the response data and stores the file to a third container in Data Lake Storage""], [""forms processing logic app"", ""component"", ""The forms processing logic app receives the processed response data""], [""Azure Cosmos DB"", ""component"", ""The forms processing logic app sends the processed data to Azure Cosmos DB""], [""database"", ""component"", ""Azure Cosmos DB, which saves the data in a database""], [""Power BI"", ""component"", ""Power BI obtains the data from Azure Cosmos DB and provides insights and dashboards""]], ""relationships"": [[""designated Outlook email account"", ""calls"", ""logic app"", ""The arrival of an email triggers a logic app to process the email.""], [""Azure Logic Apps"", ""contains"", ""logic app"", ""The logic app is built by using the capabilities of Azure Logic Apps.""], [""logic app"", ""calls"", ""Container"", ""The logic app uploads the PDF files to a container in Azure Data Lake Storage""], [""Container"", ""part-of"", ""Azure Data Lake Storage"", ""container in Azure Data Lake Storage""], [""Container"", ""calls"", ""logic app 2"", ""The arrival of a PDF file in the PDF container triggers another logic app""], [""logic app"", ""calls"", ""function app"", ""The logic app sends the location of the PDF file to a function app for processing.""], [""function app"", ""part-of"", ""Azure Functions"", ""container in Azure Data Lake Storage""], [""function app"", ""calls"", ""Container 2"", ""Split files are saved to a second container in Data Lake Storage""], [""Azure Data Lake Storage"", ""contains"", ""Container 2"", ""Split files are saved to a second container in Data Lake Storage""], [""function app"", ""calls"", ""Azure REST API"", ""It uses HTTPS POST, an Azure REST API""], [""Azure REST API"", ""calls"", ""AI Document Intelligence"", ""HTTPS POST, an Azure REST API, to send the location of the single-page PDF file to AI Document Intelligence""], [""Azure Data Lake Storage"", ""contains"", ""Container 3"", ""third container in Data Lake Storage""], [""function app"", ""calls"", ""Container 3"", ""It creates a JSON data file that contains the response data and stores the file to a third container""], [""forms processing logic app"", ""calls"", ""Container 3"", ""The forms processing logic app receives the processed response data""], [""forms processing logic app"", ""calls"", ""Azure Cosmos DB"", ""The forms processing logic app sends the processed data to Azure Cosmos DB""], [""Azure Cosmos DB"", ""calls"", ""database"", ""Azure Cosmos DB, which saves the data in a database""], [""Power BI"", ""calls"", ""Azure Cosmos DB"", ""Power BI obtains the data from Azure Cosmos DB and provides insights and dashboards""]]}","Here's the extracted entities and relationships in JSON format:

```json
{
  ""entities"": [
    [""Outlook Email Account"", ""system""],
    [""Logic App (Email Trigger)"", ""component"", ""Processes PDF files from email arrival""],
    [""Azure Logic Apps"", ""system""],
    [""Azure Data Lake Storage (PDF Container)"", ""system""],
    [""Logic App (PDF Processing)"", ""component"", ""Processes PDF forms""],
    [""Azure Function App"", ""system""],
    [""AI Document Intelligence"", ""system""],
    [""Azure REST API"", ""component"", ""Used for sending location of single-page PDF file""],
    [""Azure Cosmos DB"", ""system""],
    [""Power BI"", ""system""]
  ],
  ""relationships"": [
    [""Outlook Email Account"", ""calls"", ""Logic App (Email Trigger)"", ""Triggers logic app when new email arrives""],
    [""Logic App (Email Trigger)"", ""contains"", ""Azure Logic Apps""],
    [""Logic App (Email Trigger)"", ""calls"", ""Azure Data Lake Storage (PDF Container)"", ""Uploads PDF files to container""],
    [""Azure Data Lake Storage (PDF Container)"", ""part-of"", ""Azure Data Lake Storage""],
    [""Azure Data Lake Storage (PDF Container)"", ""contains"", ""Logic App (PDF Processing)"", ""Triggers logic app when new PDF file arrives""],
    [""Logic App (PDF Processing)"", ""contains"", ""Azure Logic Apps""],
    [""Logic App (PDF Processing)"", ""calls"", ""Azure Function App"", ""Sends location of single-page PDF file for processing""],
    [""Azure Function App"", ""part-of"", ""Azure Functions""],
    [""Azure Function App"", ""calls"", ""AI Document Intelligence"", ""Uses HTTPS POST to send location of single-page PDF file""],
    [""AI Document Intelligence"", ""called-from"", ""Azure Function App"", ""Sends response back to function app after processing""],
    [""Azure Function App"", ""calls"", ""Azure Data Lake Storage (JSON Container)"", ""Stores JSON data file containing response data""],
    [""Logic App (PDF Processing)"", ""contains"", ""Azure Logic Apps""],
    [""Logic App (PDF Processing)"", ""calls"", ""Azure Cosmos DB"", ""Sends processed data to database and collections""],
    [""Azure Function App"", ""called-from"", ""AI Document Intelligence""],
    [""Power BI"", ""part-of"", ""Azure Power BI""],
    [""Power BI"", ""obtains_data_from"", ""Azure Cosmos DB"", ""Provides insights and dashboards from the obtained data""]
  ]
}
```","Here's the extracted entities and relationships in JSON format:

```json
{
  ""entities"": [
    [""Outlook Email Account"", ""system""],
    [""Logic App (Email Trigger)"", ""component"", ""Processes PDF files from email arrival""],
    [""Azure Logic Apps"", ""system""],
    [""Azure Data Lake Storage (PDF Container)"", ""system""],
    [""Logic App (PDF Processing)"", ""component"", ""Processes PDF forms""],
    [""Azure Function App"", ""system""],
    [""AI Document Intelligence"", ""system""],
    [""Azure REST API"", ""component"", ""Used for sending location of single-page PDF file""],
    [""Azure Cosmos DB"", ""system""],
    [""Power BI"", ""system""]
  ],
  ""relationships"": [
    [""Outlook Email Account"", ""calls"", ""Logic App (Email Trigger)"", ""Triggers logic app when new email arrives""],
    [""Logic App (Email Trigger)"", ""contains"", ""Azure Logic Apps""],
    [""Logic App (Email Trigger)"", ""calls"", ""Azure Data Lake Storage (PDF Container)"", ""Uploads PDF files to container""],
    [""Azure Data Lake Storage (PDF Container)"", ""part-of"", ""Azure Data Lake Storage""],
    [""Azure Data Lake Storage (PDF Container)"", ""contains"", ""Logic App (PDF Processing)"", ""Triggers logic app when new PDF file arrives""],
    [""Logic App (PDF Processing)"", ""contains"", ""Azure Logic Apps""],
    [""Logic App (PDF Processing)"", ""calls"", ""Azure Function App"", ""Sends location of single-page PDF file for processing""],
    [""Azure Function App"", ""part-of"", ""Azure Functions""],
    [""Azure Function App"", ""calls"", ""AI Document Intelligence"", ""Uses HTTPS POST to send location of single-page PDF file""],
    [""AI Document Intelligence"", ""called-from"", ""Azure Function App"", ""Sends response back to function app after processing""],
    [""Azure Function App"", ""calls"", ""Azure Data Lake Storage (JSON Container)"", ""Stores JSON data file containing response data""],
    [""Logic App (PDF Processing)"", ""contains"", ""Azure Logic Apps""],
    [""Logic App (PDF Processing)"", ""calls"", ""Azure Cosmos DB"", ""Sends processed data to database and collections""],
    [""Azure Function App"", ""called-from"", ""AI Document Intelligence""],
    [""Power BI"", ""part-of"", ""Azure Power BI""],
    [""Power BI"", ""obtains_data_from"", ""Azure Cosmos DB"", ""Provides insights and dashboards from the obtained data""]
  ]
}
```",8.65774861900718
3,mistral-nemo,../IMAGES NEW/Azure/15 Azure automate-document-classification.txt,"
    The user provides a document file that the web app uploads. The file contains multiple documents of various types. It can, for instance, be a PDF or multipage TIFF file.
        The document file is stored in Azure Blob Storage.
        The web app adds a command message to a storage queue to initiate pipeline processing.

    Durable Functions orchestration is triggered by the command message. The message contains metadata that identifies the location in Blob Storage of the document file to be processed. Each Durable Functions instance processes only one document file.

    The Scan activity function calls the Computer Vision Read API, passing in the location in storage of the document to be processed. Optical character recognition (OCR) results are returned to the orchestration to be used by subsequent activities.

    The Classify activity function calls the document classifier service that's hosted in an Azure Kubernetes Service (AKS) cluster. This service uses regular expression pattern matching to identify the starting page of each known document and to calculate how many document types are contained in the document file. The types and page ranges of the documents are calculated and returned to the orchestration.



Note

Azure doesn't offer a service that can classify multiple document types in a single file. This solution uses a non-Azure service that's hosted in AKS.

The Metadata Store activity function saves the document type and page range information in an Azure Cosmos DB store.

The Indexing activity function creates a new search document in the Cognitive Search service for each identified document type and uses the Azure AI Search libraries for .NET to include in the search document the full OCR results and document information. A correlation ID is also added to the search document so that the search results can be matched with the corresponding document metadata from Azure Cosmos DB.

End users can search for documents by contents and metadata. Correlation IDs in the search result set can be used to look up document records that are in Azure Cosmos DB. The records include links to the original document file in Blob Storage.


","{""entities"": [[""web app"", ""system"", ""The user provides a document file that the web app uploads""], [""Azure Blob Storage"", ""system"", ""The document file is stored in Azure Blob Storage""], [""storage queue"", ""system"", ""the web app adds a command message to a storage queue to initiate pipeline processing""], [""Durable Functions orchestration"", ""system"", ""Durable Functions orchestration is triggered by the command message.""], [""Scan activity function"", ""component"", ""The Scan activity function calls the Computer Vision Read API.""], [""Computer Vision Read API"", ""component"", ""The Scan activity function calls the Computer Vision Read API.""], [""Classify activity function"", ""component"", ""The Classify activity function calls the document classifier service that's hosted in an Azure Kubernetes Service (AKS) cluster""], [""document classifier service"", ""component"", ""The Classify activity function calls the document classifier service that's hosted in an Azure Kubernetes Service (AKS) cluster""], [""Azure Kubernetes Service (AKS) cluster"", ""system"", ""The Classify activity function calls the document classifier service that's hosted in an Azure Kubernetes Service (AKS) cluster""], [""User"", ""person"", ""provides a document file that the web app uploads""]], ""relationships"": [[""User"", ""calls"", ""web app"", ""The user provides a document file that the web app uploads""], [""web app"", ""calls"", ""Azure Blob Storage"", ""The user provides a document file that the web app uploads.The document file is stored in Azure Blob Storage""], [""web app"", ""calls"", ""storage queue"", ""the web app adds a command message to a storage queue to initiate pipeline processing""], [""storage queue"", ""calls"", ""Durable Functions orchestration"", ""Durable Functions orchestration is triggered by the command message.""], [""Durable Functions orchestration"", ""calls"", ""Azure Blob Storage"", ""Each Durable Functions instance processes only one document file""], [""Scan activity function"", ""calls"", ""Computer Vision Read API"", ""the Scan activity function calls the Computer Vision Read API""], [""document classifier service"", ""part-of"", ""Azure Kubernetes Service (AKS) cluster"", ""document classifier service that's hosted in an Azure Kubernetes Service (AKS) cluster""], [""Classify activity function"", ""calls"", ""Scan activity function"", ""The Classify activity function calls the document classifier service""], [""Classify activity function"", ""calls"", ""Durable Functions orchestration"", ""The types and page ranges of the documents are calculated and returned to the orchestration""]]}","Here's the JSON response based on the provided text:

```json
{
  ""entities"": [
    [""WebApp"", ""system"", ""The entry point for uploading documents""],
    [""AzureBlobStorage"", ""system"", ""Stores document files""],
    [""DurableFunctions"", ""system"", ""Orchestrates pipeline processing""],
    [""ScanActivityFunction"", ""component"", ""Extracts OCR results using Computer Vision Read API""],
    [""ComputerVisionReadAPI"", ""component"", ""Performs optical character recognition""],
    [""ClassifyActivityFunction"", ""component"", ""Identifies document types and page ranges""],
    [""DocumentClassifierService"", ""system"", ""Hosted in AKS for document classification""],
    [""AKSCluster"", ""system"", ""Hosts the DocumentClassifierService""],
    [""MetadataStoreActivityFunction"", ""component"", ""Saves document type and page range information in Cosmos DB""],
    [""AzureCosmosDB"", ""system"", ""Stores document metadata""],
    [""IndexingActivityFunction"", ""component"", ""Creates search documents in Cognitive Search""],
    [""CognitiveSearchService"", ""system"", ""Provides full-text search functionality""]
  ],
  ""relationships"": [
    [""WebApp"", ""contains"", ""AzureBlobStorage"", ""The uploaded document file is stored here""],
    [""WebApp"", ""calls"", ""DurableFunctions"", ""Initiates pipeline processing""],
    [""DurableFunctions"", ""contains"", ""ScanActivityFunction"", ""Extracts OCR results""],
    [""ScanActivityFunction"", ""calls"", ""ComputerVisionReadAPI"", ""Performs optical character recognition""],
    [""DurableFunctions"", ""contains"", ""ClassifyActivityFunction"", ""Identifies document types and page ranges""],
    [""ClassifyActivityFunction"", ""called-from"", ""DocumentClassifierService"", ""Uses regular expression pattern matching""],
    [""AKSCluster"", ""contains"", ""DocumentClassifierService"", ""Hosts the service""],
    [""DurableFunctions"", ""contains"", ""MetadataStoreActivityFunction"", ""Saves document metadata in Cosmos DB""],
    [""MetadataStoreActivityFunction"", ""called-from"", ""AzureCosmosDB"", ""Stores document type and page range information here""],
    [""DurableFunctions"", ""contains"", ""IndexingActivityFunction"", ""Creates search documents in Cognitive Search""],
    [""IndexingActivityFunction"", ""calls"", ""CognitiveSearchService"", ""Provides full-text search functionality""]
  ]
}
```","Here's the JSON response based on the provided text:

```json
{
  ""entities"": [
    [""WebApp"", ""system"", ""The entry point for uploading documents""],
    [""AzureBlobStorage"", ""system"", ""Stores document files""],
    [""DurableFunctions"", ""system"", ""Orchestrates pipeline processing""],
    [""ScanActivityFunction"", ""component"", ""Extracts OCR results using Computer Vision Read API""],
    [""ComputerVisionReadAPI"", ""component"", ""Performs optical character recognition""],
    [""ClassifyActivityFunction"", ""component"", ""Identifies document types and page ranges""],
    [""DocumentClassifierService"", ""system"", ""Hosted in AKS for document classification""],
    [""AKSCluster"", ""system"", ""Hosts the DocumentClassifierService""],
    [""MetadataStoreActivityFunction"", ""component"", ""Saves document type and page range information in Cosmos DB""],
    [""AzureCosmosDB"", ""system"", ""Stores document metadata""],
    [""IndexingActivityFunction"", ""component"", ""Creates search documents in Cognitive Search""],
    [""CognitiveSearchService"", ""system"", ""Provides full-text search functionality""]
  ],
  ""relationships"": [
    [""WebApp"", ""contains"", ""AzureBlobStorage"", ""The uploaded document file is stored here""],
    [""WebApp"", ""calls"", ""DurableFunctions"", ""Initiates pipeline processing""],
    [""DurableFunctions"", ""contains"", ""ScanActivityFunction"", ""Extracts OCR results""],
    [""ScanActivityFunction"", ""calls"", ""ComputerVisionReadAPI"", ""Performs optical character recognition""],
    [""DurableFunctions"", ""contains"", ""ClassifyActivityFunction"", ""Identifies document types and page ranges""],
    [""ClassifyActivityFunction"", ""called-from"", ""DocumentClassifierService"", ""Uses regular expression pattern matching""],
    [""AKSCluster"", ""contains"", ""DocumentClassifierService"", ""Hosts the service""],
    [""DurableFunctions"", ""contains"", ""MetadataStoreActivityFunction"", ""Saves document metadata in Cosmos DB""],
    [""MetadataStoreActivityFunction"", ""called-from"", ""AzureCosmosDB"", ""Stores document type and page range information here""],
    [""DurableFunctions"", ""contains"", ""IndexingActivityFunction"", ""Creates search documents in Cognitive Search""],
    [""IndexingActivityFunction"", ""calls"", ""CognitiveSearchService"", ""Provides full-text search functionality""]
  ]
}
```",8.524841964012012
4,mistral-nemo,../IMAGES NEW/Azure/06 Azure logic-apps-data-integration.txt,"
    API Management accepts API calls in the form of HTTP requests.

    API Management securely routes the HTTP requests to Logic Apps.

    Each HTTP request triggers a run in Logic Apps:
        Logic Apps uses secured template parameters to retrieve database credentials from Azure Key Vault.
        Logic Apps uses Transport Layer Security (TLS) to send the database credentials and a database statement to the on-premises data gateway.

    The on-premises data gateway connects to a SQL Server database to run the statement.

    SQL Server stores the data and makes it available to apps that users access.

    Azure Monitor collects information on Logic Apps events and performance.

","{""entities"": [[""API Management"", ""system"", ""accepts API calls in the form of HTTP requests""], [""Logic Apps"", ""system"", ""uses secured template parameters to retrieve database credentials from Azure Key Vault""], [""on-premises data gateway"", ""system"", """"], [""SQL Server"", ""system"", ""stores the data and makes it available to apps that users access""], [""Azure Monitor"", ""system"", ""collects information on Logic Apps events and performance""], [""Azure Key Vault"", ""system"", ""database credentials""]], ""relationships"": [[""API Management"", ""calls"", ""Logic Apps"", ""routes the HTTP requests to Logic Apps""], [""Logic Apps"", ""calls"", ""Azure Key Vault"", ""Logic Apps uses secured template parameters to retrieve database credentials from Azure Key Vault""], [""Logic Apps"", ""calls"", ""on-premises data gateway"", ""send the database credentials and a database statement to the on-premises data gateway""], [""on-premises data gateway"", ""calls"", ""SQL Server"", ""connects to a SQL Server database""], [""Azure Monitor"", ""calls"", ""Logic Apps"", ""collects information on Logic Apps events and performance""]]}","{
  ""entities"": [
    [""API Management"", ""system""],
    [""Logic Apps"", ""component""],
    [""HTTP requests"", ""entity""],
    [""Azure Key Vault"", ""component""],
    [""on-premises data gateway"", ""component""],
    [""SQL Server database"", ""system""],
    [""Azure Monitor"", ""component""]
  ],
  ""relationships"": [
    [""API Management"", ""contains"", ""Logic Apps"", ""Logic Apps accepts HTTP requests and triggers Logic Apps runs""],
    [""Logic Apps"", ""calls"", ""Azure Key Vault"", ""Logic Apps retrieves database credentials from Azure Key Vault""],
    [""Logic Apps"", ""calls"", ""on-premises data gateway"", ""Logic Apps sends the database credentials and a statement to the on-premises data gateway""],
    [""SQL Server database"", ""part-of"", ""on-premises data gateway"", ""The on-premises data gateway connects to SQL Server database""],
    [""API Management"", ""called-from"", ""HTTP requests"", ""API Management accepts API calls in the form of HTTP requests""],
    [""Azure Monitor"", ""contains"", ""Logic Apps"", ""Azure Monitor collects information on Logic Apps events""]
  ]
}","{
  ""entities"": [
    [""API Management"", ""system""],
    [""Logic Apps"", ""component""],
    [""HTTP requests"", ""entity""],
    [""Azure Key Vault"", ""component""],
    [""on-premises data gateway"", ""component""],
    [""SQL Server database"", ""system""],
    [""Azure Monitor"", ""component""]
  ],
  ""relationships"": [
    [""API Management"", ""contains"", ""Logic Apps"", ""Logic Apps accepts HTTP requests and triggers Logic Apps runs""],
    [""Logic Apps"", ""calls"", ""Azure Key Vault"", ""Logic Apps retrieves database credentials from Azure Key Vault""],
    [""Logic Apps"", ""calls"", ""on-premises data gateway"", ""Logic Apps sends the database credentials and a statement to the on-premises data gateway""],
    [""SQL Server database"", ""part-of"", ""on-premises data gateway"", ""The on-premises data gateway connects to SQL Server database""],
    [""API Management"", ""called-from"", ""HTTP requests"", ""API Management accepts API calls in the form of HTTP requests""],
    [""Azure Monitor"", ""contains"", ""Logic Apps"", ""Azure Monitor collects information on Logic Apps events""]
  ]
}",4.390790328005096
5,mistral-nemo,../IMAGES NEW/Azure/13 Azure Secure Research.txt,"
    Data owners upload datasets into a public blob storage account. The data is encrypted by using Microsoft-managed keys.

    Azure Data Factory uses a trigger that starts copying of the uploaded dataset to a specific location (import path) on another storage account with security controls. The storage account can only be reached through a private endpoint. Also, it's accessed by a service principal with limited permissions. Data Factory deletes the original copy making the dataset immutable.

    Researchers access the secure environment through a streaming application using Azure Virtual Desktop as a privileged jump box.

    The dataset in the secure storage account is presented to the data science VMs provisioned in a secure network environment for research work. Much of the data preparation is done on those VMs.

    The secure environment has Azure Machine Learning compute that can access the dataset through a private endpoint for users for Azure Machine Learning capabilities, such as to train, deploy, automate, and manage machine learning models. At this point, models are created that meet regulatory guidelines. All model data is de-identified by removing personal information.

    Models or de-identified data is saved to a separate location on the secure storage (export path). When new data is added to the export path, a logic app is triggered. In this architecture, the logic app is outside the secure environment because no data is sent to the logic app. Its only function is to send notification and start the manual approval process.

    The app starts an approval process requesting a review of data that is queued to be exported. The manual reviewers ensure that sensitive data isn't exported. After the review process, the data is either approved or denied.

    Note

    If an approval step is not required on exfiltration, the logic app step could be omitted.

    If the de-identified data is approved, it's sent to the Data Factory instance.

    Data Factory moves the data to the public storage account in a separate container to allow external researchers to have access to their exported data and models. Alternately, you can provision another storage account in a lower security environment.

","{""entities"": [[""datasets"", ""component"", ""Data owners upload datasets into a public blob storage account""], [""public blob storage account"", ""system"", ""Data owners upload datasets into a public blob storage account""], [""Azure Data Factory"", ""system"", ""Azure Data Factory uses a trigger that starts copying of the uploaded dataset to a specific location""], [""storage account"", ""system"", ""Azure Data Factory uses a trigger that starts copying of the uploaded dataset to a specific location (import path) on another storage account with security controls""], [""copied dataset"", ""system"", ""Azure Data Factory uses a trigger that starts copying of the uploaded dataset to a specific location (import path) on another storage account with security controls""], [""private endpoint"", ""component"", ""The storage account can only be reached through a private endpoint.""], [""service principal"", ""component"", ""Also, it's accessed by a service principal with limited permissions.""], [""streaming application"", ""component"", ""access the secure environment through a streaming application""], [""Azure Virtual Desktop"", ""component"", ""Azure Virtual Desktop as a privileged jump box""], [""data science VMs"", ""component"", ""data science VMs provisioned in a secure network environment""], [""Azure Machine Learning compute"", ""component"", ""The secure environment has Azure Machine Learning compute that can access the dataset""], [""secure network environment"", ""system"", ""data science VMs provisioned in a secure network environment""], [""machine learning models"", ""component"", ""At this point, models are created that meet regulatory guidelines""], [""de-identified data"", ""component"", ""Models or de-identified data is saved to a separate location on the secure storage (export path)""], [""logic app"", ""component"", ""When new data is added to the export path, a logic app is triggered""], [""separate container"", ""component"", ""Data Factory moves the data to the public storage account in a separate container""], [""moved data"", ""component"", ""Data Factory moves the data to the public storage account in a separate container""], [""Data owners"", ""person"", ""Data owners upload datasets into a public blob storage account""], [""Researchers"", ""person"", ""Researchers access the secure environment through a streaming application using Azure Virtual Desktop as a privileged jump box""], [""manual reviewers"", ""person"", ""The manual reviewers ensure that sensitive data isn't exported.""], [""Users"", ""person"", ""The secure environment has Azure Machine Learning compute that can access the dataset""]], ""relationships"": [[""datasets"", ""part-of"", ""public blob storage account"", ""Data owners upload datasets into a public blob storage account""], [""Data owners"", ""calls"", ""datasets"", ""Data owners upload datasets into a public blob storage account""], [""Azure Data Factory"", ""calls"", ""datasets"", ""Azure Data Factory uses a trigger that starts copying of the uploaded dataset""], [""storage account"", ""contains"", ""copied dataset"", ""opying of the uploaded dataset to a specific location (import path) on another storage account with security controls""], [""Azure Data Factory"", ""calls"", ""copied dataset"", ""Azure Data Factory uses a trigger that starts copying of the uploaded dataset to a specific location""], [""private endpoint"", ""calls"", ""storage account"", ""The storage account can only be reached through a private endpoint""], [""storage account"", ""is-called-from"", ""service principal"", ""Also, it's accessed by a service principal with limited permissions""], [""Researchers"", ""calls"", ""Azure Virtual Desktop"", "" Researchers access the secure environment through a streaming application""], [""Azure Virtual Desktop"", ""calls"", ""streaming application"", ""through a streaming application using Azure Virtual Desktop""], [""streaming application"", ""calls"", ""storage account"", ""Researchers access the secure environment through a streaming application using Azure Virtual Desktop as a privileged jump box""], [""data science VMs"", ""part-of"", ""secure network environment"", ""The dataset in the secure storage account is presented to the data science VMs""], [""data science VMs"", ""calls"", ""copied dataset"", "" The dataset in the secure storage account is presented to the data science VMs""], [""secure network environment"", ""contains"", ""Azure Machine Learning compute"", ""The secure environment has Azure Machine Learning compute that can access the dataset""], [""Azure Machine Learning compute"", ""calls"", ""Azure Machine Learning compute"", ""The secure environment has Azure Machine Learning compute that can access the dataset""], [""machine learning models"", ""part-of"", ""storage account"", ""Models or de-identified data is saved to a separate location on the secure storage (export path)""], [""machine learning models"", ""calls"", ""logic app"", ""When new data is added to the export path, a logic app is triggered""], [""logic app"", ""calls"", ""manual reviewers"", ""The app starts an approval process requesting a review of data that is queued to be exported.""], [""public blob storage account"", ""contains"", ""separate container"", ""Data Factory moves the data to the public storage account in a separate container""], [""Azure Data Factory"", ""calls"", ""de-identified data"", ""Data Factory moves the data to the public storage account in a separate container to allow external researchers to have access to their exported data and models""], [""separate container"", ""contains"", ""moved data"", ""Data Factory moves the data to the public storage account in a separate container""], [""Azure Data Factory"", ""calls"", ""moved data"", ""Data Factory moves the data to the public storage account in a separate container to allow external researchers to have access to their exported data and models""], [""Users"", ""calls"", ""Azure Machine Learning compute"", ""The secure environment has Azure Machine Learning compute that can access the dataset""]]}","Here's the JSON response based on the provided context:

```json
{
  ""entities"": [
    [""Azure Data Factory"", ""system"", ""A service for orchestrating data movement and transformation activities.""],
    [""Blob Storage Account (Public)"", ""system"", ""The public storage account accessible to external researchers.""],
    [""Blob Storage Account (Secure)"", ""system"", ""The secure storage account with private endpoint access.""],
    [""Service Principal"", ""person"", ""A managed identity used to authenticate and authorize access to the secure storage account.""],
    [""Azure Virtual Desktop"", ""component"", ""Provides remote desktop services for accessing the secure environment.""],
    [""Data Science VMs"", ""system"", ""The virtual machines provisioned in a secure network for data preparation and research work.""],
    [""Azure Machine Learning compute"", ""component"", ""A component that enables training, deployment, automation, and management of machine learning models.""],
    [""Logic App"", ""component"", ""An automation service used to trigger approval processes and notifications.""],
    [""Manual Reviewers"", ""person"", ""Users responsible for reviewing data before exporting it.""]
  ],
  ""relationships"": [
    [""Azure Data Factory"", ""contains"", ""Blob Storage Account (Public)"", ""The public storage account is part of the Azure Data Factory instance.""],
    [""Blob Storage Account (Secure)"", ""part-of"", ""Azure Data Factory"", ""The secure storage account is a component of Azure Data Factory.""],
    [""Blob Storage Account (Secure)"", ""contains"", ""Service Principal"", ""The service principal has access to the secure storage account.""],
    [""Azure Virtual Desktop"", ""called-from"", ""Researchers"", ""Researchers access the secure environment through Azure Virtual Desktop.""],
    [""Data Science VMs"", ""calls"", ""Blob Storage Account (Secure)"", ""The data science VMs access the dataset in the secure storage account for research work.""],
    [""Azure Machine Learning compute"", ""calls"", ""Blob Storage Account (Secure)"", ""Azure Machine Learning accesses the dataset through a private endpoint for training models.""],
    [""Logic App"", ""called-from"", ""Blob Storage Account (Secure)"", ""The logic app is triggered when new data is added to the export path in the secure storage account.""],
    [""Logic App"", ""calls"", ""Manual Reviewers"", ""The logic app starts an approval process requesting a review from manual reviewers.""]
  ]
}
```","Here's the JSON response based on the provided context:

```json
{
  ""entities"": [
    [""Azure Data Factory"", ""system"", ""A service for orchestrating data movement and transformation activities.""],
    [""Blob Storage Account (Public)"", ""system"", ""The public storage account accessible to external researchers.""],
    [""Blob Storage Account (Secure)"", ""system"", ""The secure storage account with private endpoint access.""],
    [""Service Principal"", ""person"", ""A managed identity used to authenticate and authorize access to the secure storage account.""],
    [""Azure Virtual Desktop"", ""component"", ""Provides remote desktop services for accessing the secure environment.""],
    [""Data Science VMs"", ""system"", ""The virtual machines provisioned in a secure network for data preparation and research work.""],
    [""Azure Machine Learning compute"", ""component"", ""A component that enables training, deployment, automation, and management of machine learning models.""],
    [""Logic App"", ""component"", ""An automation service used to trigger approval processes and notifications.""],
    [""Manual Reviewers"", ""person"", ""Users responsible for reviewing data before exporting it.""]
  ],
  ""relationships"": [
    [""Azure Data Factory"", ""contains"", ""Blob Storage Account (Public)"", ""The public storage account is part of the Azure Data Factory instance.""],
    [""Blob Storage Account (Secure)"", ""part-of"", ""Azure Data Factory"", ""The secure storage account is a component of Azure Data Factory.""],
    [""Blob Storage Account (Secure)"", ""contains"", ""Service Principal"", ""The service principal has access to the secure storage account.""],
    [""Azure Virtual Desktop"", ""called-from"", ""Researchers"", ""Researchers access the secure environment through Azure Virtual Desktop.""],
    [""Data Science VMs"", ""calls"", ""Blob Storage Account (Secure)"", ""The data science VMs access the dataset in the secure storage account for research work.""],
    [""Azure Machine Learning compute"", ""calls"", ""Blob Storage Account (Secure)"", ""Azure Machine Learning accesses the dataset through a private endpoint for training models.""],
    [""Logic App"", ""called-from"", ""Blob Storage Account (Secure)"", ""The logic app is triggered when new data is added to the export path in the secure storage account.""],
    [""Logic App"", ""calls"", ""Manual Reviewers"", ""The logic app starts an approval process requesting a review from manual reviewers.""]
  ]
}
```",8.468653519987129
6,mistral-nemo,../IMAGES NEW/Azure/12 Azure Network Microservices original.txt,"
    Outside services and clients make a POST request to APIM, with a data body that includes patient information.
    APIM calls the CreatePatient function in the Patient API with the given patient information.
    The CreatePatient function in Patient API calls the CreateAuditRecord function in the Audit API function app to create an audit record.
    The Audit API CreateAuditRecord function creates the audit record in Azure Cosmos DB, and returns a success response to the Patient API CreatePatient function.
    The CreatePatient function creates the patient document in Azure Cosmos DB, and returns a success response to APIM.
    The outside services and clients receive the success response from APIM.

","{""entities"": [[""Outside services"", ""system"", ""Outside services and clients make a POST request to APIM""], [""clients"", ""system"", ""Outside services and clients make a POST request to APIM""], [""APIM"", ""system"", ""Outside services and clients make a POST request to APIM""], [""Patient API"", ""system"", "" The CreatePatient function in Patient API calls the CreateAuditRecord function in the Audit API function app""], [""CreatePatient function"", ""component"", "" The CreatePatient function in Patient API calls the CreateAuditRecord function in the Audit API function app""], [""Audit API function app"", ""system"", ""The CreatePatient function in Patient API calls the CreateAuditRecord function in the Audit API function app""], [""CreateAuditRecord function"", ""component"", ""CreatePatient function in Patient API calls the CreateAuditRecord function""], [""Azure Cosmos DB"", ""system"", ""The Audit API CreateAuditRecord function creates the audit record in Azure Cosmos DB, and returns a success response to the Patient API CreatePatient function""]], ""relationships"": [[""CreatePatient function"", ""part-of"", ""Patient API"", ""Reason""], [""Outside services"", ""calls"", ""APIM"", ""utside services and clients make a POST request to APIM""], [""clients"", ""calls"", ""APIM"", ""outside services and clients make a POST request to APIM""], [""APIM"", ""calls"", ""CreatePatient function"", ""APIM calls the CreatePatient function in the Patient API""], [""CreateAuditRecord function"", ""part-of"", ""Audit API function app"", ""Reason""], [""CreatePatient function"", ""calls"", ""CreateAuditRecord function"", ""CreatePatient function in Patient API calls the CreateAuditRecord function in the Audit API function app""], [""CreateAuditRecord function"", ""calls"", ""Azure Cosmos DB"", ""Audit API CreateAuditRecord function creates the audit record in Azure Cosmos DB""], [""CreateAuditRecord function"", ""calls"", ""CreatePatient function"", ""returns a success response to the Patient API CreatePatient function.""], [""CreatePatient function"", ""calls"", ""Azure Cosmos DB"", ""The CreatePatient function creates the patient document in Azure Cosmos DB""], [""CreatePatient function"", ""is-called-from"", ""APIM"", ""The CreatePatient function returns a success response to APIM""]]}","```json
{
  ""entities"": [
    [""APIM"", ""system"", ""API Management service""],
    [""CreatePatient"", ""function"", ""Function in Patient API""],
    [""Patient API"", ""system"", ""API for patient-related operations""],
    [""Audit API"", ""system"", ""API for audit-related operations""],
    [""Azure Cosmos DB"", ""system"", ""Cloud database service""]
  ],
  ""relationships"": [
    [""APIM"", ""calls"", ""CreatePatient""],
    [""CreatePatient"", ""called-from"", ""APIM""],
    [""CreatePatient"", ""calls"", ""CreateAuditRecord""],
    [""CreateAuditRecord"", ""called-from"", ""CreatePatient""],
    [""CreateAuditRecord"", ""contains"", ""Azure Cosmos DB""],
    [""CreatePatient"", ""contains"", ""Azure Cosmos DB""]
  ]
}
```","```json
{
  ""entities"": [
    [""APIM"", ""system"", ""API Management service""],
    [""CreatePatient"", ""function"", ""Function in Patient API""],
    [""Patient API"", ""system"", ""API for patient-related operations""],
    [""Audit API"", ""system"", ""API for audit-related operations""],
    [""Azure Cosmos DB"", ""system"", ""Cloud database service""]
  ],
  ""relationships"": [
    [""APIM"", ""calls"", ""CreatePatient""],
    [""CreatePatient"", ""called-from"", ""APIM""],
    [""CreatePatient"", ""calls"", ""CreateAuditRecord""],
    [""CreateAuditRecord"", ""called-from"", ""CreatePatient""],
    [""CreateAuditRecord"", ""contains"", ""Azure Cosmos DB""],
    [""CreatePatient"", ""contains"", ""Azure Cosmos DB""]
  ]
}
```",3.248908701003529
7,mistral-nemo,../IMAGES NEW/Azure/10 Azure LoB original.txt,"
The data flows through the solution as follows:

    Supplier data stored in CDS is moved to SQL via Data Factory.
    Purchase order (PO) data stored in ERP system is sent to Azure SQL database.
    Azure Functions uses API to surface PO data monthly and creates a task for users to review.
    Power Apps retrieves data from Azure SQL Database through API.
    User reviews and updates POs in Power Apps and sends this data to suppliers through CSV export.
    Power BI reports trends in supplier status.

","{""entities"": [[""Supplier data"", ""component"", ""Supplier data stored in CDS""], [""CDS"", ""system"", "" Supplier data stored in CDS""], [""Azure SQL database"", ""system"", ""moved to SQL via Data Factory""], [""Data Factory"", ""system"", ""moved to SQL via Data Factory""], [""Purchase order (PO)"", ""system"", ""moved to SQL via Data Factory""], [""ERP system"", ""system"", ""Purchase order (PO) data stored in ERP system""], [""Azure Functions"", ""system"", ""uses API to surface PO data monthly and creates a task for users to review""], [""Power Apps"", ""system"", ""retrieves data from Azure SQL Database through API""], [""CSV export"", ""system"", ""ends this data to suppliers through CSV export""], [""User"", ""person"", "" reviews and updates POs in Power Apps""], [""suppliers"", ""person"", "" reviews and updates POs in Power Apps""]], ""relationships"": [[""Supplier data"", ""part-of"", ""CDS"", ""Supplier data stored in CDS""], [""Supplier data"", ""is-called-from"", ""Data Factory"", ""moved to SQL via Data Factory""], [""Data Factory"", ""calls"", ""Azure SQL database"", ""moved to SQL via Data Factory""], [""Purchase order (PO)"", ""part-of"", ""ERP system"", ""Purchase order (PO) data stored in ERP system""], [""Purchase order (PO)"", ""calls"", ""Azure SQL database"", ""Purchase order (PO) data stored in ERP system is sent to Azure SQL database""], [""Azure Functions"", ""calls"", ""Purchase order (PO)"", ""uses API to surface PO data monthly""], [""Azure Functions"", ""calls"", ""User"", ""creates a task for users to review""], [""Power Apps"", ""calls"", ""Azure SQL database"", ""retrieves data from Azure SQL Database through API""], [""User"", ""calls"", ""Power Apps"", ""Reviews and updates POs in Power Apps""], [""User"", ""calls"", ""CSV export"", ""sends this data to suppliers through CSV export""], [""CSV export"", ""calls"", ""suppliers"", ""sends this data to suppliers through CSV export""]]}","```json
{
  ""entities"": [
    [""Supplier"", ""system""],
    [""CDS"", ""component""],
    [""Data Factory"", ""component""],
    [""SQL"", ""component""],
    [""ERP System"", ""system""],
    [""Azure SQL Database"", ""component""],
    [""Azure Functions"", ""component""],
    [""PO"", ""person""],
    [""API"", ""component""],
    [""Power Apps"", ""component""],
    [""User"", ""person""],
    [""CSV Export"", ""component""],
    [""Power BI"", ""component""]
  ],
  ""relationships"": [
    [""Supplier data"", ""contains"", ""CDS""],
    [""CDS"", ""part-of"", ""Supplier""],
    [""Data Factory"", ""calls"", ""SQL""],
    [""ERP System"", ""contains"", ""PO data""],
    [""Azure SQL Database"", ""called-from"", ""ERP System""],
    [""Azure Functions"", ""uses"", ""API""],
    [""API"", ""called-from"", ""Azure Functions""],
    [""Power Apps"", ""retrieves_data_from"", ""Azure SQL Database""],
    [""Azure SQL Database"", ""contains"", ""PO data""],
    [""User"", ""updates_POs_in"", ""Power Apps""],
    [""Power Apps"", ""sends_data_to"", ""Suppliers via CSV Export""],
    [""CSV Export"", ""part-of"", ""Power Apps""],
    [""Power BI"", ""reports_trends_in"", ""supplier_status""]
  ]
}
```","```json
{
  ""entities"": [
    [""Supplier"", ""system""],
    [""CDS"", ""component""],
    [""Data Factory"", ""component""],
    [""SQL"", ""component""],
    [""ERP System"", ""system""],
    [""Azure SQL Database"", ""component""],
    [""Azure Functions"", ""component""],
    [""PO"", ""person""],
    [""API"", ""component""],
    [""Power Apps"", ""component""],
    [""User"", ""person""],
    [""CSV Export"", ""component""],
    [""Power BI"", ""component""]
  ],
  ""relationships"": [
    [""Supplier data"", ""contains"", ""CDS""],
    [""CDS"", ""part-of"", ""Supplier""],
    [""Data Factory"", ""calls"", ""SQL""],
    [""ERP System"", ""contains"", ""PO data""],
    [""Azure SQL Database"", ""called-from"", ""ERP System""],
    [""Azure Functions"", ""uses"", ""API""],
    [""API"", ""called-from"", ""Azure Functions""],
    [""Power Apps"", ""retrieves_data_from"", ""Azure SQL Database""],
    [""Azure SQL Database"", ""contains"", ""PO data""],
    [""User"", ""updates_POs_in"", ""Power Apps""],
    [""Power Apps"", ""sends_data_to"", ""Suppliers via CSV Export""],
    [""CSV Export"", ""part-of"", ""Power Apps""],
    [""Power BI"", ""reports_trends_in"", ""supplier_status""]
  ]
}
```",5.238888673018664
8,mistral-nemo,../IMAGES NEW/Azure/09 Azure protect APIs original.txt,"
    To gain access to an application, an API client authenticates by providing credentials such as username and password. The IdP is Azure AD B2C in this solution, but you can use a different one.

    The authentication request goes via Azure Front Door to Azure AD B2C, which is configured with a custom domain for sign-in. Azure AD B2C authenticates the user and returns a JSON Web Token (JWT) bearer token back to the user.

    The client triggers an event that accesses a backend API. This event could be a click of a button on a web application or on a mobile device, or a direct call to the endpoint of the backend API.

    The request goes through Azure Front Door, whose back end is mapped to the public endpoint of API Management. API Management intercepts the request and validates the bearer token against Azure AD B2C by using its validate-jwt policy. If the token isn't valid, API Management rejects the request by responding with a 401 code.

    If the token is valid, API Management forwards the request to the appropriate backend API.

    The diagram shows backend APIs running in three environments:
        App Service Environment
        Function Apps
        Azure Kubernetes Services (AKS)

    APIs running in on-premises and hybrid cloud environments can also be integrated with API Management if network connectivity is established between the APIs and API Management.

","{""entities"": [[""API client"", ""system"", ""wants to gain access to an application""], [""application"", ""system"", ""API client wants to gain access to an application""], [""Azure AD B2C"", ""system"", ""The IdP is Azure AD B2C""], [""Azure Front Door"", ""system"", ""authentication request goes via Azure Front Door to Azure AD B2C""], [""backend API"", ""system"", ""The client triggers an event that accesses a backend API""], [""Azure Front Door"", ""system"", ""The request goes through Azure Front Door, whose back end is mapped to the public endpoint of API Management.""], [""backend"", ""component"", ""Azure Front Door, whose back end""], [""API Management"", ""system"", ""API Management intercepts the request and validates the bearer token against Azure AD B2C ""], [""public endpoint"", ""system"", ""whose back end is mapped to the public endpoint of API Management""], [""User"", ""person"", ""Azure AD B2C authenticates the user and returns a JSON Web Token (JWT) bearer token back to the user""]], ""relationships"": [[""API client"", ""calls"", ""application"", """"], [""Azure Front Door"", ""calls"", ""Azure AD B2C"", ""authentication request goes via Azure Front Door to Azure AD B2C""], [""Azure AD B2C"", ""is-called-from"", ""User"", ""Azure AD B2C authenticates the user and returns a JSON Web Token (JWT) bearer token back to the user""], [""API client"", ""calls"", ""backend API"", ""The client triggers an event that accesses a backend API""], [""Azure Front Door"", ""contains"", ""backend"", ""Azure Front Door, whose back end""], [""public endpoint"", ""part-of"", ""API Management"", ""Azure Front Door, whose back end""], [""backend"", ""calls"", ""public endpoint"", ""whose back end is mapped to the public endpoint of API Management""], [""API Management"", ""calls"", ""Azure AD B2C"", ""API Management intercepts the request and validates the bearer token against Azure AD B2C""]]}","Here's the extracted entities and relationships in JSON format:

```json
{
  ""entities"": [
    [""API Client"", ""person""],
    [""Azure AD B2C"", ""system""],
    [""Azure Front Door"", ""component""],
    [""Backend API"", ""component""],
    [""App Service Environment"", ""system""],
    [""Function Apps"", ""system""],
    [""Azure Kubernetes Services (AKS)"", ""system""],
    [""API Management"", ""system""]
  ],
  ""relationships"": [
    [""API Client"", ""calls"", ""Azure Front Door"", ""The API client triggers a request to Azure Front Door""],
    [""Azure Front Door"", ""contains"", ""Azure AD B2C"", ""Azure Front Door routes the authentication request to Azure AD B2C""],
    [""Azure AD B2C"", ""called-from"", ""API Client"", ""Azure AD B2C authenticates the user and returns a JWT bearer token back to API Client""],
    [""Azure Front Door"", ""contains"", ""API Management"", ""The request then goes through Azure Front Door whose backend is mapped to API Management""],
    [""API Management"", ""validates"", ""Azure AD B2C"", ""API Management validates the bearer token against Azure AD B2C using its validate-jwt policy""],
    [""API Management"", ""forwards"", ""Backend API"", ""If the token is valid, API Management forwards the request to Backend API""],
    [""App Service Environment"", ""contains"", ""Backend API"", ""Backend APIs are running in App Service Environment""],
    [""Function Apps"", ""contains"", ""Backend API"", ""Backend APIs are running in Function Apps""],
    [""Azure Kubernetes Services (AKS)"", ""contains"", ""Backend API"", ""Backend APIs are running in Azure Kubernetes Services""]
  ]
}
```","Here's the extracted entities and relationships in JSON format:

```json
{
  ""entities"": [
    [""API Client"", ""person""],
    [""Azure AD B2C"", ""system""],
    [""Azure Front Door"", ""component""],
    [""Backend API"", ""component""],
    [""App Service Environment"", ""system""],
    [""Function Apps"", ""system""],
    [""Azure Kubernetes Services (AKS)"", ""system""],
    [""API Management"", ""system""]
  ],
  ""relationships"": [
    [""API Client"", ""calls"", ""Azure Front Door"", ""The API client triggers a request to Azure Front Door""],
    [""Azure Front Door"", ""contains"", ""Azure AD B2C"", ""Azure Front Door routes the authentication request to Azure AD B2C""],
    [""Azure AD B2C"", ""called-from"", ""API Client"", ""Azure AD B2C authenticates the user and returns a JWT bearer token back to API Client""],
    [""Azure Front Door"", ""contains"", ""API Management"", ""The request then goes through Azure Front Door whose backend is mapped to API Management""],
    [""API Management"", ""validates"", ""Azure AD B2C"", ""API Management validates the bearer token against Azure AD B2C using its validate-jwt policy""],
    [""API Management"", ""forwards"", ""Backend API"", ""If the token is valid, API Management forwards the request to Backend API""],
    [""App Service Environment"", ""contains"", ""Backend API"", ""Backend APIs are running in App Service Environment""],
    [""Function Apps"", ""contains"", ""Backend API"", ""Backend APIs are running in Function Apps""],
    [""Azure Kubernetes Services (AKS)"", ""contains"", ""Backend API"", ""Backend APIs are running in Azure Kubernetes Services""]
  ]
}
```",6.320200782996835
9,mistral-nemo,../IMAGES NEW/Azure/11 Mainframe original.txt,"
    A Connect agent component captures change logs by using mainframe or midrange native utilities and caches the logs in temporary storage.
    For mainframe systems, a publisher component on the mainframe manages data migration.
    For midrange systems, in place of the publisher, a listener component manages data migration. It's located on either a Windows or Linux machine.
    The publisher or listener moves the data from on-premises to Azure via an enhanced-security connection. The publisher or listener handles the commit and rollback of transactions for each unit of work, maintaining the integrity of data.
    The Connect Replicator Engine captures the data from the publisher or listener and applies it to the target. It distributes data for parallel processing.
    The target is a database that receives the changes via ODBC or ingests the changes via Azure Event Hubs.
    The changed data is consumed by Azure Databricks and applied to Azure data platform services.
    The Connect Controller Daemon authenticates the request and establishes the socket connection between the publisher or listener and the Replicator Engine.

","{""entities"": [[""Connect agent"", ""component"", ""captures change logs""], [""temporary storage"", ""component"", ""caches the logs in temporary storage""], [""mainframe native utilities"", ""system"", ""captures change logs by using mainframe or midrange native utilities""], [""midrange native utilities"", ""system"", ""captures change logs by using mainframe or midrange native utilities""], [""mainframe systems"", ""system"", ""For mainframe systems, a publisher component on the mainframe manages data migration.""], [""midrange systems"", ""system"", ""For midrange systems, in place of the publisher, a listener component manages data migration.""], [""publisher"", ""component"", ""For mainframe systems, a publisher component on the mainframe manages data migration.""], [""listener"", ""component"", ""For midrange systems, in place of the publisher, a listener component manages data migration.""], [""Connect Replicator Engine"", ""system"", ""captures the data from the publisher or listener and applies it to the target.""], [""on-premises"", ""system"", ""The publisher or listener moves the data from on-premises to Azure""], [""Azure"", ""system"", ""The publisher or listener moves the data from on-premises to Azure""], [""Connect Replicator Engine"", ""system"", ""The Connect Replicator Engine captures the data from the publisher or listener""], [""target"", ""system"", ""applies it to the target""], [""database"", ""system"", ""target is a database""], [""ODBC"", ""component"", ""The target is a database that receives the changes via ODBC or ingests the changes via Azure Event Hubs""], [""Azure Event Hubs"", ""component"", ""The target is a database that receives the changes via ODBC or ingests the changes via Azure Event Hubs""], [""Azure Databricks"", ""component"", ""the changed data is consumed by Azure Databricks and applied to Azure data platform services.""], [""Azure data platform services"", ""component"", ""the changed data is consumed by Azure Databricks and applied to Azure data platform services.""], [""Connect Controller Daemon"", ""component"", ""authenticates the request and establishes the socket connection between the publisher or listener and the Replicator Engine.""]], ""relationships"": [[""Connect agent"", ""calls"", ""mainframe native utilities"", ""captures change logs by using mainframe or midrange native utilities""], [""Connect agent"", ""calls"", ""midrange native utilities"", ""captures change logs by using mainframe or midrange native utilities""], [""Connect agent"", ""calls"", ""temporary storage"", ""captures change logs by using mainframe or midrange native utilities""], [""mainframe systems"", ""contains"", ""mainframe native utilities"", ""F""], [""midrange systems"", ""contains"", ""midrange native utilities"", """"], [""mainframe systems"", ""contains"", ""publisher"", ""For mainframe systems, a publisher component on the mainframe manages data migration.""], [""midrange systems"", ""contains"", ""listener"", ""For midrange systems, in place of the publisher, a listener component manages data migration.""], [""publisher"", ""calls"", ""on-premises"", ""The publisher or listener moves the data from on-premises to Azure""], [""publisher"", ""calls"", ""Azure"", ""The publisher or listener moves the data from on-premises to Azure""], [""listener"", ""calls"", ""on-premises"", ""The publisher or listener moves the data from on-premises to Azure""], [""listener"", ""calls"", ""Azure"", ""The publisher or listener moves the data from on-premises to Azure""], [""Connect Replicator Engine"", ""calls"", ""publisher"", ""captures the data from the publisher or listener and applies it to the target.""], [""Connect Replicator Engine"", ""calls"", ""listener"", ""captures the data from the publisher or listener and applies it to the target.""], [""Connect Replicator Engine"", ""calls"", ""target"", ""captures the data from the publisher or listener and applies it to the target.""], [""target"", ""contains"", ""database"", ""target is a database""], [""database"", ""is-called-from"", ""ODBC"", ""database that receives the changes via ODBC""], [""database"", ""is-called-from"", ""Azure Event Hubs"", ""ingests the changes via Azure Event Hubs""], [""database"", ""is-called-from"", ""Azure Databricks"", ""the changed data is consumed by Azure Databricks""], [""Azure Databricks"", ""calls"", ""Azure data platform services"", ""consumed by Azure Databricks and applied to Azure data platform services.""], [""Connect Controller Daemon"", ""is-called-from"", ""publisher"", ""establishes the socket connection between the publisher or listener and the Replicator Engine..""], [""Connect Controller Daemon"", ""is-called-from"", ""listener"", ""establishes the socket connection between the publisher or listener and the Replicator Engine..""], [""Connect Controller Daemon"", ""calls"", ""Connect Replicator Engine"", ""establishes the socket connection between the publisher or listener and the Replicator Engine..""]]}","Here's the extracted information in the required JSON format:

```json
{
  ""entities"": [
    [""Connect agent"", ""component"", ""Captures change logs""],
    [""mainframe"", ""system"", ""Source system for Connect agent""],
    [""midrange"", ""system"", ""Source system for Connect agent""],
    [""publisher"", ""component"", ""Manages data migration on mainframe""],
    [""listener"", ""component"", ""Manages data migration on midrange systems""],
    [""Windows/Linux machine"", ""system"", ""Hosts listener component""],
    [""Azure"", ""system"", ""Destination for migrated data""],
    [""Connect Replicator Engine"", ""component"", ""Captures data from publisher/listener and applies it to target""],
    [""target database"", ""component"", ""Receives changes via ODBC or Azure Event Hubs""],
    [""Azure Databricks"", ""component"", ""Consumes changed data and applies it to Azure data platform services""],
    [""Connect Controller Daemon"", ""component"", ""Authenticates requests and establishes socket connection""]
  ],
  ""relationships"": [
    [""Connect agent"", ""contains"", ""mainframe""],
    [""Connect agent"", ""contains"", ""midrange""],
    [""publisher"", ""part-of"", ""mainframe""],
    [""listener"", ""part-of"", ""Windows/Linux machine""],
    [""publisher/listener"", ""calls"", ""Azure""],
    [""Connect Replicator Engine"", ""called-from"", ""publisher/listener""],
    [""Connect Replicator Engine"", ""contains"", ""target database""],
    [""target database"", ""called-from"", ""Azure Databricks""],
    [""Connect Controller Daemon"", ""contains"", ""socket connection""]
  ]
}
```","Here's the extracted information in the required JSON format:

```json
{
  ""entities"": [
    [""Connect agent"", ""component"", ""Captures change logs""],
    [""mainframe"", ""system"", ""Source system for Connect agent""],
    [""midrange"", ""system"", ""Source system for Connect agent""],
    [""publisher"", ""component"", ""Manages data migration on mainframe""],
    [""listener"", ""component"", ""Manages data migration on midrange systems""],
    [""Windows/Linux machine"", ""system"", ""Hosts listener component""],
    [""Azure"", ""system"", ""Destination for migrated data""],
    [""Connect Replicator Engine"", ""component"", ""Captures data from publisher/listener and applies it to target""],
    [""target database"", ""component"", ""Receives changes via ODBC or Azure Event Hubs""],
    [""Azure Databricks"", ""component"", ""Consumes changed data and applies it to Azure data platform services""],
    [""Connect Controller Daemon"", ""component"", ""Authenticates requests and establishes socket connection""]
  ],
  ""relationships"": [
    [""Connect agent"", ""contains"", ""mainframe""],
    [""Connect agent"", ""contains"", ""midrange""],
    [""publisher"", ""part-of"", ""mainframe""],
    [""listener"", ""part-of"", ""Windows/Linux machine""],
    [""publisher/listener"", ""calls"", ""Azure""],
    [""Connect Replicator Engine"", ""called-from"", ""publisher/listener""],
    [""Connect Replicator Engine"", ""contains"", ""target database""],
    [""target database"", ""called-from"", ""Azure Databricks""],
    [""Connect Controller Daemon"", ""contains"", ""socket connection""]
  ]
}
```",6.107219981990056
10,mistral-nemo,../IMAGES NEW/Azure/05. azure Original.txt,"
    Backend systems. The right-hand side of the diagram shows the various backend systems that the enterprise has deployed or relies on. These systems might include SaaS systems, other Azure services, or web services that expose REST or SOAP endpoints.

    Azure Logic Apps. In this architecture, logic apps are triggered by HTTP requests. You can also nest workflows for more complex orchestration. Logic Apps uses connectors to integrate with commonly used services. Logic Apps offers hundreds of connectors, and you can create custom connectors.

    Azure API Management. API Management consists of two related components:

        API gateway. The API gateway accepts HTTP calls and routes them to the backend.

        Developer portal. Each instance of Azure API Management provides access to a developer portal. This portal gives your developers access to documentation and code samples for calling the APIs. You can also test APIs in the developer portal.

    Azure DNS. Azure DNS provides name resolution by using the Azure infrastructure. By hosting your domains in Azure, you can manage your DNS records by using the same credentials, APIs, tools, and billing that you use for your other Azure services. To use a custom domain name, such as contoso.com, create DNS records that map the custom domain name to the IP address. For more information, see Configure a custom domain name in API Management.

    Microsoft Entra ID. Use Microsoft Entra ID to authenticate clients that call the API gateway. Microsoft Entra ID supports the OpenID Connect (OIDC) protocol. Clients obtain an access token from Microsoft Entra ID, and API Gateway validates the token to authorize the request. If you use the Standard or Premium tier of API Management, Microsoft Entra ID can also help secure access to the developer portal.

","{""entities"": [[""Backend systems"", ""system"", ""various backend systems that the enterprise has deployed or relies on""], [""SaaS systems"", ""component"", ""SaaS systems""], [""other Azure services"", ""component"", ""other Azure services""], [""web services"", ""component"", ""expose REST or SOAP endpoints""], [""Azure Logic Apps"", ""system"", ""Logic Apps uses connectors to integrate with commonly used services""], [""Azure API Management"", ""system"", ""Logic Apps uses connectors to integrate with commonly used services""], [""API gateway"", ""component"", ""The API gateway accepts HTTP calls and routes them to the backend""], [""Developer portal"", ""component"", ""This portal gives your developers access to documentation and code samples for calling the APIs""], [""Azure DNS"", ""system"", ""Azure DNS provides name resolution by using the Azure infrastructure""], [""Microsoft Entra ID"", ""system"", ""Use Microsoft Entra ID to authenticate clients that call the API gateway""], [""clients"", ""system"", ""clients that call the API gateway""], [""developers"", ""person"", ""accesses documentation and code samples""]], ""relationships"": [[""Backend systems"", ""contains"", ""SaaS systems"", ""These systems might include ""], [""Backend systems"", ""contains"", ""web services"", ""These systems might include ""], [""Backend systems"", ""contains"", ""other Azure services"", ""These systems might include ""], [""web services"", ""contains"", ""SaaS systems"", ""These systems might include ""], [""Azure API Management"", ""contains"", ""API gateway"", ""API Management consists of two related components""], [""Azure API Management"", ""contains"", ""Developer portal"", ""API Management consists of two related components""], [""clients"", ""calls"", ""API gateway"", ""clients that call the API gateway""], [""clients"", ""calls"", ""Microsoft Entra ID"", ""Clients obtain an access token from Microsoft Entra ID""], [""developers"", ""calls"", ""Developer portal"", ""This portal gives your developers access to documentation and code samples for calling the APIs. You can also test APIs in the developer portal""]]}","```json
{
  ""entities"": [
    [""Azure Logic Apps"", ""system""],
    [""Azure API Management"", ""system""],
    [""API gateway"", ""component""],
    [""Developer portal"", ""component""],
    [""Azure DNS"", ""system""],
    [""Microsoft Entra ID"", ""system""]
  ],
  ""relationships"": [
    [""Azure Logic Apps"", ""contains"", ""API gateway""],
    [""Azure API Management"", ""contains"", ""API gateway""],
    [""Azure API Management"", ""contains"", ""Developer portal""],
    [""API gateway"", ""part-of"", ""Azure API Management""],
    [""Developer portal"", ""part-of"", ""Azure API Management""],
    [""Azure Logic Apps"", ""calls"", ""Microsoft Entra ID""],
    [""Microsoft Entra ID"", ""called-from"", ""Azure Logic Apps""]
  ]
}
```","```json
{
  ""entities"": [
    [""Azure Logic Apps"", ""system""],
    [""Azure API Management"", ""system""],
    [""API gateway"", ""component""],
    [""Developer portal"", ""component""],
    [""Azure DNS"", ""system""],
    [""Microsoft Entra ID"", ""system""]
  ],
  ""relationships"": [
    [""Azure Logic Apps"", ""contains"", ""API gateway""],
    [""Azure API Management"", ""contains"", ""API gateway""],
    [""Azure API Management"", ""contains"", ""Developer portal""],
    [""API gateway"", ""part-of"", ""Azure API Management""],
    [""Developer portal"", ""part-of"", ""Azure API Management""],
    [""Azure Logic Apps"", ""calls"", ""Microsoft Entra ID""],
    [""Microsoft Entra ID"", ""called-from"", ""Azure Logic Apps""]
  ]
}
```",3.3795100260176696
11,mistral-nemo,../IMAGES NEW/TEST/08 Azure Business Processes.txt,"
The data flows through the solution as follows:

    The airline system communicates with a custom API hosted in Azure API Management.
    A custom API coordinator receives notifications and handles incoming messages from the airline system. It sends them to Power Apps, where flights are assigned to Microsoft Teams channels.
    When a user selects a flight to monitor, or when the system assigns the user to a flight, the system queues a Graph API call in an Azure Storage Account queue for further processing.
    Azure Functions runs the Graph API calls based on the incoming messages in the storage queue, sending notifications to Teams, and also streams all events to an Azure Event Hubs for further analytics.
    The airline's notification system is managed by a custom bot messaging service that employs Azure Bot Service.
    Custom bots send flight updates to users in Teams.
    An Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs, ultimately generating insightful reports with Power BI.

","{""entities"": [[""airline system"", ""system"", ""communicates with a custom API hosted in Azure API Management""], [""custom API"", ""component"", ""communicates with a custom API hosted in Azure API Management""], [""Azure API Management"", ""system"", ""communicates with a custom API hosted in Azure API Management""], [""custom API coordinator"", ""system"", ""receives notifications and handles incoming messages from the airline system""], [""Power Apps"", ""system"", ""where flights are assigned to Microsoft Teams channels""], [""Microsoft Teams channels"", ""system"", ""where flights are assigned to Microsoft Teams channels""], [""Storage Account queue"", ""system"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing.""], [""Graph API call"", ""system"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing.""], [""Azure Functions"", ""system"", ""runs the Graph API calls based on the incoming messages in the storage queue""], [""Azure Event Hubs"", ""system"", ""Azure Event Hubs for further analytics""], [""notification system"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""custom bot messaging service"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""Azure Bot Service"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""Users"", ""person"", ""selects a flight to monitor, or when the system assigns the user to a flight""], [""Azure Data Lake storage"", ""system"", ""offers long-term retention and micro-batch processing of events from Event Hubs""], [""Power BI"", ""system"", ""generating insightful reports""]], ""relationships"": [[""Azure API Management"", ""contains"", ""custom API"", ""custom API hosted in Azure API Management""], [""airline system"", ""calls"", ""custom API"", ""communicates with a custom API""], [""custom API coordinator"", ""is-called-from"", ""airline system"", ""receives notifications and handles incoming messages from the airline system""], [""Power Apps"", ""calls"", ""Microsoft Teams channels"", ""Power Apps, where flights are assigned to Microsoft Teams channels""], [""airline system"", ""calls"", ""Graph API call"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing""], [""Azure Functions"", ""calls"", ""Graph API call"", ""runs the Graph API calls based on the incoming messages in the storage queue""], [""Azure Functions"", ""calls"", ""Storage Account queue"", ""based on the incoming messages in the storage queue""], [""Azure Functions"", ""calls"", ""Microsoft Teams channels"", ""sending notifications to Teams""], [""Azure Functions"", ""calls"", ""Azure Event Hubs"", ""also streams all events to an Azure Event Hubs for further analytics""], [""notification system"", ""is-called-from"", ""custom bot messaging service"", ""managed by a custom bot messaging service""], [""custom bot messaging service"", ""calls"", ""Azure Bot Service"", ""custom bot messaging service that employs Azure Bot Service""], [""custom bot messaging service"", ""calls"", ""Microsoft Teams channels"", ""Custom bots send flight updates to users in Teams.""], [""Microsoft Teams channels"", ""calls"", ""Users"", ""Custom bots send flight updates to users in Teams.""], [""Azure Data Lake storage"", ""is-called-from"", ""Azure Event Hubs"", ""Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs""], [""Azure Data Lake storage"", ""calls"", ""Power BI"", ""Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs, ultimately generating insightful reports with Power BI""]]}","{
  ""entities"": [
    [""Airline System"", ""system""],
    [""Azure API Management"", ""system""],
    [""Custom API Coordinator"", ""component""],
    [""Power Apps"", ""system""],
    [""Microsoft Teams"", ""system""],
    [""Azure Storage Account"", ""system""],
    [""Azure Functions"", ""component""],
    [""Graph API"", ""component""],
    [""Azure Event Hubs"", ""system""],
    [""Azure Data Lake storage"", ""system""],
    [""Power BI"", ""system""],
    [""Custom Bot Messaging Service"", ""component""],
    [""Azure Bot Service"", ""system""]
  ],
  ""relationships"": [
    [""Airline System"", ""calls"", ""Azure API Management""],
    [""Custom API Coordinator"", ""part-of"", ""Azure API Management""],
    [""Custom API Coordinator"", ""contains"", ""Power Apps""],
    [""Power Apps"", ""calls"", ""Microsoft Teams""],
    [""Azure Storage Account"", ""contains"", ""Graph API""],
    [""Azure Functions"", ""called-from"", ""Azure Storage Account""],
    [""Azure Functions"", ""calls"", ""Graph API""],
    [""Azure Functions"", ""calls"", ""Azure Event Hubs""],
    [""Custom Bot Messaging Service"", ""part-of"", ""Azure Bot Service""],
    [""Custom Bot Messaging Service"", ""calls"", ""Microsoft Teams""]
  ]
}","{
  ""entities"": [
    [""Airline System"", ""system""],
    [""Azure API Management"", ""system""],
    [""Custom API Coordinator"", ""component""],
    [""Power Apps"", ""system""],
    [""Microsoft Teams"", ""system""],
    [""Azure Storage Account"", ""system""],
    [""Azure Functions"", ""component""],
    [""Graph API"", ""component""],
    [""Azure Event Hubs"", ""system""],
    [""Azure Data Lake storage"", ""system""],
    [""Power BI"", ""system""],
    [""Custom Bot Messaging Service"", ""component""],
    [""Azure Bot Service"", ""system""]
  ],
  ""relationships"": [
    [""Airline System"", ""calls"", ""Azure API Management""],
    [""Custom API Coordinator"", ""part-of"", ""Azure API Management""],
    [""Custom API Coordinator"", ""contains"", ""Power Apps""],
    [""Power Apps"", ""calls"", ""Microsoft Teams""],
    [""Azure Storage Account"", ""contains"", ""Graph API""],
    [""Azure Functions"", ""called-from"", ""Azure Storage Account""],
    [""Azure Functions"", ""calls"", ""Graph API""],
    [""Azure Functions"", ""calls"", ""Azure Event Hubs""],
    [""Custom Bot Messaging Service"", ""part-of"", ""Azure Bot Service""],
    [""Custom Bot Messaging Service"", ""calls"", ""Microsoft Teams""]
  ]
}",4.978343350987416
12,mistral-nemo,../IMAGES NEW/Azure/08 Azure Business Processes.txt,"
The data flows through the solution as follows:

    The airline system communicates with a custom API hosted in Azure API Management.
    A custom API coordinator receives notifications and handles incoming messages from the airline system. It sends them to Power Apps, where flights are assigned to Microsoft Teams channels.
    When a user selects a flight to monitor, or when the system assigns the user to a flight, the system queues a Graph API call in an Azure Storage Account queue for further processing.
    Azure Functions runs the Graph API calls based on the incoming messages in the storage queue, sending notifications to Teams, and also streams all events to an Azure Event Hubs for further analytics.
    The airline's notification system is managed by a custom bot messaging service that employs Azure Bot Service.
    Custom bots send flight updates to users in Teams.
    An Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs, ultimately generating insightful reports with Power BI.

","{""entities"": [[""airline system"", ""system"", ""communicates with a custom API hosted in Azure API Management""], [""custom API"", ""component"", ""communicates with a custom API hosted in Azure API Management""], [""Azure API Management"", ""system"", ""communicates with a custom API hosted in Azure API Management""], [""custom API coordinator"", ""system"", ""receives notifications and handles incoming messages from the airline system""], [""Power Apps"", ""system"", ""where flights are assigned to Microsoft Teams channels""], [""Microsoft Teams channels"", ""system"", ""where flights are assigned to Microsoft Teams channels""], [""Storage Account queue"", ""system"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing.""], [""Graph API call"", ""system"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing.""], [""Azure Functions"", ""system"", ""runs the Graph API calls based on the incoming messages in the storage queue""], [""Azure Event Hubs"", ""system"", ""Azure Event Hubs for further analytics""], [""notification system"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""custom bot messaging service"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""Azure Bot Service"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""Users"", ""person"", ""selects a flight to monitor, or when the system assigns the user to a flight""], [""Azure Data Lake storage"", ""system"", ""offers long-term retention and micro-batch processing of events from Event Hubs""], [""Power BI"", ""system"", ""generating insightful reports""]], ""relationships"": [[""Azure API Management"", ""contains"", ""custom API"", ""custom API hosted in Azure API Management""], [""airline system"", ""calls"", ""custom API"", ""communicates with a custom API""], [""custom API coordinator"", ""is-called-from"", ""airline system"", ""receives notifications and handles incoming messages from the airline system""], [""Power Apps"", ""calls"", ""Microsoft Teams channels"", ""Power Apps, where flights are assigned to Microsoft Teams channels""], [""airline system"", ""calls"", ""Graph API call"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing""], [""Azure Functions"", ""calls"", ""Graph API call"", ""runs the Graph API calls based on the incoming messages in the storage queue""], [""Azure Functions"", ""calls"", ""Storage Account queue"", ""based on the incoming messages in the storage queue""], [""Azure Functions"", ""calls"", ""Microsoft Teams channels"", ""sending notifications to Teams""], [""Azure Functions"", ""calls"", ""Azure Event Hubs"", ""also streams all events to an Azure Event Hubs for further analytics""], [""notification system"", ""is-called-from"", ""custom bot messaging service"", ""managed by a custom bot messaging service""], [""custom bot messaging service"", ""calls"", ""Azure Bot Service"", ""custom bot messaging service that employs Azure Bot Service""], [""custom bot messaging service"", ""calls"", ""Microsoft Teams channels"", ""Custom bots send flight updates to users in Teams.""], [""Microsoft Teams channels"", ""calls"", ""Users"", ""Custom bots send flight updates to users in Teams.""], [""Azure Data Lake storage"", ""is-called-from"", ""Azure Event Hubs"", ""Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs""], [""Azure Data Lake storage"", ""calls"", ""Power BI"", ""Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs, ultimately generating insightful reports with Power BI""]]}","Based on the provided context, here's the extracted entities and relationships in JSON format:

```json
{
  ""entities"": [
    [""Airline System"", ""system""],
    [""Custom API Coordinator"", ""component""],
    [""Power Apps"", ""system""],
    [""Azure Storage Account Queue"", ""system""],
    [""Azure Functions"", ""system""],
    [""Azure Event Hubs"", ""system""],
    [""Custom Bot Messaging Service"", ""system""],
    [""Azure Bot Service"", ""system""],
    [""Azure Data Lake storage"", ""system""],
    [""Power BI"", ""system""]
  ],
  ""relationships"": [
    [""Airline System"", ""calls"", ""Custom API Coordinator"", ""The airline system communicates with a custom API coordinator""],
    [""Custom API Coordinator"", ""contains"", ""Power Apps"", ""It sends messages to Power Apps for flight assignments.""],
    [""Custom API Coordinator"", ""queues"", ""Azure Storage Account Queue"", ""It queues Graph API calls in Azure Storage Account queue.""],
    [""Azure Storage Account Queue"", ""calls"", ""Azure Functions"", ""Azure Functions runs the Graph API calls based on incoming messages from the storage queue.""],
    [""Azure Functions"", ""streams_to"", ""Azure Event Hubs"", ""Azure Functions streams all events to an Azure Event Hubs for further analytics.""],
    [""Custom Bot Messaging Service"", ""uses"", ""Azure Bot Service"", ""The custom bot messaging service employs Azure Bot Service.""],
    [""Azure Event Hubs"", ""generates_reports_for"", ""Power BI"", ""An Azure Data Lake storage generates insightful reports with Power BI.""]
  ]
}
```","Based on the provided context, here's the extracted entities and relationships in JSON format:

```json
{
  ""entities"": [
    [""Airline System"", ""system""],
    [""Custom API Coordinator"", ""component""],
    [""Power Apps"", ""system""],
    [""Azure Storage Account Queue"", ""system""],
    [""Azure Functions"", ""system""],
    [""Azure Event Hubs"", ""system""],
    [""Custom Bot Messaging Service"", ""system""],
    [""Azure Bot Service"", ""system""],
    [""Azure Data Lake storage"", ""system""],
    [""Power BI"", ""system""]
  ],
  ""relationships"": [
    [""Airline System"", ""calls"", ""Custom API Coordinator"", ""The airline system communicates with a custom API coordinator""],
    [""Custom API Coordinator"", ""contains"", ""Power Apps"", ""It sends messages to Power Apps for flight assignments.""],
    [""Custom API Coordinator"", ""queues"", ""Azure Storage Account Queue"", ""It queues Graph API calls in Azure Storage Account queue.""],
    [""Azure Storage Account Queue"", ""calls"", ""Azure Functions"", ""Azure Functions runs the Graph API calls based on incoming messages from the storage queue.""],
    [""Azure Functions"", ""streams_to"", ""Azure Event Hubs"", ""Azure Functions streams all events to an Azure Event Hubs for further analytics.""],
    [""Custom Bot Messaging Service"", ""uses"", ""Azure Bot Service"", ""The custom bot messaging service employs Azure Bot Service.""],
    [""Azure Event Hubs"", ""generates_reports_for"", ""Power BI"", ""An Azure Data Lake storage generates insightful reports with Power BI.""]
  ]
}
```",5.720626537979115
13,mistral-nemo,../IMAGES NEW/Azure/05. azure Original.txt,"
    Backend systems. The right-hand side of the diagram shows the various backend systems that the enterprise has deployed or relies on. These systems might include SaaS systems, other Azure services, or web services that expose REST or SOAP endpoints.

    Azure Logic Apps. In this architecture, logic apps are triggered by HTTP requests. You can also nest workflows for more complex orchestration. Logic Apps uses connectors to integrate with commonly used services. Logic Apps offers hundreds of connectors, and you can create custom connectors.

    Azure API Management. API Management consists of two related components:

        API gateway. The API gateway accepts HTTP calls and routes them to the backend.

        Developer portal. Each instance of Azure API Management provides access to a developer portal. This portal gives your developers access to documentation and code samples for calling the APIs. You can also test APIs in the developer portal.

    Azure DNS. Azure DNS provides name resolution by using the Azure infrastructure. By hosting your domains in Azure, you can manage your DNS records by using the same credentials, APIs, tools, and billing that you use for your other Azure services. To use a custom domain name, such as contoso.com, create DNS records that map the custom domain name to the IP address. For more information, see Configure a custom domain name in API Management.

    Microsoft Entra ID. Use Microsoft Entra ID to authenticate clients that call the API gateway. Microsoft Entra ID supports the OpenID Connect (OIDC) protocol. Clients obtain an access token from Microsoft Entra ID, and API Gateway validates the token to authorize the request. If you use the Standard or Premium tier of API Management, Microsoft Entra ID can also help secure access to the developer portal.

","{""entities"": [[""Backend systems"", ""system"", ""various backend systems that the enterprise has deployed or relies on""], [""SaaS systems"", ""component"", ""SaaS systems""], [""other Azure services"", ""component"", ""other Azure services""], [""web services"", ""component"", ""expose REST or SOAP endpoints""], [""Azure Logic Apps"", ""system"", ""Logic Apps uses connectors to integrate with commonly used services""], [""Azure API Management"", ""system"", ""Logic Apps uses connectors to integrate with commonly used services""], [""API gateway"", ""component"", ""The API gateway accepts HTTP calls and routes them to the backend""], [""Developer portal"", ""component"", ""This portal gives your developers access to documentation and code samples for calling the APIs""], [""Azure DNS"", ""system"", ""Azure DNS provides name resolution by using the Azure infrastructure""], [""Microsoft Entra ID"", ""system"", ""Use Microsoft Entra ID to authenticate clients that call the API gateway""], [""clients"", ""system"", ""clients that call the API gateway""], [""developers"", ""person"", ""accesses documentation and code samples""]], ""relationships"": [[""Backend systems"", ""contains"", ""SaaS systems"", ""These systems might include ""], [""Backend systems"", ""contains"", ""web services"", ""These systems might include ""], [""Backend systems"", ""contains"", ""other Azure services"", ""These systems might include ""], [""web services"", ""contains"", ""SaaS systems"", ""These systems might include ""], [""Azure API Management"", ""contains"", ""API gateway"", ""API Management consists of two related components""], [""Azure API Management"", ""contains"", ""Developer portal"", ""API Management consists of two related components""], [""clients"", ""calls"", ""API gateway"", ""clients that call the API gateway""], [""clients"", ""calls"", ""Microsoft Entra ID"", ""Clients obtain an access token from Microsoft Entra ID""], [""developers"", ""calls"", ""Developer portal"", ""This portal gives your developers access to documentation and code samples for calling the APIs. You can also test APIs in the developer portal""]]}","Based on the provided text, here's the JSON response:

```json
{
  ""entities"": [
    [""Azure Logic Apps"", ""system""],
    [""Azure API Management"", ""system""],
    [""API gateway"", ""component"", ""Routes HTTP calls to backend systems.""],
    [""Developer portal"", ""component"", ""Provides access to documentation and code samples for calling APIs.""],
    [""Azure DNS"", ""system""],
    [""Microsoft Entra ID"", ""system""]
  ],
  ""relationships"": [
    [""Azure Logic Apps"", ""contains"", ""API gateway""],
    [""Azure API Management"", ""contains"", ""API gateway""],
    [""Azure API Management"", ""contains"", ""Developer portal""],
    [""Azure DNS"", ""part-of"", ""Microsoft Entra ID""],
    [""API gateway"", ""called-from"", ""Azure Logic Apps""],
    [""API gateway"", ""calls"", ""Backend systems""]
  ]
}
```","Based on the provided text, here's the JSON response:

```json
{
  ""entities"": [
    [""Azure Logic Apps"", ""system""],
    [""Azure API Management"", ""system""],
    [""API gateway"", ""component"", ""Routes HTTP calls to backend systems.""],
    [""Developer portal"", ""component"", ""Provides access to documentation and code samples for calling APIs.""],
    [""Azure DNS"", ""system""],
    [""Microsoft Entra ID"", ""system""]
  ],
  ""relationships"": [
    [""Azure Logic Apps"", ""contains"", ""API gateway""],
    [""Azure API Management"", ""contains"", ""API gateway""],
    [""Azure API Management"", ""contains"", ""Developer portal""],
    [""Azure DNS"", ""part-of"", ""Microsoft Entra ID""],
    [""API gateway"", ""called-from"", ""Azure Logic Apps""],
    [""API gateway"", ""calls"", ""Backend systems""]
  ]
}
```",3.644737362017622
14,mistral-nemo,../IMAGES NEW/Azure/14 Azure Call Center Analytics.txt,"
    A phone call between an agent and a customer is recorded and stored in Azure Blob Storage. Audio files are uploaded to an Azure Storage account via a supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API.

    Azure AI Speech is used to transcribe audio files in Batch mode asynchronously with speaker diarization enabled. The transcription results are persisted in Blob Storage.

    Azure AI Language is used to detect and redact personal data in the transcript.

    For batch mode transcription and personal data detection and redaction, use the AI services Ingestion Client tool. The Ingestion Client tool uses a no-code approach for call center transcription.

    Azure OpenAI is used to process the transcript and extract entities, summarize the conversation, and analyze sentiments. The processed output is stored in Blob Storage and then analyzed and visualized by using other services. You can also store the output in a datastore for keeping track of metadata and for reporting. Use Azure OpenAI to process the stored transcription information.

    Power BI or a custom web application that's hosted by App Service is used to visualize the output. Both options provide near real-time insights. You can store this output in a customer relationship management (CRM), so agents have contextual information about why the customer called and can quickly solve potential problems. This process is fully automated, which saves the agents time and effort.

","{""entities"": [[""phone call"", ""component"", ""A phone call between an agent and a customer is recorded""], [""agent"", ""person"", ""A phone call between an agent and a customer is recorded""], [""customer"", ""person"", ""A phone call between an agent and a customer is recorded""], [""Azure Blob Storage"", ""system"", ""is recorded and stored in Azure Blob Storage""], [""Audio files"", ""system"", ""Audio files are uploaded to an Azure Storage account via a supported method""], [""supported method"", ""component"", ""Audio files are uploaded to an Azure Storage account via a supported method""], [""UI-based tool"", ""component"", ""supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""Azure Storage Explorer"", ""component"", ""supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""Storage SDK"", ""component"", ""supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""API"", ""component"", ""supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""Azure AI Speech"", ""component"", ""transcribe audio files in Batch mode asynchronously""], [""transcription results"", ""component"", ""The transcription results are persisted in Blob Storage.""], [""Azure AI Language"", ""component"", ""Azure AI Language is used to detect and redact personal data in the transcript.""], [""AI services Ingestion Client tool"", ""component"", ""For batch mode transcription and personal data detection and redaction, use the AI services Ingestion Client tool""], [""Azure OpenAI"", ""component"", ""Azure OpenAI is used to process the transcript and extract entities, summarize the conversation, and analyze sentiments.""], [""Azure OpenAI output"", ""component"", ""The processed output is stored in Blob Storage and then analyzed and visualized by using other services.""], [""other services"", ""component"", ""The processed output is stored in Blob Storage and then analyzed and visualized by using other services.""], [""App Service"", ""system"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""Power BI"", ""system"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""custom web application"", ""system"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""Azure OpenAI output 2"", ""component"", ""You can also store the output in a datastore for keeping track of metadata and for reporting""], [""datastore"", ""component"", ""You can also store the output in a datastore for keeping track of metadata and for reporting""], [""customer relationship management (CRM)"", ""system"", ""You can store this output in a customer relationship management (CRM)""], [""Azure OpenAI output 3"", ""component"", ""You can store this output in a customer relationship management (CRM)""]], ""relationships"": [[""agent"", ""calls"", ""phone call"", ""A phone call between an agent and a customer is recorded""], [""customer"", ""calls"", ""phone call"", ""A phone call between an agent and a customer is recorded""], [""phone call"", ""part-of"", ""Azure Blob Storage"", ""is recorded and stored in Azure Blob Storage""], [""Audio files"", ""part-of"", ""Azure Blob Storage"", ""Audio files are uploaded to an Azure Storage account via a supported method""], [""supported method"", ""calls"", ""Audio files"", ""Audio files are uploaded to an Azure Storage account via a supported method""], [""supported method"", ""contains"", ""UI-based tool"", ""upported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""supported method"", ""contains"", ""Azure Storage Explorer"", ""upported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""supported method"", ""contains"", ""Storage SDK"", ""upported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""supported method"", ""contains"", ""API"", ""supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""Azure AI Speech"", ""calls"", ""Audio files"", ""transcribe audio files in Batch mode asynchronously""], [""Azure Blob Storage"", ""contains"", ""transcription results"", ""The transcription results are persisted in Blob Storage.""], [""Azure AI Speech"", ""calls"", ""transcription results"", ""The transcription results are persisted in Blob Storage.""], [""Azure AI Language"", ""calls"", ""transcription results"", ""Azure AI Language is used to detect and redact personal data in the transcript.""], [""AI services Ingestion Client tool"", ""calls"", ""transcription results"", ""For batch mode transcription and personal data detection and redaction, use the AI services Ingestion Client tool""], [""Azure OpenAI"", ""calls"", ""transcription results"", ""Azure OpenAI is used to process the transcript and extract entities, summarize the conversation, and analyze sentiments.""], [""Azure OpenAI"", ""calls"", ""Azure OpenAI output"", ""The processed output is stored in Blob Storage and then analyzed and visualized by using other services.""], [""Azure Blob Storage"", ""contains"", ""Azure OpenAI output"", ""The processed output is stored in Blob Storage and then analyzed and visualized by using other services.""], [""other services"", ""calls"", ""Azure OpenAI output"", ""The processed output is stored in Blob Storage and then analyzed and visualized by using other services.""], [""Power BI"", ""part-of"", ""App Service"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""custom web application"", ""part-of"", ""App Service"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""custom web application"", ""calls"", ""Azure OpenAI output"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""Power BI"", ""calls"", ""Azure OpenAI output"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""agent"", ""calls"", ""customer relationship management (CRM)"", ""You can store this output in a customer relationship management (CRM), so agents have contextual information about why the customer called and can quickly solve potential problems""], [""Azure OpenAI output 2"", ""part-of"", ""datastore"", ""You can also store the output in a datastore for keeping track of metadata and for reporting""], [""Azure OpenAI output 3"", ""part-of"", ""customer relationship management (CRM)"", ""You can also store the output in a datastore for keeping track of metadata and for reporting""], [""Azure OpenAI output"", ""calls"", ""Azure OpenAI output 2"", ""You can also store the output in a datastore for keeping track of metadata and for reporting""], [""Azure OpenAI output"", ""calls"", ""Azure OpenAI output 3"", ""You can store this output in a customer relationship management (CRM), so agents have contextual information about why the customer called and can quickly solve potential problems""]]}","Here's the JSON response based on the provided text:

```json
{
  ""entities"": [
    [""Azure Blob Storage"", ""system""],
    [""Audio File"", ""component""],
    [""Azure AI Speech"", ""component""],
    [""Azure AI Language"", ""component""],
    [""Ingestion Client Tool"", ""component""],
    [""Azure OpenAI"", ""component""],
    [""Power BI"", ""component""],
    [""App Service"", ""component""],
    [""CRM"", ""system""],
    [""Agent"", ""person""],
    [""Customer"", ""person""]
  ],
  ""relationships"": [
    [""Audio File"", ""stored-in"", ""Azure Blob Storage""],
    [""Azure AI Speech"", ""uses"", ""Azure Blob Storage""],
    [""Azure AI Language"", ""uses"", ""Azure Blob Storage""],
    [""Ingestion Client Tool"", ""used-for"", ""Azure AI Speech""],
    [""Ingestion Client Tool"", ""used-for"", ""Azure AI Language""],
    [""Azure OpenAI"", ""processes"", ""Audio File""],
    [""Power BI"", ""visualizes-output-from"", ""Azure OpenAI""],
    [""App Service"", ""hosts"", ""Power BI""],
    [""Agent"", ""uses"", ""CRM""]
  ]
}
```","Here's the JSON response based on the provided text:

```json
{
  ""entities"": [
    [""Azure Blob Storage"", ""system""],
    [""Audio File"", ""component""],
    [""Azure AI Speech"", ""component""],
    [""Azure AI Language"", ""component""],
    [""Ingestion Client Tool"", ""component""],
    [""Azure OpenAI"", ""component""],
    [""Power BI"", ""component""],
    [""App Service"", ""component""],
    [""CRM"", ""system""],
    [""Agent"", ""person""],
    [""Customer"", ""person""]
  ],
  ""relationships"": [
    [""Audio File"", ""stored-in"", ""Azure Blob Storage""],
    [""Azure AI Speech"", ""uses"", ""Azure Blob Storage""],
    [""Azure AI Language"", ""uses"", ""Azure Blob Storage""],
    [""Ingestion Client Tool"", ""used-for"", ""Azure AI Speech""],
    [""Ingestion Client Tool"", ""used-for"", ""Azure AI Language""],
    [""Azure OpenAI"", ""processes"", ""Audio File""],
    [""Power BI"", ""visualizes-output-from"", ""Azure OpenAI""],
    [""App Service"", ""hosts"", ""Power BI""],
    [""Agent"", ""uses"", ""CRM""]
  ]
}
```",4.470499766990542
15,mistral-nemo,../IMAGES NEW/Azure/10 Azure LoB original.txt,"
The data flows through the solution as follows:

    Supplier data stored in CDS is moved to SQL via Data Factory.
    Purchase order (PO) data stored in ERP system is sent to Azure SQL database.
    Azure Functions uses API to surface PO data monthly and creates a task for users to review.
    Power Apps retrieves data from Azure SQL Database through API.
    User reviews and updates POs in Power Apps and sends this data to suppliers through CSV export.
    Power BI reports trends in supplier status.

","{""entities"": [[""Supplier data"", ""component"", ""Supplier data stored in CDS""], [""CDS"", ""system"", "" Supplier data stored in CDS""], [""Azure SQL database"", ""system"", ""moved to SQL via Data Factory""], [""Data Factory"", ""system"", ""moved to SQL via Data Factory""], [""Purchase order (PO)"", ""system"", ""moved to SQL via Data Factory""], [""ERP system"", ""system"", ""Purchase order (PO) data stored in ERP system""], [""Azure Functions"", ""system"", ""uses API to surface PO data monthly and creates a task for users to review""], [""Power Apps"", ""system"", ""retrieves data from Azure SQL Database through API""], [""CSV export"", ""system"", ""ends this data to suppliers through CSV export""], [""User"", ""person"", "" reviews and updates POs in Power Apps""], [""suppliers"", ""person"", "" reviews and updates POs in Power Apps""]], ""relationships"": [[""Supplier data"", ""part-of"", ""CDS"", ""Supplier data stored in CDS""], [""Supplier data"", ""is-called-from"", ""Data Factory"", ""moved to SQL via Data Factory""], [""Data Factory"", ""calls"", ""Azure SQL database"", ""moved to SQL via Data Factory""], [""Purchase order (PO)"", ""part-of"", ""ERP system"", ""Purchase order (PO) data stored in ERP system""], [""Purchase order (PO)"", ""calls"", ""Azure SQL database"", ""Purchase order (PO) data stored in ERP system is sent to Azure SQL database""], [""Azure Functions"", ""calls"", ""Purchase order (PO)"", ""uses API to surface PO data monthly""], [""Azure Functions"", ""calls"", ""User"", ""creates a task for users to review""], [""Power Apps"", ""calls"", ""Azure SQL database"", ""retrieves data from Azure SQL Database through API""], [""User"", ""calls"", ""Power Apps"", ""Reviews and updates POs in Power Apps""], [""User"", ""calls"", ""CSV export"", ""sends this data to suppliers through CSV export""], [""CSV export"", ""calls"", ""suppliers"", ""sends this data to suppliers through CSV export""]]}","```json
{
  ""entities"": [
    [""Supplier data"", ""component""],
    [""CDS"", ""system""],
    [""Data Factory"", ""component""],
    [""SQL"", ""system""],
    [""Purchase order (PO) data"", ""component""],
    [""ERP system"", ""system""],
    [""Azure SQL database"", ""system""],
    [""Azure Functions"", ""component""],
    [""API"", ""component""],
    [""Power Apps"", ""component""],
    [""Azure SQL Database"", ""system""],
    [""User"", ""person""],
    [""POs"", ""component""],
    [""CSV export"", ""component""],
    [""Power BI"", ""component""],
    [""Supplier status trends"", ""component""]
  ],
  ""relationships"": [
    [""Supplier data"", ""moved-from"", ""CDS""],
    [""Supplier data"", ""moved-to"", ""SQL""],
    [""Purchase order (PO) data"", ""sent-from"", ""ERP system""],
    [""Purchase order (PO) data"", ""sent-to"", ""Azure SQL database""],
    [""Azure Functions"", ""uses"", ""API""],
    [""Azure Functions"", ""creates-task-for"", ""User""],
    [""Power Apps"", ""retrieves-data-from"", ""Azure SQL Database""],
    [""User"", ""reviews-and-updates"", ""POs""],
    [""POs"", ""sent-to-suppliers-through"", ""CSV export""],
    [""Power BI"", ""reports-on"", ""Supplier status trends""]
  ]
}
```","```json
{
  ""entities"": [
    [""Supplier data"", ""component""],
    [""CDS"", ""system""],
    [""Data Factory"", ""component""],
    [""SQL"", ""system""],
    [""Purchase order (PO) data"", ""component""],
    [""ERP system"", ""system""],
    [""Azure SQL database"", ""system""],
    [""Azure Functions"", ""component""],
    [""API"", ""component""],
    [""Power Apps"", ""component""],
    [""Azure SQL Database"", ""system""],
    [""User"", ""person""],
    [""POs"", ""component""],
    [""CSV export"", ""component""],
    [""Power BI"", ""component""],
    [""Supplier status trends"", ""component""]
  ],
  ""relationships"": [
    [""Supplier data"", ""moved-from"", ""CDS""],
    [""Supplier data"", ""moved-to"", ""SQL""],
    [""Purchase order (PO) data"", ""sent-from"", ""ERP system""],
    [""Purchase order (PO) data"", ""sent-to"", ""Azure SQL database""],
    [""Azure Functions"", ""uses"", ""API""],
    [""Azure Functions"", ""creates-task-for"", ""User""],
    [""Power Apps"", ""retrieves-data-from"", ""Azure SQL Database""],
    [""User"", ""reviews-and-updates"", ""POs""],
    [""POs"", ""sent-to-suppliers-through"", ""CSV export""],
    [""Power BI"", ""reports-on"", ""Supplier status trends""]
  ]
}
```",5.288738647999708
16,mistral-nemo,../IMAGES NEW/Azure/08 Azure Business Processes.txt,"
The data flows through the solution as follows:

    The airline system communicates with a custom API hosted in Azure API Management.
    A custom API coordinator receives notifications and handles incoming messages from the airline system. It sends them to Power Apps, where flights are assigned to Microsoft Teams channels.
    When a user selects a flight to monitor, or when the system assigns the user to a flight, the system queues a Graph API call in an Azure Storage Account queue for further processing.
    Azure Functions runs the Graph API calls based on the incoming messages in the storage queue, sending notifications to Teams, and also streams all events to an Azure Event Hubs for further analytics.
    The airline's notification system is managed by a custom bot messaging service that employs Azure Bot Service.
    Custom bots send flight updates to users in Teams.
    An Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs, ultimately generating insightful reports with Power BI.

","{""entities"": [[""airline system"", ""system"", ""communicates with a custom API hosted in Azure API Management""], [""custom API"", ""component"", ""communicates with a custom API hosted in Azure API Management""], [""Azure API Management"", ""system"", ""communicates with a custom API hosted in Azure API Management""], [""custom API coordinator"", ""system"", ""receives notifications and handles incoming messages from the airline system""], [""Power Apps"", ""system"", ""where flights are assigned to Microsoft Teams channels""], [""Microsoft Teams channels"", ""system"", ""where flights are assigned to Microsoft Teams channels""], [""Storage Account queue"", ""system"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing.""], [""Graph API call"", ""system"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing.""], [""Azure Functions"", ""system"", ""runs the Graph API calls based on the incoming messages in the storage queue""], [""Azure Event Hubs"", ""system"", ""Azure Event Hubs for further analytics""], [""notification system"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""custom bot messaging service"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""Azure Bot Service"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""Users"", ""person"", ""selects a flight to monitor, or when the system assigns the user to a flight""], [""Azure Data Lake storage"", ""system"", ""offers long-term retention and micro-batch processing of events from Event Hubs""], [""Power BI"", ""system"", ""generating insightful reports""]], ""relationships"": [[""Azure API Management"", ""contains"", ""custom API"", ""custom API hosted in Azure API Management""], [""airline system"", ""calls"", ""custom API"", ""communicates with a custom API""], [""custom API coordinator"", ""is-called-from"", ""airline system"", ""receives notifications and handles incoming messages from the airline system""], [""Power Apps"", ""calls"", ""Microsoft Teams channels"", ""Power Apps, where flights are assigned to Microsoft Teams channels""], [""airline system"", ""calls"", ""Graph API call"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing""], [""Azure Functions"", ""calls"", ""Graph API call"", ""runs the Graph API calls based on the incoming messages in the storage queue""], [""Azure Functions"", ""calls"", ""Storage Account queue"", ""based on the incoming messages in the storage queue""], [""Azure Functions"", ""calls"", ""Microsoft Teams channels"", ""sending notifications to Teams""], [""Azure Functions"", ""calls"", ""Azure Event Hubs"", ""also streams all events to an Azure Event Hubs for further analytics""], [""notification system"", ""is-called-from"", ""custom bot messaging service"", ""managed by a custom bot messaging service""], [""custom bot messaging service"", ""calls"", ""Azure Bot Service"", ""custom bot messaging service that employs Azure Bot Service""], [""custom bot messaging service"", ""calls"", ""Microsoft Teams channels"", ""Custom bots send flight updates to users in Teams.""], [""Microsoft Teams channels"", ""calls"", ""Users"", ""Custom bots send flight updates to users in Teams.""], [""Azure Data Lake storage"", ""is-called-from"", ""Azure Event Hubs"", ""Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs""], [""Azure Data Lake storage"", ""calls"", ""Power BI"", ""Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs, ultimately generating insightful reports with Power BI""]]}","{
  ""entities"": [
    [""Airline System"", ""system""],
    [""Azure API Management"", ""system""],
    [""Custom API Coordinator"", ""component""],
    [""Power Apps"", ""system""],
    [""Microsoft Teams"", ""system""],
    [""Azure Storage Account"", ""system""],
    [""Azure Functions"", ""system""],
    [""Azure Event Hubs"", ""system""],
    [""Custom Bot Messaging Service"", ""component""],
    [""Azure Bot Service"", ""system""],
    [""Azure Data Lake Storage"", ""system""],
    [""Power BI"", ""system""]
  ],
  ""relationships"": [
    [""Airline System"", ""calls"", ""Azure API Management""],
    [""Custom API Coordinator"", ""part-of"", ""Azure API Management""],
    [""Custom API Coordinator"", ""contains"", ""Power Apps""],
    [""Power Apps"", ""called-from"", ""Custom API Coordinator""],
    [""Power Apps"", ""contains"", ""Microsoft Teams""],
    [""Custom API Coordinator"", ""calls"", ""Azure Storage Account""],
    [""Azure Functions"", ""part-of"", ""Azure Storage Account""],
    [""Azure Functions"", ""contains"", ""Azure Event Hubs""],
    [""Azure Event Hubs"", ""called-from"", ""Azure Functions""],
    [""Custom Bot Messaging Service"", ""part-of"", ""Azure Bot Service""],
    [""Azure Bot Service"", ""calls"", ""Microsoft Teams""],
    [""Azure Data Lake Storage"", ""part-of"", ""Azure Event Hubs""],
    [""Power BI"", ""part-of"", ""Azure Data Lake Storage""]
  ]
}","{
  ""entities"": [
    [""Airline System"", ""system""],
    [""Azure API Management"", ""system""],
    [""Custom API Coordinator"", ""component""],
    [""Power Apps"", ""system""],
    [""Microsoft Teams"", ""system""],
    [""Azure Storage Account"", ""system""],
    [""Azure Functions"", ""system""],
    [""Azure Event Hubs"", ""system""],
    [""Custom Bot Messaging Service"", ""component""],
    [""Azure Bot Service"", ""system""],
    [""Azure Data Lake Storage"", ""system""],
    [""Power BI"", ""system""]
  ],
  ""relationships"": [
    [""Airline System"", ""calls"", ""Azure API Management""],
    [""Custom API Coordinator"", ""part-of"", ""Azure API Management""],
    [""Custom API Coordinator"", ""contains"", ""Power Apps""],
    [""Power Apps"", ""called-from"", ""Custom API Coordinator""],
    [""Power Apps"", ""contains"", ""Microsoft Teams""],
    [""Custom API Coordinator"", ""calls"", ""Azure Storage Account""],
    [""Azure Functions"", ""part-of"", ""Azure Storage Account""],
    [""Azure Functions"", ""contains"", ""Azure Event Hubs""],
    [""Azure Event Hubs"", ""called-from"", ""Azure Functions""],
    [""Custom Bot Messaging Service"", ""part-of"", ""Azure Bot Service""],
    [""Azure Bot Service"", ""calls"", ""Microsoft Teams""],
    [""Azure Data Lake Storage"", ""part-of"", ""Azure Event Hubs""],
    [""Power BI"", ""part-of"", ""Azure Data Lake Storage""]
  ]
}",5.5045893829956185
17,mistral-nemo,../IMAGES NEW/TEST/08 Azure Business Processes.txt,"
The data flows through the solution as follows:

    The airline system communicates with a custom API hosted in Azure API Management.
    A custom API coordinator receives notifications and handles incoming messages from the airline system. It sends them to Power Apps, where flights are assigned to Microsoft Teams channels.
    When a user selects a flight to monitor, or when the system assigns the user to a flight, the system queues a Graph API call in an Azure Storage Account queue for further processing.
    Azure Functions runs the Graph API calls based on the incoming messages in the storage queue, sending notifications to Teams, and also streams all events to an Azure Event Hubs for further analytics.
    The airline's notification system is managed by a custom bot messaging service that employs Azure Bot Service.
    Custom bots send flight updates to users in Teams.
    An Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs, ultimately generating insightful reports with Power BI.

","{""entities"": [[""airline system"", ""system"", ""communicates with a custom API hosted in Azure API Management""], [""custom API"", ""component"", ""communicates with a custom API hosted in Azure API Management""], [""Azure API Management"", ""system"", ""communicates with a custom API hosted in Azure API Management""], [""custom API coordinator"", ""system"", ""receives notifications and handles incoming messages from the airline system""], [""Power Apps"", ""system"", ""where flights are assigned to Microsoft Teams channels""], [""Microsoft Teams channels"", ""system"", ""where flights are assigned to Microsoft Teams channels""], [""Storage Account queue"", ""system"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing.""], [""Graph API call"", ""system"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing.""], [""Azure Functions"", ""system"", ""runs the Graph API calls based on the incoming messages in the storage queue""], [""Azure Event Hubs"", ""system"", ""Azure Event Hubs for further analytics""], [""notification system"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""custom bot messaging service"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""Azure Bot Service"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""Users"", ""person"", ""selects a flight to monitor, or when the system assigns the user to a flight""], [""Azure Data Lake storage"", ""system"", ""offers long-term retention and micro-batch processing of events from Event Hubs""], [""Power BI"", ""system"", ""generating insightful reports""]], ""relationships"": [[""Azure API Management"", ""contains"", ""custom API"", ""custom API hosted in Azure API Management""], [""airline system"", ""calls"", ""custom API"", ""communicates with a custom API""], [""custom API coordinator"", ""is-called-from"", ""airline system"", ""receives notifications and handles incoming messages from the airline system""], [""Power Apps"", ""calls"", ""Microsoft Teams channels"", ""Power Apps, where flights are assigned to Microsoft Teams channels""], [""airline system"", ""calls"", ""Graph API call"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing""], [""Azure Functions"", ""calls"", ""Graph API call"", ""runs the Graph API calls based on the incoming messages in the storage queue""], [""Azure Functions"", ""calls"", ""Storage Account queue"", ""based on the incoming messages in the storage queue""], [""Azure Functions"", ""calls"", ""Microsoft Teams channels"", ""sending notifications to Teams""], [""Azure Functions"", ""calls"", ""Azure Event Hubs"", ""also streams all events to an Azure Event Hubs for further analytics""], [""notification system"", ""is-called-from"", ""custom bot messaging service"", ""managed by a custom bot messaging service""], [""custom bot messaging service"", ""calls"", ""Azure Bot Service"", ""custom bot messaging service that employs Azure Bot Service""], [""custom bot messaging service"", ""calls"", ""Microsoft Teams channels"", ""Custom bots send flight updates to users in Teams.""], [""Microsoft Teams channels"", ""calls"", ""Users"", ""Custom bots send flight updates to users in Teams.""], [""Azure Data Lake storage"", ""is-called-from"", ""Azure Event Hubs"", ""Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs""], [""Azure Data Lake storage"", ""calls"", ""Power BI"", ""Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs, ultimately generating insightful reports with Power BI""]]}","Here's the JSON response based on the provided text:

```json
{
  ""entities"": [
    [""Airline System"", ""system""],
    [""Azure API Management"", ""system""],
    [""Custom API Coordinator"", ""component""],
    [""Power Apps"", ""system""],
    [""Microsoft Teams"", ""system""],
    [""Azure Storage Account Queue"", ""system""],
    [""Azure Functions"", ""system""],
    [""Azure Event Hubs"", ""system""],
    [""Custom Bot Messaging Service"", ""component""],
    [""Azure Bot Service"", ""system""],
    [""Azure Data Lake storage"", ""system""],
    [""Power BI"", ""system""]
  ],
  ""relationships"": [
    [""Airline System"", ""calls"", ""Azure API Management"", ""The airline system communicates with a custom API hosted in Azure API Management.""],
    [""Custom API Coordinator"", ""part-of"", ""Azure API Management"", ""A custom API coordinator receives notifications...""],
    [""Custom API Coordinator"", ""calls"", ""Power Apps"", ""...and sends them to Power Apps""],
    [""Microsoft Teams"", ""contains"", ""Flight channels"", ""Flights are assigned to Microsoft Teams channels.""],
    [""System/Unknown Entity"", ""queues"", ""Azure Storage Account Queue"", ""The system queues a Graph API call...""],
    [""Azure Functions"", ""runs"", ""Azure Storage Account Queue"", ""...Azure Functions runs the Graph API calls based on the incoming messages""],
    [""Azure Functions"", ""sends"", ""Microsoft Teams"", ""sending notifications to Teams""],
    [""Azure Functions"", ""streams"", ""Azure Event Hubs"", ""also streams all events to an Azure Event Hubs...""],
    [""Custom Bot Messaging Service"", ""part-of"", ""Azure Bot Service"", ""The airline's notification system is managed by a custom bot messaging service that employs Azure Bot Service.""],
    [""Azure Data Lake storage"", ""receives"", ""Azure Event Hubs"", ""...ultimately generating insightful reports with Power BI.""],
    [""Power BI"", ""generates"", ""Reports"", ""...generating insightful reports""]
  ]
}
```","Here's the JSON response based on the provided text:

```json
{
  ""entities"": [
    [""Airline System"", ""system""],
    [""Azure API Management"", ""system""],
    [""Custom API Coordinator"", ""component""],
    [""Power Apps"", ""system""],
    [""Microsoft Teams"", ""system""],
    [""Azure Storage Account Queue"", ""system""],
    [""Azure Functions"", ""system""],
    [""Azure Event Hubs"", ""system""],
    [""Custom Bot Messaging Service"", ""component""],
    [""Azure Bot Service"", ""system""],
    [""Azure Data Lake storage"", ""system""],
    [""Power BI"", ""system""]
  ],
  ""relationships"": [
    [""Airline System"", ""calls"", ""Azure API Management"", ""The airline system communicates with a custom API hosted in Azure API Management.""],
    [""Custom API Coordinator"", ""part-of"", ""Azure API Management"", ""A custom API coordinator receives notifications...""],
    [""Custom API Coordinator"", ""calls"", ""Power Apps"", ""...and sends them to Power Apps""],
    [""Microsoft Teams"", ""contains"", ""Flight channels"", ""Flights are assigned to Microsoft Teams channels.""],
    [""System/Unknown Entity"", ""queues"", ""Azure Storage Account Queue"", ""The system queues a Graph API call...""],
    [""Azure Functions"", ""runs"", ""Azure Storage Account Queue"", ""...Azure Functions runs the Graph API calls based on the incoming messages""],
    [""Azure Functions"", ""sends"", ""Microsoft Teams"", ""sending notifications to Teams""],
    [""Azure Functions"", ""streams"", ""Azure Event Hubs"", ""also streams all events to an Azure Event Hubs...""],
    [""Custom Bot Messaging Service"", ""part-of"", ""Azure Bot Service"", ""The airline's notification system is managed by a custom bot messaging service that employs Azure Bot Service.""],
    [""Azure Data Lake storage"", ""receives"", ""Azure Event Hubs"", ""...ultimately generating insightful reports with Power BI.""],
    [""Power BI"", ""generates"", ""Reports"", ""...generating insightful reports""]
  ]
}
```",7.164700338995317
18,mistral-nemo,../IMAGES NEW/Azure/12 Azure Network Microservices original.txt,"
    Outside services and clients make a POST request to APIM, with a data body that includes patient information.
    APIM calls the CreatePatient function in the Patient API with the given patient information.
    The CreatePatient function in Patient API calls the CreateAuditRecord function in the Audit API function app to create an audit record.
    The Audit API CreateAuditRecord function creates the audit record in Azure Cosmos DB, and returns a success response to the Patient API CreatePatient function.
    The CreatePatient function creates the patient document in Azure Cosmos DB, and returns a success response to APIM.
    The outside services and clients receive the success response from APIM.

","{""entities"": [[""Outside services"", ""system"", ""Outside services and clients make a POST request to APIM""], [""clients"", ""system"", ""Outside services and clients make a POST request to APIM""], [""APIM"", ""system"", ""Outside services and clients make a POST request to APIM""], [""Patient API"", ""system"", "" The CreatePatient function in Patient API calls the CreateAuditRecord function in the Audit API function app""], [""CreatePatient function"", ""component"", "" The CreatePatient function in Patient API calls the CreateAuditRecord function in the Audit API function app""], [""Audit API function app"", ""system"", ""The CreatePatient function in Patient API calls the CreateAuditRecord function in the Audit API function app""], [""CreateAuditRecord function"", ""component"", ""CreatePatient function in Patient API calls the CreateAuditRecord function""], [""Azure Cosmos DB"", ""system"", ""The Audit API CreateAuditRecord function creates the audit record in Azure Cosmos DB, and returns a success response to the Patient API CreatePatient function""]], ""relationships"": [[""CreatePatient function"", ""part-of"", ""Patient API"", ""Reason""], [""Outside services"", ""calls"", ""APIM"", ""utside services and clients make a POST request to APIM""], [""clients"", ""calls"", ""APIM"", ""outside services and clients make a POST request to APIM""], [""APIM"", ""calls"", ""CreatePatient function"", ""APIM calls the CreatePatient function in the Patient API""], [""CreateAuditRecord function"", ""part-of"", ""Audit API function app"", ""Reason""], [""CreatePatient function"", ""calls"", ""CreateAuditRecord function"", ""CreatePatient function in Patient API calls the CreateAuditRecord function in the Audit API function app""], [""CreateAuditRecord function"", ""calls"", ""Azure Cosmos DB"", ""Audit API CreateAuditRecord function creates the audit record in Azure Cosmos DB""], [""CreateAuditRecord function"", ""calls"", ""CreatePatient function"", ""returns a success response to the Patient API CreatePatient function.""], [""CreatePatient function"", ""calls"", ""Azure Cosmos DB"", ""The CreatePatient function creates the patient document in Azure Cosmos DB""], [""CreatePatient function"", ""is-called-from"", ""APIM"", ""The CreatePatient function returns a success response to APIM""]]}","{
  ""entities"": [
    [""APIM"", ""system""],
    [""Patient API"", ""system""],
    [""CreatePatient"", ""component""],
    [""Audit API"", ""system""],
    [""CreateAuditRecord"", ""component""],
    [""Azure Cosmos DB"", ""system""],
    [""outside services and clients"", ""person""]
  ],
  ""relationships"": [
    [""outside services and clients"", ""calls"", ""APIM""],
    [""APIM"", ""calls"", ""Patient API""],
    [""Patient API"", ""contains"", ""CreatePatient""],
    [""CreatePatient"", ""calls"", ""Audit API""],
    [""Audit API"", ""contains"", ""CreateAuditRecord""],
    [""CreateAuditRecord"", ""called-from"", ""CreatePatient""],
    [""CreateAuditRecord"", ""contains"", ""Azure Cosmos DB""],
    [""CreatePatient"", ""contains"", ""Azure Cosmos DB""],
    [""APIM"", ""calls"", ""outside services and clients""]
  ]
}","{
  ""entities"": [
    [""APIM"", ""system""],
    [""Patient API"", ""system""],
    [""CreatePatient"", ""component""],
    [""Audit API"", ""system""],
    [""CreateAuditRecord"", ""component""],
    [""Azure Cosmos DB"", ""system""],
    [""outside services and clients"", ""person""]
  ],
  ""relationships"": [
    [""outside services and clients"", ""calls"", ""APIM""],
    [""APIM"", ""calls"", ""Patient API""],
    [""Patient API"", ""contains"", ""CreatePatient""],
    [""CreatePatient"", ""calls"", ""Audit API""],
    [""Audit API"", ""contains"", ""CreateAuditRecord""],
    [""CreateAuditRecord"", ""called-from"", ""CreatePatient""],
    [""CreateAuditRecord"", ""contains"", ""Azure Cosmos DB""],
    [""CreatePatient"", ""contains"", ""Azure Cosmos DB""],
    [""APIM"", ""calls"", ""outside services and clients""]
  ]
}",3.65552421999746
19,mistral-nemo,../IMAGES NEW/Azure/13 Azure Secure Research.txt,"
    Data owners upload datasets into a public blob storage account. The data is encrypted by using Microsoft-managed keys.

    Azure Data Factory uses a trigger that starts copying of the uploaded dataset to a specific location (import path) on another storage account with security controls. The storage account can only be reached through a private endpoint. Also, it's accessed by a service principal with limited permissions. Data Factory deletes the original copy making the dataset immutable.

    Researchers access the secure environment through a streaming application using Azure Virtual Desktop as a privileged jump box.

    The dataset in the secure storage account is presented to the data science VMs provisioned in a secure network environment for research work. Much of the data preparation is done on those VMs.

    The secure environment has Azure Machine Learning compute that can access the dataset through a private endpoint for users for Azure Machine Learning capabilities, such as to train, deploy, automate, and manage machine learning models. At this point, models are created that meet regulatory guidelines. All model data is de-identified by removing personal information.

    Models or de-identified data is saved to a separate location on the secure storage (export path). When new data is added to the export path, a logic app is triggered. In this architecture, the logic app is outside the secure environment because no data is sent to the logic app. Its only function is to send notification and start the manual approval process.

    The app starts an approval process requesting a review of data that is queued to be exported. The manual reviewers ensure that sensitive data isn't exported. After the review process, the data is either approved or denied.

    Note

    If an approval step is not required on exfiltration, the logic app step could be omitted.

    If the de-identified data is approved, it's sent to the Data Factory instance.

    Data Factory moves the data to the public storage account in a separate container to allow external researchers to have access to their exported data and models. Alternately, you can provision another storage account in a lower security environment.

","{""entities"": [[""datasets"", ""component"", ""Data owners upload datasets into a public blob storage account""], [""public blob storage account"", ""system"", ""Data owners upload datasets into a public blob storage account""], [""Azure Data Factory"", ""system"", ""Azure Data Factory uses a trigger that starts copying of the uploaded dataset to a specific location""], [""storage account"", ""system"", ""Azure Data Factory uses a trigger that starts copying of the uploaded dataset to a specific location (import path) on another storage account with security controls""], [""copied dataset"", ""system"", ""Azure Data Factory uses a trigger that starts copying of the uploaded dataset to a specific location (import path) on another storage account with security controls""], [""private endpoint"", ""component"", ""The storage account can only be reached through a private endpoint.""], [""service principal"", ""component"", ""Also, it's accessed by a service principal with limited permissions.""], [""streaming application"", ""component"", ""access the secure environment through a streaming application""], [""Azure Virtual Desktop"", ""component"", ""Azure Virtual Desktop as a privileged jump box""], [""data science VMs"", ""component"", ""data science VMs provisioned in a secure network environment""], [""Azure Machine Learning compute"", ""component"", ""The secure environment has Azure Machine Learning compute that can access the dataset""], [""secure network environment"", ""system"", ""data science VMs provisioned in a secure network environment""], [""machine learning models"", ""component"", ""At this point, models are created that meet regulatory guidelines""], [""de-identified data"", ""component"", ""Models or de-identified data is saved to a separate location on the secure storage (export path)""], [""logic app"", ""component"", ""When new data is added to the export path, a logic app is triggered""], [""separate container"", ""component"", ""Data Factory moves the data to the public storage account in a separate container""], [""moved data"", ""component"", ""Data Factory moves the data to the public storage account in a separate container""], [""Data owners"", ""person"", ""Data owners upload datasets into a public blob storage account""], [""Researchers"", ""person"", ""Researchers access the secure environment through a streaming application using Azure Virtual Desktop as a privileged jump box""], [""manual reviewers"", ""person"", ""The manual reviewers ensure that sensitive data isn't exported.""], [""Users"", ""person"", ""The secure environment has Azure Machine Learning compute that can access the dataset""]], ""relationships"": [[""datasets"", ""part-of"", ""public blob storage account"", ""Data owners upload datasets into a public blob storage account""], [""Data owners"", ""calls"", ""datasets"", ""Data owners upload datasets into a public blob storage account""], [""Azure Data Factory"", ""calls"", ""datasets"", ""Azure Data Factory uses a trigger that starts copying of the uploaded dataset""], [""storage account"", ""contains"", ""copied dataset"", ""opying of the uploaded dataset to a specific location (import path) on another storage account with security controls""], [""Azure Data Factory"", ""calls"", ""copied dataset"", ""Azure Data Factory uses a trigger that starts copying of the uploaded dataset to a specific location""], [""private endpoint"", ""calls"", ""storage account"", ""The storage account can only be reached through a private endpoint""], [""storage account"", ""is-called-from"", ""service principal"", ""Also, it's accessed by a service principal with limited permissions""], [""Researchers"", ""calls"", ""Azure Virtual Desktop"", "" Researchers access the secure environment through a streaming application""], [""Azure Virtual Desktop"", ""calls"", ""streaming application"", ""through a streaming application using Azure Virtual Desktop""], [""streaming application"", ""calls"", ""storage account"", ""Researchers access the secure environment through a streaming application using Azure Virtual Desktop as a privileged jump box""], [""data science VMs"", ""part-of"", ""secure network environment"", ""The dataset in the secure storage account is presented to the data science VMs""], [""data science VMs"", ""calls"", ""copied dataset"", "" The dataset in the secure storage account is presented to the data science VMs""], [""secure network environment"", ""contains"", ""Azure Machine Learning compute"", ""The secure environment has Azure Machine Learning compute that can access the dataset""], [""Azure Machine Learning compute"", ""calls"", ""Azure Machine Learning compute"", ""The secure environment has Azure Machine Learning compute that can access the dataset""], [""machine learning models"", ""part-of"", ""storage account"", ""Models or de-identified data is saved to a separate location on the secure storage (export path)""], [""machine learning models"", ""calls"", ""logic app"", ""When new data is added to the export path, a logic app is triggered""], [""logic app"", ""calls"", ""manual reviewers"", ""The app starts an approval process requesting a review of data that is queued to be exported.""], [""public blob storage account"", ""contains"", ""separate container"", ""Data Factory moves the data to the public storage account in a separate container""], [""Azure Data Factory"", ""calls"", ""de-identified data"", ""Data Factory moves the data to the public storage account in a separate container to allow external researchers to have access to their exported data and models""], [""separate container"", ""contains"", ""moved data"", ""Data Factory moves the data to the public storage account in a separate container""], [""Azure Data Factory"", ""calls"", ""moved data"", ""Data Factory moves the data to the public storage account in a separate container to allow external researchers to have access to their exported data and models""], [""Users"", ""calls"", ""Azure Machine Learning compute"", ""The secure environment has Azure Machine Learning compute that can access the dataset""]]}","Here's the JSON output based on the provided text:

```json
{
  ""entities"": [
    [""Data Owners"", ""person""],
    [""Blob Storage Account (Public)"", ""system""],
    [""Microsoft-Managed Keys"", ""component""],
    [""Azure Data Factory"", ""system""],
    [""Trigger"", ""component""],
    [""Storage Account (Secure)"", ""system""],
    [""Private Endpoint"", ""component""],
    [""Service Principal"", ""person""],
    [""Import Path"", ""component""],
    [""Researchers"", ""person""],
    [""Streaming Application"", ""component""],
    [""Azure Virtual Desktop"", ""system""],
    [""Data Science VMs"", ""system""],
    [""Secure Network Environment"", ""system""],
    [""Azure Machine Learning Compute"", ""system""],
    [""Models"", ""component""],
    [""De-identified Data"", ""component""],
    [""Logic App"", ""system""],
    [""Notification"", ""component""],
    [""Approval Process"", ""component""],
    [""Data Reviewers"", ""person""],
    [""Public Storage Account (External)"", ""system""]
  ],
  ""relationships"": [
    [""Blob Storage Account (Public)"", ""contains"", ""Microsoft-Managed Keys""],
    [""Azure Data Factory"", ""part-of"", ""Trigger""],
    [""Storage Account (Secure)"", ""contains"", ""Private Endpoint""],
    [""Storage Account (Secure)"", ""contains"", ""Import Path""],
    [""Researchers"", ""calls"", ""Streaming Application""],
    [""Streaming Application"", ""called-from"", ""Azure Virtual Desktop""],
    [""Data Science VMs"", ""part-of"", ""Secure Network Environment""],
    [""Azure Machine Learning Compute"", ""accesses"", ""Models""],
    [""Azure Machine Learning Compute"", ""accesses"", ""De-identified Data""],
    [""Logic App"", ""contains"", ""Notification""],
    [""Logic App"", ""contains"", ""Approval Process""],
    [""Data Reviewers"", ""calls"", ""Approval Process""]
  ]
}
```","Here's the JSON output based on the provided text:

```json
{
  ""entities"": [
    [""Data Owners"", ""person""],
    [""Blob Storage Account (Public)"", ""system""],
    [""Microsoft-Managed Keys"", ""component""],
    [""Azure Data Factory"", ""system""],
    [""Trigger"", ""component""],
    [""Storage Account (Secure)"", ""system""],
    [""Private Endpoint"", ""component""],
    [""Service Principal"", ""person""],
    [""Import Path"", ""component""],
    [""Researchers"", ""person""],
    [""Streaming Application"", ""component""],
    [""Azure Virtual Desktop"", ""system""],
    [""Data Science VMs"", ""system""],
    [""Secure Network Environment"", ""system""],
    [""Azure Machine Learning Compute"", ""system""],
    [""Models"", ""component""],
    [""De-identified Data"", ""component""],
    [""Logic App"", ""system""],
    [""Notification"", ""component""],
    [""Approval Process"", ""component""],
    [""Data Reviewers"", ""person""],
    [""Public Storage Account (External)"", ""system""]
  ],
  ""relationships"": [
    [""Blob Storage Account (Public)"", ""contains"", ""Microsoft-Managed Keys""],
    [""Azure Data Factory"", ""part-of"", ""Trigger""],
    [""Storage Account (Secure)"", ""contains"", ""Private Endpoint""],
    [""Storage Account (Secure)"", ""contains"", ""Import Path""],
    [""Researchers"", ""calls"", ""Streaming Application""],
    [""Streaming Application"", ""called-from"", ""Azure Virtual Desktop""],
    [""Data Science VMs"", ""part-of"", ""Secure Network Environment""],
    [""Azure Machine Learning Compute"", ""accesses"", ""Models""],
    [""Azure Machine Learning Compute"", ""accesses"", ""De-identified Data""],
    [""Logic App"", ""contains"", ""Notification""],
    [""Logic App"", ""contains"", ""Approval Process""],
    [""Data Reviewers"", ""calls"", ""Approval Process""]
  ]
}
```",6.93584517101408
20,mistral-nemo,../IMAGES NEW/Azure/11 Mainframe original.txt,"
    A Connect agent component captures change logs by using mainframe or midrange native utilities and caches the logs in temporary storage.
    For mainframe systems, a publisher component on the mainframe manages data migration.
    For midrange systems, in place of the publisher, a listener component manages data migration. It's located on either a Windows or Linux machine.
    The publisher or listener moves the data from on-premises to Azure via an enhanced-security connection. The publisher or listener handles the commit and rollback of transactions for each unit of work, maintaining the integrity of data.
    The Connect Replicator Engine captures the data from the publisher or listener and applies it to the target. It distributes data for parallel processing.
    The target is a database that receives the changes via ODBC or ingests the changes via Azure Event Hubs.
    The changed data is consumed by Azure Databricks and applied to Azure data platform services.
    The Connect Controller Daemon authenticates the request and establishes the socket connection between the publisher or listener and the Replicator Engine.

","{""entities"": [[""Connect agent"", ""component"", ""captures change logs""], [""temporary storage"", ""component"", ""caches the logs in temporary storage""], [""mainframe native utilities"", ""system"", ""captures change logs by using mainframe or midrange native utilities""], [""midrange native utilities"", ""system"", ""captures change logs by using mainframe or midrange native utilities""], [""mainframe systems"", ""system"", ""For mainframe systems, a publisher component on the mainframe manages data migration.""], [""midrange systems"", ""system"", ""For midrange systems, in place of the publisher, a listener component manages data migration.""], [""publisher"", ""component"", ""For mainframe systems, a publisher component on the mainframe manages data migration.""], [""listener"", ""component"", ""For midrange systems, in place of the publisher, a listener component manages data migration.""], [""Connect Replicator Engine"", ""system"", ""captures the data from the publisher or listener and applies it to the target.""], [""on-premises"", ""system"", ""The publisher or listener moves the data from on-premises to Azure""], [""Azure"", ""system"", ""The publisher or listener moves the data from on-premises to Azure""], [""Connect Replicator Engine"", ""system"", ""The Connect Replicator Engine captures the data from the publisher or listener""], [""target"", ""system"", ""applies it to the target""], [""database"", ""system"", ""target is a database""], [""ODBC"", ""component"", ""The target is a database that receives the changes via ODBC or ingests the changes via Azure Event Hubs""], [""Azure Event Hubs"", ""component"", ""The target is a database that receives the changes via ODBC or ingests the changes via Azure Event Hubs""], [""Azure Databricks"", ""component"", ""the changed data is consumed by Azure Databricks and applied to Azure data platform services.""], [""Azure data platform services"", ""component"", ""the changed data is consumed by Azure Databricks and applied to Azure data platform services.""], [""Connect Controller Daemon"", ""component"", ""authenticates the request and establishes the socket connection between the publisher or listener and the Replicator Engine.""]], ""relationships"": [[""Connect agent"", ""calls"", ""mainframe native utilities"", ""captures change logs by using mainframe or midrange native utilities""], [""Connect agent"", ""calls"", ""midrange native utilities"", ""captures change logs by using mainframe or midrange native utilities""], [""Connect agent"", ""calls"", ""temporary storage"", ""captures change logs by using mainframe or midrange native utilities""], [""mainframe systems"", ""contains"", ""mainframe native utilities"", ""F""], [""midrange systems"", ""contains"", ""midrange native utilities"", """"], [""mainframe systems"", ""contains"", ""publisher"", ""For mainframe systems, a publisher component on the mainframe manages data migration.""], [""midrange systems"", ""contains"", ""listener"", ""For midrange systems, in place of the publisher, a listener component manages data migration.""], [""publisher"", ""calls"", ""on-premises"", ""The publisher or listener moves the data from on-premises to Azure""], [""publisher"", ""calls"", ""Azure"", ""The publisher or listener moves the data from on-premises to Azure""], [""listener"", ""calls"", ""on-premises"", ""The publisher or listener moves the data from on-premises to Azure""], [""listener"", ""calls"", ""Azure"", ""The publisher or listener moves the data from on-premises to Azure""], [""Connect Replicator Engine"", ""calls"", ""publisher"", ""captures the data from the publisher or listener and applies it to the target.""], [""Connect Replicator Engine"", ""calls"", ""listener"", ""captures the data from the publisher or listener and applies it to the target.""], [""Connect Replicator Engine"", ""calls"", ""target"", ""captures the data from the publisher or listener and applies it to the target.""], [""target"", ""contains"", ""database"", ""target is a database""], [""database"", ""is-called-from"", ""ODBC"", ""database that receives the changes via ODBC""], [""database"", ""is-called-from"", ""Azure Event Hubs"", ""ingests the changes via Azure Event Hubs""], [""database"", ""is-called-from"", ""Azure Databricks"", ""the changed data is consumed by Azure Databricks""], [""Azure Databricks"", ""calls"", ""Azure data platform services"", ""consumed by Azure Databricks and applied to Azure data platform services.""], [""Connect Controller Daemon"", ""is-called-from"", ""publisher"", ""establishes the socket connection between the publisher or listener and the Replicator Engine..""], [""Connect Controller Daemon"", ""is-called-from"", ""listener"", ""establishes the socket connection between the publisher or listener and the Replicator Engine..""], [""Connect Controller Daemon"", ""calls"", ""Connect Replicator Engine"", ""establishes the socket connection between the publisher or listener and the Replicator Engine..""]]}","{
  ""entities"": [
    [""Connect Agent"", ""component"", ""Captures change logs from mainframe or midrange systems""],
    [""Mainframe Native Utilities"", ""system"", ""Provides change logs for mainframe systems""],
    [""Midrange Systems"", ""system"", ""Systems where logs are captured by Connect Agent""],
    [""Publisher Component"", ""component"", ""Manages data migration for mainframe systems""],
    [""Listener Component"", ""component"", ""Manages data migration for midrange systems, located on Windows or Linux machine""],
    [""Enhanced-Security Connection"", ""system"", ""Connection used to move data from on-premises to Azure""],
    [""Connect Replicator Engine"", ""component"", ""Captures data from publisher or listener and applies it to target""],
    [""Target Database"", ""component"", ""Receives changes via ODBC or ingests changes via Azure Event Hubs""],
    [""Azure Databricks"", ""system"", ""Consumes changed data and applies it to Azure Data Platform Services""],
    [""Connect Controller Daemon"", ""component"", ""Authenticates requests and establishes socket connection""]
  ],
  ""relationships"": [
    [""Connect Agent"", ""calls"", ""Mainframe Native Utilities"", ""Captures change logs from Mainframe Native Utilities""],
    [""Connect Agent"", ""calls"", ""Midrange Systems"", ""Captures change logs from Midrange Systems""],
    [""Publisher Component"", ""part-of"", ""Enhanced-Security Connection"", ""Moves data through Enhanced-Security Connection""],
    [""Listener Component"", ""part-of"", ""Enhanced-Security Connection"", ""Moves data through Enhanced-Security Connection""],
    [""Connect Replicator Engine"", ""called-from"", ""Publisher Component"", ""Captures data from Publisher Component""],
    [""Connect Replicator Engine"", ""called-from"", ""Listener Component"", ""Captures data from Listener Component""],
    [""Target Database"", ""part-of"", ""Azure Databricks"", ""Receives changes consumed by Azure Databricks""],
    [""Connect Controller Daemon"", ""contains"", ""Connect Agent"", ""Authenticates requests for Connect Agent""],
    [""Connect Controller Daemon"", ""contains"", ""Connect Replicator Engine"", ""Establishes socket connection for Connect Replicator Engine""]
  ]
}","{
  ""entities"": [
    [""Connect Agent"", ""component"", ""Captures change logs from mainframe or midrange systems""],
    [""Mainframe Native Utilities"", ""system"", ""Provides change logs for mainframe systems""],
    [""Midrange Systems"", ""system"", ""Systems where logs are captured by Connect Agent""],
    [""Publisher Component"", ""component"", ""Manages data migration for mainframe systems""],
    [""Listener Component"", ""component"", ""Manages data migration for midrange systems, located on Windows or Linux machine""],
    [""Enhanced-Security Connection"", ""system"", ""Connection used to move data from on-premises to Azure""],
    [""Connect Replicator Engine"", ""component"", ""Captures data from publisher or listener and applies it to target""],
    [""Target Database"", ""component"", ""Receives changes via ODBC or ingests changes via Azure Event Hubs""],
    [""Azure Databricks"", ""system"", ""Consumes changed data and applies it to Azure Data Platform Services""],
    [""Connect Controller Daemon"", ""component"", ""Authenticates requests and establishes socket connection""]
  ],
  ""relationships"": [
    [""Connect Agent"", ""calls"", ""Mainframe Native Utilities"", ""Captures change logs from Mainframe Native Utilities""],
    [""Connect Agent"", ""calls"", ""Midrange Systems"", ""Captures change logs from Midrange Systems""],
    [""Publisher Component"", ""part-of"", ""Enhanced-Security Connection"", ""Moves data through Enhanced-Security Connection""],
    [""Listener Component"", ""part-of"", ""Enhanced-Security Connection"", ""Moves data through Enhanced-Security Connection""],
    [""Connect Replicator Engine"", ""called-from"", ""Publisher Component"", ""Captures data from Publisher Component""],
    [""Connect Replicator Engine"", ""called-from"", ""Listener Component"", ""Captures data from Listener Component""],
    [""Target Database"", ""part-of"", ""Azure Databricks"", ""Receives changes consumed by Azure Databricks""],
    [""Connect Controller Daemon"", ""contains"", ""Connect Agent"", ""Authenticates requests for Connect Agent""],
    [""Connect Controller Daemon"", ""contains"", ""Connect Replicator Engine"", ""Establishes socket connection for Connect Replicator Engine""]
  ]
}",7.818675592978252
21,mistral-nemo,../IMAGES NEW/Azure/07 Azure internal APIs original.txt,"
The data flows as follows:

    Developers check in code to a GitHub repository that's connected to a CI/CD pipeline agent that's installed on an Azure VM.
    The agent pushes the build to the API application that's hosted on ILB ASE.
    Azure API Management consumes the preceding APIs via HOST headers that are specified in API Management policy.
    API Management uses the App Service Environment's DNS name for all the APIs.
    Application Gateway exposes API Management's developer and API portal.
    Azure Private DNS is used to route the traffic internally between ASE, API Management, and Application Gateway.
    External users utilize the exposed developer portal to consume the APIs via Application Gateway's public IP.

","{""entities"": [[""GitHub repository"", ""system"", """"], [""Developers"", ""person"", """"], [""External users"", ""person"", """"], [""CI/CD pipeline agent"", ""system"", """"], [""Azure VM"", ""system"", """"], [""ILB ASE"", ""system"", """"], [""API application"", ""component"", """"], [""Azure API Management"", ""system"", ""consumes the preceding APIs via HOST headers""], [""App Service Environment"", ""component"", """"], [""Application Gateway"", ""component"", ""exposes API Management's developer and API portal""], [""Developer portal"", ""component"", ""API Management's developer and API portal""], [""API portal"", ""component"", ""API Management's developer and API portal""], [""Application Gateway"", ""component"", ""exposes API Management's developer and API portal""], [""Azure Private DNS"", ""component"", ""used to route the traffic internally between ASE, API Management, and Application Gateway""]], ""relationships"": [[""Azure VM"", ""contains"", ""CI/CD pipeline agent"", ""installed on an Azure VM""], [""API application"", ""part-of"", ""ILB ASE"", ""API application that's hosted on ILB ASE""], [""GitHub repository"", ""calls"", ""CI/CD pipeline agent"", ""GitHub repository that's connected to a CI/CD pipeline agent""], [""CI/CD pipeline agent"", ""calls"", ""API application"", ""agent pushes the build to the API application""], [""Azure API Management"", ""calls"", ""App Service Environment"", ""uses the App Service Environment's DNS name for all the APIs""], [""External users"", ""calls"", ""Application Gateway"", """"], [""Application Gateway"", ""calls"", ""API application"", ""to consume the APIs via Application Gateway's public IP""], [""Azure API Management"", ""contains"", ""Developer portal"", ""API Management's developer and API portal""], [""Azure API Management"", ""contains"", ""API portal"", ""API Management's developer and API portal""], [""Application Gateway"", ""calls"", ""API portal"", ""exposes API Management's developer and API portal.""], [""Application Gateway"", ""calls"", ""Developer portal"", ""exposes API Management's developer and API portal.""], [""Azure Private DNS"", ""calls"", ""Azure API Management"", ""route the traffic internally between ASE, API Management, and Application Gateway""], [""Azure Private DNS"", ""calls"", ""Application Gateway"", ""route the traffic internally between ASE, API Management, and Application Gateway""]]}","{
  ""entities"": [
    [""Developers"", ""person""],
    [""GitHub repository"", ""system""],
    [""CI/CD pipeline agent"", ""component""],
    [""Azure VM"", ""system""],
    [""API application"", ""system""],
    [""ILB ASE"", ""system""],
    [""Azure API Management"", ""system""],
    [""App Service Environment"", ""system""],
    [""Application Gateway"", ""system""],
    [""External users"", ""person""]
  ],
  ""relationships"": [
    [""Developers"", ""checks in code to"", ""GitHub repository""],
    [""GitHub repository"", ""is connected to"", ""CI/CD pipeline agent""],
    [""CI/CD pipeline agent"", ""part-of"", ""Azure VM""],
    [""CI/CD pipeline agent"", ""pushes the build to"", ""API application""],
    [""API application"", ""hosted on"", ""ILB ASE""],
    [""Azure API Management"", ""consumes APIs via HOST headers that are specified in policy from"", ""API application""],
    [""Azure API Management"", ""uses DNS name for APIs of"", ""App Service Environment""],
    [""Application Gateway"", ""exposes developer and API portal of"", ""Azure API Management""],
    [""External users"", ""utilize exposed developer portal via Application Gateway's public IP""]
  ]
}","{
  ""entities"": [
    [""Developers"", ""person""],
    [""GitHub repository"", ""system""],
    [""CI/CD pipeline agent"", ""component""],
    [""Azure VM"", ""system""],
    [""API application"", ""system""],
    [""ILB ASE"", ""system""],
    [""Azure API Management"", ""system""],
    [""App Service Environment"", ""system""],
    [""Application Gateway"", ""system""],
    [""External users"", ""person""]
  ],
  ""relationships"": [
    [""Developers"", ""checks in code to"", ""GitHub repository""],
    [""GitHub repository"", ""is connected to"", ""CI/CD pipeline agent""],
    [""CI/CD pipeline agent"", ""part-of"", ""Azure VM""],
    [""CI/CD pipeline agent"", ""pushes the build to"", ""API application""],
    [""API application"", ""hosted on"", ""ILB ASE""],
    [""Azure API Management"", ""consumes APIs via HOST headers that are specified in policy from"", ""API application""],
    [""Azure API Management"", ""uses DNS name for APIs of"", ""App Service Environment""],
    [""Application Gateway"", ""exposes developer and API portal of"", ""Azure API Management""],
    [""External users"", ""utilize exposed developer portal via Application Gateway's public IP""]
  ]
}",4.604525835980894
22,mistral-nemo,../IMAGES NEW/Azure/16 Azure automate-pdf-forms.txt,"
    A designated Outlook email account receives PDF files as attachments. The arrival of an email triggers a logic app to process the email. The logic app is built by using the capabilities of Azure Logic Apps.
    The logic app uploads the PDF files to a container in Azure Data Lake Storage.
    You can also manually or programmatically upload PDF files to the same PDF container.
    The arrival of a PDF file in the PDF container triggers another logic app to process the PDF forms that are in the PDF file.
    The logic app sends the location of the PDF file to a function app for processing. The function app is built by using the capabilities of Azure Functions.
    The function app receives the location of the file and takes these actions:
        It splits the file into single pages if the file has multiple pages. Each page contains one independent form. Split files are saved to a second container in Data Lake Storage.
        It uses HTTPS POST, an Azure REST API, to send the location of the single-page PDF file to AI Document Intelligence for processing. When Azure AI Document Intelligence completes its processing, it sends a response back to the function app, which places the information into a data structure.
        It creates a JSON data file that contains the response data and stores the file to a third container in Data Lake Storage.
    The forms processing logic app receives the processed response data.
    The forms processing logic app sends the processed data to Azure Cosmos DB, which saves the data in a database and in collections.
    Power BI obtains the data from Azure Cosmos DB and provides insights and dashboards.
    You can implement further processing as needed on the data that's in Azure Cosmos DB.

","{""entities"": [[""designated Outlook email account"", ""component"", ""A designated Outlook email account receives PDF files as attachments""], [""logic app"", ""component"", ""The arrival of an email triggers a logic app to process the email.""], [""Azure Logic Apps"", ""system"", ""The logic app is built by using the capabilities of Azure Logic Apps.""], [""Container"", ""component"", ""The logic app uploads the PDF files to a container in Azure Data Lake Storage""], [""Azure Data Lake Storage"", ""system"", ""The logic app uploads the PDF files to a container in Azure Data Lake Storage""], [""logic app 2"", ""system"", ""The arrival of a PDF file in the PDF container triggers another logic app to process the PDF forms""], [""function app"", ""component"", ""The logic app sends the location of the PDF file to a function app for processing.""], [""Azure Functions"", ""system"", ""The function app is built by using the capabilities of Azure Functions""], [""Azure REST API"", ""component"", ""It uses HTTPS POST, an Azure REST API, to send the location of the single-page PDF file""], [""Container 2"", ""component"", ""Split files are saved to a second container in Data Lake Storage""], [""AI Document Intelligence"", ""component"", ""It uses HTTPS POST, an Azure REST API, to send the location of the single-page PDF file to AI Document Intelligence for processing""], [""Container 3"", ""component"", ""JSON data file that contains the response data and stores the file to a third container in Data Lake Storage""], [""forms processing logic app"", ""component"", ""The forms processing logic app receives the processed response data""], [""Azure Cosmos DB"", ""component"", ""The forms processing logic app sends the processed data to Azure Cosmos DB""], [""database"", ""component"", ""Azure Cosmos DB, which saves the data in a database""], [""Power BI"", ""component"", ""Power BI obtains the data from Azure Cosmos DB and provides insights and dashboards""]], ""relationships"": [[""designated Outlook email account"", ""calls"", ""logic app"", ""The arrival of an email triggers a logic app to process the email.""], [""Azure Logic Apps"", ""contains"", ""logic app"", ""The logic app is built by using the capabilities of Azure Logic Apps.""], [""logic app"", ""calls"", ""Container"", ""The logic app uploads the PDF files to a container in Azure Data Lake Storage""], [""Container"", ""part-of"", ""Azure Data Lake Storage"", ""container in Azure Data Lake Storage""], [""Container"", ""calls"", ""logic app 2"", ""The arrival of a PDF file in the PDF container triggers another logic app""], [""logic app"", ""calls"", ""function app"", ""The logic app sends the location of the PDF file to a function app for processing.""], [""function app"", ""part-of"", ""Azure Functions"", ""container in Azure Data Lake Storage""], [""function app"", ""calls"", ""Container 2"", ""Split files are saved to a second container in Data Lake Storage""], [""Azure Data Lake Storage"", ""contains"", ""Container 2"", ""Split files are saved to a second container in Data Lake Storage""], [""function app"", ""calls"", ""Azure REST API"", ""It uses HTTPS POST, an Azure REST API""], [""Azure REST API"", ""calls"", ""AI Document Intelligence"", ""HTTPS POST, an Azure REST API, to send the location of the single-page PDF file to AI Document Intelligence""], [""Azure Data Lake Storage"", ""contains"", ""Container 3"", ""third container in Data Lake Storage""], [""function app"", ""calls"", ""Container 3"", ""It creates a JSON data file that contains the response data and stores the file to a third container""], [""forms processing logic app"", ""calls"", ""Container 3"", ""The forms processing logic app receives the processed response data""], [""forms processing logic app"", ""calls"", ""Azure Cosmos DB"", ""The forms processing logic app sends the processed data to Azure Cosmos DB""], [""Azure Cosmos DB"", ""calls"", ""database"", ""Azure Cosmos DB, which saves the data in a database""], [""Power BI"", ""calls"", ""Azure Cosmos DB"", ""Power BI obtains the data from Azure Cosmos DB and provides insights and dashboards""]]}","Based on the provided context, here's the extracted entities and their relationships in JSON format:

```json
{
  ""entities"": [
    [""Outlook Email Account"", ""system""],
    [""Logic App (Triggered by Email)"", ""component""],
    [""Azure Logic Apps"", ""system""],
    [""PDF Container"", ""component""],
    [""Azure Data Lake Storage"", ""system""],
    [""Logic App (Triggered by PDF)"", ""component""],
    [""Function App"", ""component""],
    [""Azure Functions"", ""system""],
    [""AI Document Intelligence"", ""component""],
    [""Azure REST API"", ""component""],
    [""Split Files Container"", ""component""],
    [""Processed Data JSON File"", ""component""],
    [""Processed Data Container"", ""component""],
    [""Forms Processing Logic App"", ""component""],
    [""Azure Cosmos DB"", ""system""],
    [""Power BI"", ""component""]
  ],
  ""relationships"": [
    [""Outlook Email Account"", ""calls"", ""Logic App (Triggered by Email)"", ""Email arrival triggers logic app""],
    [""Logic App (Triggered by Email)"", ""contains"", ""PDF Container"", ""Uploads PDF files to the container""],
    [""PDF Container"", ""part-of"", ""Azure Data Lake Storage""],
    [""PDF Container"", ""calls"", ""Logic App (Triggered by PDF)"", ""PDF arrival triggers another logic app""],
    [""Logic App (Triggered by PDF)"", ""contains"", ""Split Files Container"", ""Saves split files to this container""],
    [""Split Files Container"", ""part-of"", ""Azure Data Lake Storage""],
    [""Logic App (Triggered by PDF)"", ""calls"", ""Function App"", ""Sends location of single-page PDF file for processing""],
    [""Function App"", ""contains"", ""Processed Data JSON File"", ""Creates JSON data file containing response data""],
    [""Processed Data JSON File"", ""part-of"", ""Processed Data Container""],
    [""Processed Data Container"", ""part-of"", ""Azure Data Lake Storage""],
    [""Processed Data Container"", ""called-from"", ""Forms Processing Logic App"", ""Logic app receives processed response data""],
    [""Forms Processing Logic App"", ""contains"", ""Azure Cosmos DB"", ""Sends processed data to Azure Cosmos DB""],
    [""Azure Cosmos DB"", ""part-of"", ""Power BI"", ""Power BI obtains data from Azure Cosmos DB""]
  ]
}
```","Based on the provided context, here's the extracted entities and their relationships in JSON format:

```json
{
  ""entities"": [
    [""Outlook Email Account"", ""system""],
    [""Logic App (Triggered by Email)"", ""component""],
    [""Azure Logic Apps"", ""system""],
    [""PDF Container"", ""component""],
    [""Azure Data Lake Storage"", ""system""],
    [""Logic App (Triggered by PDF)"", ""component""],
    [""Function App"", ""component""],
    [""Azure Functions"", ""system""],
    [""AI Document Intelligence"", ""component""],
    [""Azure REST API"", ""component""],
    [""Split Files Container"", ""component""],
    [""Processed Data JSON File"", ""component""],
    [""Processed Data Container"", ""component""],
    [""Forms Processing Logic App"", ""component""],
    [""Azure Cosmos DB"", ""system""],
    [""Power BI"", ""component""]
  ],
  ""relationships"": [
    [""Outlook Email Account"", ""calls"", ""Logic App (Triggered by Email)"", ""Email arrival triggers logic app""],
    [""Logic App (Triggered by Email)"", ""contains"", ""PDF Container"", ""Uploads PDF files to the container""],
    [""PDF Container"", ""part-of"", ""Azure Data Lake Storage""],
    [""PDF Container"", ""calls"", ""Logic App (Triggered by PDF)"", ""PDF arrival triggers another logic app""],
    [""Logic App (Triggered by PDF)"", ""contains"", ""Split Files Container"", ""Saves split files to this container""],
    [""Split Files Container"", ""part-of"", ""Azure Data Lake Storage""],
    [""Logic App (Triggered by PDF)"", ""calls"", ""Function App"", ""Sends location of single-page PDF file for processing""],
    [""Function App"", ""contains"", ""Processed Data JSON File"", ""Creates JSON data file containing response data""],
    [""Processed Data JSON File"", ""part-of"", ""Processed Data Container""],
    [""Processed Data Container"", ""part-of"", ""Azure Data Lake Storage""],
    [""Processed Data Container"", ""called-from"", ""Forms Processing Logic App"", ""Logic app receives processed response data""],
    [""Forms Processing Logic App"", ""contains"", ""Azure Cosmos DB"", ""Sends processed data to Azure Cosmos DB""],
    [""Azure Cosmos DB"", ""part-of"", ""Power BI"", ""Power BI obtains data from Azure Cosmos DB""]
  ]
}
```",8.364905450987862
23,mistral-nemo,../IMAGES NEW/Azure/06 Azure logic-apps-data-integration.txt,"
    API Management accepts API calls in the form of HTTP requests.

    API Management securely routes the HTTP requests to Logic Apps.

    Each HTTP request triggers a run in Logic Apps:
        Logic Apps uses secured template parameters to retrieve database credentials from Azure Key Vault.
        Logic Apps uses Transport Layer Security (TLS) to send the database credentials and a database statement to the on-premises data gateway.

    The on-premises data gateway connects to a SQL Server database to run the statement.

    SQL Server stores the data and makes it available to apps that users access.

    Azure Monitor collects information on Logic Apps events and performance.

","{""entities"": [[""API Management"", ""system"", ""accepts API calls in the form of HTTP requests""], [""Logic Apps"", ""system"", ""uses secured template parameters to retrieve database credentials from Azure Key Vault""], [""on-premises data gateway"", ""system"", """"], [""SQL Server"", ""system"", ""stores the data and makes it available to apps that users access""], [""Azure Monitor"", ""system"", ""collects information on Logic Apps events and performance""], [""Azure Key Vault"", ""system"", ""database credentials""]], ""relationships"": [[""API Management"", ""calls"", ""Logic Apps"", ""routes the HTTP requests to Logic Apps""], [""Logic Apps"", ""calls"", ""Azure Key Vault"", ""Logic Apps uses secured template parameters to retrieve database credentials from Azure Key Vault""], [""Logic Apps"", ""calls"", ""on-premises data gateway"", ""send the database credentials and a database statement to the on-premises data gateway""], [""on-premises data gateway"", ""calls"", ""SQL Server"", ""connects to a SQL Server database""], [""Azure Monitor"", ""calls"", ""Logic Apps"", ""collects information on Logic Apps events and performance""]]}","```json
{
  ""entities"": [
    [""API Management"", ""system""],
    [""Logic Apps"", ""system""],
    [""Azure Key Vault"", ""component""],
    [""on-premises data gateway"", ""component""],
    [""SQL Server database"", ""system""]
  ],
  ""relationships"": [
    [""API Management"", ""calls"", ""Logic Apps"", ""Accepts API calls""],
    [""Logic Apps"", ""contains"", ""Azure Key Vault"", ""Retrieves database credentials""],
    [""Logic Apps"", ""called-from"", ""on-premises data gateway"", ""Connects to run statement""],
    [""SQL Server database"", ""contains"", ""on-premises data gateway"", ""Runs the statement""],
    [""Azure Monitor"", ""collects"", ""Logic Apps"", ""Collects information on Logic Apps events""]
  ]
}
```","```json
{
  ""entities"": [
    [""API Management"", ""system""],
    [""Logic Apps"", ""system""],
    [""Azure Key Vault"", ""component""],
    [""on-premises data gateway"", ""component""],
    [""SQL Server database"", ""system""]
  ],
  ""relationships"": [
    [""API Management"", ""calls"", ""Logic Apps"", ""Accepts API calls""],
    [""Logic Apps"", ""contains"", ""Azure Key Vault"", ""Retrieves database credentials""],
    [""Logic Apps"", ""called-from"", ""on-premises data gateway"", ""Connects to run statement""],
    [""SQL Server database"", ""contains"", ""on-premises data gateway"", ""Runs the statement""],
    [""Azure Monitor"", ""collects"", ""Logic Apps"", ""Collects information on Logic Apps events""]
  ]
}
```",3.2670160209818278
24,mistral-nemo,../IMAGES NEW/Azure/15 Azure automate-document-classification.txt,"
    The user provides a document file that the web app uploads. The file contains multiple documents of various types. It can, for instance, be a PDF or multipage TIFF file.
        The document file is stored in Azure Blob Storage.
        The web app adds a command message to a storage queue to initiate pipeline processing.

    Durable Functions orchestration is triggered by the command message. The message contains metadata that identifies the location in Blob Storage of the document file to be processed. Each Durable Functions instance processes only one document file.

    The Scan activity function calls the Computer Vision Read API, passing in the location in storage of the document to be processed. Optical character recognition (OCR) results are returned to the orchestration to be used by subsequent activities.

    The Classify activity function calls the document classifier service that's hosted in an Azure Kubernetes Service (AKS) cluster. This service uses regular expression pattern matching to identify the starting page of each known document and to calculate how many document types are contained in the document file. The types and page ranges of the documents are calculated and returned to the orchestration.



Note

Azure doesn't offer a service that can classify multiple document types in a single file. This solution uses a non-Azure service that's hosted in AKS.

The Metadata Store activity function saves the document type and page range information in an Azure Cosmos DB store.

The Indexing activity function creates a new search document in the Cognitive Search service for each identified document type and uses the Azure AI Search libraries for .NET to include in the search document the full OCR results and document information. A correlation ID is also added to the search document so that the search results can be matched with the corresponding document metadata from Azure Cosmos DB.

End users can search for documents by contents and metadata. Correlation IDs in the search result set can be used to look up document records that are in Azure Cosmos DB. The records include links to the original document file in Blob Storage.


","{""entities"": [[""web app"", ""system"", ""The user provides a document file that the web app uploads""], [""Azure Blob Storage"", ""system"", ""The document file is stored in Azure Blob Storage""], [""storage queue"", ""system"", ""the web app adds a command message to a storage queue to initiate pipeline processing""], [""Durable Functions orchestration"", ""system"", ""Durable Functions orchestration is triggered by the command message.""], [""Scan activity function"", ""component"", ""The Scan activity function calls the Computer Vision Read API.""], [""Computer Vision Read API"", ""component"", ""The Scan activity function calls the Computer Vision Read API.""], [""Classify activity function"", ""component"", ""The Classify activity function calls the document classifier service that's hosted in an Azure Kubernetes Service (AKS) cluster""], [""document classifier service"", ""component"", ""The Classify activity function calls the document classifier service that's hosted in an Azure Kubernetes Service (AKS) cluster""], [""Azure Kubernetes Service (AKS) cluster"", ""system"", ""The Classify activity function calls the document classifier service that's hosted in an Azure Kubernetes Service (AKS) cluster""], [""User"", ""person"", ""provides a document file that the web app uploads""]], ""relationships"": [[""User"", ""calls"", ""web app"", ""The user provides a document file that the web app uploads""], [""web app"", ""calls"", ""Azure Blob Storage"", ""The user provides a document file that the web app uploads.The document file is stored in Azure Blob Storage""], [""web app"", ""calls"", ""storage queue"", ""the web app adds a command message to a storage queue to initiate pipeline processing""], [""storage queue"", ""calls"", ""Durable Functions orchestration"", ""Durable Functions orchestration is triggered by the command message.""], [""Durable Functions orchestration"", ""calls"", ""Azure Blob Storage"", ""Each Durable Functions instance processes only one document file""], [""Scan activity function"", ""calls"", ""Computer Vision Read API"", ""the Scan activity function calls the Computer Vision Read API""], [""document classifier service"", ""part-of"", ""Azure Kubernetes Service (AKS) cluster"", ""document classifier service that's hosted in an Azure Kubernetes Service (AKS) cluster""], [""Classify activity function"", ""calls"", ""Scan activity function"", ""The Classify activity function calls the document classifier service""], [""Classify activity function"", ""calls"", ""Durable Functions orchestration"", ""The types and page ranges of the documents are calculated and returned to the orchestration""]]}","```json
{
  ""entities"": [
    [""User"", ""person"", ""The user provides a document file""],
    [""Document File"", ""component"", ""A file containing multiple documents of various types.""],
    [""Azure Blob Storage"", ""system"", ""Stores the document file""],
    [""Web App"", ""component"", ""Adds a command message to initiate pipeline processing""],
    [""Storage Queue"", ""component"", ""Receives the command message from the web app""],
    [""Durable Functions Orchestration"", ""component"", ""Triggered by the command message""],
    [""Scan Activity Function"", ""component"", ""Calls Computer Vision Read API for OCR""],
    [""Computer Vision Read API"", ""system"", ""Performs optical character recognition on documents""],
    [""Classify Activity Function"", ""component"", ""Identifies document types and page ranges""],
    [""Document Classifier Service"", ""system"", ""Hosted in AKS, uses regular expression pattern matching""],
    [""Azure Kubernetes Service (AKS)"", ""system"", ""Hosts the Document Classifier Service""],
    [""Metadata Store Activity Function"", ""component"", ""Saves document type and range information in Cosmos DB""],
    [""Azure Cosmos DB"", ""system"", ""Stores document metadata""],
    [""Indexing Activity Function"", ""component"", ""Creates search documents in Cognitive Search service""],
    [""Cognitive Search service"", ""system"", ""Used for searching documents by content and metadata""],
    [""End User"", ""person"", ""Searches for documents based on contents and metadata""]
  ],
  ""relationships"": [
    [""Document File"", ""part-of"", ""Azure Blob Storage""],
    [""Web App"", ""calls"", ""Storage Queue""],
    [""Storage Queue"", ""called-from"", ""Web App""],
    [""Durable Functions Orchestration"", ""contains"", ""Scan Activity Function""],
    [""Durable Functions Orchestration"", ""contains"", ""Classify Activity Function""],
    [""Durable Functions Orchestration"", ""contains"", ""Metadata Store Activity Function""],
    [""Durable Functions Orchestration"", ""contains"", ""Indexing Activity Function""],
    [""Scan Activity Function"", ""calls"", ""Computer Vision Read API""],
    [""Classify Activity Function"", ""called-from"", ""Document Classifier Service""],
    [""Document Classifier Service"", ""part-of"", ""Azure Kubernetes Service (AKS)""],
    [""Metadata Store Activity Function"", ""calls"", ""Azure Cosmos DB""],
    [""Indexing Activity Function"", ""creates"", ""Cognitive Search service""],
    [""End User"", ""searches"", ""Cognitive Search service""]
  ]
}
```","```json
{
  ""entities"": [
    [""User"", ""person"", ""The user provides a document file""],
    [""Document File"", ""component"", ""A file containing multiple documents of various types.""],
    [""Azure Blob Storage"", ""system"", ""Stores the document file""],
    [""Web App"", ""component"", ""Adds a command message to initiate pipeline processing""],
    [""Storage Queue"", ""component"", ""Receives the command message from the web app""],
    [""Durable Functions Orchestration"", ""component"", ""Triggered by the command message""],
    [""Scan Activity Function"", ""component"", ""Calls Computer Vision Read API for OCR""],
    [""Computer Vision Read API"", ""system"", ""Performs optical character recognition on documents""],
    [""Classify Activity Function"", ""component"", ""Identifies document types and page ranges""],
    [""Document Classifier Service"", ""system"", ""Hosted in AKS, uses regular expression pattern matching""],
    [""Azure Kubernetes Service (AKS)"", ""system"", ""Hosts the Document Classifier Service""],
    [""Metadata Store Activity Function"", ""component"", ""Saves document type and range information in Cosmos DB""],
    [""Azure Cosmos DB"", ""system"", ""Stores document metadata""],
    [""Indexing Activity Function"", ""component"", ""Creates search documents in Cognitive Search service""],
    [""Cognitive Search service"", ""system"", ""Used for searching documents by content and metadata""],
    [""End User"", ""person"", ""Searches for documents based on contents and metadata""]
  ],
  ""relationships"": [
    [""Document File"", ""part-of"", ""Azure Blob Storage""],
    [""Web App"", ""calls"", ""Storage Queue""],
    [""Storage Queue"", ""called-from"", ""Web App""],
    [""Durable Functions Orchestration"", ""contains"", ""Scan Activity Function""],
    [""Durable Functions Orchestration"", ""contains"", ""Classify Activity Function""],
    [""Durable Functions Orchestration"", ""contains"", ""Metadata Store Activity Function""],
    [""Durable Functions Orchestration"", ""contains"", ""Indexing Activity Function""],
    [""Scan Activity Function"", ""calls"", ""Computer Vision Read API""],
    [""Classify Activity Function"", ""called-from"", ""Document Classifier Service""],
    [""Document Classifier Service"", ""part-of"", ""Azure Kubernetes Service (AKS)""],
    [""Metadata Store Activity Function"", ""calls"", ""Azure Cosmos DB""],
    [""Indexing Activity Function"", ""creates"", ""Cognitive Search service""],
    [""End User"", ""searches"", ""Cognitive Search service""]
  ]
}
```",9.090272511006333
25,mistral-nemo,../IMAGES NEW/Azure/09 Azure protect APIs original.txt,"
    To gain access to an application, an API client authenticates by providing credentials such as username and password. The IdP is Azure AD B2C in this solution, but you can use a different one.

    The authentication request goes via Azure Front Door to Azure AD B2C, which is configured with a custom domain for sign-in. Azure AD B2C authenticates the user and returns a JSON Web Token (JWT) bearer token back to the user.

    The client triggers an event that accesses a backend API. This event could be a click of a button on a web application or on a mobile device, or a direct call to the endpoint of the backend API.

    The request goes through Azure Front Door, whose back end is mapped to the public endpoint of API Management. API Management intercepts the request and validates the bearer token against Azure AD B2C by using its validate-jwt policy. If the token isn't valid, API Management rejects the request by responding with a 401 code.

    If the token is valid, API Management forwards the request to the appropriate backend API.

    The diagram shows backend APIs running in three environments:
        App Service Environment
        Function Apps
        Azure Kubernetes Services (AKS)

    APIs running in on-premises and hybrid cloud environments can also be integrated with API Management if network connectivity is established between the APIs and API Management.

","{""entities"": [[""API client"", ""system"", ""wants to gain access to an application""], [""application"", ""system"", ""API client wants to gain access to an application""], [""Azure AD B2C"", ""system"", ""The IdP is Azure AD B2C""], [""Azure Front Door"", ""system"", ""authentication request goes via Azure Front Door to Azure AD B2C""], [""backend API"", ""system"", ""The client triggers an event that accesses a backend API""], [""Azure Front Door"", ""system"", ""The request goes through Azure Front Door, whose back end is mapped to the public endpoint of API Management.""], [""backend"", ""component"", ""Azure Front Door, whose back end""], [""API Management"", ""system"", ""API Management intercepts the request and validates the bearer token against Azure AD B2C ""], [""public endpoint"", ""system"", ""whose back end is mapped to the public endpoint of API Management""], [""User"", ""person"", ""Azure AD B2C authenticates the user and returns a JSON Web Token (JWT) bearer token back to the user""]], ""relationships"": [[""API client"", ""calls"", ""application"", """"], [""Azure Front Door"", ""calls"", ""Azure AD B2C"", ""authentication request goes via Azure Front Door to Azure AD B2C""], [""Azure AD B2C"", ""is-called-from"", ""User"", ""Azure AD B2C authenticates the user and returns a JSON Web Token (JWT) bearer token back to the user""], [""API client"", ""calls"", ""backend API"", ""The client triggers an event that accesses a backend API""], [""Azure Front Door"", ""contains"", ""backend"", ""Azure Front Door, whose back end""], [""public endpoint"", ""part-of"", ""API Management"", ""Azure Front Door, whose back end""], [""backend"", ""calls"", ""public endpoint"", ""whose back end is mapped to the public endpoint of API Management""], [""API Management"", ""calls"", ""Azure AD B2C"", ""API Management intercepts the request and validates the bearer token against Azure AD B2C""]]}","{
  ""entities"": [
    [""API Client"", ""component""],
    [""Azure AD B2C"", ""system""],
    [""Azure Front Door"", ""system""],
    [""Azure API Management"", ""system""],
    [""Backend API"", ""component""],
    [""App Service Environment"", ""system""],
    [""Function Apps"", ""system""],
    [""Azure Kubernetes Services (AKS)"", ""system""]
  ],
  ""relationships"": [
    [""API Client"", ""calls"", ""Azure Front Door""],
    [""Azure Front Door"", ""contains"", ""Azure AD B2C""],
    [""Azure Front Door"", ""called-from"", ""Azure API Management""],
    [""Azure API Management"", ""contains"", ""Backend API""],
    [""Azure API Management"", ""part-of"", ""App Service Environment""],
    [""Azure API Management"", ""part-of"", ""Function Apps""],
    [""Azure API Management"", ""part-of"", ""Azure Kubernetes Services (AKS)""]
  ]
}","{
  ""entities"": [
    [""API Client"", ""component""],
    [""Azure AD B2C"", ""system""],
    [""Azure Front Door"", ""system""],
    [""Azure API Management"", ""system""],
    [""Backend API"", ""component""],
    [""App Service Environment"", ""system""],
    [""Function Apps"", ""system""],
    [""Azure Kubernetes Services (AKS)"", ""system""]
  ],
  ""relationships"": [
    [""API Client"", ""calls"", ""Azure Front Door""],
    [""Azure Front Door"", ""contains"", ""Azure AD B2C""],
    [""Azure Front Door"", ""called-from"", ""Azure API Management""],
    [""Azure API Management"", ""contains"", ""Backend API""],
    [""Azure API Management"", ""part-of"", ""App Service Environment""],
    [""Azure API Management"", ""part-of"", ""Function Apps""],
    [""Azure API Management"", ""part-of"", ""Azure Kubernetes Services (AKS)""]
  ]
}",3.7872780570178293
26,mistral-nemo,../IMAGES NEW/Azure/11 Mainframe original.txt,"
    A Connect agent component captures change logs by using mainframe or midrange native utilities and caches the logs in temporary storage.
    For mainframe systems, a publisher component on the mainframe manages data migration.
    For midrange systems, in place of the publisher, a listener component manages data migration. It's located on either a Windows or Linux machine.
    The publisher or listener moves the data from on-premises to Azure via an enhanced-security connection. The publisher or listener handles the commit and rollback of transactions for each unit of work, maintaining the integrity of data.
    The Connect Replicator Engine captures the data from the publisher or listener and applies it to the target. It distributes data for parallel processing.
    The target is a database that receives the changes via ODBC or ingests the changes via Azure Event Hubs.
    The changed data is consumed by Azure Databricks and applied to Azure data platform services.
    The Connect Controller Daemon authenticates the request and establishes the socket connection between the publisher or listener and the Replicator Engine.

","{""entities"": [[""Connect agent"", ""component"", ""captures change logs""], [""temporary storage"", ""component"", ""caches the logs in temporary storage""], [""mainframe native utilities"", ""system"", ""captures change logs by using mainframe or midrange native utilities""], [""midrange native utilities"", ""system"", ""captures change logs by using mainframe or midrange native utilities""], [""mainframe systems"", ""system"", ""For mainframe systems, a publisher component on the mainframe manages data migration.""], [""midrange systems"", ""system"", ""For midrange systems, in place of the publisher, a listener component manages data migration.""], [""publisher"", ""component"", ""For mainframe systems, a publisher component on the mainframe manages data migration.""], [""listener"", ""component"", ""For midrange systems, in place of the publisher, a listener component manages data migration.""], [""Connect Replicator Engine"", ""system"", ""captures the data from the publisher or listener and applies it to the target.""], [""on-premises"", ""system"", ""The publisher or listener moves the data from on-premises to Azure""], [""Azure"", ""system"", ""The publisher or listener moves the data from on-premises to Azure""], [""Connect Replicator Engine"", ""system"", ""The Connect Replicator Engine captures the data from the publisher or listener""], [""target"", ""system"", ""applies it to the target""], [""database"", ""system"", ""target is a database""], [""ODBC"", ""component"", ""The target is a database that receives the changes via ODBC or ingests the changes via Azure Event Hubs""], [""Azure Event Hubs"", ""component"", ""The target is a database that receives the changes via ODBC or ingests the changes via Azure Event Hubs""], [""Azure Databricks"", ""component"", ""the changed data is consumed by Azure Databricks and applied to Azure data platform services.""], [""Azure data platform services"", ""component"", ""the changed data is consumed by Azure Databricks and applied to Azure data platform services.""], [""Connect Controller Daemon"", ""component"", ""authenticates the request and establishes the socket connection between the publisher or listener and the Replicator Engine.""]], ""relationships"": [[""Connect agent"", ""calls"", ""mainframe native utilities"", ""captures change logs by using mainframe or midrange native utilities""], [""Connect agent"", ""calls"", ""midrange native utilities"", ""captures change logs by using mainframe or midrange native utilities""], [""Connect agent"", ""calls"", ""temporary storage"", ""captures change logs by using mainframe or midrange native utilities""], [""mainframe systems"", ""contains"", ""mainframe native utilities"", ""F""], [""midrange systems"", ""contains"", ""midrange native utilities"", """"], [""mainframe systems"", ""contains"", ""publisher"", ""For mainframe systems, a publisher component on the mainframe manages data migration.""], [""midrange systems"", ""contains"", ""listener"", ""For midrange systems, in place of the publisher, a listener component manages data migration.""], [""publisher"", ""calls"", ""on-premises"", ""The publisher or listener moves the data from on-premises to Azure""], [""publisher"", ""calls"", ""Azure"", ""The publisher or listener moves the data from on-premises to Azure""], [""listener"", ""calls"", ""on-premises"", ""The publisher or listener moves the data from on-premises to Azure""], [""listener"", ""calls"", ""Azure"", ""The publisher or listener moves the data from on-premises to Azure""], [""Connect Replicator Engine"", ""calls"", ""publisher"", ""captures the data from the publisher or listener and applies it to the target.""], [""Connect Replicator Engine"", ""calls"", ""listener"", ""captures the data from the publisher or listener and applies it to the target.""], [""Connect Replicator Engine"", ""calls"", ""target"", ""captures the data from the publisher or listener and applies it to the target.""], [""target"", ""contains"", ""database"", ""target is a database""], [""database"", ""is-called-from"", ""ODBC"", ""database that receives the changes via ODBC""], [""database"", ""is-called-from"", ""Azure Event Hubs"", ""ingests the changes via Azure Event Hubs""], [""database"", ""is-called-from"", ""Azure Databricks"", ""the changed data is consumed by Azure Databricks""], [""Azure Databricks"", ""calls"", ""Azure data platform services"", ""consumed by Azure Databricks and applied to Azure data platform services.""], [""Connect Controller Daemon"", ""is-called-from"", ""publisher"", ""establishes the socket connection between the publisher or listener and the Replicator Engine..""], [""Connect Controller Daemon"", ""is-called-from"", ""listener"", ""establishes the socket connection between the publisher or listener and the Replicator Engine..""], [""Connect Controller Daemon"", ""calls"", ""Connect Replicator Engine"", ""establishes the socket connection between the publisher or listener and the Replicator Engine..""]]}","Based on the provided text, here's the extracted entities and relationships in JSON format:

```json
{
  ""entities"": [
    [""Connect agent"", ""component"", ""Captures change logs""],
    [""mainframe native utilities"", ""system"", ""Used for capturing logs""],
    [""midrange native utilities"", ""system"", ""Used for capturing logs""],
    [""publisher component"", ""component"", ""Manages data migration on mainframe""],
    [""listener component"", ""component"", ""Manages data migration on midrange systems""],
    [""Windows machine"", ""system"", ""Hosts listener component""],
    [""Linux machine"", ""system"", ""Hosts listener component""],
    [""Azure"", ""system"", ""Receives migrated data""],
    [""enhanced-security connection"", ""component"", ""Used for migrating data to Azure""],
    [""Connect Replicator Engine"", ""component"", ""Captures data from publisher/listener and applies it to target""],
    [""target database"", ""system"", ""Receives changes via ODBC or ingests via Azure Event Hubs""],
    [""Azure Databricks"", ""system"", ""Consumes changed data and applies it to Azure data platform services""],
    [""Connect Controller Daemon"", ""component"", ""Authenticates requests and establishes socket connection""]
  ],
  ""relationships"": [
    [""Connect agent"", ""contains"", ""mainframe native utilities""],
    [""Connect agent"", ""contains"", ""midrange native utilities""],
    [""publisher component"", ""part-of"", ""mainframe""],
    [""listener component"", ""part-of"", ""Windows machine""],
    [""listener component"", ""part-of"", ""Linux machine""],
    [""enhanced-security connection"", ""calls"", ""Azure""],
    [""Connect Replicator Engine"", ""called-from"", ""publisher component""],
    [""Connect Replicator Engine"", ""called-from"", ""listener component""],
    [""Connect Replicator Engine"", ""contains"", ""target database""],
    [""target database"", ""calls"", ""Azure Event Hubs""],
    [""target database"", ""calls"", ""ODBC""],
    [""Azure Databricks"", ""called-from"", ""target database""],
    [""Connect Controller Daemon"", ""part-of"", ""publisher component""],
    [""Connect Controller Daemon"", ""part-of"", ""listener component""]
  ]
}
```","Based on the provided text, here's the extracted entities and relationships in JSON format:

```json
{
  ""entities"": [
    [""Connect agent"", ""component"", ""Captures change logs""],
    [""mainframe native utilities"", ""system"", ""Used for capturing logs""],
    [""midrange native utilities"", ""system"", ""Used for capturing logs""],
    [""publisher component"", ""component"", ""Manages data migration on mainframe""],
    [""listener component"", ""component"", ""Manages data migration on midrange systems""],
    [""Windows machine"", ""system"", ""Hosts listener component""],
    [""Linux machine"", ""system"", ""Hosts listener component""],
    [""Azure"", ""system"", ""Receives migrated data""],
    [""enhanced-security connection"", ""component"", ""Used for migrating data to Azure""],
    [""Connect Replicator Engine"", ""component"", ""Captures data from publisher/listener and applies it to target""],
    [""target database"", ""system"", ""Receives changes via ODBC or ingests via Azure Event Hubs""],
    [""Azure Databricks"", ""system"", ""Consumes changed data and applies it to Azure data platform services""],
    [""Connect Controller Daemon"", ""component"", ""Authenticates requests and establishes socket connection""]
  ],
  ""relationships"": [
    [""Connect agent"", ""contains"", ""mainframe native utilities""],
    [""Connect agent"", ""contains"", ""midrange native utilities""],
    [""publisher component"", ""part-of"", ""mainframe""],
    [""listener component"", ""part-of"", ""Windows machine""],
    [""listener component"", ""part-of"", ""Linux machine""],
    [""enhanced-security connection"", ""calls"", ""Azure""],
    [""Connect Replicator Engine"", ""called-from"", ""publisher component""],
    [""Connect Replicator Engine"", ""called-from"", ""listener component""],
    [""Connect Replicator Engine"", ""contains"", ""target database""],
    [""target database"", ""calls"", ""Azure Event Hubs""],
    [""target database"", ""calls"", ""ODBC""],
    [""Azure Databricks"", ""called-from"", ""target database""],
    [""Connect Controller Daemon"", ""part-of"", ""publisher component""],
    [""Connect Controller Daemon"", ""part-of"", ""listener component""]
  ]
}
```",8.152684125001542
27,mistral-nemo,../IMAGES NEW/Azure/08 Azure Business Processes.txt,"
The data flows through the solution as follows:

    The airline system communicates with a custom API hosted in Azure API Management.
    A custom API coordinator receives notifications and handles incoming messages from the airline system. It sends them to Power Apps, where flights are assigned to Microsoft Teams channels.
    When a user selects a flight to monitor, or when the system assigns the user to a flight, the system queues a Graph API call in an Azure Storage Account queue for further processing.
    Azure Functions runs the Graph API calls based on the incoming messages in the storage queue, sending notifications to Teams, and also streams all events to an Azure Event Hubs for further analytics.
    The airline's notification system is managed by a custom bot messaging service that employs Azure Bot Service.
    Custom bots send flight updates to users in Teams.
    An Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs, ultimately generating insightful reports with Power BI.

","{""entities"": [[""airline system"", ""system"", ""communicates with a custom API hosted in Azure API Management""], [""custom API"", ""component"", ""communicates with a custom API hosted in Azure API Management""], [""Azure API Management"", ""system"", ""communicates with a custom API hosted in Azure API Management""], [""custom API coordinator"", ""system"", ""receives notifications and handles incoming messages from the airline system""], [""Power Apps"", ""system"", ""where flights are assigned to Microsoft Teams channels""], [""Microsoft Teams channels"", ""system"", ""where flights are assigned to Microsoft Teams channels""], [""Storage Account queue"", ""system"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing.""], [""Graph API call"", ""system"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing.""], [""Azure Functions"", ""system"", ""runs the Graph API calls based on the incoming messages in the storage queue""], [""Azure Event Hubs"", ""system"", ""Azure Event Hubs for further analytics""], [""notification system"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""custom bot messaging service"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""Azure Bot Service"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""Users"", ""person"", ""selects a flight to monitor, or when the system assigns the user to a flight""], [""Azure Data Lake storage"", ""system"", ""offers long-term retention and micro-batch processing of events from Event Hubs""], [""Power BI"", ""system"", ""generating insightful reports""]], ""relationships"": [[""Azure API Management"", ""contains"", ""custom API"", ""custom API hosted in Azure API Management""], [""airline system"", ""calls"", ""custom API"", ""communicates with a custom API""], [""custom API coordinator"", ""is-called-from"", ""airline system"", ""receives notifications and handles incoming messages from the airline system""], [""Power Apps"", ""calls"", ""Microsoft Teams channels"", ""Power Apps, where flights are assigned to Microsoft Teams channels""], [""airline system"", ""calls"", ""Graph API call"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing""], [""Azure Functions"", ""calls"", ""Graph API call"", ""runs the Graph API calls based on the incoming messages in the storage queue""], [""Azure Functions"", ""calls"", ""Storage Account queue"", ""based on the incoming messages in the storage queue""], [""Azure Functions"", ""calls"", ""Microsoft Teams channels"", ""sending notifications to Teams""], [""Azure Functions"", ""calls"", ""Azure Event Hubs"", ""also streams all events to an Azure Event Hubs for further analytics""], [""notification system"", ""is-called-from"", ""custom bot messaging service"", ""managed by a custom bot messaging service""], [""custom bot messaging service"", ""calls"", ""Azure Bot Service"", ""custom bot messaging service that employs Azure Bot Service""], [""custom bot messaging service"", ""calls"", ""Microsoft Teams channels"", ""Custom bots send flight updates to users in Teams.""], [""Microsoft Teams channels"", ""calls"", ""Users"", ""Custom bots send flight updates to users in Teams.""], [""Azure Data Lake storage"", ""is-called-from"", ""Azure Event Hubs"", ""Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs""], [""Azure Data Lake storage"", ""calls"", ""Power BI"", ""Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs, ultimately generating insightful reports with Power BI""]]}","```json
{
  ""entities"": [
    [""Airline System"", ""system""],
    [""Custom API Coordinator"", ""component""],
    [""Power Apps"", ""component""],
    [""Microsoft Teams"", ""system""],
    [""Azure Storage Account Queue"", ""component""],
    [""Azure Functions"", ""component""],
    [""Azure Event Hubs"", ""component""],
    [""Azure Data Lake storage"", ""component""],
    [""Power BI"", ""component""]
  ],
  ""relationships"": [
    [""Airline System"", ""communicates with"", ""Custom API Coordinator""],
    [""Custom API Coordinator"", ""sends messages to"", ""Power Apps""],
    [""Power Apps"", ""queues Graph API calls in"", ""Azure Storage Account Queue""],
    [""Azure Storage Account Queue"", ""runs Graph API calls based on incoming messages for"", ""Azure Functions""],
    [""Azure Functions"", ""streams events to"", ""Azure Event Hubs""],
    [""Custom bot messaging service"", ""sends flight updates to users in"", ""Microsoft Teams""],
    [""Azure Data Lake storage"", ""offers long-term retention and micro-batch processing of events from"", ""Azure Event Hubs""],
    [""Power BI"", ""generates reports with data from"", ""Azure Data Lake storage""]
  ]
}
```","```json
{
  ""entities"": [
    [""Airline System"", ""system""],
    [""Custom API Coordinator"", ""component""],
    [""Power Apps"", ""component""],
    [""Microsoft Teams"", ""system""],
    [""Azure Storage Account Queue"", ""component""],
    [""Azure Functions"", ""component""],
    [""Azure Event Hubs"", ""component""],
    [""Azure Data Lake storage"", ""component""],
    [""Power BI"", ""component""]
  ],
  ""relationships"": [
    [""Airline System"", ""communicates with"", ""Custom API Coordinator""],
    [""Custom API Coordinator"", ""sends messages to"", ""Power Apps""],
    [""Power Apps"", ""queues Graph API calls in"", ""Azure Storage Account Queue""],
    [""Azure Storage Account Queue"", ""runs Graph API calls based on incoming messages for"", ""Azure Functions""],
    [""Azure Functions"", ""streams events to"", ""Azure Event Hubs""],
    [""Custom bot messaging service"", ""sends flight updates to users in"", ""Microsoft Teams""],
    [""Azure Data Lake storage"", ""offers long-term retention and micro-batch processing of events from"", ""Azure Event Hubs""],
    [""Power BI"", ""generates reports with data from"", ""Azure Data Lake storage""]
  ]
}
```",4.639844760007691
28,mistral-nemo,../IMAGES NEW/Azure/07 Azure internal APIs original.txt,"
The data flows as follows:

    Developers check in code to a GitHub repository that's connected to a CI/CD pipeline agent that's installed on an Azure VM.
    The agent pushes the build to the API application that's hosted on ILB ASE.
    Azure API Management consumes the preceding APIs via HOST headers that are specified in API Management policy.
    API Management uses the App Service Environment's DNS name for all the APIs.
    Application Gateway exposes API Management's developer and API portal.
    Azure Private DNS is used to route the traffic internally between ASE, API Management, and Application Gateway.
    External users utilize the exposed developer portal to consume the APIs via Application Gateway's public IP.

","{""entities"": [[""GitHub repository"", ""system"", """"], [""Developers"", ""person"", """"], [""External users"", ""person"", """"], [""CI/CD pipeline agent"", ""system"", """"], [""Azure VM"", ""system"", """"], [""ILB ASE"", ""system"", """"], [""API application"", ""component"", """"], [""Azure API Management"", ""system"", ""consumes the preceding APIs via HOST headers""], [""App Service Environment"", ""component"", """"], [""Application Gateway"", ""component"", ""exposes API Management's developer and API portal""], [""Developer portal"", ""component"", ""API Management's developer and API portal""], [""API portal"", ""component"", ""API Management's developer and API portal""], [""Application Gateway"", ""component"", ""exposes API Management's developer and API portal""], [""Azure Private DNS"", ""component"", ""used to route the traffic internally between ASE, API Management, and Application Gateway""]], ""relationships"": [[""Azure VM"", ""contains"", ""CI/CD pipeline agent"", ""installed on an Azure VM""], [""API application"", ""part-of"", ""ILB ASE"", ""API application that's hosted on ILB ASE""], [""GitHub repository"", ""calls"", ""CI/CD pipeline agent"", ""GitHub repository that's connected to a CI/CD pipeline agent""], [""CI/CD pipeline agent"", ""calls"", ""API application"", ""agent pushes the build to the API application""], [""Azure API Management"", ""calls"", ""App Service Environment"", ""uses the App Service Environment's DNS name for all the APIs""], [""External users"", ""calls"", ""Application Gateway"", """"], [""Application Gateway"", ""calls"", ""API application"", ""to consume the APIs via Application Gateway's public IP""], [""Azure API Management"", ""contains"", ""Developer portal"", ""API Management's developer and API portal""], [""Azure API Management"", ""contains"", ""API portal"", ""API Management's developer and API portal""], [""Application Gateway"", ""calls"", ""API portal"", ""exposes API Management's developer and API portal.""], [""Application Gateway"", ""calls"", ""Developer portal"", ""exposes API Management's developer and API portal.""], [""Azure Private DNS"", ""calls"", ""Azure API Management"", ""route the traffic internally between ASE, API Management, and Application Gateway""], [""Azure Private DNS"", ""calls"", ""Application Gateway"", ""route the traffic internally between ASE, API Management, and Application Gateway""]]}","{
""entities"": [
[""Developers"", ""person""],
[""GitHub repository"", ""component""],
[""CI/CD pipeline agent"", ""component""],
[""Azure VM"", ""system""],
[""API application"", ""component""],
[""ILB ASE"", ""system""],
[""Azure API Management"", ""system""],
[""HOST headers"", ""component""],
[""API Management policy"", ""component""],
[""App Service Environment's DNS name"", ""component""],
[""Application Gateway"", ""system""],
[""Azure Private DNS"", ""system""],
[""External users"", ""person""],
[""developer portal"", ""component""],
[""public IP"", ""component""]
],
""relationships"": [
[""Developers"", ""check-in"", ""GitHub repository""],
[""CI/CD pipeline agent"", ""part-of"", ""Azure VM""],
[""GitHub repository"", ""calls"", ""CI/CD pipeline agent""],
[""CI/CD pipeline agent"", ""pushes"", ""API application""],
[""Azure API Management"", ""contains"", ""HOST headers""],
[""HOST headers"", ""part-of"", ""Azure API Management""],
[""Azure API Management"", ""uses"", ""App Service Environment's DNS name""],
[""Application Gateway"", ""exposes"", ""developer portal""],
[""External users"", ""consume"", ""API application via Application Gateway's public IP""]
]
}","{
""entities"": [
[""Developers"", ""person""],
[""GitHub repository"", ""component""],
[""CI/CD pipeline agent"", ""component""],
[""Azure VM"", ""system""],
[""API application"", ""component""],
[""ILB ASE"", ""system""],
[""Azure API Management"", ""system""],
[""HOST headers"", ""component""],
[""API Management policy"", ""component""],
[""App Service Environment's DNS name"", ""component""],
[""Application Gateway"", ""system""],
[""Azure Private DNS"", ""system""],
[""External users"", ""person""],
[""developer portal"", ""component""],
[""public IP"", ""component""]
],
""relationships"": [
[""Developers"", ""check-in"", ""GitHub repository""],
[""CI/CD pipeline agent"", ""part-of"", ""Azure VM""],
[""GitHub repository"", ""calls"", ""CI/CD pipeline agent""],
[""CI/CD pipeline agent"", ""pushes"", ""API application""],
[""Azure API Management"", ""contains"", ""HOST headers""],
[""HOST headers"", ""part-of"", ""Azure API Management""],
[""Azure API Management"", ""uses"", ""App Service Environment's DNS name""],
[""Application Gateway"", ""exposes"", ""developer portal""],
[""External users"", ""consume"", ""API application via Application Gateway's public IP""]
]
}",4.644465629011393
29,mistral-nemo,../IMAGES NEW/Azure/12 Azure Network Microservices original.txt,"
    Outside services and clients make a POST request to APIM, with a data body that includes patient information.
    APIM calls the CreatePatient function in the Patient API with the given patient information.
    The CreatePatient function in Patient API calls the CreateAuditRecord function in the Audit API function app to create an audit record.
    The Audit API CreateAuditRecord function creates the audit record in Azure Cosmos DB, and returns a success response to the Patient API CreatePatient function.
    The CreatePatient function creates the patient document in Azure Cosmos DB, and returns a success response to APIM.
    The outside services and clients receive the success response from APIM.

","{""entities"": [[""Outside services"", ""system"", ""Outside services and clients make a POST request to APIM""], [""clients"", ""system"", ""Outside services and clients make a POST request to APIM""], [""APIM"", ""system"", ""Outside services and clients make a POST request to APIM""], [""Patient API"", ""system"", "" The CreatePatient function in Patient API calls the CreateAuditRecord function in the Audit API function app""], [""CreatePatient function"", ""component"", "" The CreatePatient function in Patient API calls the CreateAuditRecord function in the Audit API function app""], [""Audit API function app"", ""system"", ""The CreatePatient function in Patient API calls the CreateAuditRecord function in the Audit API function app""], [""CreateAuditRecord function"", ""component"", ""CreatePatient function in Patient API calls the CreateAuditRecord function""], [""Azure Cosmos DB"", ""system"", ""The Audit API CreateAuditRecord function creates the audit record in Azure Cosmos DB, and returns a success response to the Patient API CreatePatient function""]], ""relationships"": [[""CreatePatient function"", ""part-of"", ""Patient API"", ""Reason""], [""Outside services"", ""calls"", ""APIM"", ""utside services and clients make a POST request to APIM""], [""clients"", ""calls"", ""APIM"", ""outside services and clients make a POST request to APIM""], [""APIM"", ""calls"", ""CreatePatient function"", ""APIM calls the CreatePatient function in the Patient API""], [""CreateAuditRecord function"", ""part-of"", ""Audit API function app"", ""Reason""], [""CreatePatient function"", ""calls"", ""CreateAuditRecord function"", ""CreatePatient function in Patient API calls the CreateAuditRecord function in the Audit API function app""], [""CreateAuditRecord function"", ""calls"", ""Azure Cosmos DB"", ""Audit API CreateAuditRecord function creates the audit record in Azure Cosmos DB""], [""CreateAuditRecord function"", ""calls"", ""CreatePatient function"", ""returns a success response to the Patient API CreatePatient function.""], [""CreatePatient function"", ""calls"", ""Azure Cosmos DB"", ""The CreatePatient function creates the patient document in Azure Cosmos DB""], [""CreatePatient function"", ""is-called-from"", ""APIM"", ""The CreatePatient function returns a success response to APIM""]]}","Here's the JSON response based on the provided text:

```json
{
  ""entities"": [
    [""APIM"", ""system"", ""API Management system""],
    [""Patient_API"", ""system"", ""Patient API""],
    [""Audit_API"", ""system"", ""Audit API""],
    [""CreatePatient"", ""component"", ""CreatePatient function in Patient_API""],
    [""CreateAuditRecord"", ""component"", ""CreateAuditRecord function in Audit_API""],
    [""Azure_Cosmos_DB"", ""system"", ""Azure Cosmos DB""],
    [""Outside_Services_Clients"", ""person"", ""External services and clients""]
  ],
  ""relationships"": [
    [""APIM"", ""calls"", ""CreatePatient"", ""APIM calls the CreatePatient function in Patient_API""],
    [""CreatePatient"", ""part-of"", ""Patient_API"", ""CreatePatient is a part of Patient_API""],
    [""CreatePatient"", ""calls"", ""CreateAuditRecord"", ""CreatePatient function calls CreateAuditRecord function""],
    [""CreateAuditRecord"", ""part-of"", ""Audit_API"", ""CreateAuditRecord is a part of Audit_API""],
    [""CreateAuditRecord"", ""contains"", ""Azure_Cosmos_DB"", ""CreateAuditRecord creates audit record in Azure_Cosmos_DB""],
    [""CreatePatient"", ""contains"", ""Azure_Cosmos_DB"", ""CreatePatient creates patient document in Azure_Cosmos_DB""],
    [""APIM"", ""called-from"", ""Outside_Services_Clients"", ""APIM receives success response from Outside_Services_Clients""]
  ]
}
```","Here's the JSON response based on the provided text:

```json
{
  ""entities"": [
    [""APIM"", ""system"", ""API Management system""],
    [""Patient_API"", ""system"", ""Patient API""],
    [""Audit_API"", ""system"", ""Audit API""],
    [""CreatePatient"", ""component"", ""CreatePatient function in Patient_API""],
    [""CreateAuditRecord"", ""component"", ""CreateAuditRecord function in Audit_API""],
    [""Azure_Cosmos_DB"", ""system"", ""Azure Cosmos DB""],
    [""Outside_Services_Clients"", ""person"", ""External services and clients""]
  ],
  ""relationships"": [
    [""APIM"", ""calls"", ""CreatePatient"", ""APIM calls the CreatePatient function in Patient_API""],
    [""CreatePatient"", ""part-of"", ""Patient_API"", ""CreatePatient is a part of Patient_API""],
    [""CreatePatient"", ""calls"", ""CreateAuditRecord"", ""CreatePatient function calls CreateAuditRecord function""],
    [""CreateAuditRecord"", ""part-of"", ""Audit_API"", ""CreateAuditRecord is a part of Audit_API""],
    [""CreateAuditRecord"", ""contains"", ""Azure_Cosmos_DB"", ""CreateAuditRecord creates audit record in Azure_Cosmos_DB""],
    [""CreatePatient"", ""contains"", ""Azure_Cosmos_DB"", ""CreatePatient creates patient document in Azure_Cosmos_DB""],
    [""APIM"", ""called-from"", ""Outside_Services_Clients"", ""APIM receives success response from Outside_Services_Clients""]
  ]
}
```",5.546065536007518
30,mistral-nemo,../IMAGES NEW/Azure/09 Azure protect APIs original.txt,"
    To gain access to an application, an API client authenticates by providing credentials such as username and password. The IdP is Azure AD B2C in this solution, but you can use a different one.

    The authentication request goes via Azure Front Door to Azure AD B2C, which is configured with a custom domain for sign-in. Azure AD B2C authenticates the user and returns a JSON Web Token (JWT) bearer token back to the user.

    The client triggers an event that accesses a backend API. This event could be a click of a button on a web application or on a mobile device, or a direct call to the endpoint of the backend API.

    The request goes through Azure Front Door, whose back end is mapped to the public endpoint of API Management. API Management intercepts the request and validates the bearer token against Azure AD B2C by using its validate-jwt policy. If the token isn't valid, API Management rejects the request by responding with a 401 code.

    If the token is valid, API Management forwards the request to the appropriate backend API.

    The diagram shows backend APIs running in three environments:
        App Service Environment
        Function Apps
        Azure Kubernetes Services (AKS)

    APIs running in on-premises and hybrid cloud environments can also be integrated with API Management if network connectivity is established between the APIs and API Management.

","{""entities"": [[""API client"", ""system"", ""wants to gain access to an application""], [""application"", ""system"", ""API client wants to gain access to an application""], [""Azure AD B2C"", ""system"", ""The IdP is Azure AD B2C""], [""Azure Front Door"", ""system"", ""authentication request goes via Azure Front Door to Azure AD B2C""], [""backend API"", ""system"", ""The client triggers an event that accesses a backend API""], [""Azure Front Door"", ""system"", ""The request goes through Azure Front Door, whose back end is mapped to the public endpoint of API Management.""], [""backend"", ""component"", ""Azure Front Door, whose back end""], [""API Management"", ""system"", ""API Management intercepts the request and validates the bearer token against Azure AD B2C ""], [""public endpoint"", ""system"", ""whose back end is mapped to the public endpoint of API Management""], [""User"", ""person"", ""Azure AD B2C authenticates the user and returns a JSON Web Token (JWT) bearer token back to the user""]], ""relationships"": [[""API client"", ""calls"", ""application"", """"], [""Azure Front Door"", ""calls"", ""Azure AD B2C"", ""authentication request goes via Azure Front Door to Azure AD B2C""], [""Azure AD B2C"", ""is-called-from"", ""User"", ""Azure AD B2C authenticates the user and returns a JSON Web Token (JWT) bearer token back to the user""], [""API client"", ""calls"", ""backend API"", ""The client triggers an event that accesses a backend API""], [""Azure Front Door"", ""contains"", ""backend"", ""Azure Front Door, whose back end""], [""public endpoint"", ""part-of"", ""API Management"", ""Azure Front Door, whose back end""], [""backend"", ""calls"", ""public endpoint"", ""whose back end is mapped to the public endpoint of API Management""], [""API Management"", ""calls"", ""Azure AD B2C"", ""API Management intercepts the request and validates the bearer token against Azure AD B2C""]]}","{
  ""entities"": [
    [""API Client"", ""component""],
    [""Azure Front Door"", ""system""],
    [""Azure AD B2C"", ""system""],
    [""JSON Web Token (JWT) bearer token"", ""entity""],
    [""Backend API"", ""component""],
    [""App Service Environment"", ""system""],
    [""Function Apps"", ""system""],
    [""Azure Kubernetes Services (AKS)"", ""system""],
    [""API Management"", ""system""]
  ],
  ""relationships"": [
    [""API Client"", ""calls"", ""Azure Front Door""],
    [""Azure Front Door"", ""contains"", ""Azure AD B2C""],
    [""Azure Front Door"", ""called-from"", ""API Client""],
    [""Azure AD B2C"", ""returns"", ""JSON Web Token (JWT) bearer token""],
    [""Azure Front Door"", ""part-of"", ""API Management""],
    [""API Management"", ""contains"", ""Azure Front Door""],
    [""API Management"", ""validates"", ""JSON Web Token (JWT) bearer token""],
    [""API Management"", ""calls"", ""Backend API""],
    [""Backend API"", ""part-of"", ""App Service Environment""],
    [""Backend API"", ""part-of"", ""Function Apps""],
    [""Backend API"", ""part-of"", ""Azure Kubernetes Services (AKS)""]
  ]
}","{
  ""entities"": [
    [""API Client"", ""component""],
    [""Azure Front Door"", ""system""],
    [""Azure AD B2C"", ""system""],
    [""JSON Web Token (JWT) bearer token"", ""entity""],
    [""Backend API"", ""component""],
    [""App Service Environment"", ""system""],
    [""Function Apps"", ""system""],
    [""Azure Kubernetes Services (AKS)"", ""system""],
    [""API Management"", ""system""]
  ],
  ""relationships"": [
    [""API Client"", ""calls"", ""Azure Front Door""],
    [""Azure Front Door"", ""contains"", ""Azure AD B2C""],
    [""Azure Front Door"", ""called-from"", ""API Client""],
    [""Azure AD B2C"", ""returns"", ""JSON Web Token (JWT) bearer token""],
    [""Azure Front Door"", ""part-of"", ""API Management""],
    [""API Management"", ""contains"", ""Azure Front Door""],
    [""API Management"", ""validates"", ""JSON Web Token (JWT) bearer token""],
    [""API Management"", ""calls"", ""Backend API""],
    [""Backend API"", ""part-of"", ""App Service Environment""],
    [""Backend API"", ""part-of"", ""Function Apps""],
    [""Backend API"", ""part-of"", ""Azure Kubernetes Services (AKS)""]
  ]
}",4.990177703992231
31,mistral-nemo,../IMAGES NEW/Azure/15 Azure automate-document-classification.txt,"
    The user provides a document file that the web app uploads. The file contains multiple documents of various types. It can, for instance, be a PDF or multipage TIFF file.
        The document file is stored in Azure Blob Storage.
        The web app adds a command message to a storage queue to initiate pipeline processing.

    Durable Functions orchestration is triggered by the command message. The message contains metadata that identifies the location in Blob Storage of the document file to be processed. Each Durable Functions instance processes only one document file.

    The Scan activity function calls the Computer Vision Read API, passing in the location in storage of the document to be processed. Optical character recognition (OCR) results are returned to the orchestration to be used by subsequent activities.

    The Classify activity function calls the document classifier service that's hosted in an Azure Kubernetes Service (AKS) cluster. This service uses regular expression pattern matching to identify the starting page of each known document and to calculate how many document types are contained in the document file. The types and page ranges of the documents are calculated and returned to the orchestration.



Note

Azure doesn't offer a service that can classify multiple document types in a single file. This solution uses a non-Azure service that's hosted in AKS.

The Metadata Store activity function saves the document type and page range information in an Azure Cosmos DB store.

The Indexing activity function creates a new search document in the Cognitive Search service for each identified document type and uses the Azure AI Search libraries for .NET to include in the search document the full OCR results and document information. A correlation ID is also added to the search document so that the search results can be matched with the corresponding document metadata from Azure Cosmos DB.

End users can search for documents by contents and metadata. Correlation IDs in the search result set can be used to look up document records that are in Azure Cosmos DB. The records include links to the original document file in Blob Storage.


","{""entities"": [[""web app"", ""system"", ""The user provides a document file that the web app uploads""], [""Azure Blob Storage"", ""system"", ""The document file is stored in Azure Blob Storage""], [""storage queue"", ""system"", ""the web app adds a command message to a storage queue to initiate pipeline processing""], [""Durable Functions orchestration"", ""system"", ""Durable Functions orchestration is triggered by the command message.""], [""Scan activity function"", ""component"", ""The Scan activity function calls the Computer Vision Read API.""], [""Computer Vision Read API"", ""component"", ""The Scan activity function calls the Computer Vision Read API.""], [""Classify activity function"", ""component"", ""The Classify activity function calls the document classifier service that's hosted in an Azure Kubernetes Service (AKS) cluster""], [""document classifier service"", ""component"", ""The Classify activity function calls the document classifier service that's hosted in an Azure Kubernetes Service (AKS) cluster""], [""Azure Kubernetes Service (AKS) cluster"", ""system"", ""The Classify activity function calls the document classifier service that's hosted in an Azure Kubernetes Service (AKS) cluster""], [""User"", ""person"", ""provides a document file that the web app uploads""]], ""relationships"": [[""User"", ""calls"", ""web app"", ""The user provides a document file that the web app uploads""], [""web app"", ""calls"", ""Azure Blob Storage"", ""The user provides a document file that the web app uploads.The document file is stored in Azure Blob Storage""], [""web app"", ""calls"", ""storage queue"", ""the web app adds a command message to a storage queue to initiate pipeline processing""], [""storage queue"", ""calls"", ""Durable Functions orchestration"", ""Durable Functions orchestration is triggered by the command message.""], [""Durable Functions orchestration"", ""calls"", ""Azure Blob Storage"", ""Each Durable Functions instance processes only one document file""], [""Scan activity function"", ""calls"", ""Computer Vision Read API"", ""the Scan activity function calls the Computer Vision Read API""], [""document classifier service"", ""part-of"", ""Azure Kubernetes Service (AKS) cluster"", ""document classifier service that's hosted in an Azure Kubernetes Service (AKS) cluster""], [""Classify activity function"", ""calls"", ""Scan activity function"", ""The Classify activity function calls the document classifier service""], [""Classify activity function"", ""calls"", ""Durable Functions orchestration"", ""The types and page ranges of the documents are calculated and returned to the orchestration""]]}","Here's the extracted information in the requested JSON format:

```json
{
  ""entities"": [
    [""Azure Blob Storage"", ""system""],
    [""Web App"", ""component""],
    [""Durable Functions Orchestration"", ""component""],
    [""Scan Activity Function"", ""component""],
    [""Computer Vision Read API"", ""component""],
    [""Classify Activity Function"", ""component""],
    [""Document Classifier Service"", ""component""],
    [""Azure Kubernetes Service (AKS) cluster"", ""system""],
    [""Metadata Store Activity Function"", ""component""],
    [""Azure Cosmos DB store"", ""system""],
    [""Indexing Activity Function"", ""component""],
    [""Cognitive Search service"", ""component""]
  ],
  ""relationships"": [
    [""Web App"", ""adds"", ""Storage Queue"", ""to initiate pipeline processing""],
    [""Durable Functions Orchestration"", ""triggered by"", ""Command Message"", ""from Storage Queue""],
    [""Scan Activity Function"", ""calls"", ""Computer Vision Read API"", ""for OCR results""],
    [""Classify Activity Function"", ""calls"", ""Document Classifier Service"", ""to identify document types""],
    [""Document Classifier Service"", ""hosted in"", ""Azure Kubernetes Service (AKS) cluster""],
    [""Metadata Store Activity Function"", ""saves data in"", ""Azure Cosmos DB store""],
    [""Indexing Activity Function"", ""creates search documents in"", ""Cognitive Search service""]
  ]
}
```","Here's the extracted information in the requested JSON format:

```json
{
  ""entities"": [
    [""Azure Blob Storage"", ""system""],
    [""Web App"", ""component""],
    [""Durable Functions Orchestration"", ""component""],
    [""Scan Activity Function"", ""component""],
    [""Computer Vision Read API"", ""component""],
    [""Classify Activity Function"", ""component""],
    [""Document Classifier Service"", ""component""],
    [""Azure Kubernetes Service (AKS) cluster"", ""system""],
    [""Metadata Store Activity Function"", ""component""],
    [""Azure Cosmos DB store"", ""system""],
    [""Indexing Activity Function"", ""component""],
    [""Cognitive Search service"", ""component""]
  ],
  ""relationships"": [
    [""Web App"", ""adds"", ""Storage Queue"", ""to initiate pipeline processing""],
    [""Durable Functions Orchestration"", ""triggered by"", ""Command Message"", ""from Storage Queue""],
    [""Scan Activity Function"", ""calls"", ""Computer Vision Read API"", ""for OCR results""],
    [""Classify Activity Function"", ""calls"", ""Document Classifier Service"", ""to identify document types""],
    [""Document Classifier Service"", ""hosted in"", ""Azure Kubernetes Service (AKS) cluster""],
    [""Metadata Store Activity Function"", ""saves data in"", ""Azure Cosmos DB store""],
    [""Indexing Activity Function"", ""creates search documents in"", ""Cognitive Search service""]
  ]
}
```",5.417234380991431
32,mistral-nemo,../IMAGES NEW/Azure/05. azure Original.txt,"
    Backend systems. The right-hand side of the diagram shows the various backend systems that the enterprise has deployed or relies on. These systems might include SaaS systems, other Azure services, or web services that expose REST or SOAP endpoints.

    Azure Logic Apps. In this architecture, logic apps are triggered by HTTP requests. You can also nest workflows for more complex orchestration. Logic Apps uses connectors to integrate with commonly used services. Logic Apps offers hundreds of connectors, and you can create custom connectors.

    Azure API Management. API Management consists of two related components:

        API gateway. The API gateway accepts HTTP calls and routes them to the backend.

        Developer portal. Each instance of Azure API Management provides access to a developer portal. This portal gives your developers access to documentation and code samples for calling the APIs. You can also test APIs in the developer portal.

    Azure DNS. Azure DNS provides name resolution by using the Azure infrastructure. By hosting your domains in Azure, you can manage your DNS records by using the same credentials, APIs, tools, and billing that you use for your other Azure services. To use a custom domain name, such as contoso.com, create DNS records that map the custom domain name to the IP address. For more information, see Configure a custom domain name in API Management.

    Microsoft Entra ID. Use Microsoft Entra ID to authenticate clients that call the API gateway. Microsoft Entra ID supports the OpenID Connect (OIDC) protocol. Clients obtain an access token from Microsoft Entra ID, and API Gateway validates the token to authorize the request. If you use the Standard or Premium tier of API Management, Microsoft Entra ID can also help secure access to the developer portal.

","{""entities"": [[""Backend systems"", ""system"", ""various backend systems that the enterprise has deployed or relies on""], [""SaaS systems"", ""component"", ""SaaS systems""], [""other Azure services"", ""component"", ""other Azure services""], [""web services"", ""component"", ""expose REST or SOAP endpoints""], [""Azure Logic Apps"", ""system"", ""Logic Apps uses connectors to integrate with commonly used services""], [""Azure API Management"", ""system"", ""Logic Apps uses connectors to integrate with commonly used services""], [""API gateway"", ""component"", ""The API gateway accepts HTTP calls and routes them to the backend""], [""Developer portal"", ""component"", ""This portal gives your developers access to documentation and code samples for calling the APIs""], [""Azure DNS"", ""system"", ""Azure DNS provides name resolution by using the Azure infrastructure""], [""Microsoft Entra ID"", ""system"", ""Use Microsoft Entra ID to authenticate clients that call the API gateway""], [""clients"", ""system"", ""clients that call the API gateway""], [""developers"", ""person"", ""accesses documentation and code samples""]], ""relationships"": [[""Backend systems"", ""contains"", ""SaaS systems"", ""These systems might include ""], [""Backend systems"", ""contains"", ""web services"", ""These systems might include ""], [""Backend systems"", ""contains"", ""other Azure services"", ""These systems might include ""], [""web services"", ""contains"", ""SaaS systems"", ""These systems might include ""], [""Azure API Management"", ""contains"", ""API gateway"", ""API Management consists of two related components""], [""Azure API Management"", ""contains"", ""Developer portal"", ""API Management consists of two related components""], [""clients"", ""calls"", ""API gateway"", ""clients that call the API gateway""], [""clients"", ""calls"", ""Microsoft Entra ID"", ""Clients obtain an access token from Microsoft Entra ID""], [""developers"", ""calls"", ""Developer portal"", ""This portal gives your developers access to documentation and code samples for calling the APIs. You can also test APIs in the developer portal""]]}","Based on the provided context, here's the extracted entities and relationships in JSON format:

```json
{
  ""entities"": [
    [""Azure Logic Apps"", ""system"", ""A system that triggers workflows by HTTP requests and integrates with services using connectors.""],
    [""API gateway"", ""component"", ""A component of Azure API Management that accepts HTTP calls and routes them to the backend.""],
    [""Developer portal"", ""component"", ""A component of Azure API Management that provides access to documentation, code samples, and API testing for developers.""],
    [""Azure DNS"", ""system"", ""A system that provides name resolution using Azure infrastructure.""],
    [""Microsoft Entra ID"", ""system"", ""A system that authenticates clients calling the API gateway and secures access to the developer portal.""],
    [""HTTP requests"", ""component"", ""The triggering mechanism for Azure Logic Apps workflows.""],
    [""Azure services"", ""system"", ""Various backend systems deployed or relied on by the enterprise, including SaaS systems and web services with REST or SOAP endpoints.""]
  ],
  ""relationships"": [
    [""Azure Logic Apps"", ""contains"", ""HTTP requests""],
    [""API gateway"", ""part-of"", ""Azure API Management""],
    [""Developer portal"", ""part-of"", ""Azure API Management""],
    [""Azure API Management"", ""calls"", ""Azure Logic Apps""],
    [""Microsoft Entra ID"", ""called-from"", ""API gateway""],
    [""Microsoft Entra ID"", ""secures"", ""Developer portal""],
    [""Azure DNS"", ""contains"", ""Azure services""]
  ]
}
```","Based on the provided context, here's the extracted entities and relationships in JSON format:

```json
{
  ""entities"": [
    [""Azure Logic Apps"", ""system"", ""A system that triggers workflows by HTTP requests and integrates with services using connectors.""],
    [""API gateway"", ""component"", ""A component of Azure API Management that accepts HTTP calls and routes them to the backend.""],
    [""Developer portal"", ""component"", ""A component of Azure API Management that provides access to documentation, code samples, and API testing for developers.""],
    [""Azure DNS"", ""system"", ""A system that provides name resolution using Azure infrastructure.""],
    [""Microsoft Entra ID"", ""system"", ""A system that authenticates clients calling the API gateway and secures access to the developer portal.""],
    [""HTTP requests"", ""component"", ""The triggering mechanism for Azure Logic Apps workflows.""],
    [""Azure services"", ""system"", ""Various backend systems deployed or relied on by the enterprise, including SaaS systems and web services with REST or SOAP endpoints.""]
  ],
  ""relationships"": [
    [""Azure Logic Apps"", ""contains"", ""HTTP requests""],
    [""API gateway"", ""part-of"", ""Azure API Management""],
    [""Developer portal"", ""part-of"", ""Azure API Management""],
    [""Azure API Management"", ""calls"", ""Azure Logic Apps""],
    [""Microsoft Entra ID"", ""called-from"", ""API gateway""],
    [""Microsoft Entra ID"", ""secures"", ""Developer portal""],
    [""Azure DNS"", ""contains"", ""Azure services""]
  ]
}
```",5.770936974993674
33,mistral-nemo,../IMAGES NEW/Azure/16 Azure automate-pdf-forms.txt,"
    A designated Outlook email account receives PDF files as attachments. The arrival of an email triggers a logic app to process the email. The logic app is built by using the capabilities of Azure Logic Apps.
    The logic app uploads the PDF files to a container in Azure Data Lake Storage.
    You can also manually or programmatically upload PDF files to the same PDF container.
    The arrival of a PDF file in the PDF container triggers another logic app to process the PDF forms that are in the PDF file.
    The logic app sends the location of the PDF file to a function app for processing. The function app is built by using the capabilities of Azure Functions.
    The function app receives the location of the file and takes these actions:
        It splits the file into single pages if the file has multiple pages. Each page contains one independent form. Split files are saved to a second container in Data Lake Storage.
        It uses HTTPS POST, an Azure REST API, to send the location of the single-page PDF file to AI Document Intelligence for processing. When Azure AI Document Intelligence completes its processing, it sends a response back to the function app, which places the information into a data structure.
        It creates a JSON data file that contains the response data and stores the file to a third container in Data Lake Storage.
    The forms processing logic app receives the processed response data.
    The forms processing logic app sends the processed data to Azure Cosmos DB, which saves the data in a database and in collections.
    Power BI obtains the data from Azure Cosmos DB and provides insights and dashboards.
    You can implement further processing as needed on the data that's in Azure Cosmos DB.

","{""entities"": [[""designated Outlook email account"", ""component"", ""A designated Outlook email account receives PDF files as attachments""], [""logic app"", ""component"", ""The arrival of an email triggers a logic app to process the email.""], [""Azure Logic Apps"", ""system"", ""The logic app is built by using the capabilities of Azure Logic Apps.""], [""Container"", ""component"", ""The logic app uploads the PDF files to a container in Azure Data Lake Storage""], [""Azure Data Lake Storage"", ""system"", ""The logic app uploads the PDF files to a container in Azure Data Lake Storage""], [""logic app 2"", ""system"", ""The arrival of a PDF file in the PDF container triggers another logic app to process the PDF forms""], [""function app"", ""component"", ""The logic app sends the location of the PDF file to a function app for processing.""], [""Azure Functions"", ""system"", ""The function app is built by using the capabilities of Azure Functions""], [""Azure REST API"", ""component"", ""It uses HTTPS POST, an Azure REST API, to send the location of the single-page PDF file""], [""Container 2"", ""component"", ""Split files are saved to a second container in Data Lake Storage""], [""AI Document Intelligence"", ""component"", ""It uses HTTPS POST, an Azure REST API, to send the location of the single-page PDF file to AI Document Intelligence for processing""], [""Container 3"", ""component"", ""JSON data file that contains the response data and stores the file to a third container in Data Lake Storage""], [""forms processing logic app"", ""component"", ""The forms processing logic app receives the processed response data""], [""Azure Cosmos DB"", ""component"", ""The forms processing logic app sends the processed data to Azure Cosmos DB""], [""database"", ""component"", ""Azure Cosmos DB, which saves the data in a database""], [""Power BI"", ""component"", ""Power BI obtains the data from Azure Cosmos DB and provides insights and dashboards""]], ""relationships"": [[""designated Outlook email account"", ""calls"", ""logic app"", ""The arrival of an email triggers a logic app to process the email.""], [""Azure Logic Apps"", ""contains"", ""logic app"", ""The logic app is built by using the capabilities of Azure Logic Apps.""], [""logic app"", ""calls"", ""Container"", ""The logic app uploads the PDF files to a container in Azure Data Lake Storage""], [""Container"", ""part-of"", ""Azure Data Lake Storage"", ""container in Azure Data Lake Storage""], [""Container"", ""calls"", ""logic app 2"", ""The arrival of a PDF file in the PDF container triggers another logic app""], [""logic app"", ""calls"", ""function app"", ""The logic app sends the location of the PDF file to a function app for processing.""], [""function app"", ""part-of"", ""Azure Functions"", ""container in Azure Data Lake Storage""], [""function app"", ""calls"", ""Container 2"", ""Split files are saved to a second container in Data Lake Storage""], [""Azure Data Lake Storage"", ""contains"", ""Container 2"", ""Split files are saved to a second container in Data Lake Storage""], [""function app"", ""calls"", ""Azure REST API"", ""It uses HTTPS POST, an Azure REST API""], [""Azure REST API"", ""calls"", ""AI Document Intelligence"", ""HTTPS POST, an Azure REST API, to send the location of the single-page PDF file to AI Document Intelligence""], [""Azure Data Lake Storage"", ""contains"", ""Container 3"", ""third container in Data Lake Storage""], [""function app"", ""calls"", ""Container 3"", ""It creates a JSON data file that contains the response data and stores the file to a third container""], [""forms processing logic app"", ""calls"", ""Container 3"", ""The forms processing logic app receives the processed response data""], [""forms processing logic app"", ""calls"", ""Azure Cosmos DB"", ""The forms processing logic app sends the processed data to Azure Cosmos DB""], [""Azure Cosmos DB"", ""calls"", ""database"", ""Azure Cosmos DB, which saves the data in a database""], [""Power BI"", ""calls"", ""Azure Cosmos DB"", ""Power BI obtains the data from Azure Cosmos DB and provides insights and dashboards""]]}","Here's the JSON response based on the provided text:

```json
{
  ""entities"": [
    [""Outlook Email Account"", ""system""],
    [""Logic App (Email Trigger)"", ""component""],
    [""Azure Logic Apps"", ""system""],
    [""Azure Data Lake Storage (PDF Container)"", ""component""],
    [""Logic App (PDF Processing)"", ""component""],
    [""Azure Functions"", ""system""],
    [""Function App"", ""component""],
    [""AI Document Intelligence"", ""system""],
    [""Azure Cosmos DB"", ""system""],
    [""Power BI"", ""system""]
  ],
  ""relationships"": [
    [""Outlook Email Account"", ""contains"", ""Logic App (Email Trigger)""],
    [""Logic App (Email Trigger)"", ""calls"", ""Azure Logic Apps""],
    [""Logic App (Email Trigger)"", ""contains"", ""Azure Data Lake Storage (PDF Container)""],
    [""Azure Data Lake Storage (PDF Container)"", ""part-of"", ""Logic App (Email Trigger)""],
    [""Logic App (PDF Processing)"", ""called-from"", ""Azure Data Lake Storage (PDF Container)""],
    [""Function App"", ""calls"", ""AI Document Intelligence""],
    [""AI Document Intelligence"", ""contains"", ""Function App""],
    [""Logic App (Forms Processing)"", ""calls"", ""Azure Cosmos DB""],
    [""Azure Cosmos DB"", ""contains"", ""Logic App (Forms Processing)""],
    [""Power BI"", ""called-from"", ""Azure Cosmos DB""]
  ]
}
```","Here's the JSON response based on the provided text:

```json
{
  ""entities"": [
    [""Outlook Email Account"", ""system""],
    [""Logic App (Email Trigger)"", ""component""],
    [""Azure Logic Apps"", ""system""],
    [""Azure Data Lake Storage (PDF Container)"", ""component""],
    [""Logic App (PDF Processing)"", ""component""],
    [""Azure Functions"", ""system""],
    [""Function App"", ""component""],
    [""AI Document Intelligence"", ""system""],
    [""Azure Cosmos DB"", ""system""],
    [""Power BI"", ""system""]
  ],
  ""relationships"": [
    [""Outlook Email Account"", ""contains"", ""Logic App (Email Trigger)""],
    [""Logic App (Email Trigger)"", ""calls"", ""Azure Logic Apps""],
    [""Logic App (Email Trigger)"", ""contains"", ""Azure Data Lake Storage (PDF Container)""],
    [""Azure Data Lake Storage (PDF Container)"", ""part-of"", ""Logic App (Email Trigger)""],
    [""Logic App (PDF Processing)"", ""called-from"", ""Azure Data Lake Storage (PDF Container)""],
    [""Function App"", ""calls"", ""AI Document Intelligence""],
    [""AI Document Intelligence"", ""contains"", ""Function App""],
    [""Logic App (Forms Processing)"", ""calls"", ""Azure Cosmos DB""],
    [""Azure Cosmos DB"", ""contains"", ""Logic App (Forms Processing)""],
    [""Power BI"", ""called-from"", ""Azure Cosmos DB""]
  ]
}
```",5.3853542339929845
34,mistral-nemo,../IMAGES NEW/Azure/06 Azure logic-apps-data-integration.txt,"
    API Management accepts API calls in the form of HTTP requests.

    API Management securely routes the HTTP requests to Logic Apps.

    Each HTTP request triggers a run in Logic Apps:
        Logic Apps uses secured template parameters to retrieve database credentials from Azure Key Vault.
        Logic Apps uses Transport Layer Security (TLS) to send the database credentials and a database statement to the on-premises data gateway.

    The on-premises data gateway connects to a SQL Server database to run the statement.

    SQL Server stores the data and makes it available to apps that users access.

    Azure Monitor collects information on Logic Apps events and performance.

","{""entities"": [[""API Management"", ""system"", ""accepts API calls in the form of HTTP requests""], [""Logic Apps"", ""system"", ""uses secured template parameters to retrieve database credentials from Azure Key Vault""], [""on-premises data gateway"", ""system"", """"], [""SQL Server"", ""system"", ""stores the data and makes it available to apps that users access""], [""Azure Monitor"", ""system"", ""collects information on Logic Apps events and performance""], [""Azure Key Vault"", ""system"", ""database credentials""]], ""relationships"": [[""API Management"", ""calls"", ""Logic Apps"", ""routes the HTTP requests to Logic Apps""], [""Logic Apps"", ""calls"", ""Azure Key Vault"", ""Logic Apps uses secured template parameters to retrieve database credentials from Azure Key Vault""], [""Logic Apps"", ""calls"", ""on-premises data gateway"", ""send the database credentials and a database statement to the on-premises data gateway""], [""on-premises data gateway"", ""calls"", ""SQL Server"", ""connects to a SQL Server database""], [""Azure Monitor"", ""calls"", ""Logic Apps"", ""collects information on Logic Apps events and performance""]]}","{
  ""entities"": [
    [""API Management"", ""system""],
    [""Logic Apps"", ""system""],
    [""Azure Key Vault"", ""component""],
    [""on-premises data gateway"", ""component""],
    [""SQL Server database"", ""system""]
  ],
  ""relationships"": [
    [""API Management"", ""calls"", ""Logic Apps""],
    [""Logic Apps"", ""contains"", ""Azure Key Vault""],
    [""Logic Apps"", ""called-from"", ""Azure Key Vault""],
    [""Logic Apps"", ""calls"", ""on-premises data gateway""],
    [""on-premises data gateway"", ""part-of"", ""SQL Server database""],
    [""SQL Server database"", ""stores-data-for"", ""apps accessed by users""]
  ]
}","{
  ""entities"": [
    [""API Management"", ""system""],
    [""Logic Apps"", ""system""],
    [""Azure Key Vault"", ""component""],
    [""on-premises data gateway"", ""component""],
    [""SQL Server database"", ""system""]
  ],
  ""relationships"": [
    [""API Management"", ""calls"", ""Logic Apps""],
    [""Logic Apps"", ""contains"", ""Azure Key Vault""],
    [""Logic Apps"", ""called-from"", ""Azure Key Vault""],
    [""Logic Apps"", ""calls"", ""on-premises data gateway""],
    [""on-premises data gateway"", ""part-of"", ""SQL Server database""],
    [""SQL Server database"", ""stores-data-for"", ""apps accessed by users""]
  ]
}",3.022488932008855
35,mistral-nemo,../IMAGES NEW/TEST/08 Azure Business Processes.txt,"
The data flows through the solution as follows:

    The airline system communicates with a custom API hosted in Azure API Management.
    A custom API coordinator receives notifications and handles incoming messages from the airline system. It sends them to Power Apps, where flights are assigned to Microsoft Teams channels.
    When a user selects a flight to monitor, or when the system assigns the user to a flight, the system queues a Graph API call in an Azure Storage Account queue for further processing.
    Azure Functions runs the Graph API calls based on the incoming messages in the storage queue, sending notifications to Teams, and also streams all events to an Azure Event Hubs for further analytics.
    The airline's notification system is managed by a custom bot messaging service that employs Azure Bot Service.
    Custom bots send flight updates to users in Teams.
    An Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs, ultimately generating insightful reports with Power BI.

","{""entities"": [[""airline system"", ""system"", ""communicates with a custom API hosted in Azure API Management""], [""custom API"", ""component"", ""communicates with a custom API hosted in Azure API Management""], [""Azure API Management"", ""system"", ""communicates with a custom API hosted in Azure API Management""], [""custom API coordinator"", ""system"", ""receives notifications and handles incoming messages from the airline system""], [""Power Apps"", ""system"", ""where flights are assigned to Microsoft Teams channels""], [""Microsoft Teams channels"", ""system"", ""where flights are assigned to Microsoft Teams channels""], [""Storage Account queue"", ""system"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing.""], [""Graph API call"", ""system"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing.""], [""Azure Functions"", ""system"", ""runs the Graph API calls based on the incoming messages in the storage queue""], [""Azure Event Hubs"", ""system"", ""Azure Event Hubs for further analytics""], [""notification system"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""custom bot messaging service"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""Azure Bot Service"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""Users"", ""person"", ""selects a flight to monitor, or when the system assigns the user to a flight""], [""Azure Data Lake storage"", ""system"", ""offers long-term retention and micro-batch processing of events from Event Hubs""], [""Power BI"", ""system"", ""generating insightful reports""]], ""relationships"": [[""Azure API Management"", ""contains"", ""custom API"", ""custom API hosted in Azure API Management""], [""airline system"", ""calls"", ""custom API"", ""communicates with a custom API""], [""custom API coordinator"", ""is-called-from"", ""airline system"", ""receives notifications and handles incoming messages from the airline system""], [""Power Apps"", ""calls"", ""Microsoft Teams channels"", ""Power Apps, where flights are assigned to Microsoft Teams channels""], [""airline system"", ""calls"", ""Graph API call"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing""], [""Azure Functions"", ""calls"", ""Graph API call"", ""runs the Graph API calls based on the incoming messages in the storage queue""], [""Azure Functions"", ""calls"", ""Storage Account queue"", ""based on the incoming messages in the storage queue""], [""Azure Functions"", ""calls"", ""Microsoft Teams channels"", ""sending notifications to Teams""], [""Azure Functions"", ""calls"", ""Azure Event Hubs"", ""also streams all events to an Azure Event Hubs for further analytics""], [""notification system"", ""is-called-from"", ""custom bot messaging service"", ""managed by a custom bot messaging service""], [""custom bot messaging service"", ""calls"", ""Azure Bot Service"", ""custom bot messaging service that employs Azure Bot Service""], [""custom bot messaging service"", ""calls"", ""Microsoft Teams channels"", ""Custom bots send flight updates to users in Teams.""], [""Microsoft Teams channels"", ""calls"", ""Users"", ""Custom bots send flight updates to users in Teams.""], [""Azure Data Lake storage"", ""is-called-from"", ""Azure Event Hubs"", ""Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs""], [""Azure Data Lake storage"", ""calls"", ""Power BI"", ""Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs, ultimately generating insightful reports with Power BI""]]}","{
  ""entities"": [
    [""Airline System"", ""system""],
    [""Custom API"", ""component""],
    [""Azure API Management"", ""system""],
    [""Custom API Coordinator"", ""component""],
    [""Power Apps"", ""system""],
    [""Microsoft Teams"", ""system""],
    [""Azure Storage Account"", ""system""],
    [""Azure Functions"", ""system""],
    [""Graph API"", ""component""],
    [""Azure Event Hubs"", ""system""],
    [""Custom Bot Messaging Service"", ""system""],
    [""Azure Bot Service"", ""system""],
    [""Azure Data Lake storage"", ""system""],
    [""Power BI"", ""system""]
  ],
  ""relationships"": [
    [""Airline System"", ""calls"", ""Custom API""],
    [""Custom API Coordinator"", ""part-of"", ""Airline System""],
    [""Custom API Coordinator"", ""calls"", ""Power Apps""],
    [""Custom API Coordinator"", ""contains"", ""Graph API""],
    [""Azure Storage Account"", ""contains"", ""Graph API""],
    [""Azure Functions"", ""runs"", ""Graph API""],
    [""Azure Functions"", ""sends"", ""Microsoft Teams""],
    [""Azure Functions"", ""streams to"", ""Azure Event Hubs""],
    [""Custom Bot Messaging Service"", ""part-of"", ""Airline System""],
    [""Custom Bot Messaging Service"", ""calls"", ""Azure Bot Service""],
    [""Azure Bot Service"", ""sends messages to"", ""Microsoft Teams""],
    [""Azure Event Hubs"", ""processed by"", ""Azure Data Lake storage""],
    [""Azure Data Lake storage"", ""generates reports with"", ""Power BI""]
  ]
}","{
  ""entities"": [
    [""Airline System"", ""system""],
    [""Custom API"", ""component""],
    [""Azure API Management"", ""system""],
    [""Custom API Coordinator"", ""component""],
    [""Power Apps"", ""system""],
    [""Microsoft Teams"", ""system""],
    [""Azure Storage Account"", ""system""],
    [""Azure Functions"", ""system""],
    [""Graph API"", ""component""],
    [""Azure Event Hubs"", ""system""],
    [""Custom Bot Messaging Service"", ""system""],
    [""Azure Bot Service"", ""system""],
    [""Azure Data Lake storage"", ""system""],
    [""Power BI"", ""system""]
  ],
  ""relationships"": [
    [""Airline System"", ""calls"", ""Custom API""],
    [""Custom API Coordinator"", ""part-of"", ""Airline System""],
    [""Custom API Coordinator"", ""calls"", ""Power Apps""],
    [""Custom API Coordinator"", ""contains"", ""Graph API""],
    [""Azure Storage Account"", ""contains"", ""Graph API""],
    [""Azure Functions"", ""runs"", ""Graph API""],
    [""Azure Functions"", ""sends"", ""Microsoft Teams""],
    [""Azure Functions"", ""streams to"", ""Azure Event Hubs""],
    [""Custom Bot Messaging Service"", ""part-of"", ""Airline System""],
    [""Custom Bot Messaging Service"", ""calls"", ""Azure Bot Service""],
    [""Azure Bot Service"", ""sends messages to"", ""Microsoft Teams""],
    [""Azure Event Hubs"", ""processed by"", ""Azure Data Lake storage""],
    [""Azure Data Lake storage"", ""generates reports with"", ""Power BI""]
  ]
}",5.863146007002797
36,mistral-nemo,../IMAGES NEW/Azure/14 Azure Call Center Analytics.txt,"
    A phone call between an agent and a customer is recorded and stored in Azure Blob Storage. Audio files are uploaded to an Azure Storage account via a supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API.

    Azure AI Speech is used to transcribe audio files in Batch mode asynchronously with speaker diarization enabled. The transcription results are persisted in Blob Storage.

    Azure AI Language is used to detect and redact personal data in the transcript.

    For batch mode transcription and personal data detection and redaction, use the AI services Ingestion Client tool. The Ingestion Client tool uses a no-code approach for call center transcription.

    Azure OpenAI is used to process the transcript and extract entities, summarize the conversation, and analyze sentiments. The processed output is stored in Blob Storage and then analyzed and visualized by using other services. You can also store the output in a datastore for keeping track of metadata and for reporting. Use Azure OpenAI to process the stored transcription information.

    Power BI or a custom web application that's hosted by App Service is used to visualize the output. Both options provide near real-time insights. You can store this output in a customer relationship management (CRM), so agents have contextual information about why the customer called and can quickly solve potential problems. This process is fully automated, which saves the agents time and effort.

","{""entities"": [[""phone call"", ""component"", ""A phone call between an agent and a customer is recorded""], [""agent"", ""person"", ""A phone call between an agent and a customer is recorded""], [""customer"", ""person"", ""A phone call between an agent and a customer is recorded""], [""Azure Blob Storage"", ""system"", ""is recorded and stored in Azure Blob Storage""], [""Audio files"", ""system"", ""Audio files are uploaded to an Azure Storage account via a supported method""], [""supported method"", ""component"", ""Audio files are uploaded to an Azure Storage account via a supported method""], [""UI-based tool"", ""component"", ""supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""Azure Storage Explorer"", ""component"", ""supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""Storage SDK"", ""component"", ""supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""API"", ""component"", ""supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""Azure AI Speech"", ""component"", ""transcribe audio files in Batch mode asynchronously""], [""transcription results"", ""component"", ""The transcription results are persisted in Blob Storage.""], [""Azure AI Language"", ""component"", ""Azure AI Language is used to detect and redact personal data in the transcript.""], [""AI services Ingestion Client tool"", ""component"", ""For batch mode transcription and personal data detection and redaction, use the AI services Ingestion Client tool""], [""Azure OpenAI"", ""component"", ""Azure OpenAI is used to process the transcript and extract entities, summarize the conversation, and analyze sentiments.""], [""Azure OpenAI output"", ""component"", ""The processed output is stored in Blob Storage and then analyzed and visualized by using other services.""], [""other services"", ""component"", ""The processed output is stored in Blob Storage and then analyzed and visualized by using other services.""], [""App Service"", ""system"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""Power BI"", ""system"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""custom web application"", ""system"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""Azure OpenAI output 2"", ""component"", ""You can also store the output in a datastore for keeping track of metadata and for reporting""], [""datastore"", ""component"", ""You can also store the output in a datastore for keeping track of metadata and for reporting""], [""customer relationship management (CRM)"", ""system"", ""You can store this output in a customer relationship management (CRM)""], [""Azure OpenAI output 3"", ""component"", ""You can store this output in a customer relationship management (CRM)""]], ""relationships"": [[""agent"", ""calls"", ""phone call"", ""A phone call between an agent and a customer is recorded""], [""customer"", ""calls"", ""phone call"", ""A phone call between an agent and a customer is recorded""], [""phone call"", ""part-of"", ""Azure Blob Storage"", ""is recorded and stored in Azure Blob Storage""], [""Audio files"", ""part-of"", ""Azure Blob Storage"", ""Audio files are uploaded to an Azure Storage account via a supported method""], [""supported method"", ""calls"", ""Audio files"", ""Audio files are uploaded to an Azure Storage account via a supported method""], [""supported method"", ""contains"", ""UI-based tool"", ""upported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""supported method"", ""contains"", ""Azure Storage Explorer"", ""upported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""supported method"", ""contains"", ""Storage SDK"", ""upported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""supported method"", ""contains"", ""API"", ""supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""Azure AI Speech"", ""calls"", ""Audio files"", ""transcribe audio files in Batch mode asynchronously""], [""Azure Blob Storage"", ""contains"", ""transcription results"", ""The transcription results are persisted in Blob Storage.""], [""Azure AI Speech"", ""calls"", ""transcription results"", ""The transcription results are persisted in Blob Storage.""], [""Azure AI Language"", ""calls"", ""transcription results"", ""Azure AI Language is used to detect and redact personal data in the transcript.""], [""AI services Ingestion Client tool"", ""calls"", ""transcription results"", ""For batch mode transcription and personal data detection and redaction, use the AI services Ingestion Client tool""], [""Azure OpenAI"", ""calls"", ""transcription results"", ""Azure OpenAI is used to process the transcript and extract entities, summarize the conversation, and analyze sentiments.""], [""Azure OpenAI"", ""calls"", ""Azure OpenAI output"", ""The processed output is stored in Blob Storage and then analyzed and visualized by using other services.""], [""Azure Blob Storage"", ""contains"", ""Azure OpenAI output"", ""The processed output is stored in Blob Storage and then analyzed and visualized by using other services.""], [""other services"", ""calls"", ""Azure OpenAI output"", ""The processed output is stored in Blob Storage and then analyzed and visualized by using other services.""], [""Power BI"", ""part-of"", ""App Service"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""custom web application"", ""part-of"", ""App Service"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""custom web application"", ""calls"", ""Azure OpenAI output"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""Power BI"", ""calls"", ""Azure OpenAI output"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""agent"", ""calls"", ""customer relationship management (CRM)"", ""You can store this output in a customer relationship management (CRM), so agents have contextual information about why the customer called and can quickly solve potential problems""], [""Azure OpenAI output 2"", ""part-of"", ""datastore"", ""You can also store the output in a datastore for keeping track of metadata and for reporting""], [""Azure OpenAI output 3"", ""part-of"", ""customer relationship management (CRM)"", ""You can also store the output in a datastore for keeping track of metadata and for reporting""], [""Azure OpenAI output"", ""calls"", ""Azure OpenAI output 2"", ""You can also store the output in a datastore for keeping track of metadata and for reporting""], [""Azure OpenAI output"", ""calls"", ""Azure OpenAI output 3"", ""You can store this output in a customer relationship management (CRM), so agents have contextual information about why the customer called and can quickly solve potential problems""]]}","Here's the JSON response based on the provided text:

```json
{
  ""entities"": [
    [""Azure Blob Storage"", ""system"", ""Stores audio files and transcription results""],
    [""Agent"", ""person"", ""The user having a conversation with the customer""],
    [""Customer"", ""person"", ""The user being called by the agent""],
    [""Azure AI Speech"", ""component"", ""Used for transcribing audio files""],
    [""Azure AI Language"", ""component"", ""Used for detecting and redacting personal data in transcriptions""],
    [""Azure OpenAI"", ""system"", ""Used for processing transcriptions, extracting entities, summarizing conversations, and analyzing sentiments""],
    [""Ingestion Client tool"", ""component"", ""A no-code tool used for batch mode transcription and personal data detection/redaction""],
    [""App Service"", ""system"", ""Hosts a custom web application for visualizing output""],
    [""Power BI"", ""system"", ""Used for visualizing output""],
    [""CRM"", ""system"", ""Stores output for agent reference""]
  ],
  ""relationships"": [
    [""Azure Blob Storage"", ""contains"", ""Agent's audio file""],
    [""Azure AI Speech"", ""calls"", ""Azure Blob Storage""],
    [""Azure AI Language"", ""called-from"", ""Azure AI Speech""],
    [""Azure OpenAI"", ""calls"", ""Azure Blob Storage""],
    [""Power BI"", ""contains"", ""Visualized output""],
    [""CRM"", ""stores"", ""Output for agent reference""]
  ]
}
```","Here's the JSON response based on the provided text:

```json
{
  ""entities"": [
    [""Azure Blob Storage"", ""system"", ""Stores audio files and transcription results""],
    [""Agent"", ""person"", ""The user having a conversation with the customer""],
    [""Customer"", ""person"", ""The user being called by the agent""],
    [""Azure AI Speech"", ""component"", ""Used for transcribing audio files""],
    [""Azure AI Language"", ""component"", ""Used for detecting and redacting personal data in transcriptions""],
    [""Azure OpenAI"", ""system"", ""Used for processing transcriptions, extracting entities, summarizing conversations, and analyzing sentiments""],
    [""Ingestion Client tool"", ""component"", ""A no-code tool used for batch mode transcription and personal data detection/redaction""],
    [""App Service"", ""system"", ""Hosts a custom web application for visualizing output""],
    [""Power BI"", ""system"", ""Used for visualizing output""],
    [""CRM"", ""system"", ""Stores output for agent reference""]
  ],
  ""relationships"": [
    [""Azure Blob Storage"", ""contains"", ""Agent's audio file""],
    [""Azure AI Speech"", ""calls"", ""Azure Blob Storage""],
    [""Azure AI Language"", ""called-from"", ""Azure AI Speech""],
    [""Azure OpenAI"", ""calls"", ""Azure Blob Storage""],
    [""Power BI"", ""contains"", ""Visualized output""],
    [""CRM"", ""stores"", ""Output for agent reference""]
  ]
}
```",5.571934737992706
37,mistral-nemo,../IMAGES NEW/Azure/13 Azure Secure Research.txt,"
    Data owners upload datasets into a public blob storage account. The data is encrypted by using Microsoft-managed keys.

    Azure Data Factory uses a trigger that starts copying of the uploaded dataset to a specific location (import path) on another storage account with security controls. The storage account can only be reached through a private endpoint. Also, it's accessed by a service principal with limited permissions. Data Factory deletes the original copy making the dataset immutable.

    Researchers access the secure environment through a streaming application using Azure Virtual Desktop as a privileged jump box.

    The dataset in the secure storage account is presented to the data science VMs provisioned in a secure network environment for research work. Much of the data preparation is done on those VMs.

    The secure environment has Azure Machine Learning compute that can access the dataset through a private endpoint for users for Azure Machine Learning capabilities, such as to train, deploy, automate, and manage machine learning models. At this point, models are created that meet regulatory guidelines. All model data is de-identified by removing personal information.

    Models or de-identified data is saved to a separate location on the secure storage (export path). When new data is added to the export path, a logic app is triggered. In this architecture, the logic app is outside the secure environment because no data is sent to the logic app. Its only function is to send notification and start the manual approval process.

    The app starts an approval process requesting a review of data that is queued to be exported. The manual reviewers ensure that sensitive data isn't exported. After the review process, the data is either approved or denied.

    Note

    If an approval step is not required on exfiltration, the logic app step could be omitted.

    If the de-identified data is approved, it's sent to the Data Factory instance.

    Data Factory moves the data to the public storage account in a separate container to allow external researchers to have access to their exported data and models. Alternately, you can provision another storage account in a lower security environment.

","{""entities"": [[""datasets"", ""component"", ""Data owners upload datasets into a public blob storage account""], [""public blob storage account"", ""system"", ""Data owners upload datasets into a public blob storage account""], [""Azure Data Factory"", ""system"", ""Azure Data Factory uses a trigger that starts copying of the uploaded dataset to a specific location""], [""storage account"", ""system"", ""Azure Data Factory uses a trigger that starts copying of the uploaded dataset to a specific location (import path) on another storage account with security controls""], [""copied dataset"", ""system"", ""Azure Data Factory uses a trigger that starts copying of the uploaded dataset to a specific location (import path) on another storage account with security controls""], [""private endpoint"", ""component"", ""The storage account can only be reached through a private endpoint.""], [""service principal"", ""component"", ""Also, it's accessed by a service principal with limited permissions.""], [""streaming application"", ""component"", ""access the secure environment through a streaming application""], [""Azure Virtual Desktop"", ""component"", ""Azure Virtual Desktop as a privileged jump box""], [""data science VMs"", ""component"", ""data science VMs provisioned in a secure network environment""], [""Azure Machine Learning compute"", ""component"", ""The secure environment has Azure Machine Learning compute that can access the dataset""], [""secure network environment"", ""system"", ""data science VMs provisioned in a secure network environment""], [""machine learning models"", ""component"", ""At this point, models are created that meet regulatory guidelines""], [""de-identified data"", ""component"", ""Models or de-identified data is saved to a separate location on the secure storage (export path)""], [""logic app"", ""component"", ""When new data is added to the export path, a logic app is triggered""], [""separate container"", ""component"", ""Data Factory moves the data to the public storage account in a separate container""], [""moved data"", ""component"", ""Data Factory moves the data to the public storage account in a separate container""], [""Data owners"", ""person"", ""Data owners upload datasets into a public blob storage account""], [""Researchers"", ""person"", ""Researchers access the secure environment through a streaming application using Azure Virtual Desktop as a privileged jump box""], [""manual reviewers"", ""person"", ""The manual reviewers ensure that sensitive data isn't exported.""], [""Users"", ""person"", ""The secure environment has Azure Machine Learning compute that can access the dataset""]], ""relationships"": [[""datasets"", ""part-of"", ""public blob storage account"", ""Data owners upload datasets into a public blob storage account""], [""Data owners"", ""calls"", ""datasets"", ""Data owners upload datasets into a public blob storage account""], [""Azure Data Factory"", ""calls"", ""datasets"", ""Azure Data Factory uses a trigger that starts copying of the uploaded dataset""], [""storage account"", ""contains"", ""copied dataset"", ""opying of the uploaded dataset to a specific location (import path) on another storage account with security controls""], [""Azure Data Factory"", ""calls"", ""copied dataset"", ""Azure Data Factory uses a trigger that starts copying of the uploaded dataset to a specific location""], [""private endpoint"", ""calls"", ""storage account"", ""The storage account can only be reached through a private endpoint""], [""storage account"", ""is-called-from"", ""service principal"", ""Also, it's accessed by a service principal with limited permissions""], [""Researchers"", ""calls"", ""Azure Virtual Desktop"", "" Researchers access the secure environment through a streaming application""], [""Azure Virtual Desktop"", ""calls"", ""streaming application"", ""through a streaming application using Azure Virtual Desktop""], [""streaming application"", ""calls"", ""storage account"", ""Researchers access the secure environment through a streaming application using Azure Virtual Desktop as a privileged jump box""], [""data science VMs"", ""part-of"", ""secure network environment"", ""The dataset in the secure storage account is presented to the data science VMs""], [""data science VMs"", ""calls"", ""copied dataset"", "" The dataset in the secure storage account is presented to the data science VMs""], [""secure network environment"", ""contains"", ""Azure Machine Learning compute"", ""The secure environment has Azure Machine Learning compute that can access the dataset""], [""Azure Machine Learning compute"", ""calls"", ""Azure Machine Learning compute"", ""The secure environment has Azure Machine Learning compute that can access the dataset""], [""machine learning models"", ""part-of"", ""storage account"", ""Models or de-identified data is saved to a separate location on the secure storage (export path)""], [""machine learning models"", ""calls"", ""logic app"", ""When new data is added to the export path, a logic app is triggered""], [""logic app"", ""calls"", ""manual reviewers"", ""The app starts an approval process requesting a review of data that is queued to be exported.""], [""public blob storage account"", ""contains"", ""separate container"", ""Data Factory moves the data to the public storage account in a separate container""], [""Azure Data Factory"", ""calls"", ""de-identified data"", ""Data Factory moves the data to the public storage account in a separate container to allow external researchers to have access to their exported data and models""], [""separate container"", ""contains"", ""moved data"", ""Data Factory moves the data to the public storage account in a separate container""], [""Azure Data Factory"", ""calls"", ""moved data"", ""Data Factory moves the data to the public storage account in a separate container to allow external researchers to have access to their exported data and models""], [""Users"", ""calls"", ""Azure Machine Learning compute"", ""The secure environment has Azure Machine Learning compute that can access the dataset""]]}","```json
{
  ""entities"": [
    [""Azure Blob Storage"", ""system""],
    [""Microsoft-managed keys"", ""component""],
    [""Azure Data Factory"", ""system""],
    [""Trigger"", ""component""],
    [""Import path"", ""entity""],
    [""Secure storage account"", ""system""],
    [""Private endpoint"", ""component""],
    [""Service principal"", ""person""],
    [""Researchers"", ""person""],
    [""Streaming application"", ""component""],
    [""Azure Virtual Desktop"", ""system""],
    [""Data science VMs"", ""system""],
    [""Azure Machine Learning compute"", ""system""],
    [""Logic app"", ""system""],
    [""Manual reviewers"", ""person""],
    [""Public storage account"", ""system""]
  ],
  ""relationships"": [
    [""Azure Blob Storage"", ""contains"", ""Microsoft-managed keys""],
    [""Azure Data Factory"", ""contains"", ""Trigger""],
    [""Secure storage account"", ""contains"", ""Private endpoint""],
    [""Secure storage account"", ""part-of"", ""Azure Machine Learning compute""],
    [""Data science VMs"", ""part-of"", ""Secure environment""],
    [""Logic app"", ""called-from"", ""Export path""],
    [""Logic app"", ""calls"", ""Manual reviewers""]
  ]
}
```","```json
{
  ""entities"": [
    [""Azure Blob Storage"", ""system""],
    [""Microsoft-managed keys"", ""component""],
    [""Azure Data Factory"", ""system""],
    [""Trigger"", ""component""],
    [""Import path"", ""entity""],
    [""Secure storage account"", ""system""],
    [""Private endpoint"", ""component""],
    [""Service principal"", ""person""],
    [""Researchers"", ""person""],
    [""Streaming application"", ""component""],
    [""Azure Virtual Desktop"", ""system""],
    [""Data science VMs"", ""system""],
    [""Azure Machine Learning compute"", ""system""],
    [""Logic app"", ""system""],
    [""Manual reviewers"", ""person""],
    [""Public storage account"", ""system""]
  ],
  ""relationships"": [
    [""Azure Blob Storage"", ""contains"", ""Microsoft-managed keys""],
    [""Azure Data Factory"", ""contains"", ""Trigger""],
    [""Secure storage account"", ""contains"", ""Private endpoint""],
    [""Secure storage account"", ""part-of"", ""Azure Machine Learning compute""],
    [""Data science VMs"", ""part-of"", ""Secure environment""],
    [""Logic app"", ""called-from"", ""Export path""],
    [""Logic app"", ""calls"", ""Manual reviewers""]
  ]
}
```",4.58412891899934
38,mistral-nemo,../IMAGES NEW/Azure/10 Azure LoB original.txt,"
The data flows through the solution as follows:

    Supplier data stored in CDS is moved to SQL via Data Factory.
    Purchase order (PO) data stored in ERP system is sent to Azure SQL database.
    Azure Functions uses API to surface PO data monthly and creates a task for users to review.
    Power Apps retrieves data from Azure SQL Database through API.
    User reviews and updates POs in Power Apps and sends this data to suppliers through CSV export.
    Power BI reports trends in supplier status.

","{""entities"": [[""Supplier data"", ""component"", ""Supplier data stored in CDS""], [""CDS"", ""system"", "" Supplier data stored in CDS""], [""Azure SQL database"", ""system"", ""moved to SQL via Data Factory""], [""Data Factory"", ""system"", ""moved to SQL via Data Factory""], [""Purchase order (PO)"", ""system"", ""moved to SQL via Data Factory""], [""ERP system"", ""system"", ""Purchase order (PO) data stored in ERP system""], [""Azure Functions"", ""system"", ""uses API to surface PO data monthly and creates a task for users to review""], [""Power Apps"", ""system"", ""retrieves data from Azure SQL Database through API""], [""CSV export"", ""system"", ""ends this data to suppliers through CSV export""], [""User"", ""person"", "" reviews and updates POs in Power Apps""], [""suppliers"", ""person"", "" reviews and updates POs in Power Apps""]], ""relationships"": [[""Supplier data"", ""part-of"", ""CDS"", ""Supplier data stored in CDS""], [""Supplier data"", ""is-called-from"", ""Data Factory"", ""moved to SQL via Data Factory""], [""Data Factory"", ""calls"", ""Azure SQL database"", ""moved to SQL via Data Factory""], [""Purchase order (PO)"", ""part-of"", ""ERP system"", ""Purchase order (PO) data stored in ERP system""], [""Purchase order (PO)"", ""calls"", ""Azure SQL database"", ""Purchase order (PO) data stored in ERP system is sent to Azure SQL database""], [""Azure Functions"", ""calls"", ""Purchase order (PO)"", ""uses API to surface PO data monthly""], [""Azure Functions"", ""calls"", ""User"", ""creates a task for users to review""], [""Power Apps"", ""calls"", ""Azure SQL database"", ""retrieves data from Azure SQL Database through API""], [""User"", ""calls"", ""Power Apps"", ""Reviews and updates POs in Power Apps""], [""User"", ""calls"", ""CSV export"", ""sends this data to suppliers through CSV export""], [""CSV export"", ""calls"", ""suppliers"", ""sends this data to suppliers through CSV export""]]}","{
  ""entities"": [
    [""Supplier data"", ""component""],
    [""CDS"", ""system""],
    [""Data Factory"", ""component""],
    [""SQL"", ""system""],
    [""PO (Purchase Order) data"", ""component""],
    [""ERP system"", ""system""],
    [""Azure SQL database"", ""system""],
    [""Azure Functions"", ""component""],
    [""API"", ""component""],
    [""Power Apps"", ""component""],
    [""Azure SQL Database"", ""system""],
    [""CSV export"", ""component""],
    [""Power BI"", ""component""]
  ],
  ""relationships"": [
    [""Supplier data"", ""moved-from"", ""CDS"", ""Moves supplier data to SQL via Data Factory""],
    [""Supplier data"", ""part-of"", ""SQL"", ""Part of SQL system""],
    [""PO data"", ""sent-to"", ""Azure SQL database"", ""Sent PO data to Azure SQL database""],
    [""PO data"", ""part-of"", ""ERP system"", ""Part of ERP system""],
    [""Azure Functions"", ""uses"", ""API"", ""Uses API to surface PO data monthly""],
    [""Power Apps"", ""retrieves-from"", ""Azure SQL Database"", ""Retrieves data from Azure SQL Database through API""],
    [""User"", ""reviews-and-updates"", ""PO data"", ""Reviews and updates POs in Power Apps""],
    [""PO data"", ""sent-to"", ""suppliers via CSV export"", ""Sent updated PO data to suppliers through CSV export""],
    [""Power BI"", ""reports-on"", ""supplier status trends"", ""Reports trends in supplier status""]
  ]
}","{
  ""entities"": [
    [""Supplier data"", ""component""],
    [""CDS"", ""system""],
    [""Data Factory"", ""component""],
    [""SQL"", ""system""],
    [""PO (Purchase Order) data"", ""component""],
    [""ERP system"", ""system""],
    [""Azure SQL database"", ""system""],
    [""Azure Functions"", ""component""],
    [""API"", ""component""],
    [""Power Apps"", ""component""],
    [""Azure SQL Database"", ""system""],
    [""CSV export"", ""component""],
    [""Power BI"", ""component""]
  ],
  ""relationships"": [
    [""Supplier data"", ""moved-from"", ""CDS"", ""Moves supplier data to SQL via Data Factory""],
    [""Supplier data"", ""part-of"", ""SQL"", ""Part of SQL system""],
    [""PO data"", ""sent-to"", ""Azure SQL database"", ""Sent PO data to Azure SQL database""],
    [""PO data"", ""part-of"", ""ERP system"", ""Part of ERP system""],
    [""Azure Functions"", ""uses"", ""API"", ""Uses API to surface PO data monthly""],
    [""Power Apps"", ""retrieves-from"", ""Azure SQL Database"", ""Retrieves data from Azure SQL Database through API""],
    [""User"", ""reviews-and-updates"", ""PO data"", ""Reviews and updates POs in Power Apps""],
    [""PO data"", ""sent-to"", ""suppliers via CSV export"", ""Sent updated PO data to suppliers through CSV export""],
    [""Power BI"", ""reports-on"", ""supplier status trends"", ""Reports trends in supplier status""]
  ]
}",5.697532876016339
39,mistral-nemo,../IMAGES NEW/Azure/07 Azure internal APIs original.txt,"
The data flows as follows:

    Developers check in code to a GitHub repository that's connected to a CI/CD pipeline agent that's installed on an Azure VM.
    The agent pushes the build to the API application that's hosted on ILB ASE.
    Azure API Management consumes the preceding APIs via HOST headers that are specified in API Management policy.
    API Management uses the App Service Environment's DNS name for all the APIs.
    Application Gateway exposes API Management's developer and API portal.
    Azure Private DNS is used to route the traffic internally between ASE, API Management, and Application Gateway.
    External users utilize the exposed developer portal to consume the APIs via Application Gateway's public IP.

","{""entities"": [[""GitHub repository"", ""system"", """"], [""Developers"", ""person"", """"], [""External users"", ""person"", """"], [""CI/CD pipeline agent"", ""system"", """"], [""Azure VM"", ""system"", """"], [""ILB ASE"", ""system"", """"], [""API application"", ""component"", """"], [""Azure API Management"", ""system"", ""consumes the preceding APIs via HOST headers""], [""App Service Environment"", ""component"", """"], [""Application Gateway"", ""component"", ""exposes API Management's developer and API portal""], [""Developer portal"", ""component"", ""API Management's developer and API portal""], [""API portal"", ""component"", ""API Management's developer and API portal""], [""Application Gateway"", ""component"", ""exposes API Management's developer and API portal""], [""Azure Private DNS"", ""component"", ""used to route the traffic internally between ASE, API Management, and Application Gateway""]], ""relationships"": [[""Azure VM"", ""contains"", ""CI/CD pipeline agent"", ""installed on an Azure VM""], [""API application"", ""part-of"", ""ILB ASE"", ""API application that's hosted on ILB ASE""], [""GitHub repository"", ""calls"", ""CI/CD pipeline agent"", ""GitHub repository that's connected to a CI/CD pipeline agent""], [""CI/CD pipeline agent"", ""calls"", ""API application"", ""agent pushes the build to the API application""], [""Azure API Management"", ""calls"", ""App Service Environment"", ""uses the App Service Environment's DNS name for all the APIs""], [""External users"", ""calls"", ""Application Gateway"", """"], [""Application Gateway"", ""calls"", ""API application"", ""to consume the APIs via Application Gateway's public IP""], [""Azure API Management"", ""contains"", ""Developer portal"", ""API Management's developer and API portal""], [""Azure API Management"", ""contains"", ""API portal"", ""API Management's developer and API portal""], [""Application Gateway"", ""calls"", ""API portal"", ""exposes API Management's developer and API portal.""], [""Application Gateway"", ""calls"", ""Developer portal"", ""exposes API Management's developer and API portal.""], [""Azure Private DNS"", ""calls"", ""Azure API Management"", ""route the traffic internally between ASE, API Management, and Application Gateway""], [""Azure Private DNS"", ""calls"", ""Application Gateway"", ""route the traffic internally between ASE, API Management, and Application Gateway""]]}","{
  ""entities"": [
    [""Developers"", ""person"", ""Users who check in code""],
    [""GitHub"", ""system"", ""Repository hosting platform""],
    [""CI/CD pipeline agent"", ""component"", ""Automates build processes""],
    [""Azure VM"", ""system"", ""Virtual machine on Azure""],
    [""API application"", ""component"", ""Handles API logic and endpoints""],
    [""ILB ASE"", ""system"", ""Internal Load Balancer App Service Environment""],
    [""Azure API Management"", ""system"", ""API gateway and management tool""],
    [""HOST headers"", ""component"", ""Headers specifying API locations""],
    [""App Service Environment's DNS name"", ""component"", ""DNS name for APIs""],
    [""Application Gateway"", ""system"", ""Load balancer exposing API services""],
    [""Azure Private DNS"", ""system"", ""Private Domain Name System service""],
    [""External users"", ""person"", ""Users consuming APIs externally""],
    [""Developer portal"", ""component"", ""Portal for developers to consume APIs""]
  ],
  ""relationships"": [
    [""Developers"", ""checks-in"", ""GitHub"", ""Checks in code""],
    [""CI/CD pipeline agent"", ""part-of"", ""Azure VM"", ""Installed on Azure VM""],
    [""CI/CD pipeline agent"", ""pushes"", ""API application"", ""Pushes build to API application""],
    [""API application"", ""hosted-on"", ""ILB ASE"", ""Hosted on Internal Load Balancer App Service Environment""],
    [""Azure API Management"", ""consumes"", ""API application"", ""Consumes APIs via HOST headers""],
    [""Azure API Management"", ""uses"", ""App Service Environment's DNS name"", ""Uses DNS name for APIs""],
    [""Application Gateway"", ""exposes"", ""Azure API Management"", ""Exposes developer and API portal""],
    [""Azure Private DNS"", ""routes-traffic-between"", ""ASE, API Management, Application Gateway"", ""Routes traffic internally between services""],
    [""External users"", ""consume-via"", ""Application Gateway's public IP"", ""Consume APIs via Application Gateway's public IP""]
  ]
}","{
  ""entities"": [
    [""Developers"", ""person"", ""Users who check in code""],
    [""GitHub"", ""system"", ""Repository hosting platform""],
    [""CI/CD pipeline agent"", ""component"", ""Automates build processes""],
    [""Azure VM"", ""system"", ""Virtual machine on Azure""],
    [""API application"", ""component"", ""Handles API logic and endpoints""],
    [""ILB ASE"", ""system"", ""Internal Load Balancer App Service Environment""],
    [""Azure API Management"", ""system"", ""API gateway and management tool""],
    [""HOST headers"", ""component"", ""Headers specifying API locations""],
    [""App Service Environment's DNS name"", ""component"", ""DNS name for APIs""],
    [""Application Gateway"", ""system"", ""Load balancer exposing API services""],
    [""Azure Private DNS"", ""system"", ""Private Domain Name System service""],
    [""External users"", ""person"", ""Users consuming APIs externally""],
    [""Developer portal"", ""component"", ""Portal for developers to consume APIs""]
  ],
  ""relationships"": [
    [""Developers"", ""checks-in"", ""GitHub"", ""Checks in code""],
    [""CI/CD pipeline agent"", ""part-of"", ""Azure VM"", ""Installed on Azure VM""],
    [""CI/CD pipeline agent"", ""pushes"", ""API application"", ""Pushes build to API application""],
    [""API application"", ""hosted-on"", ""ILB ASE"", ""Hosted on Internal Load Balancer App Service Environment""],
    [""Azure API Management"", ""consumes"", ""API application"", ""Consumes APIs via HOST headers""],
    [""Azure API Management"", ""uses"", ""App Service Environment's DNS name"", ""Uses DNS name for APIs""],
    [""Application Gateway"", ""exposes"", ""Azure API Management"", ""Exposes developer and API portal""],
    [""Azure Private DNS"", ""routes-traffic-between"", ""ASE, API Management, Application Gateway"", ""Routes traffic internally between services""],
    [""External users"", ""consume-via"", ""Application Gateway's public IP"", ""Consume APIs via Application Gateway's public IP""]
  ]
}",7.406208872009302
40,mistral-nemo,../IMAGES NEW/Azure/13 Azure Secure Research.txt,"
    Data owners upload datasets into a public blob storage account. The data is encrypted by using Microsoft-managed keys.

    Azure Data Factory uses a trigger that starts copying of the uploaded dataset to a specific location (import path) on another storage account with security controls. The storage account can only be reached through a private endpoint. Also, it's accessed by a service principal with limited permissions. Data Factory deletes the original copy making the dataset immutable.

    Researchers access the secure environment through a streaming application using Azure Virtual Desktop as a privileged jump box.

    The dataset in the secure storage account is presented to the data science VMs provisioned in a secure network environment for research work. Much of the data preparation is done on those VMs.

    The secure environment has Azure Machine Learning compute that can access the dataset through a private endpoint for users for Azure Machine Learning capabilities, such as to train, deploy, automate, and manage machine learning models. At this point, models are created that meet regulatory guidelines. All model data is de-identified by removing personal information.

    Models or de-identified data is saved to a separate location on the secure storage (export path). When new data is added to the export path, a logic app is triggered. In this architecture, the logic app is outside the secure environment because no data is sent to the logic app. Its only function is to send notification and start the manual approval process.

    The app starts an approval process requesting a review of data that is queued to be exported. The manual reviewers ensure that sensitive data isn't exported. After the review process, the data is either approved or denied.

    Note

    If an approval step is not required on exfiltration, the logic app step could be omitted.

    If the de-identified data is approved, it's sent to the Data Factory instance.

    Data Factory moves the data to the public storage account in a separate container to allow external researchers to have access to their exported data and models. Alternately, you can provision another storage account in a lower security environment.

","{""entities"": [[""datasets"", ""component"", ""Data owners upload datasets into a public blob storage account""], [""public blob storage account"", ""system"", ""Data owners upload datasets into a public blob storage account""], [""Azure Data Factory"", ""system"", ""Azure Data Factory uses a trigger that starts copying of the uploaded dataset to a specific location""], [""storage account"", ""system"", ""Azure Data Factory uses a trigger that starts copying of the uploaded dataset to a specific location (import path) on another storage account with security controls""], [""copied dataset"", ""system"", ""Azure Data Factory uses a trigger that starts copying of the uploaded dataset to a specific location (import path) on another storage account with security controls""], [""private endpoint"", ""component"", ""The storage account can only be reached through a private endpoint.""], [""service principal"", ""component"", ""Also, it's accessed by a service principal with limited permissions.""], [""streaming application"", ""component"", ""access the secure environment through a streaming application""], [""Azure Virtual Desktop"", ""component"", ""Azure Virtual Desktop as a privileged jump box""], [""data science VMs"", ""component"", ""data science VMs provisioned in a secure network environment""], [""Azure Machine Learning compute"", ""component"", ""The secure environment has Azure Machine Learning compute that can access the dataset""], [""secure network environment"", ""system"", ""data science VMs provisioned in a secure network environment""], [""machine learning models"", ""component"", ""At this point, models are created that meet regulatory guidelines""], [""de-identified data"", ""component"", ""Models or de-identified data is saved to a separate location on the secure storage (export path)""], [""logic app"", ""component"", ""When new data is added to the export path, a logic app is triggered""], [""separate container"", ""component"", ""Data Factory moves the data to the public storage account in a separate container""], [""moved data"", ""component"", ""Data Factory moves the data to the public storage account in a separate container""], [""Data owners"", ""person"", ""Data owners upload datasets into a public blob storage account""], [""Researchers"", ""person"", ""Researchers access the secure environment through a streaming application using Azure Virtual Desktop as a privileged jump box""], [""manual reviewers"", ""person"", ""The manual reviewers ensure that sensitive data isn't exported.""], [""Users"", ""person"", ""The secure environment has Azure Machine Learning compute that can access the dataset""]], ""relationships"": [[""datasets"", ""part-of"", ""public blob storage account"", ""Data owners upload datasets into a public blob storage account""], [""Data owners"", ""calls"", ""datasets"", ""Data owners upload datasets into a public blob storage account""], [""Azure Data Factory"", ""calls"", ""datasets"", ""Azure Data Factory uses a trigger that starts copying of the uploaded dataset""], [""storage account"", ""contains"", ""copied dataset"", ""opying of the uploaded dataset to a specific location (import path) on another storage account with security controls""], [""Azure Data Factory"", ""calls"", ""copied dataset"", ""Azure Data Factory uses a trigger that starts copying of the uploaded dataset to a specific location""], [""private endpoint"", ""calls"", ""storage account"", ""The storage account can only be reached through a private endpoint""], [""storage account"", ""is-called-from"", ""service principal"", ""Also, it's accessed by a service principal with limited permissions""], [""Researchers"", ""calls"", ""Azure Virtual Desktop"", "" Researchers access the secure environment through a streaming application""], [""Azure Virtual Desktop"", ""calls"", ""streaming application"", ""through a streaming application using Azure Virtual Desktop""], [""streaming application"", ""calls"", ""storage account"", ""Researchers access the secure environment through a streaming application using Azure Virtual Desktop as a privileged jump box""], [""data science VMs"", ""part-of"", ""secure network environment"", ""The dataset in the secure storage account is presented to the data science VMs""], [""data science VMs"", ""calls"", ""copied dataset"", "" The dataset in the secure storage account is presented to the data science VMs""], [""secure network environment"", ""contains"", ""Azure Machine Learning compute"", ""The secure environment has Azure Machine Learning compute that can access the dataset""], [""Azure Machine Learning compute"", ""calls"", ""Azure Machine Learning compute"", ""The secure environment has Azure Machine Learning compute that can access the dataset""], [""machine learning models"", ""part-of"", ""storage account"", ""Models or de-identified data is saved to a separate location on the secure storage (export path)""], [""machine learning models"", ""calls"", ""logic app"", ""When new data is added to the export path, a logic app is triggered""], [""logic app"", ""calls"", ""manual reviewers"", ""The app starts an approval process requesting a review of data that is queued to be exported.""], [""public blob storage account"", ""contains"", ""separate container"", ""Data Factory moves the data to the public storage account in a separate container""], [""Azure Data Factory"", ""calls"", ""de-identified data"", ""Data Factory moves the data to the public storage account in a separate container to allow external researchers to have access to their exported data and models""], [""separate container"", ""contains"", ""moved data"", ""Data Factory moves the data to the public storage account in a separate container""], [""Azure Data Factory"", ""calls"", ""moved data"", ""Data Factory moves the data to the public storage account in a separate container to allow external researchers to have access to their exported data and models""], [""Users"", ""calls"", ""Azure Machine Learning compute"", ""The secure environment has Azure Machine Learning compute that can access the dataset""]]}","Based on the provided text, here's the extracted entities and relationships in JSON format:

```json
{
  ""entities"": [
    [""Azure Blob Storage"", ""system""],
    [""Data Factory"", ""system""],
    [""Secure Storage Account"", ""system""],
    [""Virtual Desktop"", ""component""],
    [""Researcher"", ""person""],
    [""Service Principal"", ""person""],
    [""Logic App"", ""system""],
    [""Reviewer"", ""person""],
    [""Data Science VMs"", ""system""]
  ],
  ""relationships"": [
    [""Azure Blob Storage"", ""contains"", ""Secure Storage Account""],
    [""Secure Storage Account"", ""part-of"", ""Azure Blob Storage""],
    [""Secure Storage Account"", ""called-from"", ""Data Factory""],
    [""Data Factory"", ""calls"", ""Secure Storage Account""],
    [""Virtual Desktop"", ""contains"", ""Researcher""],
    [""Secure Storage Account"", ""contains"", ""Data Science VMs""],
    [""Logic App"", ""calls"", ""Reviewer""],
    [""Reviewer"", ""called-from"", ""Logic App""]
  ]
}
```","Based on the provided text, here's the extracted entities and relationships in JSON format:

```json
{
  ""entities"": [
    [""Azure Blob Storage"", ""system""],
    [""Data Factory"", ""system""],
    [""Secure Storage Account"", ""system""],
    [""Virtual Desktop"", ""component""],
    [""Researcher"", ""person""],
    [""Service Principal"", ""person""],
    [""Logic App"", ""system""],
    [""Reviewer"", ""person""],
    [""Data Science VMs"", ""system""]
  ],
  ""relationships"": [
    [""Azure Blob Storage"", ""contains"", ""Secure Storage Account""],
    [""Secure Storage Account"", ""part-of"", ""Azure Blob Storage""],
    [""Secure Storage Account"", ""called-from"", ""Data Factory""],
    [""Data Factory"", ""calls"", ""Secure Storage Account""],
    [""Virtual Desktop"", ""contains"", ""Researcher""],
    [""Secure Storage Account"", ""contains"", ""Data Science VMs""],
    [""Logic App"", ""calls"", ""Reviewer""],
    [""Reviewer"", ""called-from"", ""Logic App""]
  ]
}
```",4.1961934119754005
41,mistral-nemo,../IMAGES NEW/Azure/16 Azure automate-pdf-forms.txt,"
    A designated Outlook email account receives PDF files as attachments. The arrival of an email triggers a logic app to process the email. The logic app is built by using the capabilities of Azure Logic Apps.
    The logic app uploads the PDF files to a container in Azure Data Lake Storage.
    You can also manually or programmatically upload PDF files to the same PDF container.
    The arrival of a PDF file in the PDF container triggers another logic app to process the PDF forms that are in the PDF file.
    The logic app sends the location of the PDF file to a function app for processing. The function app is built by using the capabilities of Azure Functions.
    The function app receives the location of the file and takes these actions:
        It splits the file into single pages if the file has multiple pages. Each page contains one independent form. Split files are saved to a second container in Data Lake Storage.
        It uses HTTPS POST, an Azure REST API, to send the location of the single-page PDF file to AI Document Intelligence for processing. When Azure AI Document Intelligence completes its processing, it sends a response back to the function app, which places the information into a data structure.
        It creates a JSON data file that contains the response data and stores the file to a third container in Data Lake Storage.
    The forms processing logic app receives the processed response data.
    The forms processing logic app sends the processed data to Azure Cosmos DB, which saves the data in a database and in collections.
    Power BI obtains the data from Azure Cosmos DB and provides insights and dashboards.
    You can implement further processing as needed on the data that's in Azure Cosmos DB.

","{""entities"": [[""designated Outlook email account"", ""component"", ""A designated Outlook email account receives PDF files as attachments""], [""logic app"", ""component"", ""The arrival of an email triggers a logic app to process the email.""], [""Azure Logic Apps"", ""system"", ""The logic app is built by using the capabilities of Azure Logic Apps.""], [""Container"", ""component"", ""The logic app uploads the PDF files to a container in Azure Data Lake Storage""], [""Azure Data Lake Storage"", ""system"", ""The logic app uploads the PDF files to a container in Azure Data Lake Storage""], [""logic app 2"", ""system"", ""The arrival of a PDF file in the PDF container triggers another logic app to process the PDF forms""], [""function app"", ""component"", ""The logic app sends the location of the PDF file to a function app for processing.""], [""Azure Functions"", ""system"", ""The function app is built by using the capabilities of Azure Functions""], [""Azure REST API"", ""component"", ""It uses HTTPS POST, an Azure REST API, to send the location of the single-page PDF file""], [""Container 2"", ""component"", ""Split files are saved to a second container in Data Lake Storage""], [""AI Document Intelligence"", ""component"", ""It uses HTTPS POST, an Azure REST API, to send the location of the single-page PDF file to AI Document Intelligence for processing""], [""Container 3"", ""component"", ""JSON data file that contains the response data and stores the file to a third container in Data Lake Storage""], [""forms processing logic app"", ""component"", ""The forms processing logic app receives the processed response data""], [""Azure Cosmos DB"", ""component"", ""The forms processing logic app sends the processed data to Azure Cosmos DB""], [""database"", ""component"", ""Azure Cosmos DB, which saves the data in a database""], [""Power BI"", ""component"", ""Power BI obtains the data from Azure Cosmos DB and provides insights and dashboards""]], ""relationships"": [[""designated Outlook email account"", ""calls"", ""logic app"", ""The arrival of an email triggers a logic app to process the email.""], [""Azure Logic Apps"", ""contains"", ""logic app"", ""The logic app is built by using the capabilities of Azure Logic Apps.""], [""logic app"", ""calls"", ""Container"", ""The logic app uploads the PDF files to a container in Azure Data Lake Storage""], [""Container"", ""part-of"", ""Azure Data Lake Storage"", ""container in Azure Data Lake Storage""], [""Container"", ""calls"", ""logic app 2"", ""The arrival of a PDF file in the PDF container triggers another logic app""], [""logic app"", ""calls"", ""function app"", ""The logic app sends the location of the PDF file to a function app for processing.""], [""function app"", ""part-of"", ""Azure Functions"", ""container in Azure Data Lake Storage""], [""function app"", ""calls"", ""Container 2"", ""Split files are saved to a second container in Data Lake Storage""], [""Azure Data Lake Storage"", ""contains"", ""Container 2"", ""Split files are saved to a second container in Data Lake Storage""], [""function app"", ""calls"", ""Azure REST API"", ""It uses HTTPS POST, an Azure REST API""], [""Azure REST API"", ""calls"", ""AI Document Intelligence"", ""HTTPS POST, an Azure REST API, to send the location of the single-page PDF file to AI Document Intelligence""], [""Azure Data Lake Storage"", ""contains"", ""Container 3"", ""third container in Data Lake Storage""], [""function app"", ""calls"", ""Container 3"", ""It creates a JSON data file that contains the response data and stores the file to a third container""], [""forms processing logic app"", ""calls"", ""Container 3"", ""The forms processing logic app receives the processed response data""], [""forms processing logic app"", ""calls"", ""Azure Cosmos DB"", ""The forms processing logic app sends the processed data to Azure Cosmos DB""], [""Azure Cosmos DB"", ""calls"", ""database"", ""Azure Cosmos DB, which saves the data in a database""], [""Power BI"", ""calls"", ""Azure Cosmos DB"", ""Power BI obtains the data from Azure Cosmos DB and provides insights and dashboards""]]}","Here's the JSON response based on the provided context:

```json
{
  ""entities"": [
    [""Outlook Email Account"", ""system""],
    [""Azure Logic Apps (Logic App 1)"", ""system""],
    [""Azure Data Lake Storage (PDF Container)"", ""system""],
    [""Azure Logic Apps (Logic App 2)"", ""system""],
    [""Azure Functions (Function App)"", ""system""],
    [""AI Document Intelligence"", ""component""],
    [""Azure Data Lake Storage (Pages Container)"", ""system""],
    [""Azure Data Lake Storage (JSON Files Container)"", ""system""],
    [""Azure Cosmos DB"", ""system""],
    [""Power BI"", ""component""]
  ],
  ""relationships"": [
    [""Outlook Email Account"", ""calls"", ""Azure Logic Apps (Logic App 1)""],
    [""Azure Logic Apps (Logic App 1)"", ""contains"", ""Azure Data Lake Storage (PDF Container)""],
    [""Azure Data Lake Storage (PDF Container)"", ""called-from"", ""Azure Logic Apps (Logic App 2)""],
    [""Azure Logic Apps (Logic App 2)"", ""calls"", ""Azure Functions (Function App)""],
    [""Azure Functions (Function App)"", ""contains"", ""AI Document Intelligence""],
    [""Azure Functions (Function App)"", ""part-of"", ""Azure Data Lake Storage (Pages Container)""],
    [""Azure Functions (Function App)"", ""calls"", ""Azure Data Lake Storage (JSON Files Container)""],
    [""Azure Logic Apps (Logic App 2)"", ""calls"", ""Azure Cosmos DB""],
    [""Azure Cosmos DB"", ""contains"", ""Power BI""]
  ]
}
```","Here's the JSON response based on the provided context:

```json
{
  ""entities"": [
    [""Outlook Email Account"", ""system""],
    [""Azure Logic Apps (Logic App 1)"", ""system""],
    [""Azure Data Lake Storage (PDF Container)"", ""system""],
    [""Azure Logic Apps (Logic App 2)"", ""system""],
    [""Azure Functions (Function App)"", ""system""],
    [""AI Document Intelligence"", ""component""],
    [""Azure Data Lake Storage (Pages Container)"", ""system""],
    [""Azure Data Lake Storage (JSON Files Container)"", ""system""],
    [""Azure Cosmos DB"", ""system""],
    [""Power BI"", ""component""]
  ],
  ""relationships"": [
    [""Outlook Email Account"", ""calls"", ""Azure Logic Apps (Logic App 1)""],
    [""Azure Logic Apps (Logic App 1)"", ""contains"", ""Azure Data Lake Storage (PDF Container)""],
    [""Azure Data Lake Storage (PDF Container)"", ""called-from"", ""Azure Logic Apps (Logic App 2)""],
    [""Azure Logic Apps (Logic App 2)"", ""calls"", ""Azure Functions (Function App)""],
    [""Azure Functions (Function App)"", ""contains"", ""AI Document Intelligence""],
    [""Azure Functions (Function App)"", ""part-of"", ""Azure Data Lake Storage (Pages Container)""],
    [""Azure Functions (Function App)"", ""calls"", ""Azure Data Lake Storage (JSON Files Container)""],
    [""Azure Logic Apps (Logic App 2)"", ""calls"", ""Azure Cosmos DB""],
    [""Azure Cosmos DB"", ""contains"", ""Power BI""]
  ]
}
```",5.9018003120145295
42,mistral-nemo,../IMAGES NEW/Azure/14 Azure Call Center Analytics.txt,"
    A phone call between an agent and a customer is recorded and stored in Azure Blob Storage. Audio files are uploaded to an Azure Storage account via a supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API.

    Azure AI Speech is used to transcribe audio files in Batch mode asynchronously with speaker diarization enabled. The transcription results are persisted in Blob Storage.

    Azure AI Language is used to detect and redact personal data in the transcript.

    For batch mode transcription and personal data detection and redaction, use the AI services Ingestion Client tool. The Ingestion Client tool uses a no-code approach for call center transcription.

    Azure OpenAI is used to process the transcript and extract entities, summarize the conversation, and analyze sentiments. The processed output is stored in Blob Storage and then analyzed and visualized by using other services. You can also store the output in a datastore for keeping track of metadata and for reporting. Use Azure OpenAI to process the stored transcription information.

    Power BI or a custom web application that's hosted by App Service is used to visualize the output. Both options provide near real-time insights. You can store this output in a customer relationship management (CRM), so agents have contextual information about why the customer called and can quickly solve potential problems. This process is fully automated, which saves the agents time and effort.

","{""entities"": [[""phone call"", ""component"", ""A phone call between an agent and a customer is recorded""], [""agent"", ""person"", ""A phone call between an agent and a customer is recorded""], [""customer"", ""person"", ""A phone call between an agent and a customer is recorded""], [""Azure Blob Storage"", ""system"", ""is recorded and stored in Azure Blob Storage""], [""Audio files"", ""system"", ""Audio files are uploaded to an Azure Storage account via a supported method""], [""supported method"", ""component"", ""Audio files are uploaded to an Azure Storage account via a supported method""], [""UI-based tool"", ""component"", ""supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""Azure Storage Explorer"", ""component"", ""supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""Storage SDK"", ""component"", ""supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""API"", ""component"", ""supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""Azure AI Speech"", ""component"", ""transcribe audio files in Batch mode asynchronously""], [""transcription results"", ""component"", ""The transcription results are persisted in Blob Storage.""], [""Azure AI Language"", ""component"", ""Azure AI Language is used to detect and redact personal data in the transcript.""], [""AI services Ingestion Client tool"", ""component"", ""For batch mode transcription and personal data detection and redaction, use the AI services Ingestion Client tool""], [""Azure OpenAI"", ""component"", ""Azure OpenAI is used to process the transcript and extract entities, summarize the conversation, and analyze sentiments.""], [""Azure OpenAI output"", ""component"", ""The processed output is stored in Blob Storage and then analyzed and visualized by using other services.""], [""other services"", ""component"", ""The processed output is stored in Blob Storage and then analyzed and visualized by using other services.""], [""App Service"", ""system"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""Power BI"", ""system"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""custom web application"", ""system"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""Azure OpenAI output 2"", ""component"", ""You can also store the output in a datastore for keeping track of metadata and for reporting""], [""datastore"", ""component"", ""You can also store the output in a datastore for keeping track of metadata and for reporting""], [""customer relationship management (CRM)"", ""system"", ""You can store this output in a customer relationship management (CRM)""], [""Azure OpenAI output 3"", ""component"", ""You can store this output in a customer relationship management (CRM)""]], ""relationships"": [[""agent"", ""calls"", ""phone call"", ""A phone call between an agent and a customer is recorded""], [""customer"", ""calls"", ""phone call"", ""A phone call between an agent and a customer is recorded""], [""phone call"", ""part-of"", ""Azure Blob Storage"", ""is recorded and stored in Azure Blob Storage""], [""Audio files"", ""part-of"", ""Azure Blob Storage"", ""Audio files are uploaded to an Azure Storage account via a supported method""], [""supported method"", ""calls"", ""Audio files"", ""Audio files are uploaded to an Azure Storage account via a supported method""], [""supported method"", ""contains"", ""UI-based tool"", ""upported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""supported method"", ""contains"", ""Azure Storage Explorer"", ""upported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""supported method"", ""contains"", ""Storage SDK"", ""upported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""supported method"", ""contains"", ""API"", ""supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""Azure AI Speech"", ""calls"", ""Audio files"", ""transcribe audio files in Batch mode asynchronously""], [""Azure Blob Storage"", ""contains"", ""transcription results"", ""The transcription results are persisted in Blob Storage.""], [""Azure AI Speech"", ""calls"", ""transcription results"", ""The transcription results are persisted in Blob Storage.""], [""Azure AI Language"", ""calls"", ""transcription results"", ""Azure AI Language is used to detect and redact personal data in the transcript.""], [""AI services Ingestion Client tool"", ""calls"", ""transcription results"", ""For batch mode transcription and personal data detection and redaction, use the AI services Ingestion Client tool""], [""Azure OpenAI"", ""calls"", ""transcription results"", ""Azure OpenAI is used to process the transcript and extract entities, summarize the conversation, and analyze sentiments.""], [""Azure OpenAI"", ""calls"", ""Azure OpenAI output"", ""The processed output is stored in Blob Storage and then analyzed and visualized by using other services.""], [""Azure Blob Storage"", ""contains"", ""Azure OpenAI output"", ""The processed output is stored in Blob Storage and then analyzed and visualized by using other services.""], [""other services"", ""calls"", ""Azure OpenAI output"", ""The processed output is stored in Blob Storage and then analyzed and visualized by using other services.""], [""Power BI"", ""part-of"", ""App Service"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""custom web application"", ""part-of"", ""App Service"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""custom web application"", ""calls"", ""Azure OpenAI output"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""Power BI"", ""calls"", ""Azure OpenAI output"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""agent"", ""calls"", ""customer relationship management (CRM)"", ""You can store this output in a customer relationship management (CRM), so agents have contextual information about why the customer called and can quickly solve potential problems""], [""Azure OpenAI output 2"", ""part-of"", ""datastore"", ""You can also store the output in a datastore for keeping track of metadata and for reporting""], [""Azure OpenAI output 3"", ""part-of"", ""customer relationship management (CRM)"", ""You can also store the output in a datastore for keeping track of metadata and for reporting""], [""Azure OpenAI output"", ""calls"", ""Azure OpenAI output 2"", ""You can also store the output in a datastore for keeping track of metadata and for reporting""], [""Azure OpenAI output"", ""calls"", ""Azure OpenAI output 3"", ""You can store this output in a customer relationship management (CRM), so agents have contextual information about why the customer called and can quickly solve potential problems""]]}","Here's the JSON response based on the provided text:

```json
{
  ""entities"": [
    [""Azure Blob Storage"", ""system""],
    [""Audio Files"", ""component""],
    [""Azure Storage Account"", ""system""],
    [""Azure AI Speech"", ""system""],
    [""Batch Mode"", ""component""],
    [""Speaker Diarization"", ""component""],
    [""Azure AI Language"", ""system""],
    [""Personal Data Detection and Redaction"", ""component""],
    [""AI Services Ingestion Client Tool"", ""system""],
    [""No-Code Approach"", ""component""],
    [""Azure OpenAI"", ""system""],
    [""Entities Extraction"", ""component""],
    [""Conversation Summarization"", ""component""],
    [""Sentiment Analysis"", ""component""],
    [""Power BI"", ""system""],
    [""App Service"", ""system""],
    [""Customer Relationship Management (CRM)"", ""system""]
  ],
  ""relationships"": [
    [""Azure Blob Storage"", ""contains"", ""Audio Files""],
    [""Azure Storage Account"", ""part-of"", ""Azure Blob Storage""],
    [""Azure AI Speech"", ""calls"", ""Batch Mode""],
    [""Batch Mode"", ""part-of"", ""Azure AI Speech""],
    [""Azure AI Language"", ""calls"", ""Personal Data Detection and Redaction""],
    [""Personal Data Detection and Redaction"", ""part-of"", ""Azure AI Language""],
    [""AI Services Ingestion Client Tool"", ""contains"", ""No-Code Approach""],
    [""Azure OpenAI"", ""processes"", ""Transcription Information""],
    [""Power BI"", ""visualizes"", ""Processed Output""],
    [""App Service"", ""hosts"", ""Custom Web Application""],
    [""Customer Relationship Management (CRM)"", ""stores"", ""Output""]
  ]
}
```","Here's the JSON response based on the provided text:

```json
{
  ""entities"": [
    [""Azure Blob Storage"", ""system""],
    [""Audio Files"", ""component""],
    [""Azure Storage Account"", ""system""],
    [""Azure AI Speech"", ""system""],
    [""Batch Mode"", ""component""],
    [""Speaker Diarization"", ""component""],
    [""Azure AI Language"", ""system""],
    [""Personal Data Detection and Redaction"", ""component""],
    [""AI Services Ingestion Client Tool"", ""system""],
    [""No-Code Approach"", ""component""],
    [""Azure OpenAI"", ""system""],
    [""Entities Extraction"", ""component""],
    [""Conversation Summarization"", ""component""],
    [""Sentiment Analysis"", ""component""],
    [""Power BI"", ""system""],
    [""App Service"", ""system""],
    [""Customer Relationship Management (CRM)"", ""system""]
  ],
  ""relationships"": [
    [""Azure Blob Storage"", ""contains"", ""Audio Files""],
    [""Azure Storage Account"", ""part-of"", ""Azure Blob Storage""],
    [""Azure AI Speech"", ""calls"", ""Batch Mode""],
    [""Batch Mode"", ""part-of"", ""Azure AI Speech""],
    [""Azure AI Language"", ""calls"", ""Personal Data Detection and Redaction""],
    [""Personal Data Detection and Redaction"", ""part-of"", ""Azure AI Language""],
    [""AI Services Ingestion Client Tool"", ""contains"", ""No-Code Approach""],
    [""Azure OpenAI"", ""processes"", ""Transcription Information""],
    [""Power BI"", ""visualizes"", ""Processed Output""],
    [""App Service"", ""hosts"", ""Custom Web Application""],
    [""Customer Relationship Management (CRM)"", ""stores"", ""Output""]
  ]
}
```",6.270344213000499
43,mistral-nemo,../IMAGES NEW/Azure/09 Azure protect APIs original.txt,"
    To gain access to an application, an API client authenticates by providing credentials such as username and password. The IdP is Azure AD B2C in this solution, but you can use a different one.

    The authentication request goes via Azure Front Door to Azure AD B2C, which is configured with a custom domain for sign-in. Azure AD B2C authenticates the user and returns a JSON Web Token (JWT) bearer token back to the user.

    The client triggers an event that accesses a backend API. This event could be a click of a button on a web application or on a mobile device, or a direct call to the endpoint of the backend API.

    The request goes through Azure Front Door, whose back end is mapped to the public endpoint of API Management. API Management intercepts the request and validates the bearer token against Azure AD B2C by using its validate-jwt policy. If the token isn't valid, API Management rejects the request by responding with a 401 code.

    If the token is valid, API Management forwards the request to the appropriate backend API.

    The diagram shows backend APIs running in three environments:
        App Service Environment
        Function Apps
        Azure Kubernetes Services (AKS)

    APIs running in on-premises and hybrid cloud environments can also be integrated with API Management if network connectivity is established between the APIs and API Management.

","{""entities"": [[""API client"", ""system"", ""wants to gain access to an application""], [""application"", ""system"", ""API client wants to gain access to an application""], [""Azure AD B2C"", ""system"", ""The IdP is Azure AD B2C""], [""Azure Front Door"", ""system"", ""authentication request goes via Azure Front Door to Azure AD B2C""], [""backend API"", ""system"", ""The client triggers an event that accesses a backend API""], [""Azure Front Door"", ""system"", ""The request goes through Azure Front Door, whose back end is mapped to the public endpoint of API Management.""], [""backend"", ""component"", ""Azure Front Door, whose back end""], [""API Management"", ""system"", ""API Management intercepts the request and validates the bearer token against Azure AD B2C ""], [""public endpoint"", ""system"", ""whose back end is mapped to the public endpoint of API Management""], [""User"", ""person"", ""Azure AD B2C authenticates the user and returns a JSON Web Token (JWT) bearer token back to the user""]], ""relationships"": [[""API client"", ""calls"", ""application"", """"], [""Azure Front Door"", ""calls"", ""Azure AD B2C"", ""authentication request goes via Azure Front Door to Azure AD B2C""], [""Azure AD B2C"", ""is-called-from"", ""User"", ""Azure AD B2C authenticates the user and returns a JSON Web Token (JWT) bearer token back to the user""], [""API client"", ""calls"", ""backend API"", ""The client triggers an event that accesses a backend API""], [""Azure Front Door"", ""contains"", ""backend"", ""Azure Front Door, whose back end""], [""public endpoint"", ""part-of"", ""API Management"", ""Azure Front Door, whose back end""], [""backend"", ""calls"", ""public endpoint"", ""whose back end is mapped to the public endpoint of API Management""], [""API Management"", ""calls"", ""Azure AD B2C"", ""API Management intercepts the request and validates the bearer token against Azure AD B2C""]]}","Here's the extracted entities and relationships based on the provided text:

```json
{
  ""entities"": [
    [""API Client"", ""component"", ""A software component that authenticates with credentials""],
    [""Azure AD B2C"", ""system"", ""An identity provider handling authentication""],
    [""Azure Front Door"", ""system"", ""A service used for routing requests""],
    [""API Management"", ""system"", ""A service managing API interactions and validating tokens""],
    [""App Service Environment"", ""system"", ""An environment hosting backend APIs""],
    [""Function Apps"", ""system"", ""An environment hosting backend APIs""],
    [""Azure Kubernetes Services (AKS)"", ""system"", ""An environment hosting backend APIs""]
  ],
  ""relationships"": [
    [""API Client"", ""calls"", ""Azure AD B2C"", ""For user authentication""],
    [""Azure Front Door"", ""contains"", ""API Management"", ""As its back-end service""],
    [""API Management"", ""validates-token"", ""Azure AD B2C"", ""Using validate-jwt policy""],
    [""API Management"", ""forwards-request"", ""App Service Environment"", ""If token is valid""],
    [""API Management"", ""forwards-request"", ""Function Apps"", ""If token is valid""],
    [""API Management"", ""forwards-request"", ""Azure Kubernetes Services (AKS)"", ""If token is valid""]
  ]
}
```","Here's the extracted entities and relationships based on the provided text:

```json
{
  ""entities"": [
    [""API Client"", ""component"", ""A software component that authenticates with credentials""],
    [""Azure AD B2C"", ""system"", ""An identity provider handling authentication""],
    [""Azure Front Door"", ""system"", ""A service used for routing requests""],
    [""API Management"", ""system"", ""A service managing API interactions and validating tokens""],
    [""App Service Environment"", ""system"", ""An environment hosting backend APIs""],
    [""Function Apps"", ""system"", ""An environment hosting backend APIs""],
    [""Azure Kubernetes Services (AKS)"", ""system"", ""An environment hosting backend APIs""]
  ],
  ""relationships"": [
    [""API Client"", ""calls"", ""Azure AD B2C"", ""For user authentication""],
    [""Azure Front Door"", ""contains"", ""API Management"", ""As its back-end service""],
    [""API Management"", ""validates-token"", ""Azure AD B2C"", ""Using validate-jwt policy""],
    [""API Management"", ""forwards-request"", ""App Service Environment"", ""If token is valid""],
    [""API Management"", ""forwards-request"", ""Function Apps"", ""If token is valid""],
    [""API Management"", ""forwards-request"", ""Azure Kubernetes Services (AKS)"", ""If token is valid""]
  ]
}
```",5.134828804002609
44,mistral-nemo,../IMAGES NEW/Azure/06 Azure logic-apps-data-integration.txt,"
    API Management accepts API calls in the form of HTTP requests.

    API Management securely routes the HTTP requests to Logic Apps.

    Each HTTP request triggers a run in Logic Apps:
        Logic Apps uses secured template parameters to retrieve database credentials from Azure Key Vault.
        Logic Apps uses Transport Layer Security (TLS) to send the database credentials and a database statement to the on-premises data gateway.

    The on-premises data gateway connects to a SQL Server database to run the statement.

    SQL Server stores the data and makes it available to apps that users access.

    Azure Monitor collects information on Logic Apps events and performance.

","{""entities"": [[""API Management"", ""system"", ""accepts API calls in the form of HTTP requests""], [""Logic Apps"", ""system"", ""uses secured template parameters to retrieve database credentials from Azure Key Vault""], [""on-premises data gateway"", ""system"", """"], [""SQL Server"", ""system"", ""stores the data and makes it available to apps that users access""], [""Azure Monitor"", ""system"", ""collects information on Logic Apps events and performance""], [""Azure Key Vault"", ""system"", ""database credentials""]], ""relationships"": [[""API Management"", ""calls"", ""Logic Apps"", ""routes the HTTP requests to Logic Apps""], [""Logic Apps"", ""calls"", ""Azure Key Vault"", ""Logic Apps uses secured template parameters to retrieve database credentials from Azure Key Vault""], [""Logic Apps"", ""calls"", ""on-premises data gateway"", ""send the database credentials and a database statement to the on-premises data gateway""], [""on-premises data gateway"", ""calls"", ""SQL Server"", ""connects to a SQL Server database""], [""Azure Monitor"", ""calls"", ""Logic Apps"", ""collects information on Logic Apps events and performance""]]}","{
  ""entities"": [
    [""API Management"", ""system"", ""Manages API calls""],
    [""Logic Apps"", ""system"", ""Processes HTTP requests""],
    [""Azure Key Vault"", ""component"", ""Stores database credentials securely""],
    [""Transport Layer Security (TLS)"", ""component"", ""Enables secure communication""],
    [""on-premises data gateway"", ""component"", ""Connects Logic Apps to SQL Server""],
    [""SQL Server"", ""system"", ""Stores and manages data""],
    [""Azure Monitor"", ""system"", ""Collects Logic Apps events and performance information""]
  ],
  ""relationships"": [
    [""API Management"", ""calls"", ""Logic Apps""],
    [""Logic Apps"", ""contains"", ""Azure Key Vault""],
    [""Logic Apps"", ""uses"", ""Transport Layer Security (TLS)""],
    [""Logic Apps"", ""called-from"", ""on-premises data gateway""],
    [""on-premises data gateway"", ""part-of"", ""SQL Server""],
    [""SQL Server"", ""stores_data_for"", ""Azure Monitor""]
  ]
}","{
  ""entities"": [
    [""API Management"", ""system"", ""Manages API calls""],
    [""Logic Apps"", ""system"", ""Processes HTTP requests""],
    [""Azure Key Vault"", ""component"", ""Stores database credentials securely""],
    [""Transport Layer Security (TLS)"", ""component"", ""Enables secure communication""],
    [""on-premises data gateway"", ""component"", ""Connects Logic Apps to SQL Server""],
    [""SQL Server"", ""system"", ""Stores and manages data""],
    [""Azure Monitor"", ""system"", ""Collects Logic Apps events and performance information""]
  ],
  ""relationships"": [
    [""API Management"", ""calls"", ""Logic Apps""],
    [""Logic Apps"", ""contains"", ""Azure Key Vault""],
    [""Logic Apps"", ""uses"", ""Transport Layer Security (TLS)""],
    [""Logic Apps"", ""called-from"", ""on-premises data gateway""],
    [""on-premises data gateway"", ""part-of"", ""SQL Server""],
    [""SQL Server"", ""stores_data_for"", ""Azure Monitor""]
  ]
}",4.088763829000527
45,mistral-nemo,../IMAGES NEW/Azure/05. azure Original.txt,"
    Backend systems. The right-hand side of the diagram shows the various backend systems that the enterprise has deployed or relies on. These systems might include SaaS systems, other Azure services, or web services that expose REST or SOAP endpoints.

    Azure Logic Apps. In this architecture, logic apps are triggered by HTTP requests. You can also nest workflows for more complex orchestration. Logic Apps uses connectors to integrate with commonly used services. Logic Apps offers hundreds of connectors, and you can create custom connectors.

    Azure API Management. API Management consists of two related components:

        API gateway. The API gateway accepts HTTP calls and routes them to the backend.

        Developer portal. Each instance of Azure API Management provides access to a developer portal. This portal gives your developers access to documentation and code samples for calling the APIs. You can also test APIs in the developer portal.

    Azure DNS. Azure DNS provides name resolution by using the Azure infrastructure. By hosting your domains in Azure, you can manage your DNS records by using the same credentials, APIs, tools, and billing that you use for your other Azure services. To use a custom domain name, such as contoso.com, create DNS records that map the custom domain name to the IP address. For more information, see Configure a custom domain name in API Management.

    Microsoft Entra ID. Use Microsoft Entra ID to authenticate clients that call the API gateway. Microsoft Entra ID supports the OpenID Connect (OIDC) protocol. Clients obtain an access token from Microsoft Entra ID, and API Gateway validates the token to authorize the request. If you use the Standard or Premium tier of API Management, Microsoft Entra ID can also help secure access to the developer portal.

","{""entities"": [[""Backend systems"", ""system"", ""various backend systems that the enterprise has deployed or relies on""], [""SaaS systems"", ""component"", ""SaaS systems""], [""other Azure services"", ""component"", ""other Azure services""], [""web services"", ""component"", ""expose REST or SOAP endpoints""], [""Azure Logic Apps"", ""system"", ""Logic Apps uses connectors to integrate with commonly used services""], [""Azure API Management"", ""system"", ""Logic Apps uses connectors to integrate with commonly used services""], [""API gateway"", ""component"", ""The API gateway accepts HTTP calls and routes them to the backend""], [""Developer portal"", ""component"", ""This portal gives your developers access to documentation and code samples for calling the APIs""], [""Azure DNS"", ""system"", ""Azure DNS provides name resolution by using the Azure infrastructure""], [""Microsoft Entra ID"", ""system"", ""Use Microsoft Entra ID to authenticate clients that call the API gateway""], [""clients"", ""system"", ""clients that call the API gateway""], [""developers"", ""person"", ""accesses documentation and code samples""]], ""relationships"": [[""Backend systems"", ""contains"", ""SaaS systems"", ""These systems might include ""], [""Backend systems"", ""contains"", ""web services"", ""These systems might include ""], [""Backend systems"", ""contains"", ""other Azure services"", ""These systems might include ""], [""web services"", ""contains"", ""SaaS systems"", ""These systems might include ""], [""Azure API Management"", ""contains"", ""API gateway"", ""API Management consists of two related components""], [""Azure API Management"", ""contains"", ""Developer portal"", ""API Management consists of two related components""], [""clients"", ""calls"", ""API gateway"", ""clients that call the API gateway""], [""clients"", ""calls"", ""Microsoft Entra ID"", ""Clients obtain an access token from Microsoft Entra ID""], [""developers"", ""calls"", ""Developer portal"", ""This portal gives your developers access to documentation and code samples for calling the APIs. You can also test APIs in the developer portal""]]}","{
  ""entities"": [
    [""Azure Logic Apps"", ""system""],
    [""Logic Apps workflows"", ""component""],
    [""HTTP requests"", ""entity""],
    [""API gateway"", ""component""],
    [""Developer portal"", ""component""],
    [""Azure API Management"", ""system""],
    [""Azure DNS"", ""system""],
    [""Microsoft Entra ID"", ""system""]
  ],
  ""relationships"": [
    [""Logic Apps workflows"", ""part-of"", ""Azure Logic Apps""],
    [""API gateway"", ""part-of"", ""Azure API Management""],
    [""Developer portal"", ""part-of"", ""Azure API Management""],
    [""API gateway"", ""calls"", ""Logic Apps""],
    [""HTTP requests"", ""called-from"", ""Logic Apps""],
    [""API gateway"", ""contains"", ""Logic Apps workflows""],
    [""Microsoft Entra ID"", ""contains"", ""API gateway""]
  ]
}","{
  ""entities"": [
    [""Azure Logic Apps"", ""system""],
    [""Logic Apps workflows"", ""component""],
    [""HTTP requests"", ""entity""],
    [""API gateway"", ""component""],
    [""Developer portal"", ""component""],
    [""Azure API Management"", ""system""],
    [""Azure DNS"", ""system""],
    [""Microsoft Entra ID"", ""system""]
  ],
  ""relationships"": [
    [""Logic Apps workflows"", ""part-of"", ""Azure Logic Apps""],
    [""API gateway"", ""part-of"", ""Azure API Management""],
    [""Developer portal"", ""part-of"", ""Azure API Management""],
    [""API gateway"", ""calls"", ""Logic Apps""],
    [""HTTP requests"", ""called-from"", ""Logic Apps""],
    [""API gateway"", ""contains"", ""Logic Apps workflows""],
    [""Microsoft Entra ID"", ""contains"", ""API gateway""]
  ]
}",3.639212031994248
46,mistral-nemo,../IMAGES NEW/Azure/08 Azure Business Processes.txt,"
The data flows through the solution as follows:

    The airline system communicates with a custom API hosted in Azure API Management.
    A custom API coordinator receives notifications and handles incoming messages from the airline system. It sends them to Power Apps, where flights are assigned to Microsoft Teams channels.
    When a user selects a flight to monitor, or when the system assigns the user to a flight, the system queues a Graph API call in an Azure Storage Account queue for further processing.
    Azure Functions runs the Graph API calls based on the incoming messages in the storage queue, sending notifications to Teams, and also streams all events to an Azure Event Hubs for further analytics.
    The airline's notification system is managed by a custom bot messaging service that employs Azure Bot Service.
    Custom bots send flight updates to users in Teams.
    An Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs, ultimately generating insightful reports with Power BI.

","{""entities"": [[""airline system"", ""system"", ""communicates with a custom API hosted in Azure API Management""], [""custom API"", ""component"", ""communicates with a custom API hosted in Azure API Management""], [""Azure API Management"", ""system"", ""communicates with a custom API hosted in Azure API Management""], [""custom API coordinator"", ""system"", ""receives notifications and handles incoming messages from the airline system""], [""Power Apps"", ""system"", ""where flights are assigned to Microsoft Teams channels""], [""Microsoft Teams channels"", ""system"", ""where flights are assigned to Microsoft Teams channels""], [""Storage Account queue"", ""system"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing.""], [""Graph API call"", ""system"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing.""], [""Azure Functions"", ""system"", ""runs the Graph API calls based on the incoming messages in the storage queue""], [""Azure Event Hubs"", ""system"", ""Azure Event Hubs for further analytics""], [""notification system"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""custom bot messaging service"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""Azure Bot Service"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""Users"", ""person"", ""selects a flight to monitor, or when the system assigns the user to a flight""], [""Azure Data Lake storage"", ""system"", ""offers long-term retention and micro-batch processing of events from Event Hubs""], [""Power BI"", ""system"", ""generating insightful reports""]], ""relationships"": [[""Azure API Management"", ""contains"", ""custom API"", ""custom API hosted in Azure API Management""], [""airline system"", ""calls"", ""custom API"", ""communicates with a custom API""], [""custom API coordinator"", ""is-called-from"", ""airline system"", ""receives notifications and handles incoming messages from the airline system""], [""Power Apps"", ""calls"", ""Microsoft Teams channels"", ""Power Apps, where flights are assigned to Microsoft Teams channels""], [""airline system"", ""calls"", ""Graph API call"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing""], [""Azure Functions"", ""calls"", ""Graph API call"", ""runs the Graph API calls based on the incoming messages in the storage queue""], [""Azure Functions"", ""calls"", ""Storage Account queue"", ""based on the incoming messages in the storage queue""], [""Azure Functions"", ""calls"", ""Microsoft Teams channels"", ""sending notifications to Teams""], [""Azure Functions"", ""calls"", ""Azure Event Hubs"", ""also streams all events to an Azure Event Hubs for further analytics""], [""notification system"", ""is-called-from"", ""custom bot messaging service"", ""managed by a custom bot messaging service""], [""custom bot messaging service"", ""calls"", ""Azure Bot Service"", ""custom bot messaging service that employs Azure Bot Service""], [""custom bot messaging service"", ""calls"", ""Microsoft Teams channels"", ""Custom bots send flight updates to users in Teams.""], [""Microsoft Teams channels"", ""calls"", ""Users"", ""Custom bots send flight updates to users in Teams.""], [""Azure Data Lake storage"", ""is-called-from"", ""Azure Event Hubs"", ""Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs""], [""Azure Data Lake storage"", ""calls"", ""Power BI"", ""Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs, ultimately generating insightful reports with Power BI""]]}","Based on the provided context, here's the JSON response:

```json
{
  ""entities"": [
    [""Airline System"", ""system""],
    [""Custom API Coordinator"", ""component""],
    [""Power Apps"", ""system""],
    [""Microsoft Teams"", ""system""],
    [""Azure Storage Account queue"", ""component""],
    [""Azure Functions"", ""component""],
    [""Azure Event Hubs"", ""component""],
    [""Custom Bot Messaging Service"", ""component""],
    [""Azure Bot Service"", ""system""],
    [""Azure Data Lake storage"", ""component""],
    [""Power BI"", ""system""]
  ],
  ""relationships"": [
    [""Airline System"", ""calls"", ""Custom API Coordinator""],
    [""Custom API Coordinator"", ""contains"", ""Power Apps""],
    [""Power Apps"", ""part-of"", ""Microsoft Teams""],
    [""Azure Storage Account queue"", ""contains"", ""Azure Functions""],
    [""Azure Functions"", ""called-from"", ""Azure Storage Account queue""],
    [""Azure Functions"", ""calls"", ""Azure Event Hubs""],
    [""Custom Bot Messaging Service"", ""contains"", ""Azure Bot Service""],
    [""Azure Bot Service"", ""part-of"", ""Microsoft Teams""],
    [""Azure Data Lake storage"", ""calls"", ""Power BI""]
  ]
}
```","Based on the provided context, here's the JSON response:

```json
{
  ""entities"": [
    [""Airline System"", ""system""],
    [""Custom API Coordinator"", ""component""],
    [""Power Apps"", ""system""],
    [""Microsoft Teams"", ""system""],
    [""Azure Storage Account queue"", ""component""],
    [""Azure Functions"", ""component""],
    [""Azure Event Hubs"", ""component""],
    [""Custom Bot Messaging Service"", ""component""],
    [""Azure Bot Service"", ""system""],
    [""Azure Data Lake storage"", ""component""],
    [""Power BI"", ""system""]
  ],
  ""relationships"": [
    [""Airline System"", ""calls"", ""Custom API Coordinator""],
    [""Custom API Coordinator"", ""contains"", ""Power Apps""],
    [""Power Apps"", ""part-of"", ""Microsoft Teams""],
    [""Azure Storage Account queue"", ""contains"", ""Azure Functions""],
    [""Azure Functions"", ""called-from"", ""Azure Storage Account queue""],
    [""Azure Functions"", ""calls"", ""Azure Event Hubs""],
    [""Custom Bot Messaging Service"", ""contains"", ""Azure Bot Service""],
    [""Azure Bot Service"", ""part-of"", ""Microsoft Teams""],
    [""Azure Data Lake storage"", ""calls"", ""Power BI""]
  ]
}
```",4.703765051002847
47,mistral-nemo,../IMAGES NEW/Azure/10 Azure LoB original.txt,"
The data flows through the solution as follows:

    Supplier data stored in CDS is moved to SQL via Data Factory.
    Purchase order (PO) data stored in ERP system is sent to Azure SQL database.
    Azure Functions uses API to surface PO data monthly and creates a task for users to review.
    Power Apps retrieves data from Azure SQL Database through API.
    User reviews and updates POs in Power Apps and sends this data to suppliers through CSV export.
    Power BI reports trends in supplier status.

","{""entities"": [[""Supplier data"", ""component"", ""Supplier data stored in CDS""], [""CDS"", ""system"", "" Supplier data stored in CDS""], [""Azure SQL database"", ""system"", ""moved to SQL via Data Factory""], [""Data Factory"", ""system"", ""moved to SQL via Data Factory""], [""Purchase order (PO)"", ""system"", ""moved to SQL via Data Factory""], [""ERP system"", ""system"", ""Purchase order (PO) data stored in ERP system""], [""Azure Functions"", ""system"", ""uses API to surface PO data monthly and creates a task for users to review""], [""Power Apps"", ""system"", ""retrieves data from Azure SQL Database through API""], [""CSV export"", ""system"", ""ends this data to suppliers through CSV export""], [""User"", ""person"", "" reviews and updates POs in Power Apps""], [""suppliers"", ""person"", "" reviews and updates POs in Power Apps""]], ""relationships"": [[""Supplier data"", ""part-of"", ""CDS"", ""Supplier data stored in CDS""], [""Supplier data"", ""is-called-from"", ""Data Factory"", ""moved to SQL via Data Factory""], [""Data Factory"", ""calls"", ""Azure SQL database"", ""moved to SQL via Data Factory""], [""Purchase order (PO)"", ""part-of"", ""ERP system"", ""Purchase order (PO) data stored in ERP system""], [""Purchase order (PO)"", ""calls"", ""Azure SQL database"", ""Purchase order (PO) data stored in ERP system is sent to Azure SQL database""], [""Azure Functions"", ""calls"", ""Purchase order (PO)"", ""uses API to surface PO data monthly""], [""Azure Functions"", ""calls"", ""User"", ""creates a task for users to review""], [""Power Apps"", ""calls"", ""Azure SQL database"", ""retrieves data from Azure SQL Database through API""], [""User"", ""calls"", ""Power Apps"", ""Reviews and updates POs in Power Apps""], [""User"", ""calls"", ""CSV export"", ""sends this data to suppliers through CSV export""], [""CSV export"", ""calls"", ""suppliers"", ""sends this data to suppliers through CSV export""]]}","{
  ""entities"": [
    [""Supplier data"", ""component""],
    [""CDS"", ""system""],
    [""Data Factory"", ""component""],
    [""SQL"", ""system""],
    [""PO data"", ""component""],
    [""ERP system"", ""system""],
    [""Azure SQL database"", ""system""],
    [""Azure Functions"", ""component""],
    [""API"", ""component""],
    [""Power Apps"", ""component""],
    [""Azure SQL Database"", ""system""],
    [""User"", ""person""],
    [""POs"", ""component""],
    [""Suppliers"", ""person""],
    [""CSV export"", ""component""],
    [""Power BI reports"", ""component""]
  ],
  ""relationships"": [
    [""Supplier data"", ""moved-to"", ""SQL"", ""Supplier data stored in CDS is moved to SQL via Data Factory.""],
    [""PO data"", ""sent-to"", ""Azure SQL database"", ""Purchase order (PO) data stored in ERP system is sent to Azure SQL database.""],
    [""Azure Functions"", ""uses"", ""API"", ""Azure Functions uses API to surface PO data monthly and creates a task for users to review.""],
    [""Power Apps"", ""retrieves-data-from"", ""Azure SQL Database"", ""Power Apps retrieves data from Azure SQL Database through API.""],
    [""User"", ""reviews-updates"", ""POs"", ""User reviews and updates POs in Power Apps""],
    [""POs"", ""sent-to"", ""Suppliers"", ""User reviews and updates POs in Power Apps and sends this data to suppliers through CSV export.""],
    [""Power BI reports"", ""reports-on"", ""supplier status"", ""Power BI reports trends in supplier status.""]
  ]
}","{
  ""entities"": [
    [""Supplier data"", ""component""],
    [""CDS"", ""system""],
    [""Data Factory"", ""component""],
    [""SQL"", ""system""],
    [""PO data"", ""component""],
    [""ERP system"", ""system""],
    [""Azure SQL database"", ""system""],
    [""Azure Functions"", ""component""],
    [""API"", ""component""],
    [""Power Apps"", ""component""],
    [""Azure SQL Database"", ""system""],
    [""User"", ""person""],
    [""POs"", ""component""],
    [""Suppliers"", ""person""],
    [""CSV export"", ""component""],
    [""Power BI reports"", ""component""]
  ],
  ""relationships"": [
    [""Supplier data"", ""moved-to"", ""SQL"", ""Supplier data stored in CDS is moved to SQL via Data Factory.""],
    [""PO data"", ""sent-to"", ""Azure SQL database"", ""Purchase order (PO) data stored in ERP system is sent to Azure SQL database.""],
    [""Azure Functions"", ""uses"", ""API"", ""Azure Functions uses API to surface PO data monthly and creates a task for users to review.""],
    [""Power Apps"", ""retrieves-data-from"", ""Azure SQL Database"", ""Power Apps retrieves data from Azure SQL Database through API.""],
    [""User"", ""reviews-updates"", ""POs"", ""User reviews and updates POs in Power Apps""],
    [""POs"", ""sent-to"", ""Suppliers"", ""User reviews and updates POs in Power Apps and sends this data to suppliers through CSV export.""],
    [""Power BI reports"", ""reports-on"", ""supplier status"", ""Power BI reports trends in supplier status.""]
  ]
}",6.0108538170170505
48,mistral-nemo,../IMAGES NEW/Azure/12 Azure Network Microservices original.txt,"
    Outside services and clients make a POST request to APIM, with a data body that includes patient information.
    APIM calls the CreatePatient function in the Patient API with the given patient information.
    The CreatePatient function in Patient API calls the CreateAuditRecord function in the Audit API function app to create an audit record.
    The Audit API CreateAuditRecord function creates the audit record in Azure Cosmos DB, and returns a success response to the Patient API CreatePatient function.
    The CreatePatient function creates the patient document in Azure Cosmos DB, and returns a success response to APIM.
    The outside services and clients receive the success response from APIM.

","{""entities"": [[""Outside services"", ""system"", ""Outside services and clients make a POST request to APIM""], [""clients"", ""system"", ""Outside services and clients make a POST request to APIM""], [""APIM"", ""system"", ""Outside services and clients make a POST request to APIM""], [""Patient API"", ""system"", "" The CreatePatient function in Patient API calls the CreateAuditRecord function in the Audit API function app""], [""CreatePatient function"", ""component"", "" The CreatePatient function in Patient API calls the CreateAuditRecord function in the Audit API function app""], [""Audit API function app"", ""system"", ""The CreatePatient function in Patient API calls the CreateAuditRecord function in the Audit API function app""], [""CreateAuditRecord function"", ""component"", ""CreatePatient function in Patient API calls the CreateAuditRecord function""], [""Azure Cosmos DB"", ""system"", ""The Audit API CreateAuditRecord function creates the audit record in Azure Cosmos DB, and returns a success response to the Patient API CreatePatient function""]], ""relationships"": [[""CreatePatient function"", ""part-of"", ""Patient API"", ""Reason""], [""Outside services"", ""calls"", ""APIM"", ""utside services and clients make a POST request to APIM""], [""clients"", ""calls"", ""APIM"", ""outside services and clients make a POST request to APIM""], [""APIM"", ""calls"", ""CreatePatient function"", ""APIM calls the CreatePatient function in the Patient API""], [""CreateAuditRecord function"", ""part-of"", ""Audit API function app"", ""Reason""], [""CreatePatient function"", ""calls"", ""CreateAuditRecord function"", ""CreatePatient function in Patient API calls the CreateAuditRecord function in the Audit API function app""], [""CreateAuditRecord function"", ""calls"", ""Azure Cosmos DB"", ""Audit API CreateAuditRecord function creates the audit record in Azure Cosmos DB""], [""CreateAuditRecord function"", ""calls"", ""CreatePatient function"", ""returns a success response to the Patient API CreatePatient function.""], [""CreatePatient function"", ""calls"", ""Azure Cosmos DB"", ""The CreatePatient function creates the patient document in Azure Cosmos DB""], [""CreatePatient function"", ""is-called-from"", ""APIM"", ""The CreatePatient function returns a success response to APIM""]]}","Based on the provided context, here's the JSON response:

```json
{
  ""entities"": [
    [""APIM"", ""system"", ""Application Programming Interface Manager""],
    [""Patient API"", ""system"", ""API handling patient-related operations""],
    [""CreatePatient"", ""function"", ""Function to create a new patient record""],
    [""Audit API"", ""system"", ""API handling audit-related operations""],
    [""CreateAuditRecord"", ""function"", ""Function to create an audit record""],
    [""Azure Cosmos DB"", ""system"", ""Cloud-based NoSQL database service""]
  ],
  ""relationships"": [
    [""APIM"", ""calls"", ""Patient API""],
    [""Patient API"", ""contains"", ""CreatePatient""],
    [""CreatePatient"", ""calls"", ""Audit API""],
    [""Audit API"", ""contains"", ""CreateAuditRecord""],
    [""CreateAuditRecord"", ""called-from"", ""CreatePatient""],
    [""CreateAuditRecord"", ""creates record in"", ""Azure Cosmos DB""],
    [""CreatePatient"", ""creates document in"", ""Azure Cosmos DB""],
    [""APIM"", ""returns response to"", ""outside services and clients""]
  ]
}
```","Based on the provided context, here's the JSON response:

```json
{
  ""entities"": [
    [""APIM"", ""system"", ""Application Programming Interface Manager""],
    [""Patient API"", ""system"", ""API handling patient-related operations""],
    [""CreatePatient"", ""function"", ""Function to create a new patient record""],
    [""Audit API"", ""system"", ""API handling audit-related operations""],
    [""CreateAuditRecord"", ""function"", ""Function to create an audit record""],
    [""Azure Cosmos DB"", ""system"", ""Cloud-based NoSQL database service""]
  ],
  ""relationships"": [
    [""APIM"", ""calls"", ""Patient API""],
    [""Patient API"", ""contains"", ""CreatePatient""],
    [""CreatePatient"", ""calls"", ""Audit API""],
    [""Audit API"", ""contains"", ""CreateAuditRecord""],
    [""CreateAuditRecord"", ""called-from"", ""CreatePatient""],
    [""CreateAuditRecord"", ""creates record in"", ""Azure Cosmos DB""],
    [""CreatePatient"", ""creates document in"", ""Azure Cosmos DB""],
    [""APIM"", ""returns response to"", ""outside services and clients""]
  ]
}
```",4.369894272007514
49,mistral-nemo,../IMAGES NEW/TEST/08 Azure Business Processes.txt,"
The data flows through the solution as follows:

    The airline system communicates with a custom API hosted in Azure API Management.
    A custom API coordinator receives notifications and handles incoming messages from the airline system. It sends them to Power Apps, where flights are assigned to Microsoft Teams channels.
    When a user selects a flight to monitor, or when the system assigns the user to a flight, the system queues a Graph API call in an Azure Storage Account queue for further processing.
    Azure Functions runs the Graph API calls based on the incoming messages in the storage queue, sending notifications to Teams, and also streams all events to an Azure Event Hubs for further analytics.
    The airline's notification system is managed by a custom bot messaging service that employs Azure Bot Service.
    Custom bots send flight updates to users in Teams.
    An Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs, ultimately generating insightful reports with Power BI.

","{""entities"": [[""airline system"", ""system"", ""communicates with a custom API hosted in Azure API Management""], [""custom API"", ""component"", ""communicates with a custom API hosted in Azure API Management""], [""Azure API Management"", ""system"", ""communicates with a custom API hosted in Azure API Management""], [""custom API coordinator"", ""system"", ""receives notifications and handles incoming messages from the airline system""], [""Power Apps"", ""system"", ""where flights are assigned to Microsoft Teams channels""], [""Microsoft Teams channels"", ""system"", ""where flights are assigned to Microsoft Teams channels""], [""Storage Account queue"", ""system"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing.""], [""Graph API call"", ""system"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing.""], [""Azure Functions"", ""system"", ""runs the Graph API calls based on the incoming messages in the storage queue""], [""Azure Event Hubs"", ""system"", ""Azure Event Hubs for further analytics""], [""notification system"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""custom bot messaging service"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""Azure Bot Service"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""Users"", ""person"", ""selects a flight to monitor, or when the system assigns the user to a flight""], [""Azure Data Lake storage"", ""system"", ""offers long-term retention and micro-batch processing of events from Event Hubs""], [""Power BI"", ""system"", ""generating insightful reports""]], ""relationships"": [[""Azure API Management"", ""contains"", ""custom API"", ""custom API hosted in Azure API Management""], [""airline system"", ""calls"", ""custom API"", ""communicates with a custom API""], [""custom API coordinator"", ""is-called-from"", ""airline system"", ""receives notifications and handles incoming messages from the airline system""], [""Power Apps"", ""calls"", ""Microsoft Teams channels"", ""Power Apps, where flights are assigned to Microsoft Teams channels""], [""airline system"", ""calls"", ""Graph API call"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing""], [""Azure Functions"", ""calls"", ""Graph API call"", ""runs the Graph API calls based on the incoming messages in the storage queue""], [""Azure Functions"", ""calls"", ""Storage Account queue"", ""based on the incoming messages in the storage queue""], [""Azure Functions"", ""calls"", ""Microsoft Teams channels"", ""sending notifications to Teams""], [""Azure Functions"", ""calls"", ""Azure Event Hubs"", ""also streams all events to an Azure Event Hubs for further analytics""], [""notification system"", ""is-called-from"", ""custom bot messaging service"", ""managed by a custom bot messaging service""], [""custom bot messaging service"", ""calls"", ""Azure Bot Service"", ""custom bot messaging service that employs Azure Bot Service""], [""custom bot messaging service"", ""calls"", ""Microsoft Teams channels"", ""Custom bots send flight updates to users in Teams.""], [""Microsoft Teams channels"", ""calls"", ""Users"", ""Custom bots send flight updates to users in Teams.""], [""Azure Data Lake storage"", ""is-called-from"", ""Azure Event Hubs"", ""Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs""], [""Azure Data Lake storage"", ""calls"", ""Power BI"", ""Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs, ultimately generating insightful reports with Power BI""]]}","Here's the JSON output based on the provided context:

```json
{
  ""entities"": [
    [""Airline System"", ""system""],
    [""Custom API"", ""component""],
    [""Azure API Management"", ""system""],
    [""Custom API Coordinator"", ""component""],
    [""Power Apps"", ""component""],
    [""Microsoft Teams"", ""system""],
    [""Azure Storage Account"", ""system""],
    [""Azure Functions"", ""component""],
    [""Graph API"", ""component""],
    [""Azure Event Hubs"", ""system""],
    [""Custom Bot Messaging Service"", ""system""],
    [""Azure Bot Service"", ""component""],
    [""Power BI"", ""component""]
  ],
  ""relationships"": [
    [""Airline System"", ""calls"", ""Custom API""],
    [""Custom API Coordinator"", ""contains"", ""Custom API""],
    [""Custom API Coordinator"", ""sends-to"", ""Power Apps""],
    [""Power Apps"", ""assigns-flights-to"", ""Microsoft Teams""],
    [""Azure Storage Account"", ""part-of"", ""Airline System""],
    [""Azure Storage Account"", ""queues-calls-for"", ""Graph API""],
    [""Azure Functions"", ""runs-calls-from"", ""Azure Storage Account""],
    [""Azure Functions"", ""sends-notifications-to"", ""Microsoft Teams""],
    [""Azure Functions"", ""streams-events-to"", ""Azure Event Hubs""],
    [""Custom Bot Messaging Service"", ""part-of"", ""Airline System""],
    [""Custom Bot Messaging Service"", ""uses"", ""Azure Bot Service""],
    [""Azure Data Lake storage"", ""part-of"", ""Airline System""],
    [""Azure Data Lake storage"", ""processes-events-from"", ""Azure Event Hubs""],
    [""Power BI"", ""generates-reports-from"", ""Azure Data Lake storage""]
  ]
}
```","Here's the JSON output based on the provided context:

```json
{
  ""entities"": [
    [""Airline System"", ""system""],
    [""Custom API"", ""component""],
    [""Azure API Management"", ""system""],
    [""Custom API Coordinator"", ""component""],
    [""Power Apps"", ""component""],
    [""Microsoft Teams"", ""system""],
    [""Azure Storage Account"", ""system""],
    [""Azure Functions"", ""component""],
    [""Graph API"", ""component""],
    [""Azure Event Hubs"", ""system""],
    [""Custom Bot Messaging Service"", ""system""],
    [""Azure Bot Service"", ""component""],
    [""Power BI"", ""component""]
  ],
  ""relationships"": [
    [""Airline System"", ""calls"", ""Custom API""],
    [""Custom API Coordinator"", ""contains"", ""Custom API""],
    [""Custom API Coordinator"", ""sends-to"", ""Power Apps""],
    [""Power Apps"", ""assigns-flights-to"", ""Microsoft Teams""],
    [""Azure Storage Account"", ""part-of"", ""Airline System""],
    [""Azure Storage Account"", ""queues-calls-for"", ""Graph API""],
    [""Azure Functions"", ""runs-calls-from"", ""Azure Storage Account""],
    [""Azure Functions"", ""sends-notifications-to"", ""Microsoft Teams""],
    [""Azure Functions"", ""streams-events-to"", ""Azure Event Hubs""],
    [""Custom Bot Messaging Service"", ""part-of"", ""Airline System""],
    [""Custom Bot Messaging Service"", ""uses"", ""Azure Bot Service""],
    [""Azure Data Lake storage"", ""part-of"", ""Airline System""],
    [""Azure Data Lake storage"", ""processes-events-from"", ""Azure Event Hubs""],
    [""Power BI"", ""generates-reports-from"", ""Azure Data Lake storage""]
  ]
}
```",6.233719315001508
50,mistral-nemo,../IMAGES NEW/Azure/11 Mainframe original.txt,"
    A Connect agent component captures change logs by using mainframe or midrange native utilities and caches the logs in temporary storage.
    For mainframe systems, a publisher component on the mainframe manages data migration.
    For midrange systems, in place of the publisher, a listener component manages data migration. It's located on either a Windows or Linux machine.
    The publisher or listener moves the data from on-premises to Azure via an enhanced-security connection. The publisher or listener handles the commit and rollback of transactions for each unit of work, maintaining the integrity of data.
    The Connect Replicator Engine captures the data from the publisher or listener and applies it to the target. It distributes data for parallel processing.
    The target is a database that receives the changes via ODBC or ingests the changes via Azure Event Hubs.
    The changed data is consumed by Azure Databricks and applied to Azure data platform services.
    The Connect Controller Daemon authenticates the request and establishes the socket connection between the publisher or listener and the Replicator Engine.

","{""entities"": [[""Connect agent"", ""component"", ""captures change logs""], [""temporary storage"", ""component"", ""caches the logs in temporary storage""], [""mainframe native utilities"", ""system"", ""captures change logs by using mainframe or midrange native utilities""], [""midrange native utilities"", ""system"", ""captures change logs by using mainframe or midrange native utilities""], [""mainframe systems"", ""system"", ""For mainframe systems, a publisher component on the mainframe manages data migration.""], [""midrange systems"", ""system"", ""For midrange systems, in place of the publisher, a listener component manages data migration.""], [""publisher"", ""component"", ""For mainframe systems, a publisher component on the mainframe manages data migration.""], [""listener"", ""component"", ""For midrange systems, in place of the publisher, a listener component manages data migration.""], [""Connect Replicator Engine"", ""system"", ""captures the data from the publisher or listener and applies it to the target.""], [""on-premises"", ""system"", ""The publisher or listener moves the data from on-premises to Azure""], [""Azure"", ""system"", ""The publisher or listener moves the data from on-premises to Azure""], [""Connect Replicator Engine"", ""system"", ""The Connect Replicator Engine captures the data from the publisher or listener""], [""target"", ""system"", ""applies it to the target""], [""database"", ""system"", ""target is a database""], [""ODBC"", ""component"", ""The target is a database that receives the changes via ODBC or ingests the changes via Azure Event Hubs""], [""Azure Event Hubs"", ""component"", ""The target is a database that receives the changes via ODBC or ingests the changes via Azure Event Hubs""], [""Azure Databricks"", ""component"", ""the changed data is consumed by Azure Databricks and applied to Azure data platform services.""], [""Azure data platform services"", ""component"", ""the changed data is consumed by Azure Databricks and applied to Azure data platform services.""], [""Connect Controller Daemon"", ""component"", ""authenticates the request and establishes the socket connection between the publisher or listener and the Replicator Engine.""]], ""relationships"": [[""Connect agent"", ""calls"", ""mainframe native utilities"", ""captures change logs by using mainframe or midrange native utilities""], [""Connect agent"", ""calls"", ""midrange native utilities"", ""captures change logs by using mainframe or midrange native utilities""], [""Connect agent"", ""calls"", ""temporary storage"", ""captures change logs by using mainframe or midrange native utilities""], [""mainframe systems"", ""contains"", ""mainframe native utilities"", ""F""], [""midrange systems"", ""contains"", ""midrange native utilities"", """"], [""mainframe systems"", ""contains"", ""publisher"", ""For mainframe systems, a publisher component on the mainframe manages data migration.""], [""midrange systems"", ""contains"", ""listener"", ""For midrange systems, in place of the publisher, a listener component manages data migration.""], [""publisher"", ""calls"", ""on-premises"", ""The publisher or listener moves the data from on-premises to Azure""], [""publisher"", ""calls"", ""Azure"", ""The publisher or listener moves the data from on-premises to Azure""], [""listener"", ""calls"", ""on-premises"", ""The publisher or listener moves the data from on-premises to Azure""], [""listener"", ""calls"", ""Azure"", ""The publisher or listener moves the data from on-premises to Azure""], [""Connect Replicator Engine"", ""calls"", ""publisher"", ""captures the data from the publisher or listener and applies it to the target.""], [""Connect Replicator Engine"", ""calls"", ""listener"", ""captures the data from the publisher or listener and applies it to the target.""], [""Connect Replicator Engine"", ""calls"", ""target"", ""captures the data from the publisher or listener and applies it to the target.""], [""target"", ""contains"", ""database"", ""target is a database""], [""database"", ""is-called-from"", ""ODBC"", ""database that receives the changes via ODBC""], [""database"", ""is-called-from"", ""Azure Event Hubs"", ""ingests the changes via Azure Event Hubs""], [""database"", ""is-called-from"", ""Azure Databricks"", ""the changed data is consumed by Azure Databricks""], [""Azure Databricks"", ""calls"", ""Azure data platform services"", ""consumed by Azure Databricks and applied to Azure data platform services.""], [""Connect Controller Daemon"", ""is-called-from"", ""publisher"", ""establishes the socket connection between the publisher or listener and the Replicator Engine..""], [""Connect Controller Daemon"", ""is-called-from"", ""listener"", ""establishes the socket connection between the publisher or listener and the Replicator Engine..""], [""Connect Controller Daemon"", ""calls"", ""Connect Replicator Engine"", ""establishes the socket connection between the publisher or listener and the Replicator Engine..""]]}","Here's the extracted information in the requested JSON format:

```json
{
  ""entities"": [
    [""Connect Agent"", ""component"", ""Captures change logs using native utilities and caches them.""],
    [""Mainframe"", ""system"", ""The mainframe system from which logs are captured.""],
    [""Midrange"", ""system"", ""The midrange system from which logs are captured.""],
    [""Publisher"", ""component"", ""Manages data migration for mainframe systems.""],
    [""Listener"", ""component"", ""Manages data migration for midrange systems, located on Windows or Linux machine.""],
    [""Azure"", ""system"", ""The destination where data is migrated to via an enhanced-security connection.""],
    [""Connect Replicator Engine"", ""component"", ""Captures data from the publisher or listener and applies it to the target.""],
    [""Target Database"", ""component"", ""Receives changes via ODBC or ingests changes via Azure Event Hubs.""],
    [""Azure Databricks"", ""system"", ""Consumes changed data and applies it to Azure data platform services.""],
    [""Connect Controller Daemon"", ""component"", ""Authenticates requests and establishes socket connection.""]
  ],
  ""relationships"": [
    [""Connect Agent"", ""contains"", ""Mainframe""],
    [""Connect Agent"", ""contains"", ""Midrange""],
    [""Publisher"", ""part-of"", ""Mainframe""],
    [""Listener"", ""part-of"", ""Midrange""],
    [""Publisher"", ""calls"", ""Azure""],
    [""Listener"", ""calls"", ""Azure""],
    [""Connect Replicator Engine"", ""called-from"", ""Publisher""],
    [""Connect Replicator Engine"", ""called-from"", ""Listener""],
    [""Target Database"", ""contains"", ""Connect Replicator Engine""],
    [""Azure Databricks"", ""contains"", ""Target Database""],
    [""Connect Controller Daemon"", ""calls"", ""Connect Replicator Engine""]
  ]
}
```","Here's the extracted information in the requested JSON format:

```json
{
  ""entities"": [
    [""Connect Agent"", ""component"", ""Captures change logs using native utilities and caches them.""],
    [""Mainframe"", ""system"", ""The mainframe system from which logs are captured.""],
    [""Midrange"", ""system"", ""The midrange system from which logs are captured.""],
    [""Publisher"", ""component"", ""Manages data migration for mainframe systems.""],
    [""Listener"", ""component"", ""Manages data migration for midrange systems, located on Windows or Linux machine.""],
    [""Azure"", ""system"", ""The destination where data is migrated to via an enhanced-security connection.""],
    [""Connect Replicator Engine"", ""component"", ""Captures data from the publisher or listener and applies it to the target.""],
    [""Target Database"", ""component"", ""Receives changes via ODBC or ingests changes via Azure Event Hubs.""],
    [""Azure Databricks"", ""system"", ""Consumes changed data and applies it to Azure data platform services.""],
    [""Connect Controller Daemon"", ""component"", ""Authenticates requests and establishes socket connection.""]
  ],
  ""relationships"": [
    [""Connect Agent"", ""contains"", ""Mainframe""],
    [""Connect Agent"", ""contains"", ""Midrange""],
    [""Publisher"", ""part-of"", ""Mainframe""],
    [""Listener"", ""part-of"", ""Midrange""],
    [""Publisher"", ""calls"", ""Azure""],
    [""Listener"", ""calls"", ""Azure""],
    [""Connect Replicator Engine"", ""called-from"", ""Publisher""],
    [""Connect Replicator Engine"", ""called-from"", ""Listener""],
    [""Target Database"", ""contains"", ""Connect Replicator Engine""],
    [""Azure Databricks"", ""contains"", ""Target Database""],
    [""Connect Controller Daemon"", ""calls"", ""Connect Replicator Engine""]
  ]
}
```",6.960375884984387
51,mistral-nemo,../IMAGES NEW/Azure/15 Azure automate-document-classification.txt,"
    The user provides a document file that the web app uploads. The file contains multiple documents of various types. It can, for instance, be a PDF or multipage TIFF file.
        The document file is stored in Azure Blob Storage.
        The web app adds a command message to a storage queue to initiate pipeline processing.

    Durable Functions orchestration is triggered by the command message. The message contains metadata that identifies the location in Blob Storage of the document file to be processed. Each Durable Functions instance processes only one document file.

    The Scan activity function calls the Computer Vision Read API, passing in the location in storage of the document to be processed. Optical character recognition (OCR) results are returned to the orchestration to be used by subsequent activities.

    The Classify activity function calls the document classifier service that's hosted in an Azure Kubernetes Service (AKS) cluster. This service uses regular expression pattern matching to identify the starting page of each known document and to calculate how many document types are contained in the document file. The types and page ranges of the documents are calculated and returned to the orchestration.



Note

Azure doesn't offer a service that can classify multiple document types in a single file. This solution uses a non-Azure service that's hosted in AKS.

The Metadata Store activity function saves the document type and page range information in an Azure Cosmos DB store.

The Indexing activity function creates a new search document in the Cognitive Search service for each identified document type and uses the Azure AI Search libraries for .NET to include in the search document the full OCR results and document information. A correlation ID is also added to the search document so that the search results can be matched with the corresponding document metadata from Azure Cosmos DB.

End users can search for documents by contents and metadata. Correlation IDs in the search result set can be used to look up document records that are in Azure Cosmos DB. The records include links to the original document file in Blob Storage.


","{""entities"": [[""web app"", ""system"", ""The user provides a document file that the web app uploads""], [""Azure Blob Storage"", ""system"", ""The document file is stored in Azure Blob Storage""], [""storage queue"", ""system"", ""the web app adds a command message to a storage queue to initiate pipeline processing""], [""Durable Functions orchestration"", ""system"", ""Durable Functions orchestration is triggered by the command message.""], [""Scan activity function"", ""component"", ""The Scan activity function calls the Computer Vision Read API.""], [""Computer Vision Read API"", ""component"", ""The Scan activity function calls the Computer Vision Read API.""], [""Classify activity function"", ""component"", ""The Classify activity function calls the document classifier service that's hosted in an Azure Kubernetes Service (AKS) cluster""], [""document classifier service"", ""component"", ""The Classify activity function calls the document classifier service that's hosted in an Azure Kubernetes Service (AKS) cluster""], [""Azure Kubernetes Service (AKS) cluster"", ""system"", ""The Classify activity function calls the document classifier service that's hosted in an Azure Kubernetes Service (AKS) cluster""], [""User"", ""person"", ""provides a document file that the web app uploads""]], ""relationships"": [[""User"", ""calls"", ""web app"", ""The user provides a document file that the web app uploads""], [""web app"", ""calls"", ""Azure Blob Storage"", ""The user provides a document file that the web app uploads.The document file is stored in Azure Blob Storage""], [""web app"", ""calls"", ""storage queue"", ""the web app adds a command message to a storage queue to initiate pipeline processing""], [""storage queue"", ""calls"", ""Durable Functions orchestration"", ""Durable Functions orchestration is triggered by the command message.""], [""Durable Functions orchestration"", ""calls"", ""Azure Blob Storage"", ""Each Durable Functions instance processes only one document file""], [""Scan activity function"", ""calls"", ""Computer Vision Read API"", ""the Scan activity function calls the Computer Vision Read API""], [""document classifier service"", ""part-of"", ""Azure Kubernetes Service (AKS) cluster"", ""document classifier service that's hosted in an Azure Kubernetes Service (AKS) cluster""], [""Classify activity function"", ""calls"", ""Scan activity function"", ""The Classify activity function calls the document classifier service""], [""Classify activity function"", ""calls"", ""Durable Functions orchestration"", ""The types and page ranges of the documents are calculated and returned to the orchestration""]]}","Here's the JSON response based on the provided text:

```json
{
  ""entities"": [
    [""User"", ""person"", """"],
    [""Web App"", ""system"", ""Handles user file uploads and initiates pipeline processing""],
    [""Azure Blob Storage"", ""system"", ""Stores document files""],
    [""Storage Queue"", ""component"", ""Used by Web App to initiate Durable Functions""],
    [""Durable Functions Orchestration"", ""system"", ""Triggers activities based on command messages""],
    [""Scan Activity Function"", ""component"", ""Calls Computer Vision Read API for OCR""],
    [""Computer Vision Read API"", ""component"", ""Performs optical character recognition""],
    [""Classify Activity Function"", ""component"", ""Calls Document Classifier Service""],
    [""Document Classifier Service"", ""system"", ""Hosted in Azure Kubernetes Service (AKS)""],
    [""Metadata Store Activity Function"", ""component"", ""Saves document information in Cosmos DB""],
    [""Azure Cosmos DB"", ""system"", ""Stores document metadata""],
    [""Indexing Activity Function"", ""component"", ""Creates search documents using Cognitive Search service""],
    [""Cognitive Search Service"", ""system"", ""Used for end-user document searches""]
  ],
  ""relationships"": [
    [""Web App"", ""calls"", ""Storage Queue"", ""Initiates pipeline processing""],
    [""Durable Functions Orchestration"", ""triggered-by"", ""Storage Queue"", ""Processes command messages""],
    [""Durable Functions Orchestration"", ""contains"", ""Scan Activity Function"", ""Handles OCR""],
    [""Scan Activity Function"", ""calls"", ""Computer Vision Read API"", ""For optical character recognition""],
    [""Durable Functions Orchestration"", ""contains"", ""Classify Activity Function"", ""Identifies document types""],
    [""Classify Activity Function"", ""calls"", ""Document Classifier Service"", ""Uses pattern matching for classification""],
    [""Durable Functions Orchestration"", ""contains"", ""Metadata Store Activity Function"", ""Saves document metadata""],
    [""Metadata Store Activity Function"", ""saves-to"", ""Azure Cosmos DB"", ""Stores document information""],
    [""Durable Functions Orchestration"", ""contains"", ""Indexing Activity Function"", ""Creates search documents""],
    [""Indexing Activity Function"", ""uses"", ""Cognitive Search Service"", ""For end-user searches""]
  ]
}
```","Here's the JSON response based on the provided text:

```json
{
  ""entities"": [
    [""User"", ""person"", """"],
    [""Web App"", ""system"", ""Handles user file uploads and initiates pipeline processing""],
    [""Azure Blob Storage"", ""system"", ""Stores document files""],
    [""Storage Queue"", ""component"", ""Used by Web App to initiate Durable Functions""],
    [""Durable Functions Orchestration"", ""system"", ""Triggers activities based on command messages""],
    [""Scan Activity Function"", ""component"", ""Calls Computer Vision Read API for OCR""],
    [""Computer Vision Read API"", ""component"", ""Performs optical character recognition""],
    [""Classify Activity Function"", ""component"", ""Calls Document Classifier Service""],
    [""Document Classifier Service"", ""system"", ""Hosted in Azure Kubernetes Service (AKS)""],
    [""Metadata Store Activity Function"", ""component"", ""Saves document information in Cosmos DB""],
    [""Azure Cosmos DB"", ""system"", ""Stores document metadata""],
    [""Indexing Activity Function"", ""component"", ""Creates search documents using Cognitive Search service""],
    [""Cognitive Search Service"", ""system"", ""Used for end-user document searches""]
  ],
  ""relationships"": [
    [""Web App"", ""calls"", ""Storage Queue"", ""Initiates pipeline processing""],
    [""Durable Functions Orchestration"", ""triggered-by"", ""Storage Queue"", ""Processes command messages""],
    [""Durable Functions Orchestration"", ""contains"", ""Scan Activity Function"", ""Handles OCR""],
    [""Scan Activity Function"", ""calls"", ""Computer Vision Read API"", ""For optical character recognition""],
    [""Durable Functions Orchestration"", ""contains"", ""Classify Activity Function"", ""Identifies document types""],
    [""Classify Activity Function"", ""calls"", ""Document Classifier Service"", ""Uses pattern matching for classification""],
    [""Durable Functions Orchestration"", ""contains"", ""Metadata Store Activity Function"", ""Saves document metadata""],
    [""Metadata Store Activity Function"", ""saves-to"", ""Azure Cosmos DB"", ""Stores document information""],
    [""Durable Functions Orchestration"", ""contains"", ""Indexing Activity Function"", ""Creates search documents""],
    [""Indexing Activity Function"", ""uses"", ""Cognitive Search Service"", ""For end-user searches""]
  ]
}
```",8.40014883101685
52,mistral-nemo,../IMAGES NEW/Azure/10 Azure LoB original.txt,"
The data flows through the solution as follows:

    Supplier data stored in CDS is moved to SQL via Data Factory.
    Purchase order (PO) data stored in ERP system is sent to Azure SQL database.
    Azure Functions uses API to surface PO data monthly and creates a task for users to review.
    Power Apps retrieves data from Azure SQL Database through API.
    User reviews and updates POs in Power Apps and sends this data to suppliers through CSV export.
    Power BI reports trends in supplier status.

","{""entities"": [[""Supplier data"", ""component"", ""Supplier data stored in CDS""], [""CDS"", ""system"", "" Supplier data stored in CDS""], [""Azure SQL database"", ""system"", ""moved to SQL via Data Factory""], [""Data Factory"", ""system"", ""moved to SQL via Data Factory""], [""Purchase order (PO)"", ""system"", ""moved to SQL via Data Factory""], [""ERP system"", ""system"", ""Purchase order (PO) data stored in ERP system""], [""Azure Functions"", ""system"", ""uses API to surface PO data monthly and creates a task for users to review""], [""Power Apps"", ""system"", ""retrieves data from Azure SQL Database through API""], [""CSV export"", ""system"", ""ends this data to suppliers through CSV export""], [""User"", ""person"", "" reviews and updates POs in Power Apps""], [""suppliers"", ""person"", "" reviews and updates POs in Power Apps""]], ""relationships"": [[""Supplier data"", ""part-of"", ""CDS"", ""Supplier data stored in CDS""], [""Supplier data"", ""is-called-from"", ""Data Factory"", ""moved to SQL via Data Factory""], [""Data Factory"", ""calls"", ""Azure SQL database"", ""moved to SQL via Data Factory""], [""Purchase order (PO)"", ""part-of"", ""ERP system"", ""Purchase order (PO) data stored in ERP system""], [""Purchase order (PO)"", ""calls"", ""Azure SQL database"", ""Purchase order (PO) data stored in ERP system is sent to Azure SQL database""], [""Azure Functions"", ""calls"", ""Purchase order (PO)"", ""uses API to surface PO data monthly""], [""Azure Functions"", ""calls"", ""User"", ""creates a task for users to review""], [""Power Apps"", ""calls"", ""Azure SQL database"", ""retrieves data from Azure SQL Database through API""], [""User"", ""calls"", ""Power Apps"", ""Reviews and updates POs in Power Apps""], [""User"", ""calls"", ""CSV export"", ""sends this data to suppliers through CSV export""], [""CSV export"", ""calls"", ""suppliers"", ""sends this data to suppliers through CSV export""]]}","{
  ""entities"": [
    [""Supplier"", ""system""],
    [""CDS"", ""component""],
    [""Data Factory"", ""component""],
    [""SQL"", ""system""],
    [""ERP system"", ""system""],
    [""Azure SQL database"", ""system""],
    [""Azure Functions"", ""component""],
    [""API"", ""component""],
    [""Power Apps"", ""component""],
    [""PO"", ""component""],
    [""CSV export"", ""component""],
    [""Power BI"", ""component""],
    [""User"", ""person""]
  ],
  ""relationships"": [
    [""Supplier"", ""contains"", ""CDS""],
    [""Data Factory"", ""calls"", ""SQL""],
    [""ERP system"", ""called-from"", ""PO""],
    [""Azure SQL database"", ""contains"", ""PO""],
    [""Azure Functions"", ""uses"", ""API""],
    [""API"", ""called-from"", ""Azure Functions""],
    [""Power Apps"", ""retrieves"", ""Azure SQL database""],
    [""PO"", ""part-of"", ""Azure SQL database""],
    [""User"", ""updates"", ""PO""],
    [""PO"", ""part-of"", ""User""],
    [""CSV export"", ""calls"", ""Supplier""],
    [""Supplier"", ""called-from"", ""CSV export""],
    [""Power BI"", ""reports"", ""supplier status""]
  ]
}","{
  ""entities"": [
    [""Supplier"", ""system""],
    [""CDS"", ""component""],
    [""Data Factory"", ""component""],
    [""SQL"", ""system""],
    [""ERP system"", ""system""],
    [""Azure SQL database"", ""system""],
    [""Azure Functions"", ""component""],
    [""API"", ""component""],
    [""Power Apps"", ""component""],
    [""PO"", ""component""],
    [""CSV export"", ""component""],
    [""Power BI"", ""component""],
    [""User"", ""person""]
  ],
  ""relationships"": [
    [""Supplier"", ""contains"", ""CDS""],
    [""Data Factory"", ""calls"", ""SQL""],
    [""ERP system"", ""called-from"", ""PO""],
    [""Azure SQL database"", ""contains"", ""PO""],
    [""Azure Functions"", ""uses"", ""API""],
    [""API"", ""called-from"", ""Azure Functions""],
    [""Power Apps"", ""retrieves"", ""Azure SQL database""],
    [""PO"", ""part-of"", ""Azure SQL database""],
    [""User"", ""updates"", ""PO""],
    [""PO"", ""part-of"", ""User""],
    [""CSV export"", ""calls"", ""Supplier""],
    [""Supplier"", ""called-from"", ""CSV export""],
    [""Power BI"", ""reports"", ""supplier status""]
  ]
}",4.875936711992836
53,mistral-nemo,../IMAGES NEW/Azure/14 Azure Call Center Analytics.txt,"
    A phone call between an agent and a customer is recorded and stored in Azure Blob Storage. Audio files are uploaded to an Azure Storage account via a supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API.

    Azure AI Speech is used to transcribe audio files in Batch mode asynchronously with speaker diarization enabled. The transcription results are persisted in Blob Storage.

    Azure AI Language is used to detect and redact personal data in the transcript.

    For batch mode transcription and personal data detection and redaction, use the AI services Ingestion Client tool. The Ingestion Client tool uses a no-code approach for call center transcription.

    Azure OpenAI is used to process the transcript and extract entities, summarize the conversation, and analyze sentiments. The processed output is stored in Blob Storage and then analyzed and visualized by using other services. You can also store the output in a datastore for keeping track of metadata and for reporting. Use Azure OpenAI to process the stored transcription information.

    Power BI or a custom web application that's hosted by App Service is used to visualize the output. Both options provide near real-time insights. You can store this output in a customer relationship management (CRM), so agents have contextual information about why the customer called and can quickly solve potential problems. This process is fully automated, which saves the agents time and effort.

","{""entities"": [[""phone call"", ""component"", ""A phone call between an agent and a customer is recorded""], [""agent"", ""person"", ""A phone call between an agent and a customer is recorded""], [""customer"", ""person"", ""A phone call between an agent and a customer is recorded""], [""Azure Blob Storage"", ""system"", ""is recorded and stored in Azure Blob Storage""], [""Audio files"", ""system"", ""Audio files are uploaded to an Azure Storage account via a supported method""], [""supported method"", ""component"", ""Audio files are uploaded to an Azure Storage account via a supported method""], [""UI-based tool"", ""component"", ""supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""Azure Storage Explorer"", ""component"", ""supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""Storage SDK"", ""component"", ""supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""API"", ""component"", ""supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""Azure AI Speech"", ""component"", ""transcribe audio files in Batch mode asynchronously""], [""transcription results"", ""component"", ""The transcription results are persisted in Blob Storage.""], [""Azure AI Language"", ""component"", ""Azure AI Language is used to detect and redact personal data in the transcript.""], [""AI services Ingestion Client tool"", ""component"", ""For batch mode transcription and personal data detection and redaction, use the AI services Ingestion Client tool""], [""Azure OpenAI"", ""component"", ""Azure OpenAI is used to process the transcript and extract entities, summarize the conversation, and analyze sentiments.""], [""Azure OpenAI output"", ""component"", ""The processed output is stored in Blob Storage and then analyzed and visualized by using other services.""], [""other services"", ""component"", ""The processed output is stored in Blob Storage and then analyzed and visualized by using other services.""], [""App Service"", ""system"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""Power BI"", ""system"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""custom web application"", ""system"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""Azure OpenAI output 2"", ""component"", ""You can also store the output in a datastore for keeping track of metadata and for reporting""], [""datastore"", ""component"", ""You can also store the output in a datastore for keeping track of metadata and for reporting""], [""customer relationship management (CRM)"", ""system"", ""You can store this output in a customer relationship management (CRM)""], [""Azure OpenAI output 3"", ""component"", ""You can store this output in a customer relationship management (CRM)""]], ""relationships"": [[""agent"", ""calls"", ""phone call"", ""A phone call between an agent and a customer is recorded""], [""customer"", ""calls"", ""phone call"", ""A phone call between an agent and a customer is recorded""], [""phone call"", ""part-of"", ""Azure Blob Storage"", ""is recorded and stored in Azure Blob Storage""], [""Audio files"", ""part-of"", ""Azure Blob Storage"", ""Audio files are uploaded to an Azure Storage account via a supported method""], [""supported method"", ""calls"", ""Audio files"", ""Audio files are uploaded to an Azure Storage account via a supported method""], [""supported method"", ""contains"", ""UI-based tool"", ""upported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""supported method"", ""contains"", ""Azure Storage Explorer"", ""upported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""supported method"", ""contains"", ""Storage SDK"", ""upported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""supported method"", ""contains"", ""API"", ""supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""Azure AI Speech"", ""calls"", ""Audio files"", ""transcribe audio files in Batch mode asynchronously""], [""Azure Blob Storage"", ""contains"", ""transcription results"", ""The transcription results are persisted in Blob Storage.""], [""Azure AI Speech"", ""calls"", ""transcription results"", ""The transcription results are persisted in Blob Storage.""], [""Azure AI Language"", ""calls"", ""transcription results"", ""Azure AI Language is used to detect and redact personal data in the transcript.""], [""AI services Ingestion Client tool"", ""calls"", ""transcription results"", ""For batch mode transcription and personal data detection and redaction, use the AI services Ingestion Client tool""], [""Azure OpenAI"", ""calls"", ""transcription results"", ""Azure OpenAI is used to process the transcript and extract entities, summarize the conversation, and analyze sentiments.""], [""Azure OpenAI"", ""calls"", ""Azure OpenAI output"", ""The processed output is stored in Blob Storage and then analyzed and visualized by using other services.""], [""Azure Blob Storage"", ""contains"", ""Azure OpenAI output"", ""The processed output is stored in Blob Storage and then analyzed and visualized by using other services.""], [""other services"", ""calls"", ""Azure OpenAI output"", ""The processed output is stored in Blob Storage and then analyzed and visualized by using other services.""], [""Power BI"", ""part-of"", ""App Service"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""custom web application"", ""part-of"", ""App Service"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""custom web application"", ""calls"", ""Azure OpenAI output"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""Power BI"", ""calls"", ""Azure OpenAI output"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""agent"", ""calls"", ""customer relationship management (CRM)"", ""You can store this output in a customer relationship management (CRM), so agents have contextual information about why the customer called and can quickly solve potential problems""], [""Azure OpenAI output 2"", ""part-of"", ""datastore"", ""You can also store the output in a datastore for keeping track of metadata and for reporting""], [""Azure OpenAI output 3"", ""part-of"", ""customer relationship management (CRM)"", ""You can also store the output in a datastore for keeping track of metadata and for reporting""], [""Azure OpenAI output"", ""calls"", ""Azure OpenAI output 2"", ""You can also store the output in a datastore for keeping track of metadata and for reporting""], [""Azure OpenAI output"", ""calls"", ""Azure OpenAI output 3"", ""You can store this output in a customer relationship management (CRM), so agents have contextual information about why the customer called and can quickly solve potential problems""]]}","```json
{
  ""entities"": [
    [""Azure Blob Storage"", ""system""],
    [""Audio files"", ""component""],
    [""Azure Storage account"", ""system""],
    [""Azure AI Speech"", ""system""],
    [""AI services Ingestion Client tool"", ""component""],
    [""Azure AI Language"", ""system""],
    [""Azure OpenAI"", ""system""],
    [""Power BI"", ""system""],
    [""App Service"", ""system""],
    [""CRM"", ""system""]
  ],
  ""relationships"": [
    [""Audio files"", ""uploaded-to"", ""Azure Storage account""],
    [""Azure Blob Storage"", ""contains"", ""Audio files""],
    [""Azure AI Speech"", ""used-for"", ""transcription of Audio files""],
    [""AI services Ingestion Client tool"", ""used-for"", ""batch mode transcription and personal data detection and redaction""],
    [""Azure AI Language"", ""used-for"", ""personal data detection and redaction in transcript""],
    [""Azure OpenAI"", ""used-for"", ""processing transcript""],
    [""Power BI"", ""used-for"", ""visualizing output""],
    [""App Service"", ""used-for"", ""hosting custom web application for visualizing output""],
    [""Azure Blob Storage"", ""stores"", ""processed output from Azure OpenAI""],
    [""CRM"", ""used-for"", ""storing contextual information""]
  ]
}
```","```json
{
  ""entities"": [
    [""Azure Blob Storage"", ""system""],
    [""Audio files"", ""component""],
    [""Azure Storage account"", ""system""],
    [""Azure AI Speech"", ""system""],
    [""AI services Ingestion Client tool"", ""component""],
    [""Azure AI Language"", ""system""],
    [""Azure OpenAI"", ""system""],
    [""Power BI"", ""system""],
    [""App Service"", ""system""],
    [""CRM"", ""system""]
  ],
  ""relationships"": [
    [""Audio files"", ""uploaded-to"", ""Azure Storage account""],
    [""Azure Blob Storage"", ""contains"", ""Audio files""],
    [""Azure AI Speech"", ""used-for"", ""transcription of Audio files""],
    [""AI services Ingestion Client tool"", ""used-for"", ""batch mode transcription and personal data detection and redaction""],
    [""Azure AI Language"", ""used-for"", ""personal data detection and redaction in transcript""],
    [""Azure OpenAI"", ""used-for"", ""processing transcript""],
    [""Power BI"", ""used-for"", ""visualizing output""],
    [""App Service"", ""used-for"", ""hosting custom web application for visualizing output""],
    [""Azure Blob Storage"", ""stores"", ""processed output from Azure OpenAI""],
    [""CRM"", ""used-for"", ""storing contextual information""]
  ]
}
```",5.070761101000244
54,mistral-nemo,../IMAGES NEW/Azure/16 Azure automate-pdf-forms.txt,"
    A designated Outlook email account receives PDF files as attachments. The arrival of an email triggers a logic app to process the email. The logic app is built by using the capabilities of Azure Logic Apps.
    The logic app uploads the PDF files to a container in Azure Data Lake Storage.
    You can also manually or programmatically upload PDF files to the same PDF container.
    The arrival of a PDF file in the PDF container triggers another logic app to process the PDF forms that are in the PDF file.
    The logic app sends the location of the PDF file to a function app for processing. The function app is built by using the capabilities of Azure Functions.
    The function app receives the location of the file and takes these actions:
        It splits the file into single pages if the file has multiple pages. Each page contains one independent form. Split files are saved to a second container in Data Lake Storage.
        It uses HTTPS POST, an Azure REST API, to send the location of the single-page PDF file to AI Document Intelligence for processing. When Azure AI Document Intelligence completes its processing, it sends a response back to the function app, which places the information into a data structure.
        It creates a JSON data file that contains the response data and stores the file to a third container in Data Lake Storage.
    The forms processing logic app receives the processed response data.
    The forms processing logic app sends the processed data to Azure Cosmos DB, which saves the data in a database and in collections.
    Power BI obtains the data from Azure Cosmos DB and provides insights and dashboards.
    You can implement further processing as needed on the data that's in Azure Cosmos DB.

","{""entities"": [[""designated Outlook email account"", ""component"", ""A designated Outlook email account receives PDF files as attachments""], [""logic app"", ""component"", ""The arrival of an email triggers a logic app to process the email.""], [""Azure Logic Apps"", ""system"", ""The logic app is built by using the capabilities of Azure Logic Apps.""], [""Container"", ""component"", ""The logic app uploads the PDF files to a container in Azure Data Lake Storage""], [""Azure Data Lake Storage"", ""system"", ""The logic app uploads the PDF files to a container in Azure Data Lake Storage""], [""logic app 2"", ""system"", ""The arrival of a PDF file in the PDF container triggers another logic app to process the PDF forms""], [""function app"", ""component"", ""The logic app sends the location of the PDF file to a function app for processing.""], [""Azure Functions"", ""system"", ""The function app is built by using the capabilities of Azure Functions""], [""Azure REST API"", ""component"", ""It uses HTTPS POST, an Azure REST API, to send the location of the single-page PDF file""], [""Container 2"", ""component"", ""Split files are saved to a second container in Data Lake Storage""], [""AI Document Intelligence"", ""component"", ""It uses HTTPS POST, an Azure REST API, to send the location of the single-page PDF file to AI Document Intelligence for processing""], [""Container 3"", ""component"", ""JSON data file that contains the response data and stores the file to a third container in Data Lake Storage""], [""forms processing logic app"", ""component"", ""The forms processing logic app receives the processed response data""], [""Azure Cosmos DB"", ""component"", ""The forms processing logic app sends the processed data to Azure Cosmos DB""], [""database"", ""component"", ""Azure Cosmos DB, which saves the data in a database""], [""Power BI"", ""component"", ""Power BI obtains the data from Azure Cosmos DB and provides insights and dashboards""]], ""relationships"": [[""designated Outlook email account"", ""calls"", ""logic app"", ""The arrival of an email triggers a logic app to process the email.""], [""Azure Logic Apps"", ""contains"", ""logic app"", ""The logic app is built by using the capabilities of Azure Logic Apps.""], [""logic app"", ""calls"", ""Container"", ""The logic app uploads the PDF files to a container in Azure Data Lake Storage""], [""Container"", ""part-of"", ""Azure Data Lake Storage"", ""container in Azure Data Lake Storage""], [""Container"", ""calls"", ""logic app 2"", ""The arrival of a PDF file in the PDF container triggers another logic app""], [""logic app"", ""calls"", ""function app"", ""The logic app sends the location of the PDF file to a function app for processing.""], [""function app"", ""part-of"", ""Azure Functions"", ""container in Azure Data Lake Storage""], [""function app"", ""calls"", ""Container 2"", ""Split files are saved to a second container in Data Lake Storage""], [""Azure Data Lake Storage"", ""contains"", ""Container 2"", ""Split files are saved to a second container in Data Lake Storage""], [""function app"", ""calls"", ""Azure REST API"", ""It uses HTTPS POST, an Azure REST API""], [""Azure REST API"", ""calls"", ""AI Document Intelligence"", ""HTTPS POST, an Azure REST API, to send the location of the single-page PDF file to AI Document Intelligence""], [""Azure Data Lake Storage"", ""contains"", ""Container 3"", ""third container in Data Lake Storage""], [""function app"", ""calls"", ""Container 3"", ""It creates a JSON data file that contains the response data and stores the file to a third container""], [""forms processing logic app"", ""calls"", ""Container 3"", ""The forms processing logic app receives the processed response data""], [""forms processing logic app"", ""calls"", ""Azure Cosmos DB"", ""The forms processing logic app sends the processed data to Azure Cosmos DB""], [""Azure Cosmos DB"", ""calls"", ""database"", ""Azure Cosmos DB, which saves the data in a database""], [""Power BI"", ""calls"", ""Azure Cosmos DB"", ""Power BI obtains the data from Azure Cosmos DB and provides insights and dashboards""]]}","Here's the extracted entities and relationships in the requested JSON format:

```json
{
  ""entities"": [
    [""Outlook Email Account"", ""system""],
    [""Azure Logic Apps (Email Trigger)"", ""component""],
    [""Azure Logic Apps (PDF Processing)"", ""component""],
    [""Azure Data Lake Storage (PDF Container)"", ""system""],
    [""Azure Functions App"", ""component""],
    [""AI Document Intelligence API"", ""component""],
    [""Azure Cosmos DB"", ""system""]
  ],
  ""relationships"": [
    [""Outlook Email Account"", ""calls"", ""Azure Logic Apps (Email Trigger)""],
    [""Azure Logic Apps (Email Trigger)"", ""contains"", ""Azure Data Lake Storage (PDF Container)""],
    [""Azure Logic Apps (PDF Processing)"", ""called-from"", ""Azure Functions App""],
    [""Azure Functions App"", ""calls"", ""AI Document Intelligence API""],
    [""AI Document Intelligence API"", ""called-from"", ""Azure Functions App""],
    [""Azure Functions App"", ""contains"", ""Azure Data Lake Storage (JSON Container)""],
    [""Azure Logic Apps (PDF Processing)"", ""contains"", ""Azure Cosmos DB""],
    [""Power BI"", ""obtains_data_from"", ""Azure Cosmos DB""]
  ]
}
```","Here's the extracted entities and relationships in the requested JSON format:

```json
{
  ""entities"": [
    [""Outlook Email Account"", ""system""],
    [""Azure Logic Apps (Email Trigger)"", ""component""],
    [""Azure Logic Apps (PDF Processing)"", ""component""],
    [""Azure Data Lake Storage (PDF Container)"", ""system""],
    [""Azure Functions App"", ""component""],
    [""AI Document Intelligence API"", ""component""],
    [""Azure Cosmos DB"", ""system""]
  ],
  ""relationships"": [
    [""Outlook Email Account"", ""calls"", ""Azure Logic Apps (Email Trigger)""],
    [""Azure Logic Apps (Email Trigger)"", ""contains"", ""Azure Data Lake Storage (PDF Container)""],
    [""Azure Logic Apps (PDF Processing)"", ""called-from"", ""Azure Functions App""],
    [""Azure Functions App"", ""calls"", ""AI Document Intelligence API""],
    [""AI Document Intelligence API"", ""called-from"", ""Azure Functions App""],
    [""Azure Functions App"", ""contains"", ""Azure Data Lake Storage (JSON Container)""],
    [""Azure Logic Apps (PDF Processing)"", ""contains"", ""Azure Cosmos DB""],
    [""Power BI"", ""obtains_data_from"", ""Azure Cosmos DB""]
  ]
}
```",4.642133673012722
55,mistral-nemo,../IMAGES NEW/Azure/11 Mainframe original.txt,"
    A Connect agent component captures change logs by using mainframe or midrange native utilities and caches the logs in temporary storage.
    For mainframe systems, a publisher component on the mainframe manages data migration.
    For midrange systems, in place of the publisher, a listener component manages data migration. It's located on either a Windows or Linux machine.
    The publisher or listener moves the data from on-premises to Azure via an enhanced-security connection. The publisher or listener handles the commit and rollback of transactions for each unit of work, maintaining the integrity of data.
    The Connect Replicator Engine captures the data from the publisher or listener and applies it to the target. It distributes data for parallel processing.
    The target is a database that receives the changes via ODBC or ingests the changes via Azure Event Hubs.
    The changed data is consumed by Azure Databricks and applied to Azure data platform services.
    The Connect Controller Daemon authenticates the request and establishes the socket connection between the publisher or listener and the Replicator Engine.

","{""entities"": [[""Connect agent"", ""component"", ""captures change logs""], [""temporary storage"", ""component"", ""caches the logs in temporary storage""], [""mainframe native utilities"", ""system"", ""captures change logs by using mainframe or midrange native utilities""], [""midrange native utilities"", ""system"", ""captures change logs by using mainframe or midrange native utilities""], [""mainframe systems"", ""system"", ""For mainframe systems, a publisher component on the mainframe manages data migration.""], [""midrange systems"", ""system"", ""For midrange systems, in place of the publisher, a listener component manages data migration.""], [""publisher"", ""component"", ""For mainframe systems, a publisher component on the mainframe manages data migration.""], [""listener"", ""component"", ""For midrange systems, in place of the publisher, a listener component manages data migration.""], [""Connect Replicator Engine"", ""system"", ""captures the data from the publisher or listener and applies it to the target.""], [""on-premises"", ""system"", ""The publisher or listener moves the data from on-premises to Azure""], [""Azure"", ""system"", ""The publisher or listener moves the data from on-premises to Azure""], [""Connect Replicator Engine"", ""system"", ""The Connect Replicator Engine captures the data from the publisher or listener""], [""target"", ""system"", ""applies it to the target""], [""database"", ""system"", ""target is a database""], [""ODBC"", ""component"", ""The target is a database that receives the changes via ODBC or ingests the changes via Azure Event Hubs""], [""Azure Event Hubs"", ""component"", ""The target is a database that receives the changes via ODBC or ingests the changes via Azure Event Hubs""], [""Azure Databricks"", ""component"", ""the changed data is consumed by Azure Databricks and applied to Azure data platform services.""], [""Azure data platform services"", ""component"", ""the changed data is consumed by Azure Databricks and applied to Azure data platform services.""], [""Connect Controller Daemon"", ""component"", ""authenticates the request and establishes the socket connection between the publisher or listener and the Replicator Engine.""]], ""relationships"": [[""Connect agent"", ""calls"", ""mainframe native utilities"", ""captures change logs by using mainframe or midrange native utilities""], [""Connect agent"", ""calls"", ""midrange native utilities"", ""captures change logs by using mainframe or midrange native utilities""], [""Connect agent"", ""calls"", ""temporary storage"", ""captures change logs by using mainframe or midrange native utilities""], [""mainframe systems"", ""contains"", ""mainframe native utilities"", ""F""], [""midrange systems"", ""contains"", ""midrange native utilities"", """"], [""mainframe systems"", ""contains"", ""publisher"", ""For mainframe systems, a publisher component on the mainframe manages data migration.""], [""midrange systems"", ""contains"", ""listener"", ""For midrange systems, in place of the publisher, a listener component manages data migration.""], [""publisher"", ""calls"", ""on-premises"", ""The publisher or listener moves the data from on-premises to Azure""], [""publisher"", ""calls"", ""Azure"", ""The publisher or listener moves the data from on-premises to Azure""], [""listener"", ""calls"", ""on-premises"", ""The publisher or listener moves the data from on-premises to Azure""], [""listener"", ""calls"", ""Azure"", ""The publisher or listener moves the data from on-premises to Azure""], [""Connect Replicator Engine"", ""calls"", ""publisher"", ""captures the data from the publisher or listener and applies it to the target.""], [""Connect Replicator Engine"", ""calls"", ""listener"", ""captures the data from the publisher or listener and applies it to the target.""], [""Connect Replicator Engine"", ""calls"", ""target"", ""captures the data from the publisher or listener and applies it to the target.""], [""target"", ""contains"", ""database"", ""target is a database""], [""database"", ""is-called-from"", ""ODBC"", ""database that receives the changes via ODBC""], [""database"", ""is-called-from"", ""Azure Event Hubs"", ""ingests the changes via Azure Event Hubs""], [""database"", ""is-called-from"", ""Azure Databricks"", ""the changed data is consumed by Azure Databricks""], [""Azure Databricks"", ""calls"", ""Azure data platform services"", ""consumed by Azure Databricks and applied to Azure data platform services.""], [""Connect Controller Daemon"", ""is-called-from"", ""publisher"", ""establishes the socket connection between the publisher or listener and the Replicator Engine..""], [""Connect Controller Daemon"", ""is-called-from"", ""listener"", ""establishes the socket connection between the publisher or listener and the Replicator Engine..""], [""Connect Controller Daemon"", ""calls"", ""Connect Replicator Engine"", ""establishes the socket connection between the publisher or listener and the Replicator Engine..""]]}","{
  ""entities"": [
    [""Connect agent"", ""component"", ""Captures change logs""],
    [""Mainframe native utilities"", ""system"", ""Provides change logs for mainframe systems""],
    [""Midrange native utilities"", ""system"", ""Provides change logs for midrange systems""],
    [""Publisher component"", ""component"", ""Manages data migration for mainframe systems""],
    [""Listener component"", ""component"", ""Manages data migration for midrange systems""],
    [""Windows/Linux machine"", ""system"", ""Hosts the listener component""],
    [""Azure"", ""system"", ""Receives migrated data""],
    [""Enhanced-security connection"", ""component"", ""Facilitates secure data transfer to Azure""],
    [""Connect Replicator Engine"", ""component"", ""Captures data from publisher/listener and applies it to target""],
    [""Database"", ""system"", ""Receives changes via ODBC or ingests changes via Azure Event Hubs""],
    [""Azure Databricks"", ""system"", ""Consumes changed data and applies it to Azure data platform services""],
    [""Connect Controller Daemon"", ""component"", ""Authenticates requests and establishes socket connections""]
  ],
  ""relationships"": [
    [""Connect agent"", ""contains"", ""Mainframe native utilities"", ""The Connect agent captures logs from mainframe utilities""],
    [""Connect agent"", ""contains"", ""Midrange native utilities"", ""The Connect agent captures logs from midrange utilities""],
    [""Publisher component"", ""part-of"", ""Mainframe systems"", ""The publisher is part of the mainframe system""],
    [""Listener component"", ""part-of"", ""Windows/Linux machine"", ""The listener is located on a Windows or Linux machine""],
    [""Publisher/listener"", ""calls"", ""Enhanced-security connection"", ""The publisher/listener moves data via the enhanced-security connection""],
    [""Connect Replicator Engine"", ""called-from"", ""Publisher/listener"", ""The Replicator Engine captures data from the publisher/listener""],
    [""Connect Replicator Engine"", ""contains"", ""Database"", ""The target database receives changes from the Replicator Engine""],
    [""Azure Databricks"", ""called-from"", ""Database"", ""Azure Databricks consumes changed data from the database""],
    [""Connect Controller Daemon"", ""calls"", ""Replicator Engine"", ""The Controller Daemon establishes socket connections to the Replicator Engine""]
  ]
}","{
  ""entities"": [
    [""Connect agent"", ""component"", ""Captures change logs""],
    [""Mainframe native utilities"", ""system"", ""Provides change logs for mainframe systems""],
    [""Midrange native utilities"", ""system"", ""Provides change logs for midrange systems""],
    [""Publisher component"", ""component"", ""Manages data migration for mainframe systems""],
    [""Listener component"", ""component"", ""Manages data migration for midrange systems""],
    [""Windows/Linux machine"", ""system"", ""Hosts the listener component""],
    [""Azure"", ""system"", ""Receives migrated data""],
    [""Enhanced-security connection"", ""component"", ""Facilitates secure data transfer to Azure""],
    [""Connect Replicator Engine"", ""component"", ""Captures data from publisher/listener and applies it to target""],
    [""Database"", ""system"", ""Receives changes via ODBC or ingests changes via Azure Event Hubs""],
    [""Azure Databricks"", ""system"", ""Consumes changed data and applies it to Azure data platform services""],
    [""Connect Controller Daemon"", ""component"", ""Authenticates requests and establishes socket connections""]
  ],
  ""relationships"": [
    [""Connect agent"", ""contains"", ""Mainframe native utilities"", ""The Connect agent captures logs from mainframe utilities""],
    [""Connect agent"", ""contains"", ""Midrange native utilities"", ""The Connect agent captures logs from midrange utilities""],
    [""Publisher component"", ""part-of"", ""Mainframe systems"", ""The publisher is part of the mainframe system""],
    [""Listener component"", ""part-of"", ""Windows/Linux machine"", ""The listener is located on a Windows or Linux machine""],
    [""Publisher/listener"", ""calls"", ""Enhanced-security connection"", ""The publisher/listener moves data via the enhanced-security connection""],
    [""Connect Replicator Engine"", ""called-from"", ""Publisher/listener"", ""The Replicator Engine captures data from the publisher/listener""],
    [""Connect Replicator Engine"", ""contains"", ""Database"", ""The target database receives changes from the Replicator Engine""],
    [""Azure Databricks"", ""called-from"", ""Database"", ""Azure Databricks consumes changed data from the database""],
    [""Connect Controller Daemon"", ""calls"", ""Replicator Engine"", ""The Controller Daemon establishes socket connections to the Replicator Engine""]
  ]
}",8.378548406995833
56,mistral-nemo,../IMAGES NEW/Azure/12 Azure Network Microservices original.txt,"
    Outside services and clients make a POST request to APIM, with a data body that includes patient information.
    APIM calls the CreatePatient function in the Patient API with the given patient information.
    The CreatePatient function in Patient API calls the CreateAuditRecord function in the Audit API function app to create an audit record.
    The Audit API CreateAuditRecord function creates the audit record in Azure Cosmos DB, and returns a success response to the Patient API CreatePatient function.
    The CreatePatient function creates the patient document in Azure Cosmos DB, and returns a success response to APIM.
    The outside services and clients receive the success response from APIM.

","{""entities"": [[""Outside services"", ""system"", ""Outside services and clients make a POST request to APIM""], [""clients"", ""system"", ""Outside services and clients make a POST request to APIM""], [""APIM"", ""system"", ""Outside services and clients make a POST request to APIM""], [""Patient API"", ""system"", "" The CreatePatient function in Patient API calls the CreateAuditRecord function in the Audit API function app""], [""CreatePatient function"", ""component"", "" The CreatePatient function in Patient API calls the CreateAuditRecord function in the Audit API function app""], [""Audit API function app"", ""system"", ""The CreatePatient function in Patient API calls the CreateAuditRecord function in the Audit API function app""], [""CreateAuditRecord function"", ""component"", ""CreatePatient function in Patient API calls the CreateAuditRecord function""], [""Azure Cosmos DB"", ""system"", ""The Audit API CreateAuditRecord function creates the audit record in Azure Cosmos DB, and returns a success response to the Patient API CreatePatient function""]], ""relationships"": [[""CreatePatient function"", ""part-of"", ""Patient API"", ""Reason""], [""Outside services"", ""calls"", ""APIM"", ""utside services and clients make a POST request to APIM""], [""clients"", ""calls"", ""APIM"", ""outside services and clients make a POST request to APIM""], [""APIM"", ""calls"", ""CreatePatient function"", ""APIM calls the CreatePatient function in the Patient API""], [""CreateAuditRecord function"", ""part-of"", ""Audit API function app"", ""Reason""], [""CreatePatient function"", ""calls"", ""CreateAuditRecord function"", ""CreatePatient function in Patient API calls the CreateAuditRecord function in the Audit API function app""], [""CreateAuditRecord function"", ""calls"", ""Azure Cosmos DB"", ""Audit API CreateAuditRecord function creates the audit record in Azure Cosmos DB""], [""CreateAuditRecord function"", ""calls"", ""CreatePatient function"", ""returns a success response to the Patient API CreatePatient function.""], [""CreatePatient function"", ""calls"", ""Azure Cosmos DB"", ""The CreatePatient function creates the patient document in Azure Cosmos DB""], [""CreatePatient function"", ""is-called-from"", ""APIM"", ""The CreatePatient function returns a success response to APIM""]]}","{
  ""entities"": [
    [""APIM"", ""system"", ""External API Management System""],
    [""Patient_API"", ""system"", ""Patient Application Programming Interface""],
    [""Audit_API"", ""system"", ""Audit Application Programming Interface""],
    [""Azure_Cosmos_DB"", ""system"", ""Azure Cosmos Database""]
  ],
  ""relationships"": [
    [""APIM"", ""calls"", ""Patient_API.CreatePatient""],
    [""Patient_API.CreatePatient"", ""calls"", ""Audit_API.CreateAuditRecord""],
    [""Audit_API.CreateAuditRecord"", ""called-from"", ""Patient_API.CreatePatient""],
    [""Audit_API.CreateAuditRecord"", ""contains"", ""Azure_Cosmos_DB""],
    [""Patient_API.CreatePatient"", ""contains"", ""Azure_Cosmos_DB""]
  ]
}","{
  ""entities"": [
    [""APIM"", ""system"", ""External API Management System""],
    [""Patient_API"", ""system"", ""Patient Application Programming Interface""],
    [""Audit_API"", ""system"", ""Audit Application Programming Interface""],
    [""Azure_Cosmos_DB"", ""system"", ""Azure Cosmos Database""]
  ],
  ""relationships"": [
    [""APIM"", ""calls"", ""Patient_API.CreatePatient""],
    [""Patient_API.CreatePatient"", ""calls"", ""Audit_API.CreateAuditRecord""],
    [""Audit_API.CreateAuditRecord"", ""called-from"", ""Patient_API.CreatePatient""],
    [""Audit_API.CreateAuditRecord"", ""contains"", ""Azure_Cosmos_DB""],
    [""Patient_API.CreatePatient"", ""contains"", ""Azure_Cosmos_DB""]
  ]
}",3.0614311330136843
57,mistral-nemo,../IMAGES NEW/Azure/15 Azure automate-document-classification.txt,"
    The user provides a document file that the web app uploads. The file contains multiple documents of various types. It can, for instance, be a PDF or multipage TIFF file.
        The document file is stored in Azure Blob Storage.
        The web app adds a command message to a storage queue to initiate pipeline processing.

    Durable Functions orchestration is triggered by the command message. The message contains metadata that identifies the location in Blob Storage of the document file to be processed. Each Durable Functions instance processes only one document file.

    The Scan activity function calls the Computer Vision Read API, passing in the location in storage of the document to be processed. Optical character recognition (OCR) results are returned to the orchestration to be used by subsequent activities.

    The Classify activity function calls the document classifier service that's hosted in an Azure Kubernetes Service (AKS) cluster. This service uses regular expression pattern matching to identify the starting page of each known document and to calculate how many document types are contained in the document file. The types and page ranges of the documents are calculated and returned to the orchestration.



Note

Azure doesn't offer a service that can classify multiple document types in a single file. This solution uses a non-Azure service that's hosted in AKS.

The Metadata Store activity function saves the document type and page range information in an Azure Cosmos DB store.

The Indexing activity function creates a new search document in the Cognitive Search service for each identified document type and uses the Azure AI Search libraries for .NET to include in the search document the full OCR results and document information. A correlation ID is also added to the search document so that the search results can be matched with the corresponding document metadata from Azure Cosmos DB.

End users can search for documents by contents and metadata. Correlation IDs in the search result set can be used to look up document records that are in Azure Cosmos DB. The records include links to the original document file in Blob Storage.


","{""entities"": [[""web app"", ""system"", ""The user provides a document file that the web app uploads""], [""Azure Blob Storage"", ""system"", ""The document file is stored in Azure Blob Storage""], [""storage queue"", ""system"", ""the web app adds a command message to a storage queue to initiate pipeline processing""], [""Durable Functions orchestration"", ""system"", ""Durable Functions orchestration is triggered by the command message.""], [""Scan activity function"", ""component"", ""The Scan activity function calls the Computer Vision Read API.""], [""Computer Vision Read API"", ""component"", ""The Scan activity function calls the Computer Vision Read API.""], [""Classify activity function"", ""component"", ""The Classify activity function calls the document classifier service that's hosted in an Azure Kubernetes Service (AKS) cluster""], [""document classifier service"", ""component"", ""The Classify activity function calls the document classifier service that's hosted in an Azure Kubernetes Service (AKS) cluster""], [""Azure Kubernetes Service (AKS) cluster"", ""system"", ""The Classify activity function calls the document classifier service that's hosted in an Azure Kubernetes Service (AKS) cluster""], [""User"", ""person"", ""provides a document file that the web app uploads""]], ""relationships"": [[""User"", ""calls"", ""web app"", ""The user provides a document file that the web app uploads""], [""web app"", ""calls"", ""Azure Blob Storage"", ""The user provides a document file that the web app uploads.The document file is stored in Azure Blob Storage""], [""web app"", ""calls"", ""storage queue"", ""the web app adds a command message to a storage queue to initiate pipeline processing""], [""storage queue"", ""calls"", ""Durable Functions orchestration"", ""Durable Functions orchestration is triggered by the command message.""], [""Durable Functions orchestration"", ""calls"", ""Azure Blob Storage"", ""Each Durable Functions instance processes only one document file""], [""Scan activity function"", ""calls"", ""Computer Vision Read API"", ""the Scan activity function calls the Computer Vision Read API""], [""document classifier service"", ""part-of"", ""Azure Kubernetes Service (AKS) cluster"", ""document classifier service that's hosted in an Azure Kubernetes Service (AKS) cluster""], [""Classify activity function"", ""calls"", ""Scan activity function"", ""The Classify activity function calls the document classifier service""], [""Classify activity function"", ""calls"", ""Durable Functions orchestration"", ""The types and page ranges of the documents are calculated and returned to the orchestration""]]}","Here's the extracted entities and relationships in the requested JSON format:

```json
{
  ""entities"": [
    [""Azure Blob Storage"", ""system"", ""Stores document files""],
    [""Web App"", ""component"", ""Handles user uploads and initiates processing""],
    [""Storage Queue"", ""component"", ""Temporary storage for command messages""],
    [""Durable Functions Orchestration"", ""component"", ""Manages workflow of document processing""],
    [""Scan Activity Function"", ""component"", ""Calls Computer Vision Read API""],
    [""Computer Vision Read API"", ""system"", ""Performs Optical Character Recognition (OCR)""],
    [""Classify Activity Function"", ""component"", ""Calls Document Classifier Service""],
    [""Document Classifier Service"", ""system"", ""Identifies document types and page ranges""],
    [""Metadata Store Activity Function"", ""component"", ""Saves document information in Azure Cosmos DB""],
    [""Azure Cosmos DB"", ""system"", ""Stores document type and page range information""],
    [""Indexing Activity Function"", ""component"", ""Creates search documents and handles correlation IDs""],
    [""Cognitive Search Service"", ""system"", ""Handles full-text search for documents""]
  ],
  ""relationships"": [
    [""Web App"", ""calls"", ""Storage Queue""],
    [""Storage Queue"", ""contains"", ""Durable Functions Orchestration""],
    [""Durable Functions Orchestration"", ""contains"", ""Scan Activity Function""],
    [""Scan Activity Function"", ""calls"", ""Computer Vision Read API""],
    [""Durable Functions Orchestration"", ""contains"", ""Classify Activity Function""],
    [""Classify Activity Function"", ""calls"", ""Document Classifier Service""],
    [""Document Classifier Service"", ""called-from"", ""Classify Activity Function""],
    [""Classify Activity Function"", ""calls"", ""Metadata Store Activity Function""],
    [""Metadata Store Activity Function"", ""stores-info-in"", ""Azure Cosmos DB""],
    [""Durable Functions Orchestration"", ""contains"", ""Indexing Activity Function""],
    [""Indexing Activity Function"", ""creates-search-documents-for"", ""Cognitive Search Service""]
  ]
}
```","Here's the extracted entities and relationships in the requested JSON format:

```json
{
  ""entities"": [
    [""Azure Blob Storage"", ""system"", ""Stores document files""],
    [""Web App"", ""component"", ""Handles user uploads and initiates processing""],
    [""Storage Queue"", ""component"", ""Temporary storage for command messages""],
    [""Durable Functions Orchestration"", ""component"", ""Manages workflow of document processing""],
    [""Scan Activity Function"", ""component"", ""Calls Computer Vision Read API""],
    [""Computer Vision Read API"", ""system"", ""Performs Optical Character Recognition (OCR)""],
    [""Classify Activity Function"", ""component"", ""Calls Document Classifier Service""],
    [""Document Classifier Service"", ""system"", ""Identifies document types and page ranges""],
    [""Metadata Store Activity Function"", ""component"", ""Saves document information in Azure Cosmos DB""],
    [""Azure Cosmos DB"", ""system"", ""Stores document type and page range information""],
    [""Indexing Activity Function"", ""component"", ""Creates search documents and handles correlation IDs""],
    [""Cognitive Search Service"", ""system"", ""Handles full-text search for documents""]
  ],
  ""relationships"": [
    [""Web App"", ""calls"", ""Storage Queue""],
    [""Storage Queue"", ""contains"", ""Durable Functions Orchestration""],
    [""Durable Functions Orchestration"", ""contains"", ""Scan Activity Function""],
    [""Scan Activity Function"", ""calls"", ""Computer Vision Read API""],
    [""Durable Functions Orchestration"", ""contains"", ""Classify Activity Function""],
    [""Classify Activity Function"", ""calls"", ""Document Classifier Service""],
    [""Document Classifier Service"", ""called-from"", ""Classify Activity Function""],
    [""Classify Activity Function"", ""calls"", ""Metadata Store Activity Function""],
    [""Metadata Store Activity Function"", ""stores-info-in"", ""Azure Cosmos DB""],
    [""Durable Functions Orchestration"", ""contains"", ""Indexing Activity Function""],
    [""Indexing Activity Function"", ""creates-search-documents-for"", ""Cognitive Search Service""]
  ]
}
```",7.466799099987838
58,mistral-nemo,../IMAGES NEW/Azure/13 Azure Secure Research.txt,"
    Data owners upload datasets into a public blob storage account. The data is encrypted by using Microsoft-managed keys.

    Azure Data Factory uses a trigger that starts copying of the uploaded dataset to a specific location (import path) on another storage account with security controls. The storage account can only be reached through a private endpoint. Also, it's accessed by a service principal with limited permissions. Data Factory deletes the original copy making the dataset immutable.

    Researchers access the secure environment through a streaming application using Azure Virtual Desktop as a privileged jump box.

    The dataset in the secure storage account is presented to the data science VMs provisioned in a secure network environment for research work. Much of the data preparation is done on those VMs.

    The secure environment has Azure Machine Learning compute that can access the dataset through a private endpoint for users for Azure Machine Learning capabilities, such as to train, deploy, automate, and manage machine learning models. At this point, models are created that meet regulatory guidelines. All model data is de-identified by removing personal information.

    Models or de-identified data is saved to a separate location on the secure storage (export path). When new data is added to the export path, a logic app is triggered. In this architecture, the logic app is outside the secure environment because no data is sent to the logic app. Its only function is to send notification and start the manual approval process.

    The app starts an approval process requesting a review of data that is queued to be exported. The manual reviewers ensure that sensitive data isn't exported. After the review process, the data is either approved or denied.

    Note

    If an approval step is not required on exfiltration, the logic app step could be omitted.

    If the de-identified data is approved, it's sent to the Data Factory instance.

    Data Factory moves the data to the public storage account in a separate container to allow external researchers to have access to their exported data and models. Alternately, you can provision another storage account in a lower security environment.

","{""entities"": [[""datasets"", ""component"", ""Data owners upload datasets into a public blob storage account""], [""public blob storage account"", ""system"", ""Data owners upload datasets into a public blob storage account""], [""Azure Data Factory"", ""system"", ""Azure Data Factory uses a trigger that starts copying of the uploaded dataset to a specific location""], [""storage account"", ""system"", ""Azure Data Factory uses a trigger that starts copying of the uploaded dataset to a specific location (import path) on another storage account with security controls""], [""copied dataset"", ""system"", ""Azure Data Factory uses a trigger that starts copying of the uploaded dataset to a specific location (import path) on another storage account with security controls""], [""private endpoint"", ""component"", ""The storage account can only be reached through a private endpoint.""], [""service principal"", ""component"", ""Also, it's accessed by a service principal with limited permissions.""], [""streaming application"", ""component"", ""access the secure environment through a streaming application""], [""Azure Virtual Desktop"", ""component"", ""Azure Virtual Desktop as a privileged jump box""], [""data science VMs"", ""component"", ""data science VMs provisioned in a secure network environment""], [""Azure Machine Learning compute"", ""component"", ""The secure environment has Azure Machine Learning compute that can access the dataset""], [""secure network environment"", ""system"", ""data science VMs provisioned in a secure network environment""], [""machine learning models"", ""component"", ""At this point, models are created that meet regulatory guidelines""], [""de-identified data"", ""component"", ""Models or de-identified data is saved to a separate location on the secure storage (export path)""], [""logic app"", ""component"", ""When new data is added to the export path, a logic app is triggered""], [""separate container"", ""component"", ""Data Factory moves the data to the public storage account in a separate container""], [""moved data"", ""component"", ""Data Factory moves the data to the public storage account in a separate container""], [""Data owners"", ""person"", ""Data owners upload datasets into a public blob storage account""], [""Researchers"", ""person"", ""Researchers access the secure environment through a streaming application using Azure Virtual Desktop as a privileged jump box""], [""manual reviewers"", ""person"", ""The manual reviewers ensure that sensitive data isn't exported.""], [""Users"", ""person"", ""The secure environment has Azure Machine Learning compute that can access the dataset""]], ""relationships"": [[""datasets"", ""part-of"", ""public blob storage account"", ""Data owners upload datasets into a public blob storage account""], [""Data owners"", ""calls"", ""datasets"", ""Data owners upload datasets into a public blob storage account""], [""Azure Data Factory"", ""calls"", ""datasets"", ""Azure Data Factory uses a trigger that starts copying of the uploaded dataset""], [""storage account"", ""contains"", ""copied dataset"", ""opying of the uploaded dataset to a specific location (import path) on another storage account with security controls""], [""Azure Data Factory"", ""calls"", ""copied dataset"", ""Azure Data Factory uses a trigger that starts copying of the uploaded dataset to a specific location""], [""private endpoint"", ""calls"", ""storage account"", ""The storage account can only be reached through a private endpoint""], [""storage account"", ""is-called-from"", ""service principal"", ""Also, it's accessed by a service principal with limited permissions""], [""Researchers"", ""calls"", ""Azure Virtual Desktop"", "" Researchers access the secure environment through a streaming application""], [""Azure Virtual Desktop"", ""calls"", ""streaming application"", ""through a streaming application using Azure Virtual Desktop""], [""streaming application"", ""calls"", ""storage account"", ""Researchers access the secure environment through a streaming application using Azure Virtual Desktop as a privileged jump box""], [""data science VMs"", ""part-of"", ""secure network environment"", ""The dataset in the secure storage account is presented to the data science VMs""], [""data science VMs"", ""calls"", ""copied dataset"", "" The dataset in the secure storage account is presented to the data science VMs""], [""secure network environment"", ""contains"", ""Azure Machine Learning compute"", ""The secure environment has Azure Machine Learning compute that can access the dataset""], [""Azure Machine Learning compute"", ""calls"", ""Azure Machine Learning compute"", ""The secure environment has Azure Machine Learning compute that can access the dataset""], [""machine learning models"", ""part-of"", ""storage account"", ""Models or de-identified data is saved to a separate location on the secure storage (export path)""], [""machine learning models"", ""calls"", ""logic app"", ""When new data is added to the export path, a logic app is triggered""], [""logic app"", ""calls"", ""manual reviewers"", ""The app starts an approval process requesting a review of data that is queued to be exported.""], [""public blob storage account"", ""contains"", ""separate container"", ""Data Factory moves the data to the public storage account in a separate container""], [""Azure Data Factory"", ""calls"", ""de-identified data"", ""Data Factory moves the data to the public storage account in a separate container to allow external researchers to have access to their exported data and models""], [""separate container"", ""contains"", ""moved data"", ""Data Factory moves the data to the public storage account in a separate container""], [""Azure Data Factory"", ""calls"", ""moved data"", ""Data Factory moves the data to the public storage account in a separate container to allow external researchers to have access to their exported data and models""], [""Users"", ""calls"", ""Azure Machine Learning compute"", ""The secure environment has Azure Machine Learning compute that can access the dataset""]]}","Here's the extracted entities and relationships from the provided context:

```json
{
  ""entities"": [
    [""Azure Blob Storage"", ""system""],
    [""Data Factory"", ""system""],
    [""Secure Storage Account"", ""system""],
    [""Private Endpoint"", ""component""],
    [""Service Principal"", ""person""],
    [""Virtual Desktop"", ""system""],
    [""Data Science VMs"", ""system""],
    [""Machine Learning Compute"", ""system""],
    [""Logic App"", ""system""],
    [""Manual Reviewers"", ""person""]
  ],
  ""relationships"": [
    [""Azure Blob Storage"", ""contains"", ""Secure Storage Account""],
    [""Secure Storage Account"", ""part-of"", ""Azure Blob Storage""],
    [""Data Factory"", ""calls"", ""Private Endpoint""],
    [""Private Endpoint"", ""called-from"", ""Data Factory""],
    [""Data Science VMs"", ""contains"", ""Machine Learning Compute""],
    [""Machine Learning Compute"", ""part-of"", ""Data Science VMs""],
    [""Logic App"", ""calls"", ""Manual Reviewers""],
    [""Manual Reviewers"", ""called-from"", ""Logic App""]
  ]
}
```","Here's the extracted entities and relationships from the provided context:

```json
{
  ""entities"": [
    [""Azure Blob Storage"", ""system""],
    [""Data Factory"", ""system""],
    [""Secure Storage Account"", ""system""],
    [""Private Endpoint"", ""component""],
    [""Service Principal"", ""person""],
    [""Virtual Desktop"", ""system""],
    [""Data Science VMs"", ""system""],
    [""Machine Learning Compute"", ""system""],
    [""Logic App"", ""system""],
    [""Manual Reviewers"", ""person""]
  ],
  ""relationships"": [
    [""Azure Blob Storage"", ""contains"", ""Secure Storage Account""],
    [""Secure Storage Account"", ""part-of"", ""Azure Blob Storage""],
    [""Data Factory"", ""calls"", ""Private Endpoint""],
    [""Private Endpoint"", ""called-from"", ""Data Factory""],
    [""Data Science VMs"", ""contains"", ""Machine Learning Compute""],
    [""Machine Learning Compute"", ""part-of"", ""Data Science VMs""],
    [""Logic App"", ""calls"", ""Manual Reviewers""],
    [""Manual Reviewers"", ""called-from"", ""Logic App""]
  ]
}
```",4.453411152004264
59,mistral-nemo,../IMAGES NEW/Azure/07 Azure internal APIs original.txt,"
The data flows as follows:

    Developers check in code to a GitHub repository that's connected to a CI/CD pipeline agent that's installed on an Azure VM.
    The agent pushes the build to the API application that's hosted on ILB ASE.
    Azure API Management consumes the preceding APIs via HOST headers that are specified in API Management policy.
    API Management uses the App Service Environment's DNS name for all the APIs.
    Application Gateway exposes API Management's developer and API portal.
    Azure Private DNS is used to route the traffic internally between ASE, API Management, and Application Gateway.
    External users utilize the exposed developer portal to consume the APIs via Application Gateway's public IP.

","{""entities"": [[""GitHub repository"", ""system"", """"], [""Developers"", ""person"", """"], [""External users"", ""person"", """"], [""CI/CD pipeline agent"", ""system"", """"], [""Azure VM"", ""system"", """"], [""ILB ASE"", ""system"", """"], [""API application"", ""component"", """"], [""Azure API Management"", ""system"", ""consumes the preceding APIs via HOST headers""], [""App Service Environment"", ""component"", """"], [""Application Gateway"", ""component"", ""exposes API Management's developer and API portal""], [""Developer portal"", ""component"", ""API Management's developer and API portal""], [""API portal"", ""component"", ""API Management's developer and API portal""], [""Application Gateway"", ""component"", ""exposes API Management's developer and API portal""], [""Azure Private DNS"", ""component"", ""used to route the traffic internally between ASE, API Management, and Application Gateway""]], ""relationships"": [[""Azure VM"", ""contains"", ""CI/CD pipeline agent"", ""installed on an Azure VM""], [""API application"", ""part-of"", ""ILB ASE"", ""API application that's hosted on ILB ASE""], [""GitHub repository"", ""calls"", ""CI/CD pipeline agent"", ""GitHub repository that's connected to a CI/CD pipeline agent""], [""CI/CD pipeline agent"", ""calls"", ""API application"", ""agent pushes the build to the API application""], [""Azure API Management"", ""calls"", ""App Service Environment"", ""uses the App Service Environment's DNS name for all the APIs""], [""External users"", ""calls"", ""Application Gateway"", """"], [""Application Gateway"", ""calls"", ""API application"", ""to consume the APIs via Application Gateway's public IP""], [""Azure API Management"", ""contains"", ""Developer portal"", ""API Management's developer and API portal""], [""Azure API Management"", ""contains"", ""API portal"", ""API Management's developer and API portal""], [""Application Gateway"", ""calls"", ""API portal"", ""exposes API Management's developer and API portal.""], [""Application Gateway"", ""calls"", ""Developer portal"", ""exposes API Management's developer and API portal.""], [""Azure Private DNS"", ""calls"", ""Azure API Management"", ""route the traffic internally between ASE, API Management, and Application Gateway""], [""Azure Private DNS"", ""calls"", ""Application Gateway"", ""route the traffic internally between ASE, API Management, and Application Gateway""]]}","Here's the JSON representation of the entities and relationships extracted from the given context:

```json
{
  ""entities"": [
    [""Developers"", ""person""],
    [""GitHub repository"", ""system""],
    [""CI/CD pipeline agent"", ""component""],
    [""Azure VM"", ""system""],
    [""API application"", ""component""],
    [""ILB ASE"", ""system""],
    [""Azure API Management"", ""system""],
    [""App Service Environment"", ""system""],
    [""Application Gateway"", ""system""],
    [""Azure Private DNS"", ""system""],
    [""External users"", ""person""]
  ],
  ""relationships"": [
    [""Developers"", ""check in code to"", ""GitHub repository""],
    [""CI/CD pipeline agent"", ""installed on"", ""Azure VM""],
    [""CI/CD pipeline agent"", ""pushes build to"", ""API application""],
    [""API application"", ""hosted on"", ""ILB ASE""],
    [""Azure API Management"", ""consumes APIs via HOST headers from"", ""API application""],
    [""Azure API Management"", ""uses DNS name for APIs from"", ""App Service Environment""],
    [""Application Gateway"", ""exposes developer and API portal of"", ""Azure API Management""],
    [""Azure Private DNS"", ""used to route traffic internally between"", ""ASE, API Management, Application Gateway""],
    [""External users"", ""consume APIs via"", ""Application Gateway""]
  ]
}
```","Here's the JSON representation of the entities and relationships extracted from the given context:

```json
{
  ""entities"": [
    [""Developers"", ""person""],
    [""GitHub repository"", ""system""],
    [""CI/CD pipeline agent"", ""component""],
    [""Azure VM"", ""system""],
    [""API application"", ""component""],
    [""ILB ASE"", ""system""],
    [""Azure API Management"", ""system""],
    [""App Service Environment"", ""system""],
    [""Application Gateway"", ""system""],
    [""Azure Private DNS"", ""system""],
    [""External users"", ""person""]
  ],
  ""relationships"": [
    [""Developers"", ""check in code to"", ""GitHub repository""],
    [""CI/CD pipeline agent"", ""installed on"", ""Azure VM""],
    [""CI/CD pipeline agent"", ""pushes build to"", ""API application""],
    [""API application"", ""hosted on"", ""ILB ASE""],
    [""Azure API Management"", ""consumes APIs via HOST headers from"", ""API application""],
    [""Azure API Management"", ""uses DNS name for APIs from"", ""App Service Environment""],
    [""Application Gateway"", ""exposes developer and API portal of"", ""Azure API Management""],
    [""Azure Private DNS"", ""used to route traffic internally between"", ""ASE, API Management, Application Gateway""],
    [""External users"", ""consume APIs via"", ""Application Gateway""]
  ]
}
```",5.026719827990746
60,mistral-nemo,../IMAGES NEW/Azure/05. azure Original.txt,"
    Backend systems. The right-hand side of the diagram shows the various backend systems that the enterprise has deployed or relies on. These systems might include SaaS systems, other Azure services, or web services that expose REST or SOAP endpoints.

    Azure Logic Apps. In this architecture, logic apps are triggered by HTTP requests. You can also nest workflows for more complex orchestration. Logic Apps uses connectors to integrate with commonly used services. Logic Apps offers hundreds of connectors, and you can create custom connectors.

    Azure API Management. API Management consists of two related components:

        API gateway. The API gateway accepts HTTP calls and routes them to the backend.

        Developer portal. Each instance of Azure API Management provides access to a developer portal. This portal gives your developers access to documentation and code samples for calling the APIs. You can also test APIs in the developer portal.

    Azure DNS. Azure DNS provides name resolution by using the Azure infrastructure. By hosting your domains in Azure, you can manage your DNS records by using the same credentials, APIs, tools, and billing that you use for your other Azure services. To use a custom domain name, such as contoso.com, create DNS records that map the custom domain name to the IP address. For more information, see Configure a custom domain name in API Management.

    Microsoft Entra ID. Use Microsoft Entra ID to authenticate clients that call the API gateway. Microsoft Entra ID supports the OpenID Connect (OIDC) protocol. Clients obtain an access token from Microsoft Entra ID, and API Gateway validates the token to authorize the request. If you use the Standard or Premium tier of API Management, Microsoft Entra ID can also help secure access to the developer portal.

","{""entities"": [[""Backend systems"", ""system"", ""various backend systems that the enterprise has deployed or relies on""], [""SaaS systems"", ""component"", ""SaaS systems""], [""other Azure services"", ""component"", ""other Azure services""], [""web services"", ""component"", ""expose REST or SOAP endpoints""], [""Azure Logic Apps"", ""system"", ""Logic Apps uses connectors to integrate with commonly used services""], [""Azure API Management"", ""system"", ""Logic Apps uses connectors to integrate with commonly used services""], [""API gateway"", ""component"", ""The API gateway accepts HTTP calls and routes them to the backend""], [""Developer portal"", ""component"", ""This portal gives your developers access to documentation and code samples for calling the APIs""], [""Azure DNS"", ""system"", ""Azure DNS provides name resolution by using the Azure infrastructure""], [""Microsoft Entra ID"", ""system"", ""Use Microsoft Entra ID to authenticate clients that call the API gateway""], [""clients"", ""system"", ""clients that call the API gateway""], [""developers"", ""person"", ""accesses documentation and code samples""]], ""relationships"": [[""Backend systems"", ""contains"", ""SaaS systems"", ""These systems might include ""], [""Backend systems"", ""contains"", ""web services"", ""These systems might include ""], [""Backend systems"", ""contains"", ""other Azure services"", ""These systems might include ""], [""web services"", ""contains"", ""SaaS systems"", ""These systems might include ""], [""Azure API Management"", ""contains"", ""API gateway"", ""API Management consists of two related components""], [""Azure API Management"", ""contains"", ""Developer portal"", ""API Management consists of two related components""], [""clients"", ""calls"", ""API gateway"", ""clients that call the API gateway""], [""clients"", ""calls"", ""Microsoft Entra ID"", ""Clients obtain an access token from Microsoft Entra ID""], [""developers"", ""calls"", ""Developer portal"", ""This portal gives your developers access to documentation and code samples for calling the APIs. You can also test APIs in the developer portal""]]}","{
  ""entities"": [
    [""Azure Logic Apps"", ""system"", ""Orchestrates workflows triggered by HTTP requests with connectors for integration""],
    [""API gateway"", ""component"", ""Accepts HTTP calls and routes them to backend systems""],
    [""Developer portal"", ""component"", ""Provides access to documentation, code samples, and API testing""],
    [""Azure API Management"", ""system"", ""Consists of API gateway and developer portal""],
    [""Azure DNS"", ""system"", ""Provides name resolution for custom domain names like contoso.com""],
    [""Microsoft Entra ID"", ""system"", ""Handles authentication for clients calling the API gateway and securing access to the developer portal""]
  ],
  ""relationships"": [
    [""Azure Logic Apps"", ""contains"", ""API gateway""],
    [""Azure Logic Apps"", ""contains"", ""Developer portal""],
    [""API gateway"", ""calls"", ""Backend systems""],
    [""API gateway"", ""called-from"", ""Microsoft Entra ID""],
    [""Developer portal"", ""part-of"", ""Azure API Management""],
    [""Azure DNS"", ""contains"", ""contoso.com""]
  ]
}","{
  ""entities"": [
    [""Azure Logic Apps"", ""system"", ""Orchestrates workflows triggered by HTTP requests with connectors for integration""],
    [""API gateway"", ""component"", ""Accepts HTTP calls and routes them to backend systems""],
    [""Developer portal"", ""component"", ""Provides access to documentation, code samples, and API testing""],
    [""Azure API Management"", ""system"", ""Consists of API gateway and developer portal""],
    [""Azure DNS"", ""system"", ""Provides name resolution for custom domain names like contoso.com""],
    [""Microsoft Entra ID"", ""system"", ""Handles authentication for clients calling the API gateway and securing access to the developer portal""]
  ],
  ""relationships"": [
    [""Azure Logic Apps"", ""contains"", ""API gateway""],
    [""Azure Logic Apps"", ""contains"", ""Developer portal""],
    [""API gateway"", ""calls"", ""Backend systems""],
    [""API gateway"", ""called-from"", ""Microsoft Entra ID""],
    [""Developer portal"", ""part-of"", ""Azure API Management""],
    [""Azure DNS"", ""contains"", ""contoso.com""]
  ]
}",4.3685928380000405
61,mistral-nemo,../IMAGES NEW/Azure/06 Azure logic-apps-data-integration.txt,"
    API Management accepts API calls in the form of HTTP requests.

    API Management securely routes the HTTP requests to Logic Apps.

    Each HTTP request triggers a run in Logic Apps:
        Logic Apps uses secured template parameters to retrieve database credentials from Azure Key Vault.
        Logic Apps uses Transport Layer Security (TLS) to send the database credentials and a database statement to the on-premises data gateway.

    The on-premises data gateway connects to a SQL Server database to run the statement.

    SQL Server stores the data and makes it available to apps that users access.

    Azure Monitor collects information on Logic Apps events and performance.

","{""entities"": [[""API Management"", ""system"", ""accepts API calls in the form of HTTP requests""], [""Logic Apps"", ""system"", ""uses secured template parameters to retrieve database credentials from Azure Key Vault""], [""on-premises data gateway"", ""system"", """"], [""SQL Server"", ""system"", ""stores the data and makes it available to apps that users access""], [""Azure Monitor"", ""system"", ""collects information on Logic Apps events and performance""], [""Azure Key Vault"", ""system"", ""database credentials""]], ""relationships"": [[""API Management"", ""calls"", ""Logic Apps"", ""routes the HTTP requests to Logic Apps""], [""Logic Apps"", ""calls"", ""Azure Key Vault"", ""Logic Apps uses secured template parameters to retrieve database credentials from Azure Key Vault""], [""Logic Apps"", ""calls"", ""on-premises data gateway"", ""send the database credentials and a database statement to the on-premises data gateway""], [""on-premises data gateway"", ""calls"", ""SQL Server"", ""connects to a SQL Server database""], [""Azure Monitor"", ""calls"", ""Logic Apps"", ""collects information on Logic Apps events and performance""]]}","Here's the extracted entities and relationships in JSON format:

```json
{
  ""entities"": [
    [""API Management"", ""system""],
    [""Logic Apps"", ""system""],
    [""Azure Key Vault"", ""system""],
    [""On-premises Data Gateway"", ""component""],
    [""SQL Server Database"", ""system""]
  ],
  ""relationships"": [
    [""API Management"", ""calls"", ""Logic Apps""],
    [""Logic Apps"", ""contains"", ""On-premises Data Gateway""],
    [""Logic Apps"", ""called-from"", ""Azure Key Vault""],
    [""On-premises Data Gateway"", ""part-of"", ""SQL Server Database""]
  ]
}
```","Here's the extracted entities and relationships in JSON format:

```json
{
  ""entities"": [
    [""API Management"", ""system""],
    [""Logic Apps"", ""system""],
    [""Azure Key Vault"", ""system""],
    [""On-premises Data Gateway"", ""component""],
    [""SQL Server Database"", ""system""]
  ],
  ""relationships"": [
    [""API Management"", ""calls"", ""Logic Apps""],
    [""Logic Apps"", ""contains"", ""On-premises Data Gateway""],
    [""Logic Apps"", ""called-from"", ""Azure Key Vault""],
    [""On-premises Data Gateway"", ""part-of"", ""SQL Server Database""]
  ]
}
```",2.7644487590005156
62,mistral-nemo,../IMAGES NEW/Azure/08 Azure Business Processes.txt,"
The data flows through the solution as follows:

    The airline system communicates with a custom API hosted in Azure API Management.
    A custom API coordinator receives notifications and handles incoming messages from the airline system. It sends them to Power Apps, where flights are assigned to Microsoft Teams channels.
    When a user selects a flight to monitor, or when the system assigns the user to a flight, the system queues a Graph API call in an Azure Storage Account queue for further processing.
    Azure Functions runs the Graph API calls based on the incoming messages in the storage queue, sending notifications to Teams, and also streams all events to an Azure Event Hubs for further analytics.
    The airline's notification system is managed by a custom bot messaging service that employs Azure Bot Service.
    Custom bots send flight updates to users in Teams.
    An Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs, ultimately generating insightful reports with Power BI.

","{""entities"": [[""airline system"", ""system"", ""communicates with a custom API hosted in Azure API Management""], [""custom API"", ""component"", ""communicates with a custom API hosted in Azure API Management""], [""Azure API Management"", ""system"", ""communicates with a custom API hosted in Azure API Management""], [""custom API coordinator"", ""system"", ""receives notifications and handles incoming messages from the airline system""], [""Power Apps"", ""system"", ""where flights are assigned to Microsoft Teams channels""], [""Microsoft Teams channels"", ""system"", ""where flights are assigned to Microsoft Teams channels""], [""Storage Account queue"", ""system"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing.""], [""Graph API call"", ""system"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing.""], [""Azure Functions"", ""system"", ""runs the Graph API calls based on the incoming messages in the storage queue""], [""Azure Event Hubs"", ""system"", ""Azure Event Hubs for further analytics""], [""notification system"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""custom bot messaging service"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""Azure Bot Service"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""Users"", ""person"", ""selects a flight to monitor, or when the system assigns the user to a flight""], [""Azure Data Lake storage"", ""system"", ""offers long-term retention and micro-batch processing of events from Event Hubs""], [""Power BI"", ""system"", ""generating insightful reports""]], ""relationships"": [[""Azure API Management"", ""contains"", ""custom API"", ""custom API hosted in Azure API Management""], [""airline system"", ""calls"", ""custom API"", ""communicates with a custom API""], [""custom API coordinator"", ""is-called-from"", ""airline system"", ""receives notifications and handles incoming messages from the airline system""], [""Power Apps"", ""calls"", ""Microsoft Teams channels"", ""Power Apps, where flights are assigned to Microsoft Teams channels""], [""airline system"", ""calls"", ""Graph API call"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing""], [""Azure Functions"", ""calls"", ""Graph API call"", ""runs the Graph API calls based on the incoming messages in the storage queue""], [""Azure Functions"", ""calls"", ""Storage Account queue"", ""based on the incoming messages in the storage queue""], [""Azure Functions"", ""calls"", ""Microsoft Teams channels"", ""sending notifications to Teams""], [""Azure Functions"", ""calls"", ""Azure Event Hubs"", ""also streams all events to an Azure Event Hubs for further analytics""], [""notification system"", ""is-called-from"", ""custom bot messaging service"", ""managed by a custom bot messaging service""], [""custom bot messaging service"", ""calls"", ""Azure Bot Service"", ""custom bot messaging service that employs Azure Bot Service""], [""custom bot messaging service"", ""calls"", ""Microsoft Teams channels"", ""Custom bots send flight updates to users in Teams.""], [""Microsoft Teams channels"", ""calls"", ""Users"", ""Custom bots send flight updates to users in Teams.""], [""Azure Data Lake storage"", ""is-called-from"", ""Azure Event Hubs"", ""Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs""], [""Azure Data Lake storage"", ""calls"", ""Power BI"", ""Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs, ultimately generating insightful reports with Power BI""]]}","{
  ""entities"": [
    [""Airline System"", ""system""],
    [""Custom API Coordinator"", ""component""],
    [""Power Apps"", ""system""],
    [""Microsoft Teams"", ""system""],
    [""Azure Storage Account Queue"", ""component""],
    [""Azure Functions"", ""system""],
    [""Azure Event Hubs"", ""system""],
    [""Custom Bot Messaging Service"", ""system""],
    [""Azure Bot Service"", ""component""],
    [""Azure Data Lake storage"", ""system""],
    [""Power BI"", ""system""]
  ],
  ""relationships"": [
    [""Airline System"", ""communicates with"", ""Custom API Coordinator""],
    [""Custom API Coordinator"", ""part-of"", ""Airline System""],
    [""Custom API Coordinator"", ""sends messages to"", ""Power Apps""],
    [""Power Apps"", ""contains"", ""Microsoft Teams""],
    [""Azure Storage Account Queue"", ""calls"", ""Azure Functions""],
    [""Azure Functions"", ""called-from"", ""Azure Storage Account Queue""],
    [""Azure Functions"", ""sends notifications to"", ""Microsoft Teams""],
    [""Azure Functions"", ""streams events to"", ""Azure Event Hubs""],
    [""Custom Bot Messaging Service"", ""uses"", ""Azure Bot Service""],
    [""Azure Data Lake storage"", ""contains"", ""Azure Event Hubs""],
    [""Azure Data Lake storage"", ""generates reports with"", ""Power BI""]
  ]
}","{
  ""entities"": [
    [""Airline System"", ""system""],
    [""Custom API Coordinator"", ""component""],
    [""Power Apps"", ""system""],
    [""Microsoft Teams"", ""system""],
    [""Azure Storage Account Queue"", ""component""],
    [""Azure Functions"", ""system""],
    [""Azure Event Hubs"", ""system""],
    [""Custom Bot Messaging Service"", ""system""],
    [""Azure Bot Service"", ""component""],
    [""Azure Data Lake storage"", ""system""],
    [""Power BI"", ""system""]
  ],
  ""relationships"": [
    [""Airline System"", ""communicates with"", ""Custom API Coordinator""],
    [""Custom API Coordinator"", ""part-of"", ""Airline System""],
    [""Custom API Coordinator"", ""sends messages to"", ""Power Apps""],
    [""Power Apps"", ""contains"", ""Microsoft Teams""],
    [""Azure Storage Account Queue"", ""calls"", ""Azure Functions""],
    [""Azure Functions"", ""called-from"", ""Azure Storage Account Queue""],
    [""Azure Functions"", ""sends notifications to"", ""Microsoft Teams""],
    [""Azure Functions"", ""streams events to"", ""Azure Event Hubs""],
    [""Custom Bot Messaging Service"", ""uses"", ""Azure Bot Service""],
    [""Azure Data Lake storage"", ""contains"", ""Azure Event Hubs""],
    [""Azure Data Lake storage"", ""generates reports with"", ""Power BI""]
  ]
}",5.084111781994579
63,mistral-nemo,../IMAGES NEW/TEST/08 Azure Business Processes.txt,"
The data flows through the solution as follows:

    The airline system communicates with a custom API hosted in Azure API Management.
    A custom API coordinator receives notifications and handles incoming messages from the airline system. It sends them to Power Apps, where flights are assigned to Microsoft Teams channels.
    When a user selects a flight to monitor, or when the system assigns the user to a flight, the system queues a Graph API call in an Azure Storage Account queue for further processing.
    Azure Functions runs the Graph API calls based on the incoming messages in the storage queue, sending notifications to Teams, and also streams all events to an Azure Event Hubs for further analytics.
    The airline's notification system is managed by a custom bot messaging service that employs Azure Bot Service.
    Custom bots send flight updates to users in Teams.
    An Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs, ultimately generating insightful reports with Power BI.

","{""entities"": [[""airline system"", ""system"", ""communicates with a custom API hosted in Azure API Management""], [""custom API"", ""component"", ""communicates with a custom API hosted in Azure API Management""], [""Azure API Management"", ""system"", ""communicates with a custom API hosted in Azure API Management""], [""custom API coordinator"", ""system"", ""receives notifications and handles incoming messages from the airline system""], [""Power Apps"", ""system"", ""where flights are assigned to Microsoft Teams channels""], [""Microsoft Teams channels"", ""system"", ""where flights are assigned to Microsoft Teams channels""], [""Storage Account queue"", ""system"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing.""], [""Graph API call"", ""system"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing.""], [""Azure Functions"", ""system"", ""runs the Graph API calls based on the incoming messages in the storage queue""], [""Azure Event Hubs"", ""system"", ""Azure Event Hubs for further analytics""], [""notification system"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""custom bot messaging service"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""Azure Bot Service"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""Users"", ""person"", ""selects a flight to monitor, or when the system assigns the user to a flight""], [""Azure Data Lake storage"", ""system"", ""offers long-term retention and micro-batch processing of events from Event Hubs""], [""Power BI"", ""system"", ""generating insightful reports""]], ""relationships"": [[""Azure API Management"", ""contains"", ""custom API"", ""custom API hosted in Azure API Management""], [""airline system"", ""calls"", ""custom API"", ""communicates with a custom API""], [""custom API coordinator"", ""is-called-from"", ""airline system"", ""receives notifications and handles incoming messages from the airline system""], [""Power Apps"", ""calls"", ""Microsoft Teams channels"", ""Power Apps, where flights are assigned to Microsoft Teams channels""], [""airline system"", ""calls"", ""Graph API call"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing""], [""Azure Functions"", ""calls"", ""Graph API call"", ""runs the Graph API calls based on the incoming messages in the storage queue""], [""Azure Functions"", ""calls"", ""Storage Account queue"", ""based on the incoming messages in the storage queue""], [""Azure Functions"", ""calls"", ""Microsoft Teams channels"", ""sending notifications to Teams""], [""Azure Functions"", ""calls"", ""Azure Event Hubs"", ""also streams all events to an Azure Event Hubs for further analytics""], [""notification system"", ""is-called-from"", ""custom bot messaging service"", ""managed by a custom bot messaging service""], [""custom bot messaging service"", ""calls"", ""Azure Bot Service"", ""custom bot messaging service that employs Azure Bot Service""], [""custom bot messaging service"", ""calls"", ""Microsoft Teams channels"", ""Custom bots send flight updates to users in Teams.""], [""Microsoft Teams channels"", ""calls"", ""Users"", ""Custom bots send flight updates to users in Teams.""], [""Azure Data Lake storage"", ""is-called-from"", ""Azure Event Hubs"", ""Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs""], [""Azure Data Lake storage"", ""calls"", ""Power BI"", ""Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs, ultimately generating insightful reports with Power BI""]]}","Here's the extracted entities and relationships in JSON format:

```json
{
  ""entities"": [
    [""Airline System"", ""system"", ""The airline system communicates with other components""],
    [""Azure API Management"", ""system"", ""Hosts a custom API""],
    [""Custom API Coordinator"", ""component"", ""Receives notifications from Airline System""],
    [""Power Apps"", ""system"", ""Assigns flights to Microsoft Teams channels""],
    [""Microsoft Teams"", ""system"", ""Where flight assignments are sent and updates are posted""],
    [""Azure Storage Account Queue"", ""component"", ""Queues Graph API calls for further processing""],
    [""Azure Functions"", ""system"", ""Runs Graph API calls based on messages in storage queue""],
    [""Azure Event Hubs"", ""system"", ""Receives event streams for analytics""],
    [""Custom Bot Messaging Service"", ""component"", ""Sends flight updates to users in Teams""],
    [""Azure Bot Service"", ""system"", ""Manages the custom bot messaging service""],
    [""Azure Data Lake Storage"", ""system"", ""Offers long-term retention and processing of events from Event Hubs""],
    [""Power BI"", ""system"", ""Generates insightful reports based on processed events""]
  ],
  ""relationships"": [
    [""Airline System"", ""calls"", ""Azure API Management""],
    [""Custom API Coordinator"", ""contains"", ""Notifications""],
    [""Custom API Coordinator"", ""sends"", ""Power Apps""],
    [""Power Apps"", ""assigns_to"", ""Microsoft Teams""],
    [""Airline System"", ""queues"", ""Azure Storage Account Queue""],
    [""Azure Functions"", ""processes"", ""Azure Storage Account Queue""],
    [""Azure Functions"", ""sends"", ""Azure Event Hubs""],
    [""Custom Bot Messaging Service"", ""uses"", ""Azure Bot Service""],
    [""Custom Bot Messaging Service"", ""sends"", ""Flight Updates""],
    [""Microsoft Teams"", ""displays"", ""Flight Updates""],
    [""Azure Data Lake Storage"", ""processes"", ""Events from Azure Event Hubs""],
    [""Power BI"", ""generates"", ""Insightful Reports""]
  ]
}
```","Here's the extracted entities and relationships in JSON format:

```json
{
  ""entities"": [
    [""Airline System"", ""system"", ""The airline system communicates with other components""],
    [""Azure API Management"", ""system"", ""Hosts a custom API""],
    [""Custom API Coordinator"", ""component"", ""Receives notifications from Airline System""],
    [""Power Apps"", ""system"", ""Assigns flights to Microsoft Teams channels""],
    [""Microsoft Teams"", ""system"", ""Where flight assignments are sent and updates are posted""],
    [""Azure Storage Account Queue"", ""component"", ""Queues Graph API calls for further processing""],
    [""Azure Functions"", ""system"", ""Runs Graph API calls based on messages in storage queue""],
    [""Azure Event Hubs"", ""system"", ""Receives event streams for analytics""],
    [""Custom Bot Messaging Service"", ""component"", ""Sends flight updates to users in Teams""],
    [""Azure Bot Service"", ""system"", ""Manages the custom bot messaging service""],
    [""Azure Data Lake Storage"", ""system"", ""Offers long-term retention and processing of events from Event Hubs""],
    [""Power BI"", ""system"", ""Generates insightful reports based on processed events""]
  ],
  ""relationships"": [
    [""Airline System"", ""calls"", ""Azure API Management""],
    [""Custom API Coordinator"", ""contains"", ""Notifications""],
    [""Custom API Coordinator"", ""sends"", ""Power Apps""],
    [""Power Apps"", ""assigns_to"", ""Microsoft Teams""],
    [""Airline System"", ""queues"", ""Azure Storage Account Queue""],
    [""Azure Functions"", ""processes"", ""Azure Storage Account Queue""],
    [""Azure Functions"", ""sends"", ""Azure Event Hubs""],
    [""Custom Bot Messaging Service"", ""uses"", ""Azure Bot Service""],
    [""Custom Bot Messaging Service"", ""sends"", ""Flight Updates""],
    [""Microsoft Teams"", ""displays"", ""Flight Updates""],
    [""Azure Data Lake Storage"", ""processes"", ""Events from Azure Event Hubs""],
    [""Power BI"", ""generates"", ""Insightful Reports""]
  ]
}
```",7.359558867989108
64,mistral-nemo,../IMAGES NEW/Azure/09 Azure protect APIs original.txt,"
    To gain access to an application, an API client authenticates by providing credentials such as username and password. The IdP is Azure AD B2C in this solution, but you can use a different one.

    The authentication request goes via Azure Front Door to Azure AD B2C, which is configured with a custom domain for sign-in. Azure AD B2C authenticates the user and returns a JSON Web Token (JWT) bearer token back to the user.

    The client triggers an event that accesses a backend API. This event could be a click of a button on a web application or on a mobile device, or a direct call to the endpoint of the backend API.

    The request goes through Azure Front Door, whose back end is mapped to the public endpoint of API Management. API Management intercepts the request and validates the bearer token against Azure AD B2C by using its validate-jwt policy. If the token isn't valid, API Management rejects the request by responding with a 401 code.

    If the token is valid, API Management forwards the request to the appropriate backend API.

    The diagram shows backend APIs running in three environments:
        App Service Environment
        Function Apps
        Azure Kubernetes Services (AKS)

    APIs running in on-premises and hybrid cloud environments can also be integrated with API Management if network connectivity is established between the APIs and API Management.

","{""entities"": [[""API client"", ""system"", ""wants to gain access to an application""], [""application"", ""system"", ""API client wants to gain access to an application""], [""Azure AD B2C"", ""system"", ""The IdP is Azure AD B2C""], [""Azure Front Door"", ""system"", ""authentication request goes via Azure Front Door to Azure AD B2C""], [""backend API"", ""system"", ""The client triggers an event that accesses a backend API""], [""Azure Front Door"", ""system"", ""The request goes through Azure Front Door, whose back end is mapped to the public endpoint of API Management.""], [""backend"", ""component"", ""Azure Front Door, whose back end""], [""API Management"", ""system"", ""API Management intercepts the request and validates the bearer token against Azure AD B2C ""], [""public endpoint"", ""system"", ""whose back end is mapped to the public endpoint of API Management""], [""User"", ""person"", ""Azure AD B2C authenticates the user and returns a JSON Web Token (JWT) bearer token back to the user""]], ""relationships"": [[""API client"", ""calls"", ""application"", """"], [""Azure Front Door"", ""calls"", ""Azure AD B2C"", ""authentication request goes via Azure Front Door to Azure AD B2C""], [""Azure AD B2C"", ""is-called-from"", ""User"", ""Azure AD B2C authenticates the user and returns a JSON Web Token (JWT) bearer token back to the user""], [""API client"", ""calls"", ""backend API"", ""The client triggers an event that accesses a backend API""], [""Azure Front Door"", ""contains"", ""backend"", ""Azure Front Door, whose back end""], [""public endpoint"", ""part-of"", ""API Management"", ""Azure Front Door, whose back end""], [""backend"", ""calls"", ""public endpoint"", ""whose back end is mapped to the public endpoint of API Management""], [""API Management"", ""calls"", ""Azure AD B2C"", ""API Management intercepts the request and validates the bearer token against Azure AD B2C""]]}","```json
{
  ""entities"": [
    [""API Client"", ""component"", ""Authenticates using credentials""],
    [""Azure AD B2C"", ""system"", ""Handles authentication and returns JWT""],
    [""Azure Front Door"", ""system"", ""Routes requests to Azure AD B2C and API Management""],
    [""JSON Web Token (JWT)"", ""entity"", ""Bearer token returned by Azure AD B2C""],
    [""Backend API"", ""component"", ""Accessed after successful authentication""],
    [""API Management"", ""system"", ""Validates JWT, intercepts requests, and routes to backend APIs""],
    [""App Service Environment"", ""system"", ""Runs some backend APIs""],
    [""Function Apps"", ""system"", ""Runs some backend APIs""],
    [""Azure Kubernetes Services (AKS)"", ""system"", ""Runs some backend APIs""]
  ],
  ""relationships"": [
    [""API Client"", ""calls"", ""Azure Front Door"", ""API Client triggers event to Azure Front Door""],
    [""Azure Front Door"", ""called-from"", ""API Client"", ""API Client accesses Azure Front Door""],
    [""Azure Front Door"", ""contains"", ""Azure AD B2C"", ""Azure Front Door routes requests to Azure AD B2C""],
    [""Azure AD B2C"", ""calls"", ""API Client"", ""Azure AD B2C returns JWT to API Client""],
    [""Azure Front Door"", ""contains"", ""API Management"", ""Azure Front Door's backend is mapped to API Management""],
    [""API Management"", ""contains"", ""Backend API"", ""API Management routes requests to appropriate backend APIs""],
    [""App Service Environment"", ""part-of"", ""Backend API"", ""Runs some backend APIs""],
    [""Function Apps"", ""part-of"", ""Backend API"", ""Runs some backend APIs""],
    [""Azure Kubernetes Services (AKS)"", ""part-of"", ""Backend API"", ""Runs some backend APIs""]
  ]
}
```","```json
{
  ""entities"": [
    [""API Client"", ""component"", ""Authenticates using credentials""],
    [""Azure AD B2C"", ""system"", ""Handles authentication and returns JWT""],
    [""Azure Front Door"", ""system"", ""Routes requests to Azure AD B2C and API Management""],
    [""JSON Web Token (JWT)"", ""entity"", ""Bearer token returned by Azure AD B2C""],
    [""Backend API"", ""component"", ""Accessed after successful authentication""],
    [""API Management"", ""system"", ""Validates JWT, intercepts requests, and routes to backend APIs""],
    [""App Service Environment"", ""system"", ""Runs some backend APIs""],
    [""Function Apps"", ""system"", ""Runs some backend APIs""],
    [""Azure Kubernetes Services (AKS)"", ""system"", ""Runs some backend APIs""]
  ],
  ""relationships"": [
    [""API Client"", ""calls"", ""Azure Front Door"", ""API Client triggers event to Azure Front Door""],
    [""Azure Front Door"", ""called-from"", ""API Client"", ""API Client accesses Azure Front Door""],
    [""Azure Front Door"", ""contains"", ""Azure AD B2C"", ""Azure Front Door routes requests to Azure AD B2C""],
    [""Azure AD B2C"", ""calls"", ""API Client"", ""Azure AD B2C returns JWT to API Client""],
    [""Azure Front Door"", ""contains"", ""API Management"", ""Azure Front Door's backend is mapped to API Management""],
    [""API Management"", ""contains"", ""Backend API"", ""API Management routes requests to appropriate backend APIs""],
    [""App Service Environment"", ""part-of"", ""Backend API"", ""Runs some backend APIs""],
    [""Function Apps"", ""part-of"", ""Backend API"", ""Runs some backend APIs""],
    [""Azure Kubernetes Services (AKS)"", ""part-of"", ""Backend API"", ""Runs some backend APIs""]
  ]
}
```",6.792330164986197
65,mistral-nemo,../IMAGES NEW/Azure/09 Azure protect APIs original.txt,"
    To gain access to an application, an API client authenticates by providing credentials such as username and password. The IdP is Azure AD B2C in this solution, but you can use a different one.

    The authentication request goes via Azure Front Door to Azure AD B2C, which is configured with a custom domain for sign-in. Azure AD B2C authenticates the user and returns a JSON Web Token (JWT) bearer token back to the user.

    The client triggers an event that accesses a backend API. This event could be a click of a button on a web application or on a mobile device, or a direct call to the endpoint of the backend API.

    The request goes through Azure Front Door, whose back end is mapped to the public endpoint of API Management. API Management intercepts the request and validates the bearer token against Azure AD B2C by using its validate-jwt policy. If the token isn't valid, API Management rejects the request by responding with a 401 code.

    If the token is valid, API Management forwards the request to the appropriate backend API.

    The diagram shows backend APIs running in three environments:
        App Service Environment
        Function Apps
        Azure Kubernetes Services (AKS)

    APIs running in on-premises and hybrid cloud environments can also be integrated with API Management if network connectivity is established between the APIs and API Management.

","{""entities"": [[""API client"", ""system"", ""wants to gain access to an application""], [""application"", ""system"", ""API client wants to gain access to an application""], [""Azure AD B2C"", ""system"", ""The IdP is Azure AD B2C""], [""Azure Front Door"", ""system"", ""authentication request goes via Azure Front Door to Azure AD B2C""], [""backend API"", ""system"", ""The client triggers an event that accesses a backend API""], [""Azure Front Door"", ""system"", ""The request goes through Azure Front Door, whose back end is mapped to the public endpoint of API Management.""], [""backend"", ""component"", ""Azure Front Door, whose back end""], [""API Management"", ""system"", ""API Management intercepts the request and validates the bearer token against Azure AD B2C ""], [""public endpoint"", ""system"", ""whose back end is mapped to the public endpoint of API Management""], [""User"", ""person"", ""Azure AD B2C authenticates the user and returns a JSON Web Token (JWT) bearer token back to the user""]], ""relationships"": [[""API client"", ""calls"", ""application"", """"], [""Azure Front Door"", ""calls"", ""Azure AD B2C"", ""authentication request goes via Azure Front Door to Azure AD B2C""], [""Azure AD B2C"", ""is-called-from"", ""User"", ""Azure AD B2C authenticates the user and returns a JSON Web Token (JWT) bearer token back to the user""], [""API client"", ""calls"", ""backend API"", ""The client triggers an event that accesses a backend API""], [""Azure Front Door"", ""contains"", ""backend"", ""Azure Front Door, whose back end""], [""public endpoint"", ""part-of"", ""API Management"", ""Azure Front Door, whose back end""], [""backend"", ""calls"", ""public endpoint"", ""whose back end is mapped to the public endpoint of API Management""], [""API Management"", ""calls"", ""Azure AD B2C"", ""API Management intercepts the request and validates the bearer token against Azure AD B2C""]]}","```json
{
  ""entities"": [
    [""API Client"", ""component""],
    [""Azure AD B2C"", ""system""],
    [""Azure Front Door"", ""system""],
    [""Backend API"", ""component""],
    [""App Service Environment"", ""system""],
    [""Function Apps"", ""system""],
    [""Azure Kubernetes Services (AKS)"", ""system""],
    [""API Management"", ""system""]
  ],
  ""relationships"": [
    [""API Client"", ""calls"", ""Azure Front Door""],
    [""Azure Front Door"", ""contains"", ""API Client""],
    [""Azure Front Door"", ""calls"", ""Azure AD B2C""],
    [""Azure AD B2C"", ""called-from"", ""Azure Front Door""],
    [""Azure AD B2C"", ""part-of"", ""Azure Front Door""],
    [""API Management"", ""contains"", ""Backend API""],
    [""Backend API"", ""part-of"", ""API Management""],
    [""API Management"", ""calls"", ""App Service Environment""],
    [""App Service Environment"", ""called-from"", ""API Management""],
    [""API Management"", ""calls"", ""Function Apps""],
    [""Function Apps"", ""called-from"", ""API Management""],
    [""API Management"", ""calls"", ""Azure Kubernetes Services (AKS)""],
    [""Azure Kubernetes Services (AKS)"", ""called-from"", ""API Management""]
  ]
}
```","```json
{
  ""entities"": [
    [""API Client"", ""component""],
    [""Azure AD B2C"", ""system""],
    [""Azure Front Door"", ""system""],
    [""Backend API"", ""component""],
    [""App Service Environment"", ""system""],
    [""Function Apps"", ""system""],
    [""Azure Kubernetes Services (AKS)"", ""system""],
    [""API Management"", ""system""]
  ],
  ""relationships"": [
    [""API Client"", ""calls"", ""Azure Front Door""],
    [""Azure Front Door"", ""contains"", ""API Client""],
    [""Azure Front Door"", ""calls"", ""Azure AD B2C""],
    [""Azure AD B2C"", ""called-from"", ""Azure Front Door""],
    [""Azure AD B2C"", ""part-of"", ""Azure Front Door""],
    [""API Management"", ""contains"", ""Backend API""],
    [""Backend API"", ""part-of"", ""API Management""],
    [""API Management"", ""calls"", ""App Service Environment""],
    [""App Service Environment"", ""called-from"", ""API Management""],
    [""API Management"", ""calls"", ""Function Apps""],
    [""Function Apps"", ""called-from"", ""API Management""],
    [""API Management"", ""calls"", ""Azure Kubernetes Services (AKS)""],
    [""Azure Kubernetes Services (AKS)"", ""called-from"", ""API Management""]
  ]
}
```",4.82333479099907
66,mistral-nemo,../IMAGES NEW/Azure/11 Mainframe original.txt,"
    A Connect agent component captures change logs by using mainframe or midrange native utilities and caches the logs in temporary storage.
    For mainframe systems, a publisher component on the mainframe manages data migration.
    For midrange systems, in place of the publisher, a listener component manages data migration. It's located on either a Windows or Linux machine.
    The publisher or listener moves the data from on-premises to Azure via an enhanced-security connection. The publisher or listener handles the commit and rollback of transactions for each unit of work, maintaining the integrity of data.
    The Connect Replicator Engine captures the data from the publisher or listener and applies it to the target. It distributes data for parallel processing.
    The target is a database that receives the changes via ODBC or ingests the changes via Azure Event Hubs.
    The changed data is consumed by Azure Databricks and applied to Azure data platform services.
    The Connect Controller Daemon authenticates the request and establishes the socket connection between the publisher or listener and the Replicator Engine.

","{""entities"": [[""Connect agent"", ""component"", ""captures change logs""], [""temporary storage"", ""component"", ""caches the logs in temporary storage""], [""mainframe native utilities"", ""system"", ""captures change logs by using mainframe or midrange native utilities""], [""midrange native utilities"", ""system"", ""captures change logs by using mainframe or midrange native utilities""], [""mainframe systems"", ""system"", ""For mainframe systems, a publisher component on the mainframe manages data migration.""], [""midrange systems"", ""system"", ""For midrange systems, in place of the publisher, a listener component manages data migration.""], [""publisher"", ""component"", ""For mainframe systems, a publisher component on the mainframe manages data migration.""], [""listener"", ""component"", ""For midrange systems, in place of the publisher, a listener component manages data migration.""], [""Connect Replicator Engine"", ""system"", ""captures the data from the publisher or listener and applies it to the target.""], [""on-premises"", ""system"", ""The publisher or listener moves the data from on-premises to Azure""], [""Azure"", ""system"", ""The publisher or listener moves the data from on-premises to Azure""], [""Connect Replicator Engine"", ""system"", ""The Connect Replicator Engine captures the data from the publisher or listener""], [""target"", ""system"", ""applies it to the target""], [""database"", ""system"", ""target is a database""], [""ODBC"", ""component"", ""The target is a database that receives the changes via ODBC or ingests the changes via Azure Event Hubs""], [""Azure Event Hubs"", ""component"", ""The target is a database that receives the changes via ODBC or ingests the changes via Azure Event Hubs""], [""Azure Databricks"", ""component"", ""the changed data is consumed by Azure Databricks and applied to Azure data platform services.""], [""Azure data platform services"", ""component"", ""the changed data is consumed by Azure Databricks and applied to Azure data platform services.""], [""Connect Controller Daemon"", ""component"", ""authenticates the request and establishes the socket connection between the publisher or listener and the Replicator Engine.""]], ""relationships"": [[""Connect agent"", ""calls"", ""mainframe native utilities"", ""captures change logs by using mainframe or midrange native utilities""], [""Connect agent"", ""calls"", ""midrange native utilities"", ""captures change logs by using mainframe or midrange native utilities""], [""Connect agent"", ""calls"", ""temporary storage"", ""captures change logs by using mainframe or midrange native utilities""], [""mainframe systems"", ""contains"", ""mainframe native utilities"", ""F""], [""midrange systems"", ""contains"", ""midrange native utilities"", """"], [""mainframe systems"", ""contains"", ""publisher"", ""For mainframe systems, a publisher component on the mainframe manages data migration.""], [""midrange systems"", ""contains"", ""listener"", ""For midrange systems, in place of the publisher, a listener component manages data migration.""], [""publisher"", ""calls"", ""on-premises"", ""The publisher or listener moves the data from on-premises to Azure""], [""publisher"", ""calls"", ""Azure"", ""The publisher or listener moves the data from on-premises to Azure""], [""listener"", ""calls"", ""on-premises"", ""The publisher or listener moves the data from on-premises to Azure""], [""listener"", ""calls"", ""Azure"", ""The publisher or listener moves the data from on-premises to Azure""], [""Connect Replicator Engine"", ""calls"", ""publisher"", ""captures the data from the publisher or listener and applies it to the target.""], [""Connect Replicator Engine"", ""calls"", ""listener"", ""captures the data from the publisher or listener and applies it to the target.""], [""Connect Replicator Engine"", ""calls"", ""target"", ""captures the data from the publisher or listener and applies it to the target.""], [""target"", ""contains"", ""database"", ""target is a database""], [""database"", ""is-called-from"", ""ODBC"", ""database that receives the changes via ODBC""], [""database"", ""is-called-from"", ""Azure Event Hubs"", ""ingests the changes via Azure Event Hubs""], [""database"", ""is-called-from"", ""Azure Databricks"", ""the changed data is consumed by Azure Databricks""], [""Azure Databricks"", ""calls"", ""Azure data platform services"", ""consumed by Azure Databricks and applied to Azure data platform services.""], [""Connect Controller Daemon"", ""is-called-from"", ""publisher"", ""establishes the socket connection between the publisher or listener and the Replicator Engine..""], [""Connect Controller Daemon"", ""is-called-from"", ""listener"", ""establishes the socket connection between the publisher or listener and the Replicator Engine..""], [""Connect Controller Daemon"", ""calls"", ""Connect Replicator Engine"", ""establishes the socket connection between the publisher or listener and the Replicator Engine..""]]}","Based on the provided context, here's the extracted entities and their relationships in JSON format:

```json
{
  ""entities"": [
    [""Connect Agent"", ""component"", ""Captures change logs""],
    [""Publisher (Mainframe)"", ""system"", ""Manages data migration for mainframe systems""],
    [""Listener (Midrange)"", ""system"", ""Manages data migration for midrange systems, located on Windows or Linux machine""],
    [""Replicator Engine"", ""component"", ""Captures data from publisher/listener and applies it to target""],
    [""Target Database"", ""system"", ""Receives changes via ODBC or Azure Event Hubs""],
    [""Azure Databricks"", ""system"", ""Consumes changed data and applies it to Azure data platform services""],
    [""Connect Controller Daemon"", ""component"", ""Authenticates requests and establishes socket connections""]
  ],
  ""relationships"": [
    [""Connect Agent"", ""contains"", ""Publisher (Mainframe)"", ""Captures change logs using mainframe utilities""],
    [""Connect Agent"", ""contains"", ""Listener (Midrange)"", ""Captures change logs using midrange utilities""],
    [""Publisher (Mainframe)"", ""calls"", ""Replicator Engine"", ""Moves data to Azure""],
    [""Listener (Midrange)"", ""calls"", ""Replicator Engine"", ""Moves data to Azure""],
    [""Replicator Engine"", ""called-from"", ""Connect Controller Daemon"", ""Establishes socket connection""],
    [""Replicator Engine"", ""contains"", ""Target Database"", ""Applies changes to target database""],
    [""Target Database"", ""calls"", ""Azure Databricks"", ""Consumes changed data""]
  ]
}
```","Based on the provided context, here's the extracted entities and their relationships in JSON format:

```json
{
  ""entities"": [
    [""Connect Agent"", ""component"", ""Captures change logs""],
    [""Publisher (Mainframe)"", ""system"", ""Manages data migration for mainframe systems""],
    [""Listener (Midrange)"", ""system"", ""Manages data migration for midrange systems, located on Windows or Linux machine""],
    [""Replicator Engine"", ""component"", ""Captures data from publisher/listener and applies it to target""],
    [""Target Database"", ""system"", ""Receives changes via ODBC or Azure Event Hubs""],
    [""Azure Databricks"", ""system"", ""Consumes changed data and applies it to Azure data platform services""],
    [""Connect Controller Daemon"", ""component"", ""Authenticates requests and establishes socket connections""]
  ],
  ""relationships"": [
    [""Connect Agent"", ""contains"", ""Publisher (Mainframe)"", ""Captures change logs using mainframe utilities""],
    [""Connect Agent"", ""contains"", ""Listener (Midrange)"", ""Captures change logs using midrange utilities""],
    [""Publisher (Mainframe)"", ""calls"", ""Replicator Engine"", ""Moves data to Azure""],
    [""Listener (Midrange)"", ""calls"", ""Replicator Engine"", ""Moves data to Azure""],
    [""Replicator Engine"", ""called-from"", ""Connect Controller Daemon"", ""Establishes socket connection""],
    [""Replicator Engine"", ""contains"", ""Target Database"", ""Applies changes to target database""],
    [""Target Database"", ""calls"", ""Azure Databricks"", ""Consumes changed data""]
  ]
}
```",6.113696301006712
67,mistral-nemo,../IMAGES NEW/Azure/12 Azure Network Microservices original.txt,"
    Outside services and clients make a POST request to APIM, with a data body that includes patient information.
    APIM calls the CreatePatient function in the Patient API with the given patient information.
    The CreatePatient function in Patient API calls the CreateAuditRecord function in the Audit API function app to create an audit record.
    The Audit API CreateAuditRecord function creates the audit record in Azure Cosmos DB, and returns a success response to the Patient API CreatePatient function.
    The CreatePatient function creates the patient document in Azure Cosmos DB, and returns a success response to APIM.
    The outside services and clients receive the success response from APIM.

","{""entities"": [[""Outside services"", ""system"", ""Outside services and clients make a POST request to APIM""], [""clients"", ""system"", ""Outside services and clients make a POST request to APIM""], [""APIM"", ""system"", ""Outside services and clients make a POST request to APIM""], [""Patient API"", ""system"", "" The CreatePatient function in Patient API calls the CreateAuditRecord function in the Audit API function app""], [""CreatePatient function"", ""component"", "" The CreatePatient function in Patient API calls the CreateAuditRecord function in the Audit API function app""], [""Audit API function app"", ""system"", ""The CreatePatient function in Patient API calls the CreateAuditRecord function in the Audit API function app""], [""CreateAuditRecord function"", ""component"", ""CreatePatient function in Patient API calls the CreateAuditRecord function""], [""Azure Cosmos DB"", ""system"", ""The Audit API CreateAuditRecord function creates the audit record in Azure Cosmos DB, and returns a success response to the Patient API CreatePatient function""]], ""relationships"": [[""CreatePatient function"", ""part-of"", ""Patient API"", ""Reason""], [""Outside services"", ""calls"", ""APIM"", ""utside services and clients make a POST request to APIM""], [""clients"", ""calls"", ""APIM"", ""outside services and clients make a POST request to APIM""], [""APIM"", ""calls"", ""CreatePatient function"", ""APIM calls the CreatePatient function in the Patient API""], [""CreateAuditRecord function"", ""part-of"", ""Audit API function app"", ""Reason""], [""CreatePatient function"", ""calls"", ""CreateAuditRecord function"", ""CreatePatient function in Patient API calls the CreateAuditRecord function in the Audit API function app""], [""CreateAuditRecord function"", ""calls"", ""Azure Cosmos DB"", ""Audit API CreateAuditRecord function creates the audit record in Azure Cosmos DB""], [""CreateAuditRecord function"", ""calls"", ""CreatePatient function"", ""returns a success response to the Patient API CreatePatient function.""], [""CreatePatient function"", ""calls"", ""Azure Cosmos DB"", ""The CreatePatient function creates the patient document in Azure Cosmos DB""], [""CreatePatient function"", ""is-called-from"", ""APIM"", ""The CreatePatient function returns a success response to APIM""]]}","{
  ""entities"": [
    [""APIM"", ""system"", ""API Management service""],
    [""CreatePatient"", ""function"", ""Function in Patient API""],
    [""Audit API"", ""system"", ""Audit API system""],
    [""CreateAuditRecord"", ""function"", ""Function in Audit API""],
    [""Azure Cosmos DB"", ""system"", ""Cloud database service""]
  ],
  ""relationships"": [
    [""APIM"", ""calls"", ""CreatePatient""],
    [""CreatePatient"", ""calls"", ""CreateAuditRecord""],
    [""CreateAuditRecord"", ""called-from"", ""CreatePatient""],
    [""CreateAuditRecord"", ""contains"", ""Azure Cosmos DB""],
    [""CreatePatient"", ""contains"", ""Azure Cosmos DB""],
    [""APIM"", ""contains"", ""CreatePatient""]
  ]
}","{
  ""entities"": [
    [""APIM"", ""system"", ""API Management service""],
    [""CreatePatient"", ""function"", ""Function in Patient API""],
    [""Audit API"", ""system"", ""Audit API system""],
    [""CreateAuditRecord"", ""function"", ""Function in Audit API""],
    [""Azure Cosmos DB"", ""system"", ""Cloud database service""]
  ],
  ""relationships"": [
    [""APIM"", ""calls"", ""CreatePatient""],
    [""CreatePatient"", ""calls"", ""CreateAuditRecord""],
    [""CreateAuditRecord"", ""called-from"", ""CreatePatient""],
    [""CreateAuditRecord"", ""contains"", ""Azure Cosmos DB""],
    [""CreatePatient"", ""contains"", ""Azure Cosmos DB""],
    [""APIM"", ""contains"", ""CreatePatient""]
  ]
}",3.1715926000033505
68,mistral-nemo,../IMAGES NEW/Azure/13 Azure Secure Research.txt,"
    Data owners upload datasets into a public blob storage account. The data is encrypted by using Microsoft-managed keys.

    Azure Data Factory uses a trigger that starts copying of the uploaded dataset to a specific location (import path) on another storage account with security controls. The storage account can only be reached through a private endpoint. Also, it's accessed by a service principal with limited permissions. Data Factory deletes the original copy making the dataset immutable.

    Researchers access the secure environment through a streaming application using Azure Virtual Desktop as a privileged jump box.

    The dataset in the secure storage account is presented to the data science VMs provisioned in a secure network environment for research work. Much of the data preparation is done on those VMs.

    The secure environment has Azure Machine Learning compute that can access the dataset through a private endpoint for users for Azure Machine Learning capabilities, such as to train, deploy, automate, and manage machine learning models. At this point, models are created that meet regulatory guidelines. All model data is de-identified by removing personal information.

    Models or de-identified data is saved to a separate location on the secure storage (export path). When new data is added to the export path, a logic app is triggered. In this architecture, the logic app is outside the secure environment because no data is sent to the logic app. Its only function is to send notification and start the manual approval process.

    The app starts an approval process requesting a review of data that is queued to be exported. The manual reviewers ensure that sensitive data isn't exported. After the review process, the data is either approved or denied.

    Note

    If an approval step is not required on exfiltration, the logic app step could be omitted.

    If the de-identified data is approved, it's sent to the Data Factory instance.

    Data Factory moves the data to the public storage account in a separate container to allow external researchers to have access to their exported data and models. Alternately, you can provision another storage account in a lower security environment.

","{""entities"": [[""datasets"", ""component"", ""Data owners upload datasets into a public blob storage account""], [""public blob storage account"", ""system"", ""Data owners upload datasets into a public blob storage account""], [""Azure Data Factory"", ""system"", ""Azure Data Factory uses a trigger that starts copying of the uploaded dataset to a specific location""], [""storage account"", ""system"", ""Azure Data Factory uses a trigger that starts copying of the uploaded dataset to a specific location (import path) on another storage account with security controls""], [""copied dataset"", ""system"", ""Azure Data Factory uses a trigger that starts copying of the uploaded dataset to a specific location (import path) on another storage account with security controls""], [""private endpoint"", ""component"", ""The storage account can only be reached through a private endpoint.""], [""service principal"", ""component"", ""Also, it's accessed by a service principal with limited permissions.""], [""streaming application"", ""component"", ""access the secure environment through a streaming application""], [""Azure Virtual Desktop"", ""component"", ""Azure Virtual Desktop as a privileged jump box""], [""data science VMs"", ""component"", ""data science VMs provisioned in a secure network environment""], [""Azure Machine Learning compute"", ""component"", ""The secure environment has Azure Machine Learning compute that can access the dataset""], [""secure network environment"", ""system"", ""data science VMs provisioned in a secure network environment""], [""machine learning models"", ""component"", ""At this point, models are created that meet regulatory guidelines""], [""de-identified data"", ""component"", ""Models or de-identified data is saved to a separate location on the secure storage (export path)""], [""logic app"", ""component"", ""When new data is added to the export path, a logic app is triggered""], [""separate container"", ""component"", ""Data Factory moves the data to the public storage account in a separate container""], [""moved data"", ""component"", ""Data Factory moves the data to the public storage account in a separate container""], [""Data owners"", ""person"", ""Data owners upload datasets into a public blob storage account""], [""Researchers"", ""person"", ""Researchers access the secure environment through a streaming application using Azure Virtual Desktop as a privileged jump box""], [""manual reviewers"", ""person"", ""The manual reviewers ensure that sensitive data isn't exported.""], [""Users"", ""person"", ""The secure environment has Azure Machine Learning compute that can access the dataset""]], ""relationships"": [[""datasets"", ""part-of"", ""public blob storage account"", ""Data owners upload datasets into a public blob storage account""], [""Data owners"", ""calls"", ""datasets"", ""Data owners upload datasets into a public blob storage account""], [""Azure Data Factory"", ""calls"", ""datasets"", ""Azure Data Factory uses a trigger that starts copying of the uploaded dataset""], [""storage account"", ""contains"", ""copied dataset"", ""opying of the uploaded dataset to a specific location (import path) on another storage account with security controls""], [""Azure Data Factory"", ""calls"", ""copied dataset"", ""Azure Data Factory uses a trigger that starts copying of the uploaded dataset to a specific location""], [""private endpoint"", ""calls"", ""storage account"", ""The storage account can only be reached through a private endpoint""], [""storage account"", ""is-called-from"", ""service principal"", ""Also, it's accessed by a service principal with limited permissions""], [""Researchers"", ""calls"", ""Azure Virtual Desktop"", "" Researchers access the secure environment through a streaming application""], [""Azure Virtual Desktop"", ""calls"", ""streaming application"", ""through a streaming application using Azure Virtual Desktop""], [""streaming application"", ""calls"", ""storage account"", ""Researchers access the secure environment through a streaming application using Azure Virtual Desktop as a privileged jump box""], [""data science VMs"", ""part-of"", ""secure network environment"", ""The dataset in the secure storage account is presented to the data science VMs""], [""data science VMs"", ""calls"", ""copied dataset"", "" The dataset in the secure storage account is presented to the data science VMs""], [""secure network environment"", ""contains"", ""Azure Machine Learning compute"", ""The secure environment has Azure Machine Learning compute that can access the dataset""], [""Azure Machine Learning compute"", ""calls"", ""Azure Machine Learning compute"", ""The secure environment has Azure Machine Learning compute that can access the dataset""], [""machine learning models"", ""part-of"", ""storage account"", ""Models or de-identified data is saved to a separate location on the secure storage (export path)""], [""machine learning models"", ""calls"", ""logic app"", ""When new data is added to the export path, a logic app is triggered""], [""logic app"", ""calls"", ""manual reviewers"", ""The app starts an approval process requesting a review of data that is queued to be exported.""], [""public blob storage account"", ""contains"", ""separate container"", ""Data Factory moves the data to the public storage account in a separate container""], [""Azure Data Factory"", ""calls"", ""de-identified data"", ""Data Factory moves the data to the public storage account in a separate container to allow external researchers to have access to their exported data and models""], [""separate container"", ""contains"", ""moved data"", ""Data Factory moves the data to the public storage account in a separate container""], [""Azure Data Factory"", ""calls"", ""moved data"", ""Data Factory moves the data to the public storage account in a separate container to allow external researchers to have access to their exported data and models""], [""Users"", ""calls"", ""Azure Machine Learning compute"", ""The secure environment has Azure Machine Learning compute that can access the dataset""]]}","Based on the provided context, here's the extracted entities and relationships in JSON format:

```json
{
  ""entities"": [
    [""Data owners"", ""person""],
    [""Azure Blob Storage"", ""system""],
    [""Microsoft-managed keys"", ""component""],
    [""Azure Data Factory"", ""system""],
    [""Trigger"", ""component""],
    [""Specific location (import path)"", ""entity""],
    [""Another storage account with security controls"", ""system""],
    [""Private endpoint"", ""component""],
    [""Service principal"", ""person""],
    [""Researchers"", ""person""],
    [""Streaming application"", ""component""],
    [""Azure Virtual Desktop"", ""system""],
    [""Data science VMs"", ""component""],
    [""Secure network environment"", ""entity""],
    [""Azure Machine Learning compute"", ""system""],
    [""Private endpoint (ML)"", ""component""],
    [""Models"", ""entity""],
    [""De-identified data"", ""entity""],
    [""Separate location on secure storage (export path)"", ""entity""],
    [""Logic app"", ""system""],
    [""Manual reviewers"", ""person""],
    [""Data Factory instance"", ""system""],
    [""Public storage account"", ""system""],
    [""External researchers"", ""person""]
  ],
  ""relationships"": [
    [""Azure Blob Storage"", ""contains"", ""Microsoft-managed keys""],
    [""Data owners"", ""calls"", ""Azure Blob Storage""],
    [""Azure Data Factory"", ""contains"", ""Trigger""],
    [""Another storage account with security controls"", ""part-of"", ""Private endpoint""],
    [""Another storage account with security controls"", ""called-from"", ""Service principal""],
    [""Researchers"", ""calls"", ""Streaming application""],
    [""Streaming application"", ""part-of"", ""Azure Virtual Desktop""],
    [""Data science VMs"", ""part-of"", ""Secure network environment""],
    [""Azure Machine Learning compute"", ""contains"", ""Private endpoint (ML)""],
    [""Azure Machine Learning compute"", ""called-from"", ""Models, De-identified data""],
    [""Separate location on secure storage (export path)"", ""contains"", ""Models, De-identified data""],
    [""Logic app"", ""calls"", ""Manual reviewers""],
    [""Data Factory instance"", ""part-of"", ""Public storage account""],
    [""External researchers"", ""accesses"", ""Public storage account""]
  ]
}
```","Based on the provided context, here's the extracted entities and relationships in JSON format:

```json
{
  ""entities"": [
    [""Data owners"", ""person""],
    [""Azure Blob Storage"", ""system""],
    [""Microsoft-managed keys"", ""component""],
    [""Azure Data Factory"", ""system""],
    [""Trigger"", ""component""],
    [""Specific location (import path)"", ""entity""],
    [""Another storage account with security controls"", ""system""],
    [""Private endpoint"", ""component""],
    [""Service principal"", ""person""],
    [""Researchers"", ""person""],
    [""Streaming application"", ""component""],
    [""Azure Virtual Desktop"", ""system""],
    [""Data science VMs"", ""component""],
    [""Secure network environment"", ""entity""],
    [""Azure Machine Learning compute"", ""system""],
    [""Private endpoint (ML)"", ""component""],
    [""Models"", ""entity""],
    [""De-identified data"", ""entity""],
    [""Separate location on secure storage (export path)"", ""entity""],
    [""Logic app"", ""system""],
    [""Manual reviewers"", ""person""],
    [""Data Factory instance"", ""system""],
    [""Public storage account"", ""system""],
    [""External researchers"", ""person""]
  ],
  ""relationships"": [
    [""Azure Blob Storage"", ""contains"", ""Microsoft-managed keys""],
    [""Data owners"", ""calls"", ""Azure Blob Storage""],
    [""Azure Data Factory"", ""contains"", ""Trigger""],
    [""Another storage account with security controls"", ""part-of"", ""Private endpoint""],
    [""Another storage account with security controls"", ""called-from"", ""Service principal""],
    [""Researchers"", ""calls"", ""Streaming application""],
    [""Streaming application"", ""part-of"", ""Azure Virtual Desktop""],
    [""Data science VMs"", ""part-of"", ""Secure network environment""],
    [""Azure Machine Learning compute"", ""contains"", ""Private endpoint (ML)""],
    [""Azure Machine Learning compute"", ""called-from"", ""Models, De-identified data""],
    [""Separate location on secure storage (export path)"", ""contains"", ""Models, De-identified data""],
    [""Logic app"", ""calls"", ""Manual reviewers""],
    [""Data Factory instance"", ""part-of"", ""Public storage account""],
    [""External researchers"", ""accesses"", ""Public storage account""]
  ]
}
```",8.155536498001311
69,mistral-nemo,../IMAGES NEW/Azure/15 Azure automate-document-classification.txt,"
    The user provides a document file that the web app uploads. The file contains multiple documents of various types. It can, for instance, be a PDF or multipage TIFF file.
        The document file is stored in Azure Blob Storage.
        The web app adds a command message to a storage queue to initiate pipeline processing.

    Durable Functions orchestration is triggered by the command message. The message contains metadata that identifies the location in Blob Storage of the document file to be processed. Each Durable Functions instance processes only one document file.

    The Scan activity function calls the Computer Vision Read API, passing in the location in storage of the document to be processed. Optical character recognition (OCR) results are returned to the orchestration to be used by subsequent activities.

    The Classify activity function calls the document classifier service that's hosted in an Azure Kubernetes Service (AKS) cluster. This service uses regular expression pattern matching to identify the starting page of each known document and to calculate how many document types are contained in the document file. The types and page ranges of the documents are calculated and returned to the orchestration.



Note

Azure doesn't offer a service that can classify multiple document types in a single file. This solution uses a non-Azure service that's hosted in AKS.

The Metadata Store activity function saves the document type and page range information in an Azure Cosmos DB store.

The Indexing activity function creates a new search document in the Cognitive Search service for each identified document type and uses the Azure AI Search libraries for .NET to include in the search document the full OCR results and document information. A correlation ID is also added to the search document so that the search results can be matched with the corresponding document metadata from Azure Cosmos DB.

End users can search for documents by contents and metadata. Correlation IDs in the search result set can be used to look up document records that are in Azure Cosmos DB. The records include links to the original document file in Blob Storage.


","{""entities"": [[""web app"", ""system"", ""The user provides a document file that the web app uploads""], [""Azure Blob Storage"", ""system"", ""The document file is stored in Azure Blob Storage""], [""storage queue"", ""system"", ""the web app adds a command message to a storage queue to initiate pipeline processing""], [""Durable Functions orchestration"", ""system"", ""Durable Functions orchestration is triggered by the command message.""], [""Scan activity function"", ""component"", ""The Scan activity function calls the Computer Vision Read API.""], [""Computer Vision Read API"", ""component"", ""The Scan activity function calls the Computer Vision Read API.""], [""Classify activity function"", ""component"", ""The Classify activity function calls the document classifier service that's hosted in an Azure Kubernetes Service (AKS) cluster""], [""document classifier service"", ""component"", ""The Classify activity function calls the document classifier service that's hosted in an Azure Kubernetes Service (AKS) cluster""], [""Azure Kubernetes Service (AKS) cluster"", ""system"", ""The Classify activity function calls the document classifier service that's hosted in an Azure Kubernetes Service (AKS) cluster""], [""User"", ""person"", ""provides a document file that the web app uploads""]], ""relationships"": [[""User"", ""calls"", ""web app"", ""The user provides a document file that the web app uploads""], [""web app"", ""calls"", ""Azure Blob Storage"", ""The user provides a document file that the web app uploads.The document file is stored in Azure Blob Storage""], [""web app"", ""calls"", ""storage queue"", ""the web app adds a command message to a storage queue to initiate pipeline processing""], [""storage queue"", ""calls"", ""Durable Functions orchestration"", ""Durable Functions orchestration is triggered by the command message.""], [""Durable Functions orchestration"", ""calls"", ""Azure Blob Storage"", ""Each Durable Functions instance processes only one document file""], [""Scan activity function"", ""calls"", ""Computer Vision Read API"", ""the Scan activity function calls the Computer Vision Read API""], [""document classifier service"", ""part-of"", ""Azure Kubernetes Service (AKS) cluster"", ""document classifier service that's hosted in an Azure Kubernetes Service (AKS) cluster""], [""Classify activity function"", ""calls"", ""Scan activity function"", ""The Classify activity function calls the document classifier service""], [""Classify activity function"", ""calls"", ""Durable Functions orchestration"", ""The types and page ranges of the documents are calculated and returned to the orchestration""]]}","Here's the JSON response based on the provided text:

```json
{
  ""entities"": [
    [""User"", ""person"", ""The user provides a document file""],
    [""Document File"", ""system"", ""Contains multiple documents of various types""],
    [""Azure Blob Storage"", ""system"", ""Stores the document file""],
    [""Web App"", ""component"", ""Adds a command message to a storage queue""],
    [""Storage Queue"", ""system"", ""Used by the web app to initiate pipeline processing""],
    [""Durable Functions Orchestration"", ""system"", ""Triggered by the command message""],
    [""Scan Activity Function"", ""component"", ""Calls Computer Vision Read API for OCR""],
    [""Computer Vision Read API"", ""component"", ""Processes document file for OCR results""],
    [""Classify Activity Function"", ""component"", ""Calls Document Classifier Service""],
    [""Document Classifier Service"", ""system"", ""Hosted in Azure Kubernetes Service (AKS)""],
    [""Metadata Store Activity Function"", ""component"", ""Saves document type and page range information""],
    [""Azure Cosmos DB"", ""system"", ""Used by Metadata Store Activity Function""],
    [""Indexing Activity Function"", ""component"", ""Creates new search documents in Cognitive Search service""],
    [""Cognitive Search Service"", ""system"", ""Handles search results and document metadata""]
  ],
  ""relationships"": [
    [""Document File"", ""contains"", ""Azure Blob Storage"", ""Stores the document file""],
    [""Web App"", ""calls"", ""Storage Queue"", ""Initiates pipeline processing""],
    [""Durable Functions Orchestration"", ""triggered-by"", ""Command Message"", ""Triggered by the command message""],
    [""Scan Activity Function"", ""calls"", ""Computer Vision Read API"", ""For OCR results""],
    [""Classify Activity Function"", ""calls"", ""Document Classifier Service"", ""Identifies document types and page ranges""],
    [""Metadata Store Activity Function"", ""saves-to"", ""Azure Cosmos DB"", ""Stores document type and page range information""],
    [""Indexing Activity Function"", ""creates"", ""Cognitive Search Service"", ""Creates new search documents for document contents""]
  ]
}
```","Here's the JSON response based on the provided text:

```json
{
  ""entities"": [
    [""User"", ""person"", ""The user provides a document file""],
    [""Document File"", ""system"", ""Contains multiple documents of various types""],
    [""Azure Blob Storage"", ""system"", ""Stores the document file""],
    [""Web App"", ""component"", ""Adds a command message to a storage queue""],
    [""Storage Queue"", ""system"", ""Used by the web app to initiate pipeline processing""],
    [""Durable Functions Orchestration"", ""system"", ""Triggered by the command message""],
    [""Scan Activity Function"", ""component"", ""Calls Computer Vision Read API for OCR""],
    [""Computer Vision Read API"", ""component"", ""Processes document file for OCR results""],
    [""Classify Activity Function"", ""component"", ""Calls Document Classifier Service""],
    [""Document Classifier Service"", ""system"", ""Hosted in Azure Kubernetes Service (AKS)""],
    [""Metadata Store Activity Function"", ""component"", ""Saves document type and page range information""],
    [""Azure Cosmos DB"", ""system"", ""Used by Metadata Store Activity Function""],
    [""Indexing Activity Function"", ""component"", ""Creates new search documents in Cognitive Search service""],
    [""Cognitive Search Service"", ""system"", ""Handles search results and document metadata""]
  ],
  ""relationships"": [
    [""Document File"", ""contains"", ""Azure Blob Storage"", ""Stores the document file""],
    [""Web App"", ""calls"", ""Storage Queue"", ""Initiates pipeline processing""],
    [""Durable Functions Orchestration"", ""triggered-by"", ""Command Message"", ""Triggered by the command message""],
    [""Scan Activity Function"", ""calls"", ""Computer Vision Read API"", ""For OCR results""],
    [""Classify Activity Function"", ""calls"", ""Document Classifier Service"", ""Identifies document types and page ranges""],
    [""Metadata Store Activity Function"", ""saves-to"", ""Azure Cosmos DB"", ""Stores document type and page range information""],
    [""Indexing Activity Function"", ""creates"", ""Cognitive Search Service"", ""Creates new search documents for document contents""]
  ]
}
```",7.726612755999668
70,mistral-nemo,../IMAGES NEW/TEST/08 Azure Business Processes.txt,"
The data flows through the solution as follows:

    The airline system communicates with a custom API hosted in Azure API Management.
    A custom API coordinator receives notifications and handles incoming messages from the airline system. It sends them to Power Apps, where flights are assigned to Microsoft Teams channels.
    When a user selects a flight to monitor, or when the system assigns the user to a flight, the system queues a Graph API call in an Azure Storage Account queue for further processing.
    Azure Functions runs the Graph API calls based on the incoming messages in the storage queue, sending notifications to Teams, and also streams all events to an Azure Event Hubs for further analytics.
    The airline's notification system is managed by a custom bot messaging service that employs Azure Bot Service.
    Custom bots send flight updates to users in Teams.
    An Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs, ultimately generating insightful reports with Power BI.

","{""entities"": [[""airline system"", ""system"", ""communicates with a custom API hosted in Azure API Management""], [""custom API"", ""component"", ""communicates with a custom API hosted in Azure API Management""], [""Azure API Management"", ""system"", ""communicates with a custom API hosted in Azure API Management""], [""custom API coordinator"", ""system"", ""receives notifications and handles incoming messages from the airline system""], [""Power Apps"", ""system"", ""where flights are assigned to Microsoft Teams channels""], [""Microsoft Teams channels"", ""system"", ""where flights are assigned to Microsoft Teams channels""], [""Storage Account queue"", ""system"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing.""], [""Graph API call"", ""system"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing.""], [""Azure Functions"", ""system"", ""runs the Graph API calls based on the incoming messages in the storage queue""], [""Azure Event Hubs"", ""system"", ""Azure Event Hubs for further analytics""], [""notification system"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""custom bot messaging service"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""Azure Bot Service"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""Users"", ""person"", ""selects a flight to monitor, or when the system assigns the user to a flight""], [""Azure Data Lake storage"", ""system"", ""offers long-term retention and micro-batch processing of events from Event Hubs""], [""Power BI"", ""system"", ""generating insightful reports""]], ""relationships"": [[""Azure API Management"", ""contains"", ""custom API"", ""custom API hosted in Azure API Management""], [""airline system"", ""calls"", ""custom API"", ""communicates with a custom API""], [""custom API coordinator"", ""is-called-from"", ""airline system"", ""receives notifications and handles incoming messages from the airline system""], [""Power Apps"", ""calls"", ""Microsoft Teams channels"", ""Power Apps, where flights are assigned to Microsoft Teams channels""], [""airline system"", ""calls"", ""Graph API call"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing""], [""Azure Functions"", ""calls"", ""Graph API call"", ""runs the Graph API calls based on the incoming messages in the storage queue""], [""Azure Functions"", ""calls"", ""Storage Account queue"", ""based on the incoming messages in the storage queue""], [""Azure Functions"", ""calls"", ""Microsoft Teams channels"", ""sending notifications to Teams""], [""Azure Functions"", ""calls"", ""Azure Event Hubs"", ""also streams all events to an Azure Event Hubs for further analytics""], [""notification system"", ""is-called-from"", ""custom bot messaging service"", ""managed by a custom bot messaging service""], [""custom bot messaging service"", ""calls"", ""Azure Bot Service"", ""custom bot messaging service that employs Azure Bot Service""], [""custom bot messaging service"", ""calls"", ""Microsoft Teams channels"", ""Custom bots send flight updates to users in Teams.""], [""Microsoft Teams channels"", ""calls"", ""Users"", ""Custom bots send flight updates to users in Teams.""], [""Azure Data Lake storage"", ""is-called-from"", ""Azure Event Hubs"", ""Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs""], [""Azure Data Lake storage"", ""calls"", ""Power BI"", ""Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs, ultimately generating insightful reports with Power BI""]]}","Here's the JSON response based on the provided text:

```json
{
  ""entities"": [
    [""Airline System"", ""system""],
    [""Custom API Coordinator"", ""component""],
    [""Power Apps"", ""system""],
    [""Microsoft Teams"", ""system""],
    [""Azure Storage Account Queue"", ""component""],
    [""Azure Functions"", ""component""],
    [""Azure Event Hubs"", ""system""],
    [""Azure Bot Service"", ""system""],
    [""Custom Bot Messaging Service"", ""component""],
    [""Azure Data Lake Storage"", ""system""],
    [""Power BI"", ""system""]
  ],
  ""relationships"": [
    [""Airline System"", ""calls"", ""Custom API Coordinator"", ""The airline system communicates with a custom API coordinator.""],
    [""Custom API Coordinator"", ""calls"", ""Power Apps"", ""It sends messages to Power Apps.""],
    [""Azure Storage Account Queue"", ""part-of"", ""Azure Functions"", ""Azure Functions runs the Graph API calls based on incoming messages in this queue.""],
    [""Azure Functions"", ""calls"", ""Microsoft Teams"", ""It sends notifications to Teams.""],
    [""Azure Functions"", ""streams-to"", ""Azure Event Hubs"", ""It streams all events to Azure Event Hubs for further analytics.""],
    [""Custom Bot Messaging Service"", ""part-of"", ""Azure Bot Service"", ""The custom bot messaging service employs Azure Bot Service.""],
    [""Custom Bot Messaging Service"", ""calls"", ""Microsoft Teams"", ""Custom bots send flight updates to users in Teams.""],
    [""Azure Event Hubs"", ""stores-in"", ""Azure Data Lake Storage"", ""Azure Data Lake storage offers long-term retention of events from Event Hubs.""],
    [""Azure Data Lake Storage"", ""generates-reports-for"", ""Power BI"", ""It generates insightful reports with Power BI.""]
  ]
}
```","Here's the JSON response based on the provided text:

```json
{
  ""entities"": [
    [""Airline System"", ""system""],
    [""Custom API Coordinator"", ""component""],
    [""Power Apps"", ""system""],
    [""Microsoft Teams"", ""system""],
    [""Azure Storage Account Queue"", ""component""],
    [""Azure Functions"", ""component""],
    [""Azure Event Hubs"", ""system""],
    [""Azure Bot Service"", ""system""],
    [""Custom Bot Messaging Service"", ""component""],
    [""Azure Data Lake Storage"", ""system""],
    [""Power BI"", ""system""]
  ],
  ""relationships"": [
    [""Airline System"", ""calls"", ""Custom API Coordinator"", ""The airline system communicates with a custom API coordinator.""],
    [""Custom API Coordinator"", ""calls"", ""Power Apps"", ""It sends messages to Power Apps.""],
    [""Azure Storage Account Queue"", ""part-of"", ""Azure Functions"", ""Azure Functions runs the Graph API calls based on incoming messages in this queue.""],
    [""Azure Functions"", ""calls"", ""Microsoft Teams"", ""It sends notifications to Teams.""],
    [""Azure Functions"", ""streams-to"", ""Azure Event Hubs"", ""It streams all events to Azure Event Hubs for further analytics.""],
    [""Custom Bot Messaging Service"", ""part-of"", ""Azure Bot Service"", ""The custom bot messaging service employs Azure Bot Service.""],
    [""Custom Bot Messaging Service"", ""calls"", ""Microsoft Teams"", ""Custom bots send flight updates to users in Teams.""],
    [""Azure Event Hubs"", ""stores-in"", ""Azure Data Lake Storage"", ""Azure Data Lake storage offers long-term retention of events from Event Hubs.""],
    [""Azure Data Lake Storage"", ""generates-reports-for"", ""Power BI"", ""It generates insightful reports with Power BI.""]
  ]
}
```",6.621187332988484
71,mistral-nemo,../IMAGES NEW/Azure/16 Azure automate-pdf-forms.txt,"
    A designated Outlook email account receives PDF files as attachments. The arrival of an email triggers a logic app to process the email. The logic app is built by using the capabilities of Azure Logic Apps.
    The logic app uploads the PDF files to a container in Azure Data Lake Storage.
    You can also manually or programmatically upload PDF files to the same PDF container.
    The arrival of a PDF file in the PDF container triggers another logic app to process the PDF forms that are in the PDF file.
    The logic app sends the location of the PDF file to a function app for processing. The function app is built by using the capabilities of Azure Functions.
    The function app receives the location of the file and takes these actions:
        It splits the file into single pages if the file has multiple pages. Each page contains one independent form. Split files are saved to a second container in Data Lake Storage.
        It uses HTTPS POST, an Azure REST API, to send the location of the single-page PDF file to AI Document Intelligence for processing. When Azure AI Document Intelligence completes its processing, it sends a response back to the function app, which places the information into a data structure.
        It creates a JSON data file that contains the response data and stores the file to a third container in Data Lake Storage.
    The forms processing logic app receives the processed response data.
    The forms processing logic app sends the processed data to Azure Cosmos DB, which saves the data in a database and in collections.
    Power BI obtains the data from Azure Cosmos DB and provides insights and dashboards.
    You can implement further processing as needed on the data that's in Azure Cosmos DB.

","{""entities"": [[""designated Outlook email account"", ""component"", ""A designated Outlook email account receives PDF files as attachments""], [""logic app"", ""component"", ""The arrival of an email triggers a logic app to process the email.""], [""Azure Logic Apps"", ""system"", ""The logic app is built by using the capabilities of Azure Logic Apps.""], [""Container"", ""component"", ""The logic app uploads the PDF files to a container in Azure Data Lake Storage""], [""Azure Data Lake Storage"", ""system"", ""The logic app uploads the PDF files to a container in Azure Data Lake Storage""], [""logic app 2"", ""system"", ""The arrival of a PDF file in the PDF container triggers another logic app to process the PDF forms""], [""function app"", ""component"", ""The logic app sends the location of the PDF file to a function app for processing.""], [""Azure Functions"", ""system"", ""The function app is built by using the capabilities of Azure Functions""], [""Azure REST API"", ""component"", ""It uses HTTPS POST, an Azure REST API, to send the location of the single-page PDF file""], [""Container 2"", ""component"", ""Split files are saved to a second container in Data Lake Storage""], [""AI Document Intelligence"", ""component"", ""It uses HTTPS POST, an Azure REST API, to send the location of the single-page PDF file to AI Document Intelligence for processing""], [""Container 3"", ""component"", ""JSON data file that contains the response data and stores the file to a third container in Data Lake Storage""], [""forms processing logic app"", ""component"", ""The forms processing logic app receives the processed response data""], [""Azure Cosmos DB"", ""component"", ""The forms processing logic app sends the processed data to Azure Cosmos DB""], [""database"", ""component"", ""Azure Cosmos DB, which saves the data in a database""], [""Power BI"", ""component"", ""Power BI obtains the data from Azure Cosmos DB and provides insights and dashboards""]], ""relationships"": [[""designated Outlook email account"", ""calls"", ""logic app"", ""The arrival of an email triggers a logic app to process the email.""], [""Azure Logic Apps"", ""contains"", ""logic app"", ""The logic app is built by using the capabilities of Azure Logic Apps.""], [""logic app"", ""calls"", ""Container"", ""The logic app uploads the PDF files to a container in Azure Data Lake Storage""], [""Container"", ""part-of"", ""Azure Data Lake Storage"", ""container in Azure Data Lake Storage""], [""Container"", ""calls"", ""logic app 2"", ""The arrival of a PDF file in the PDF container triggers another logic app""], [""logic app"", ""calls"", ""function app"", ""The logic app sends the location of the PDF file to a function app for processing.""], [""function app"", ""part-of"", ""Azure Functions"", ""container in Azure Data Lake Storage""], [""function app"", ""calls"", ""Container 2"", ""Split files are saved to a second container in Data Lake Storage""], [""Azure Data Lake Storage"", ""contains"", ""Container 2"", ""Split files are saved to a second container in Data Lake Storage""], [""function app"", ""calls"", ""Azure REST API"", ""It uses HTTPS POST, an Azure REST API""], [""Azure REST API"", ""calls"", ""AI Document Intelligence"", ""HTTPS POST, an Azure REST API, to send the location of the single-page PDF file to AI Document Intelligence""], [""Azure Data Lake Storage"", ""contains"", ""Container 3"", ""third container in Data Lake Storage""], [""function app"", ""calls"", ""Container 3"", ""It creates a JSON data file that contains the response data and stores the file to a third container""], [""forms processing logic app"", ""calls"", ""Container 3"", ""The forms processing logic app receives the processed response data""], [""forms processing logic app"", ""calls"", ""Azure Cosmos DB"", ""The forms processing logic app sends the processed data to Azure Cosmos DB""], [""Azure Cosmos DB"", ""calls"", ""database"", ""Azure Cosmos DB, which saves the data in a database""], [""Power BI"", ""calls"", ""Azure Cosmos DB"", ""Power BI obtains the data from Azure Cosmos DB and provides insights and dashboards""]]}","Here's the extracted entities and their relationships based on your description:

```json
{
  ""entities"": [
    [""Outlook Email Account"", ""system""],
    [""Azure Logic Apps"", ""system""],
    [""Azure Data Lake Storage"", ""system""],
    [""PDF Container"", ""component"", ""A container for PDF files in Azure Data Lake Storage""],
    [""Logic App (Email Trigger)"", ""component"", ""Triggers when a new email arrives in Outlook""],
    [""Logic App (PDF Processing)"", ""component"", ""Triggers when a new PDF file arrives in the PDF container""],
    [""Azure Functions"", ""system""],
    [""Function App"", ""component"", ""Built using Azure Functions capabilities""],
    [""AI Document Intelligence"", ""system""],
    [""Azure Cosmos DB"", ""system""],
    [""Power BI"", ""system""]
  ],
  ""relationships"": [
    [""Logic App (Email Trigger)"", ""calls"", ""Azure Logic Apps""],
    [""Azure Logic Apps"", ""contains"", ""Logic App (Email Trigger)""],
    [""Logic App (Email Trigger)"", ""contains"", ""PDF Container""],
    [""PDF Container"", ""part-of"", ""Azure Data Lake Storage""],
    [""Logic App (PDF Processing)"", ""contains"", ""PDF Container""],
    [""PDF Container"", ""part-of"", ""Logic App (PDF Processing)""],
    [""Function App"", ""calls"", ""AI Document Intelligence""],
    [""AI Document Intelligence"", ""called-from"", ""Function App""],
    [""Function App"", ""calls"", ""Azure Cosmos DB""],
    [""Azure Cosmos DB"", ""called-from"", ""Function App""],
    [""Power BI"", ""obtains_data_from"", ""Azure Cosmos DB""]
  ]
}
```","Here's the extracted entities and their relationships based on your description:

```json
{
  ""entities"": [
    [""Outlook Email Account"", ""system""],
    [""Azure Logic Apps"", ""system""],
    [""Azure Data Lake Storage"", ""system""],
    [""PDF Container"", ""component"", ""A container for PDF files in Azure Data Lake Storage""],
    [""Logic App (Email Trigger)"", ""component"", ""Triggers when a new email arrives in Outlook""],
    [""Logic App (PDF Processing)"", ""component"", ""Triggers when a new PDF file arrives in the PDF container""],
    [""Azure Functions"", ""system""],
    [""Function App"", ""component"", ""Built using Azure Functions capabilities""],
    [""AI Document Intelligence"", ""system""],
    [""Azure Cosmos DB"", ""system""],
    [""Power BI"", ""system""]
  ],
  ""relationships"": [
    [""Logic App (Email Trigger)"", ""calls"", ""Azure Logic Apps""],
    [""Azure Logic Apps"", ""contains"", ""Logic App (Email Trigger)""],
    [""Logic App (Email Trigger)"", ""contains"", ""PDF Container""],
    [""PDF Container"", ""part-of"", ""Azure Data Lake Storage""],
    [""Logic App (PDF Processing)"", ""contains"", ""PDF Container""],
    [""PDF Container"", ""part-of"", ""Logic App (PDF Processing)""],
    [""Function App"", ""calls"", ""AI Document Intelligence""],
    [""AI Document Intelligence"", ""called-from"", ""Function App""],
    [""Function App"", ""calls"", ""Azure Cosmos DB""],
    [""Azure Cosmos DB"", ""called-from"", ""Function App""],
    [""Power BI"", ""obtains_data_from"", ""Azure Cosmos DB""]
  ]
}
```",6.0733008940005675
72,mistral-nemo,../IMAGES NEW/Azure/05. azure Original.txt,"
    Backend systems. The right-hand side of the diagram shows the various backend systems that the enterprise has deployed or relies on. These systems might include SaaS systems, other Azure services, or web services that expose REST or SOAP endpoints.

    Azure Logic Apps. In this architecture, logic apps are triggered by HTTP requests. You can also nest workflows for more complex orchestration. Logic Apps uses connectors to integrate with commonly used services. Logic Apps offers hundreds of connectors, and you can create custom connectors.

    Azure API Management. API Management consists of two related components:

        API gateway. The API gateway accepts HTTP calls and routes them to the backend.

        Developer portal. Each instance of Azure API Management provides access to a developer portal. This portal gives your developers access to documentation and code samples for calling the APIs. You can also test APIs in the developer portal.

    Azure DNS. Azure DNS provides name resolution by using the Azure infrastructure. By hosting your domains in Azure, you can manage your DNS records by using the same credentials, APIs, tools, and billing that you use for your other Azure services. To use a custom domain name, such as contoso.com, create DNS records that map the custom domain name to the IP address. For more information, see Configure a custom domain name in API Management.

    Microsoft Entra ID. Use Microsoft Entra ID to authenticate clients that call the API gateway. Microsoft Entra ID supports the OpenID Connect (OIDC) protocol. Clients obtain an access token from Microsoft Entra ID, and API Gateway validates the token to authorize the request. If you use the Standard or Premium tier of API Management, Microsoft Entra ID can also help secure access to the developer portal.

","{""entities"": [[""Backend systems"", ""system"", ""various backend systems that the enterprise has deployed or relies on""], [""SaaS systems"", ""component"", ""SaaS systems""], [""other Azure services"", ""component"", ""other Azure services""], [""web services"", ""component"", ""expose REST or SOAP endpoints""], [""Azure Logic Apps"", ""system"", ""Logic Apps uses connectors to integrate with commonly used services""], [""Azure API Management"", ""system"", ""Logic Apps uses connectors to integrate with commonly used services""], [""API gateway"", ""component"", ""The API gateway accepts HTTP calls and routes them to the backend""], [""Developer portal"", ""component"", ""This portal gives your developers access to documentation and code samples for calling the APIs""], [""Azure DNS"", ""system"", ""Azure DNS provides name resolution by using the Azure infrastructure""], [""Microsoft Entra ID"", ""system"", ""Use Microsoft Entra ID to authenticate clients that call the API gateway""], [""clients"", ""system"", ""clients that call the API gateway""], [""developers"", ""person"", ""accesses documentation and code samples""]], ""relationships"": [[""Backend systems"", ""contains"", ""SaaS systems"", ""These systems might include ""], [""Backend systems"", ""contains"", ""web services"", ""These systems might include ""], [""Backend systems"", ""contains"", ""other Azure services"", ""These systems might include ""], [""web services"", ""contains"", ""SaaS systems"", ""These systems might include ""], [""Azure API Management"", ""contains"", ""API gateway"", ""API Management consists of two related components""], [""Azure API Management"", ""contains"", ""Developer portal"", ""API Management consists of two related components""], [""clients"", ""calls"", ""API gateway"", ""clients that call the API gateway""], [""clients"", ""calls"", ""Microsoft Entra ID"", ""Clients obtain an access token from Microsoft Entra ID""], [""developers"", ""calls"", ""Developer portal"", ""This portal gives your developers access to documentation and code samples for calling the APIs. You can also test APIs in the developer portal""]]}","Here's the extracted entities and relationships in JSON format:

```json
{
  ""entities"": [
    [""Azure Logic Apps"", ""system"", ""Orchestrates workflows, triggered by HTTP requests""],
    [""Azure API Management"", ""system"", ""Manages APIs with gateway and developer portal""],
    [""API gateway"", ""component"", ""Routes HTTP calls to backend systems""],
    [""Developer portal"", ""component"", ""Provides API documentation and testing""],
    [""Azure DNS"", ""system"", ""Handles name resolution for custom domains""],
    [""Microsoft Entra ID"", ""system"", ""Authenticates clients and secures access""]
  ],
  ""relationships"": [
    [""Azure Logic Apps"", ""calls"", ""API gateway"", ""Routes HTTP calls""],
    [""Azure API Management"", ""contains"", ""API gateway"", ""Handles API routing""],
    [""Azure API Management"", ""contains"", ""Developer portal"", ""Provides API documentation and testing""],
    [""Azure DNS"", ""called-from"", ""Custom domain name"", ""Maps custom domain to IP address""],
    [""Microsoft Entra ID"", ""calls"", ""API gateway"", ""Authenticates clients for API requests""],
    [""Microsoft Entra ID"", ""called-from"", ""Developer portal"", ""Secures access to developer portal""]
  ]
}
```","Here's the extracted entities and relationships in JSON format:

```json
{
  ""entities"": [
    [""Azure Logic Apps"", ""system"", ""Orchestrates workflows, triggered by HTTP requests""],
    [""Azure API Management"", ""system"", ""Manages APIs with gateway and developer portal""],
    [""API gateway"", ""component"", ""Routes HTTP calls to backend systems""],
    [""Developer portal"", ""component"", ""Provides API documentation and testing""],
    [""Azure DNS"", ""system"", ""Handles name resolution for custom domains""],
    [""Microsoft Entra ID"", ""system"", ""Authenticates clients and secures access""]
  ],
  ""relationships"": [
    [""Azure Logic Apps"", ""calls"", ""API gateway"", ""Routes HTTP calls""],
    [""Azure API Management"", ""contains"", ""API gateway"", ""Handles API routing""],
    [""Azure API Management"", ""contains"", ""Developer portal"", ""Provides API documentation and testing""],
    [""Azure DNS"", ""called-from"", ""Custom domain name"", ""Maps custom domain to IP address""],
    [""Microsoft Entra ID"", ""calls"", ""API gateway"", ""Authenticates clients for API requests""],
    [""Microsoft Entra ID"", ""called-from"", ""Developer portal"", ""Secures access to developer portal""]
  ]
}
```",4.766995829995722
73,mistral-nemo,../IMAGES NEW/Azure/07 Azure internal APIs original.txt,"
The data flows as follows:

    Developers check in code to a GitHub repository that's connected to a CI/CD pipeline agent that's installed on an Azure VM.
    The agent pushes the build to the API application that's hosted on ILB ASE.
    Azure API Management consumes the preceding APIs via HOST headers that are specified in API Management policy.
    API Management uses the App Service Environment's DNS name for all the APIs.
    Application Gateway exposes API Management's developer and API portal.
    Azure Private DNS is used to route the traffic internally between ASE, API Management, and Application Gateway.
    External users utilize the exposed developer portal to consume the APIs via Application Gateway's public IP.

","{""entities"": [[""GitHub repository"", ""system"", """"], [""Developers"", ""person"", """"], [""External users"", ""person"", """"], [""CI/CD pipeline agent"", ""system"", """"], [""Azure VM"", ""system"", """"], [""ILB ASE"", ""system"", """"], [""API application"", ""component"", """"], [""Azure API Management"", ""system"", ""consumes the preceding APIs via HOST headers""], [""App Service Environment"", ""component"", """"], [""Application Gateway"", ""component"", ""exposes API Management's developer and API portal""], [""Developer portal"", ""component"", ""API Management's developer and API portal""], [""API portal"", ""component"", ""API Management's developer and API portal""], [""Application Gateway"", ""component"", ""exposes API Management's developer and API portal""], [""Azure Private DNS"", ""component"", ""used to route the traffic internally between ASE, API Management, and Application Gateway""]], ""relationships"": [[""Azure VM"", ""contains"", ""CI/CD pipeline agent"", ""installed on an Azure VM""], [""API application"", ""part-of"", ""ILB ASE"", ""API application that's hosted on ILB ASE""], [""GitHub repository"", ""calls"", ""CI/CD pipeline agent"", ""GitHub repository that's connected to a CI/CD pipeline agent""], [""CI/CD pipeline agent"", ""calls"", ""API application"", ""agent pushes the build to the API application""], [""Azure API Management"", ""calls"", ""App Service Environment"", ""uses the App Service Environment's DNS name for all the APIs""], [""External users"", ""calls"", ""Application Gateway"", """"], [""Application Gateway"", ""calls"", ""API application"", ""to consume the APIs via Application Gateway's public IP""], [""Azure API Management"", ""contains"", ""Developer portal"", ""API Management's developer and API portal""], [""Azure API Management"", ""contains"", ""API portal"", ""API Management's developer and API portal""], [""Application Gateway"", ""calls"", ""API portal"", ""exposes API Management's developer and API portal.""], [""Application Gateway"", ""calls"", ""Developer portal"", ""exposes API Management's developer and API portal.""], [""Azure Private DNS"", ""calls"", ""Azure API Management"", ""route the traffic internally between ASE, API Management, and Application Gateway""], [""Azure Private DNS"", ""calls"", ""Application Gateway"", ""route the traffic internally between ASE, API Management, and Application Gateway""]]}","Here's the JSON output based on the provided context:

```json
{
  ""entities"": [
    [""Developers"", ""person""],
    [""GitHub repository"", ""system""],
    [""CI/CD pipeline agent"", ""component""],
    [""Azure VM"", ""system""],
    [""API application"", ""component""],
    [""ILB ASE"", ""system""],
    [""Azure API Management"", ""system""],
    [""HOST headers"", ""component""],
    [""App Service Environment"", ""system""],
    [""DNS name"", ""component""],
    [""Application Gateway"", ""system""],
    [""developer portal"", ""component""],
    [""API portal"", ""component""],
    [""Azure Private DNS"", ""system""],
    [""external users"", ""person""],
    [""public IP"", ""component""]
  ],
  ""relationships"": [
    [""Developers"", ""check-in"", ""GitHub repository"", ""Check in code to GitHub""],
    [""CI/CD pipeline agent"", ""part-of"", ""Azure VM"", ""Installed on Azure VM""],
    [""CI/CD pipeline agent"", ""pushes-to"", ""API application"", ""Pushes build to API application""],
    [""Azure API Management"", ""consumes"", ""API application"", ""Consumes APIs via HOST headers""],
    [""Azure API Management"", ""uses"", ""App Service Environment"", ""Uses DNS name for APIs""],
    [""Application Gateway"", ""exposes"", ""developer portal"", ""Exposes developer portal""],
    [""Application Gateway"", ""exposes"", ""API portal"", ""Exposes API portal""],
    [""Azure Private DNS"", ""routes-traffic-between"", ""ASE, API Management, Application Gateway"", ""Routes traffic internally""]
  ]
}
```","Here's the JSON output based on the provided context:

```json
{
  ""entities"": [
    [""Developers"", ""person""],
    [""GitHub repository"", ""system""],
    [""CI/CD pipeline agent"", ""component""],
    [""Azure VM"", ""system""],
    [""API application"", ""component""],
    [""ILB ASE"", ""system""],
    [""Azure API Management"", ""system""],
    [""HOST headers"", ""component""],
    [""App Service Environment"", ""system""],
    [""DNS name"", ""component""],
    [""Application Gateway"", ""system""],
    [""developer portal"", ""component""],
    [""API portal"", ""component""],
    [""Azure Private DNS"", ""system""],
    [""external users"", ""person""],
    [""public IP"", ""component""]
  ],
  ""relationships"": [
    [""Developers"", ""check-in"", ""GitHub repository"", ""Check in code to GitHub""],
    [""CI/CD pipeline agent"", ""part-of"", ""Azure VM"", ""Installed on Azure VM""],
    [""CI/CD pipeline agent"", ""pushes-to"", ""API application"", ""Pushes build to API application""],
    [""Azure API Management"", ""consumes"", ""API application"", ""Consumes APIs via HOST headers""],
    [""Azure API Management"", ""uses"", ""App Service Environment"", ""Uses DNS name for APIs""],
    [""Application Gateway"", ""exposes"", ""developer portal"", ""Exposes developer portal""],
    [""Application Gateway"", ""exposes"", ""API portal"", ""Exposes API portal""],
    [""Azure Private DNS"", ""routes-traffic-between"", ""ASE, API Management, Application Gateway"", ""Routes traffic internally""]
  ]
}
```",6.03244867300964
74,mistral-nemo,../IMAGES NEW/Azure/08 Azure Business Processes.txt,"
The data flows through the solution as follows:

    The airline system communicates with a custom API hosted in Azure API Management.
    A custom API coordinator receives notifications and handles incoming messages from the airline system. It sends them to Power Apps, where flights are assigned to Microsoft Teams channels.
    When a user selects a flight to monitor, or when the system assigns the user to a flight, the system queues a Graph API call in an Azure Storage Account queue for further processing.
    Azure Functions runs the Graph API calls based on the incoming messages in the storage queue, sending notifications to Teams, and also streams all events to an Azure Event Hubs for further analytics.
    The airline's notification system is managed by a custom bot messaging service that employs Azure Bot Service.
    Custom bots send flight updates to users in Teams.
    An Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs, ultimately generating insightful reports with Power BI.

","{""entities"": [[""airline system"", ""system"", ""communicates with a custom API hosted in Azure API Management""], [""custom API"", ""component"", ""communicates with a custom API hosted in Azure API Management""], [""Azure API Management"", ""system"", ""communicates with a custom API hosted in Azure API Management""], [""custom API coordinator"", ""system"", ""receives notifications and handles incoming messages from the airline system""], [""Power Apps"", ""system"", ""where flights are assigned to Microsoft Teams channels""], [""Microsoft Teams channels"", ""system"", ""where flights are assigned to Microsoft Teams channels""], [""Storage Account queue"", ""system"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing.""], [""Graph API call"", ""system"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing.""], [""Azure Functions"", ""system"", ""runs the Graph API calls based on the incoming messages in the storage queue""], [""Azure Event Hubs"", ""system"", ""Azure Event Hubs for further analytics""], [""notification system"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""custom bot messaging service"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""Azure Bot Service"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""Users"", ""person"", ""selects a flight to monitor, or when the system assigns the user to a flight""], [""Azure Data Lake storage"", ""system"", ""offers long-term retention and micro-batch processing of events from Event Hubs""], [""Power BI"", ""system"", ""generating insightful reports""]], ""relationships"": [[""Azure API Management"", ""contains"", ""custom API"", ""custom API hosted in Azure API Management""], [""airline system"", ""calls"", ""custom API"", ""communicates with a custom API""], [""custom API coordinator"", ""is-called-from"", ""airline system"", ""receives notifications and handles incoming messages from the airline system""], [""Power Apps"", ""calls"", ""Microsoft Teams channels"", ""Power Apps, where flights are assigned to Microsoft Teams channels""], [""airline system"", ""calls"", ""Graph API call"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing""], [""Azure Functions"", ""calls"", ""Graph API call"", ""runs the Graph API calls based on the incoming messages in the storage queue""], [""Azure Functions"", ""calls"", ""Storage Account queue"", ""based on the incoming messages in the storage queue""], [""Azure Functions"", ""calls"", ""Microsoft Teams channels"", ""sending notifications to Teams""], [""Azure Functions"", ""calls"", ""Azure Event Hubs"", ""also streams all events to an Azure Event Hubs for further analytics""], [""notification system"", ""is-called-from"", ""custom bot messaging service"", ""managed by a custom bot messaging service""], [""custom bot messaging service"", ""calls"", ""Azure Bot Service"", ""custom bot messaging service that employs Azure Bot Service""], [""custom bot messaging service"", ""calls"", ""Microsoft Teams channels"", ""Custom bots send flight updates to users in Teams.""], [""Microsoft Teams channels"", ""calls"", ""Users"", ""Custom bots send flight updates to users in Teams.""], [""Azure Data Lake storage"", ""is-called-from"", ""Azure Event Hubs"", ""Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs""], [""Azure Data Lake storage"", ""calls"", ""Power BI"", ""Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs, ultimately generating insightful reports with Power BI""]]}","Based on the provided context, here's the extracted entities and relationships in JSON format:

```json
{
  ""entities"": [
    [""Airline System"", ""system""],
    [""Azure API Management"", ""system""],
    [""Custom API Coordinator"", ""component""],
    [""Power Apps"", ""system""],
    [""Microsoft Teams"", ""system""],
    [""Azure Storage Account"", ""system""],
    [""Azure Functions"", ""system""],
    [""Azure Event Hubs"", ""system""],
    [""Azure Data Lake Storage"", ""system""],
    [""Power BI"", ""system""],
    [""Custom Bot Messaging Service"", ""component""],
    [""Azure Bot Service"", ""system""]
  ],
  ""relationships"": [
    [""Airline System"", ""calls"", ""Azure API Management""],
    [""Custom API Coordinator"", ""part-of"", ""Azure API Management""],
    [""Custom API Coordinator"", ""calls"", ""Power Apps""],
    [""Power Apps"", ""contains"", ""Microsoft Teams""],
    [""Custom API Coordinator"", ""calls"", ""Azure Storage Account""],
    [""Azure Functions"", ""called-from"", ""Azure Storage Account""],
    [""Azure Functions"", ""calls"", ""Microsoft Teams""],
    [""Azure Functions"", ""streams"", ""Azure Event Hubs""],
    [""Azure Data Lake Storage"", ""processes"", ""Azure Event Hubs""],
    [""Power BI"", ""generates"", ""Azure Data Lake Storage""],
    [""Custom Bot Messaging Service"", ""part-of"", ""Azure API Management""],
    [""Custom Bot Messaging Service"", ""calls"", ""Azure Bot Service""]
  ]
}
```","Based on the provided context, here's the extracted entities and relationships in JSON format:

```json
{
  ""entities"": [
    [""Airline System"", ""system""],
    [""Azure API Management"", ""system""],
    [""Custom API Coordinator"", ""component""],
    [""Power Apps"", ""system""],
    [""Microsoft Teams"", ""system""],
    [""Azure Storage Account"", ""system""],
    [""Azure Functions"", ""system""],
    [""Azure Event Hubs"", ""system""],
    [""Azure Data Lake Storage"", ""system""],
    [""Power BI"", ""system""],
    [""Custom Bot Messaging Service"", ""component""],
    [""Azure Bot Service"", ""system""]
  ],
  ""relationships"": [
    [""Airline System"", ""calls"", ""Azure API Management""],
    [""Custom API Coordinator"", ""part-of"", ""Azure API Management""],
    [""Custom API Coordinator"", ""calls"", ""Power Apps""],
    [""Power Apps"", ""contains"", ""Microsoft Teams""],
    [""Custom API Coordinator"", ""calls"", ""Azure Storage Account""],
    [""Azure Functions"", ""called-from"", ""Azure Storage Account""],
    [""Azure Functions"", ""calls"", ""Microsoft Teams""],
    [""Azure Functions"", ""streams"", ""Azure Event Hubs""],
    [""Azure Data Lake Storage"", ""processes"", ""Azure Event Hubs""],
    [""Power BI"", ""generates"", ""Azure Data Lake Storage""],
    [""Custom Bot Messaging Service"", ""part-of"", ""Azure API Management""],
    [""Custom Bot Messaging Service"", ""calls"", ""Azure Bot Service""]
  ]
}
```",5.655321370024467
75,mistral-nemo,../IMAGES NEW/Azure/14 Azure Call Center Analytics.txt,"
    A phone call between an agent and a customer is recorded and stored in Azure Blob Storage. Audio files are uploaded to an Azure Storage account via a supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API.

    Azure AI Speech is used to transcribe audio files in Batch mode asynchronously with speaker diarization enabled. The transcription results are persisted in Blob Storage.

    Azure AI Language is used to detect and redact personal data in the transcript.

    For batch mode transcription and personal data detection and redaction, use the AI services Ingestion Client tool. The Ingestion Client tool uses a no-code approach for call center transcription.

    Azure OpenAI is used to process the transcript and extract entities, summarize the conversation, and analyze sentiments. The processed output is stored in Blob Storage and then analyzed and visualized by using other services. You can also store the output in a datastore for keeping track of metadata and for reporting. Use Azure OpenAI to process the stored transcription information.

    Power BI or a custom web application that's hosted by App Service is used to visualize the output. Both options provide near real-time insights. You can store this output in a customer relationship management (CRM), so agents have contextual information about why the customer called and can quickly solve potential problems. This process is fully automated, which saves the agents time and effort.

","{""entities"": [[""phone call"", ""component"", ""A phone call between an agent and a customer is recorded""], [""agent"", ""person"", ""A phone call between an agent and a customer is recorded""], [""customer"", ""person"", ""A phone call between an agent and a customer is recorded""], [""Azure Blob Storage"", ""system"", ""is recorded and stored in Azure Blob Storage""], [""Audio files"", ""system"", ""Audio files are uploaded to an Azure Storage account via a supported method""], [""supported method"", ""component"", ""Audio files are uploaded to an Azure Storage account via a supported method""], [""UI-based tool"", ""component"", ""supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""Azure Storage Explorer"", ""component"", ""supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""Storage SDK"", ""component"", ""supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""API"", ""component"", ""supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""Azure AI Speech"", ""component"", ""transcribe audio files in Batch mode asynchronously""], [""transcription results"", ""component"", ""The transcription results are persisted in Blob Storage.""], [""Azure AI Language"", ""component"", ""Azure AI Language is used to detect and redact personal data in the transcript.""], [""AI services Ingestion Client tool"", ""component"", ""For batch mode transcription and personal data detection and redaction, use the AI services Ingestion Client tool""], [""Azure OpenAI"", ""component"", ""Azure OpenAI is used to process the transcript and extract entities, summarize the conversation, and analyze sentiments.""], [""Azure OpenAI output"", ""component"", ""The processed output is stored in Blob Storage and then analyzed and visualized by using other services.""], [""other services"", ""component"", ""The processed output is stored in Blob Storage and then analyzed and visualized by using other services.""], [""App Service"", ""system"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""Power BI"", ""system"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""custom web application"", ""system"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""Azure OpenAI output 2"", ""component"", ""You can also store the output in a datastore for keeping track of metadata and for reporting""], [""datastore"", ""component"", ""You can also store the output in a datastore for keeping track of metadata and for reporting""], [""customer relationship management (CRM)"", ""system"", ""You can store this output in a customer relationship management (CRM)""], [""Azure OpenAI output 3"", ""component"", ""You can store this output in a customer relationship management (CRM)""]], ""relationships"": [[""agent"", ""calls"", ""phone call"", ""A phone call between an agent and a customer is recorded""], [""customer"", ""calls"", ""phone call"", ""A phone call between an agent and a customer is recorded""], [""phone call"", ""part-of"", ""Azure Blob Storage"", ""is recorded and stored in Azure Blob Storage""], [""Audio files"", ""part-of"", ""Azure Blob Storage"", ""Audio files are uploaded to an Azure Storage account via a supported method""], [""supported method"", ""calls"", ""Audio files"", ""Audio files are uploaded to an Azure Storage account via a supported method""], [""supported method"", ""contains"", ""UI-based tool"", ""upported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""supported method"", ""contains"", ""Azure Storage Explorer"", ""upported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""supported method"", ""contains"", ""Storage SDK"", ""upported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""supported method"", ""contains"", ""API"", ""supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""Azure AI Speech"", ""calls"", ""Audio files"", ""transcribe audio files in Batch mode asynchronously""], [""Azure Blob Storage"", ""contains"", ""transcription results"", ""The transcription results are persisted in Blob Storage.""], [""Azure AI Speech"", ""calls"", ""transcription results"", ""The transcription results are persisted in Blob Storage.""], [""Azure AI Language"", ""calls"", ""transcription results"", ""Azure AI Language is used to detect and redact personal data in the transcript.""], [""AI services Ingestion Client tool"", ""calls"", ""transcription results"", ""For batch mode transcription and personal data detection and redaction, use the AI services Ingestion Client tool""], [""Azure OpenAI"", ""calls"", ""transcription results"", ""Azure OpenAI is used to process the transcript and extract entities, summarize the conversation, and analyze sentiments.""], [""Azure OpenAI"", ""calls"", ""Azure OpenAI output"", ""The processed output is stored in Blob Storage and then analyzed and visualized by using other services.""], [""Azure Blob Storage"", ""contains"", ""Azure OpenAI output"", ""The processed output is stored in Blob Storage and then analyzed and visualized by using other services.""], [""other services"", ""calls"", ""Azure OpenAI output"", ""The processed output is stored in Blob Storage and then analyzed and visualized by using other services.""], [""Power BI"", ""part-of"", ""App Service"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""custom web application"", ""part-of"", ""App Service"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""custom web application"", ""calls"", ""Azure OpenAI output"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""Power BI"", ""calls"", ""Azure OpenAI output"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""agent"", ""calls"", ""customer relationship management (CRM)"", ""You can store this output in a customer relationship management (CRM), so agents have contextual information about why the customer called and can quickly solve potential problems""], [""Azure OpenAI output 2"", ""part-of"", ""datastore"", ""You can also store the output in a datastore for keeping track of metadata and for reporting""], [""Azure OpenAI output 3"", ""part-of"", ""customer relationship management (CRM)"", ""You can also store the output in a datastore for keeping track of metadata and for reporting""], [""Azure OpenAI output"", ""calls"", ""Azure OpenAI output 2"", ""You can also store the output in a datastore for keeping track of metadata and for reporting""], [""Azure OpenAI output"", ""calls"", ""Azure OpenAI output 3"", ""You can store this output in a customer relationship management (CRM), so agents have contextual information about why the customer called and can quickly solve potential problems""]]}","Based on the provided text, here's the extracted entities and relationships in JSON format:

```json
{
  ""entities"": [
    [""Azure Blob Storage"", ""system""],
    [""Agent"", ""person""],
    [""Customer"", ""person""],
    [""Azure AI Speech"", ""component""],
    [""Azure AI Language"", ""component""],
    [""Azure OpenAI"", ""component""],
    [""Power BI"", ""system""],
    [""App Service"", ""system""],
    [""CRM"", ""system""]
  ],
  ""relationships"": [
    [""Agent"", ""calls"", ""Customer""],
    [""Customer"", ""called-from"", ""Agent""],
    [""Audio files"", ""part-of"", ""Azure Blob Storage""],
    [""Azure Blob Storage"", ""contains"", ""Audio files""],
    [""Azure AI Speech"", ""calls"", ""Azure Blob Storage""],
    [""Azure Blob Storage"", ""called-from"", ""Azure AI Speech""],
    [""Azure AI Language"", ""calls"", ""Azure Blob Storage""],
    [""Azure Blob Storage"", ""called-from"", ""Azure AI Language""],
    [""Azure OpenAI"", ""processes"", ""transcript""],
    [""Transcript"", ""part-of"", ""Azure OpenAI""],
    [""Power BI"", ""visualizes"", ""output""],
    [""Output"", ""part-of"", ""Power BI""],
    [""App Service"", ""hosts"", ""custom web application""],
    [""CRM"", ""stores"", ""output""]
  ]
}
```","Based on the provided text, here's the extracted entities and relationships in JSON format:

```json
{
  ""entities"": [
    [""Azure Blob Storage"", ""system""],
    [""Agent"", ""person""],
    [""Customer"", ""person""],
    [""Azure AI Speech"", ""component""],
    [""Azure AI Language"", ""component""],
    [""Azure OpenAI"", ""component""],
    [""Power BI"", ""system""],
    [""App Service"", ""system""],
    [""CRM"", ""system""]
  ],
  ""relationships"": [
    [""Agent"", ""calls"", ""Customer""],
    [""Customer"", ""called-from"", ""Agent""],
    [""Audio files"", ""part-of"", ""Azure Blob Storage""],
    [""Azure Blob Storage"", ""contains"", ""Audio files""],
    [""Azure AI Speech"", ""calls"", ""Azure Blob Storage""],
    [""Azure Blob Storage"", ""called-from"", ""Azure AI Speech""],
    [""Azure AI Language"", ""calls"", ""Azure Blob Storage""],
    [""Azure Blob Storage"", ""called-from"", ""Azure AI Language""],
    [""Azure OpenAI"", ""processes"", ""transcript""],
    [""Transcript"", ""part-of"", ""Azure OpenAI""],
    [""Power BI"", ""visualizes"", ""output""],
    [""Output"", ""part-of"", ""Power BI""],
    [""App Service"", ""hosts"", ""custom web application""],
    [""CRM"", ""stores"", ""output""]
  ]
}
```",5.330863608018262
76,mistral-nemo,../IMAGES NEW/Azure/06 Azure logic-apps-data-integration.txt,"
    API Management accepts API calls in the form of HTTP requests.

    API Management securely routes the HTTP requests to Logic Apps.

    Each HTTP request triggers a run in Logic Apps:
        Logic Apps uses secured template parameters to retrieve database credentials from Azure Key Vault.
        Logic Apps uses Transport Layer Security (TLS) to send the database credentials and a database statement to the on-premises data gateway.

    The on-premises data gateway connects to a SQL Server database to run the statement.

    SQL Server stores the data and makes it available to apps that users access.

    Azure Monitor collects information on Logic Apps events and performance.

","{""entities"": [[""API Management"", ""system"", ""accepts API calls in the form of HTTP requests""], [""Logic Apps"", ""system"", ""uses secured template parameters to retrieve database credentials from Azure Key Vault""], [""on-premises data gateway"", ""system"", """"], [""SQL Server"", ""system"", ""stores the data and makes it available to apps that users access""], [""Azure Monitor"", ""system"", ""collects information on Logic Apps events and performance""], [""Azure Key Vault"", ""system"", ""database credentials""]], ""relationships"": [[""API Management"", ""calls"", ""Logic Apps"", ""routes the HTTP requests to Logic Apps""], [""Logic Apps"", ""calls"", ""Azure Key Vault"", ""Logic Apps uses secured template parameters to retrieve database credentials from Azure Key Vault""], [""Logic Apps"", ""calls"", ""on-premises data gateway"", ""send the database credentials and a database statement to the on-premises data gateway""], [""on-premises data gateway"", ""calls"", ""SQL Server"", ""connects to a SQL Server database""], [""Azure Monitor"", ""calls"", ""Logic Apps"", ""collects information on Logic Apps events and performance""]]}","Here's the JSON representation of the software architecture extracted from your description:

```json
{
  ""entities"": [
    [""API Management"", ""system""],
    [""Logic Apps"", ""system""],
    [""Azure Key Vault"", ""component""],
    [""on-premises data gateway"", ""component""],
    [""SQL Server database"", ""system""],
    [""Azure Monitor"", ""system""]
  ],
  ""relationships"": [
    [""API Management"", ""calls"", ""Logic Apps""],
    [""Logic Apps"", ""contains"", ""Azure Key Vault""],
    [""Logic Apps"", ""called-from"", ""Azure Key Vault""],
    [""Logic Apps"", ""calls"", ""on-premises data gateway""],
    [""on-premises data gateway"", ""part-of"", ""SQL Server database""],
    [""Azure Monitor"", ""collects information from"", ""Logic Apps""]
  ]
}
```","Here's the JSON representation of the software architecture extracted from your description:

```json
{
  ""entities"": [
    [""API Management"", ""system""],
    [""Logic Apps"", ""system""],
    [""Azure Key Vault"", ""component""],
    [""on-premises data gateway"", ""component""],
    [""SQL Server database"", ""system""],
    [""Azure Monitor"", ""system""]
  ],
  ""relationships"": [
    [""API Management"", ""calls"", ""Logic Apps""],
    [""Logic Apps"", ""contains"", ""Azure Key Vault""],
    [""Logic Apps"", ""called-from"", ""Azure Key Vault""],
    [""Logic Apps"", ""calls"", ""on-premises data gateway""],
    [""on-premises data gateway"", ""part-of"", ""SQL Server database""],
    [""Azure Monitor"", ""collects information from"", ""Logic Apps""]
  ]
}
```",3.227114207984414
77,mistral-nemo,../IMAGES NEW/Azure/10 Azure LoB original.txt,"
The data flows through the solution as follows:

    Supplier data stored in CDS is moved to SQL via Data Factory.
    Purchase order (PO) data stored in ERP system is sent to Azure SQL database.
    Azure Functions uses API to surface PO data monthly and creates a task for users to review.
    Power Apps retrieves data from Azure SQL Database through API.
    User reviews and updates POs in Power Apps and sends this data to suppliers through CSV export.
    Power BI reports trends in supplier status.

","{""entities"": [[""Supplier data"", ""component"", ""Supplier data stored in CDS""], [""CDS"", ""system"", "" Supplier data stored in CDS""], [""Azure SQL database"", ""system"", ""moved to SQL via Data Factory""], [""Data Factory"", ""system"", ""moved to SQL via Data Factory""], [""Purchase order (PO)"", ""system"", ""moved to SQL via Data Factory""], [""ERP system"", ""system"", ""Purchase order (PO) data stored in ERP system""], [""Azure Functions"", ""system"", ""uses API to surface PO data monthly and creates a task for users to review""], [""Power Apps"", ""system"", ""retrieves data from Azure SQL Database through API""], [""CSV export"", ""system"", ""ends this data to suppliers through CSV export""], [""User"", ""person"", "" reviews and updates POs in Power Apps""], [""suppliers"", ""person"", "" reviews and updates POs in Power Apps""]], ""relationships"": [[""Supplier data"", ""part-of"", ""CDS"", ""Supplier data stored in CDS""], [""Supplier data"", ""is-called-from"", ""Data Factory"", ""moved to SQL via Data Factory""], [""Data Factory"", ""calls"", ""Azure SQL database"", ""moved to SQL via Data Factory""], [""Purchase order (PO)"", ""part-of"", ""ERP system"", ""Purchase order (PO) data stored in ERP system""], [""Purchase order (PO)"", ""calls"", ""Azure SQL database"", ""Purchase order (PO) data stored in ERP system is sent to Azure SQL database""], [""Azure Functions"", ""calls"", ""Purchase order (PO)"", ""uses API to surface PO data monthly""], [""Azure Functions"", ""calls"", ""User"", ""creates a task for users to review""], [""Power Apps"", ""calls"", ""Azure SQL database"", ""retrieves data from Azure SQL Database through API""], [""User"", ""calls"", ""Power Apps"", ""Reviews and updates POs in Power Apps""], [""User"", ""calls"", ""CSV export"", ""sends this data to suppliers through CSV export""], [""CSV export"", ""calls"", ""suppliers"", ""sends this data to suppliers through CSV export""]]}","```json
{
  ""entities"": [
    [""Supplier"", ""system""],
    [""CDS"", ""component""],
    [""SQL"", ""component""],
    [""Data Factory"", ""system""],
    [""ERP System"", ""system""],
    [""Azure SQL Database"", ""component""],
    [""Azure Functions"", ""component""],
    [""API"", ""component""],
    [""PO (Purchase Order)"", ""entity""],
    [""Task"", ""entity""],
    [""User"", ""person""],
    [""Power Apps"", ""component""],
    [""CSV"", ""format""],
    [""Supplier Status"", ""entity""],
    [""Power BI"", ""component""]
  ],
  ""relationships"": [
    [""Data Factory"", ""moves_data_from"", ""CDS"", ""Moves supplier data to SQL""],
    [""Azure Functions"", ""surfaces_data_of"", ""PO"", ""Surfaces PO data monthly through API""],
    [""Azure Functions"", ""creates_task_for"", ""User"", ""Creates a task for users to review""],
    [""Power Apps"", ""retrieves_data_from"", ""Azure SQL Database"", ""Retrieves data from Azure SQL Database through API""],
    [""User"", ""reviews_and_updates"", ""PO"", ""Reviews and updates POs in Power Apps""],
    [""Power Apps"", ""sends_data_to"", ""Supplier via CSV"", ""Sends updated PO data to suppliers through CSV export""]
  ]
}
```","```json
{
  ""entities"": [
    [""Supplier"", ""system""],
    [""CDS"", ""component""],
    [""SQL"", ""component""],
    [""Data Factory"", ""system""],
    [""ERP System"", ""system""],
    [""Azure SQL Database"", ""component""],
    [""Azure Functions"", ""component""],
    [""API"", ""component""],
    [""PO (Purchase Order)"", ""entity""],
    [""Task"", ""entity""],
    [""User"", ""person""],
    [""Power Apps"", ""component""],
    [""CSV"", ""format""],
    [""Supplier Status"", ""entity""],
    [""Power BI"", ""component""]
  ],
  ""relationships"": [
    [""Data Factory"", ""moves_data_from"", ""CDS"", ""Moves supplier data to SQL""],
    [""Azure Functions"", ""surfaces_data_of"", ""PO"", ""Surfaces PO data monthly through API""],
    [""Azure Functions"", ""creates_task_for"", ""User"", ""Creates a task for users to review""],
    [""Power Apps"", ""retrieves_data_from"", ""Azure SQL Database"", ""Retrieves data from Azure SQL Database through API""],
    [""User"", ""reviews_and_updates"", ""PO"", ""Reviews and updates POs in Power Apps""],
    [""Power Apps"", ""sends_data_to"", ""Supplier via CSV"", ""Sends updated PO data to suppliers through CSV export""]
  ]
}
```",5.028403089003405
78,mistral-nemo,../IMAGES NEW/Azure/16 Azure automate-pdf-forms.txt,"
    A designated Outlook email account receives PDF files as attachments. The arrival of an email triggers a logic app to process the email. The logic app is built by using the capabilities of Azure Logic Apps.
    The logic app uploads the PDF files to a container in Azure Data Lake Storage.
    You can also manually or programmatically upload PDF files to the same PDF container.
    The arrival of a PDF file in the PDF container triggers another logic app to process the PDF forms that are in the PDF file.
    The logic app sends the location of the PDF file to a function app for processing. The function app is built by using the capabilities of Azure Functions.
    The function app receives the location of the file and takes these actions:
        It splits the file into single pages if the file has multiple pages. Each page contains one independent form. Split files are saved to a second container in Data Lake Storage.
        It uses HTTPS POST, an Azure REST API, to send the location of the single-page PDF file to AI Document Intelligence for processing. When Azure AI Document Intelligence completes its processing, it sends a response back to the function app, which places the information into a data structure.
        It creates a JSON data file that contains the response data and stores the file to a third container in Data Lake Storage.
    The forms processing logic app receives the processed response data.
    The forms processing logic app sends the processed data to Azure Cosmos DB, which saves the data in a database and in collections.
    Power BI obtains the data from Azure Cosmos DB and provides insights and dashboards.
    You can implement further processing as needed on the data that's in Azure Cosmos DB.

","{""entities"": [[""designated Outlook email account"", ""component"", ""A designated Outlook email account receives PDF files as attachments""], [""logic app"", ""component"", ""The arrival of an email triggers a logic app to process the email.""], [""Azure Logic Apps"", ""system"", ""The logic app is built by using the capabilities of Azure Logic Apps.""], [""Container"", ""component"", ""The logic app uploads the PDF files to a container in Azure Data Lake Storage""], [""Azure Data Lake Storage"", ""system"", ""The logic app uploads the PDF files to a container in Azure Data Lake Storage""], [""logic app 2"", ""system"", ""The arrival of a PDF file in the PDF container triggers another logic app to process the PDF forms""], [""function app"", ""component"", ""The logic app sends the location of the PDF file to a function app for processing.""], [""Azure Functions"", ""system"", ""The function app is built by using the capabilities of Azure Functions""], [""Azure REST API"", ""component"", ""It uses HTTPS POST, an Azure REST API, to send the location of the single-page PDF file""], [""Container 2"", ""component"", ""Split files are saved to a second container in Data Lake Storage""], [""AI Document Intelligence"", ""component"", ""It uses HTTPS POST, an Azure REST API, to send the location of the single-page PDF file to AI Document Intelligence for processing""], [""Container 3"", ""component"", ""JSON data file that contains the response data and stores the file to a third container in Data Lake Storage""], [""forms processing logic app"", ""component"", ""The forms processing logic app receives the processed response data""], [""Azure Cosmos DB"", ""component"", ""The forms processing logic app sends the processed data to Azure Cosmos DB""], [""database"", ""component"", ""Azure Cosmos DB, which saves the data in a database""], [""Power BI"", ""component"", ""Power BI obtains the data from Azure Cosmos DB and provides insights and dashboards""]], ""relationships"": [[""designated Outlook email account"", ""calls"", ""logic app"", ""The arrival of an email triggers a logic app to process the email.""], [""Azure Logic Apps"", ""contains"", ""logic app"", ""The logic app is built by using the capabilities of Azure Logic Apps.""], [""logic app"", ""calls"", ""Container"", ""The logic app uploads the PDF files to a container in Azure Data Lake Storage""], [""Container"", ""part-of"", ""Azure Data Lake Storage"", ""container in Azure Data Lake Storage""], [""Container"", ""calls"", ""logic app 2"", ""The arrival of a PDF file in the PDF container triggers another logic app""], [""logic app"", ""calls"", ""function app"", ""The logic app sends the location of the PDF file to a function app for processing.""], [""function app"", ""part-of"", ""Azure Functions"", ""container in Azure Data Lake Storage""], [""function app"", ""calls"", ""Container 2"", ""Split files are saved to a second container in Data Lake Storage""], [""Azure Data Lake Storage"", ""contains"", ""Container 2"", ""Split files are saved to a second container in Data Lake Storage""], [""function app"", ""calls"", ""Azure REST API"", ""It uses HTTPS POST, an Azure REST API""], [""Azure REST API"", ""calls"", ""AI Document Intelligence"", ""HTTPS POST, an Azure REST API, to send the location of the single-page PDF file to AI Document Intelligence""], [""Azure Data Lake Storage"", ""contains"", ""Container 3"", ""third container in Data Lake Storage""], [""function app"", ""calls"", ""Container 3"", ""It creates a JSON data file that contains the response data and stores the file to a third container""], [""forms processing logic app"", ""calls"", ""Container 3"", ""The forms processing logic app receives the processed response data""], [""forms processing logic app"", ""calls"", ""Azure Cosmos DB"", ""The forms processing logic app sends the processed data to Azure Cosmos DB""], [""Azure Cosmos DB"", ""calls"", ""database"", ""Azure Cosmos DB, which saves the data in a database""], [""Power BI"", ""calls"", ""Azure Cosmos DB"", ""Power BI obtains the data from Azure Cosmos DB and provides insights and dashboards""]]}","Here's the extracted information and relationships in JSON format:

```json
{
  ""entities"": [
    [""Outlook Email Account"", ""system"", ""Receives PDF files as attachments""],
    [""Logic App (Email Trigger)"", ""component"", ""Processes email arrival""],
    [""Azure Data Lake Storage (PDF Container)"", ""system"", ""Stores uploaded PDF files""],
    [""Logic App (PDF Processing)"", ""component"", ""Processes PDF forms""],
    [""Function App"", ""component"", ""Splits, sends to AI Document Intelligence, and creates JSON data file""],
    [""AI Document Intelligence"", ""component"", "" Processes PDF forms""],
    [""Azure Data Lake Storage (Split Files Container)"", ""system"", ""Stores split PDF files""],
    [""Azure Data Lake Storage (JSON Data Container)"", ""system"", ""Stores JSON data files""],
    [""Forms Processing Logic App"", ""component"", ""Receives processed response data and sends to Azure Cosmos DB""],
    [""Azure Cosmos DB"", ""system"", ""Saves data in a database and collections""],
    [""Power BI"", ""component"", ""Obtains data from Azure Cosmos DB for insights and dashboards""]
  ],
  ""relationships"": [
    [""Outlook Email Account"", ""calls"", ""Logic App (Email Trigger)"", ""The arrival of an email triggers the logic app""],
    [""Logic App (Email Trigger)"", ""contains"", ""Azure Data Lake Storage (PDF Container)"", ""Uploads PDF files to the container""],
    [""Azure Data Lake Storage (PDF Container)"", ""part-of"", ""Azure Data Lake Storage"", ""Stores uploaded PDF files""],
    [""Azure Data Lake Storage"", ""called-from"", ""Logic App (Email Trigger)"", ""The logic app uploads PDF files to this storage""],
    [""Azure Data Lake Storage (PDF Container)"", ""contains"", ""Logic App (PDF Processing)"", ""Triggers the processing logic app""],
    [""Logic App (PDF Processing)"", ""part-of"", ""Logic App"", ""Processes PDF forms in the container""],
    [""Logic App (PDF Processing)"", ""calls"", ""Function App"", ""Sends location of single-page PDF file to function app for processing""],
    [""Function App"", ""called-from"", ""Logic App (PDF Processing)"", ""Receives location of single-page PDF file from logic app""],
    [""Function App"", ""contains"", ""AI Document Intelligence"", ""Uses HTTPS POST to send location of single-page PDF file""],
    [""AI Document Intelligence"", ""part-of"", ""Function App"", ""Processes PDF forms as instructed by function app""],
    [""Function App"", ""contains"", ""Azure Data Lake Storage (Split Files Container)"", ""Stores split files in this container""],
    [""Azure Data Lake Storage (Split Files Container)"", ""part-of"", ""Azure Data Lake Storage"", ""Stores split files""],
    [""Function App"", ""calls"", ""Azure Data Lake Storage (JSON Data Container)"", ""Creates JSON data file and stores it in the container""],
    [""Azure Data Lake Storage (JSON Data Container)"", ""part-of"", ""Azure Data Lake Storage"", ""Stores JSON data files""],
    [""Forms Processing Logic App"", ""called-from"", ""Azure Data Lake Storage (JSON Data Container)"", ""Receives processed response data from this storage""],
    [""Forms Processing Logic App"", ""contains"", ""Azure Cosmos DB"", ""Sends processed data to Azure Cosmos DB for saving""],
    [""Azure Cosmos DB"", ""part-of"", ""Forms Processing Logic App"", ""Stores data in a database and collections as instructed by logic app""],
    [""Power BI"", ""called-from"", ""Azure Cosmos DB"", ""Obtains data from Azure Cosmos DB for insights and dashboards""]
  ]
}
```","Here's the extracted information and relationships in JSON format:

```json
{
  ""entities"": [
    [""Outlook Email Account"", ""system"", ""Receives PDF files as attachments""],
    [""Logic App (Email Trigger)"", ""component"", ""Processes email arrival""],
    [""Azure Data Lake Storage (PDF Container)"", ""system"", ""Stores uploaded PDF files""],
    [""Logic App (PDF Processing)"", ""component"", ""Processes PDF forms""],
    [""Function App"", ""component"", ""Splits, sends to AI Document Intelligence, and creates JSON data file""],
    [""AI Document Intelligence"", ""component"", "" Processes PDF forms""],
    [""Azure Data Lake Storage (Split Files Container)"", ""system"", ""Stores split PDF files""],
    [""Azure Data Lake Storage (JSON Data Container)"", ""system"", ""Stores JSON data files""],
    [""Forms Processing Logic App"", ""component"", ""Receives processed response data and sends to Azure Cosmos DB""],
    [""Azure Cosmos DB"", ""system"", ""Saves data in a database and collections""],
    [""Power BI"", ""component"", ""Obtains data from Azure Cosmos DB for insights and dashboards""]
  ],
  ""relationships"": [
    [""Outlook Email Account"", ""calls"", ""Logic App (Email Trigger)"", ""The arrival of an email triggers the logic app""],
    [""Logic App (Email Trigger)"", ""contains"", ""Azure Data Lake Storage (PDF Container)"", ""Uploads PDF files to the container""],
    [""Azure Data Lake Storage (PDF Container)"", ""part-of"", ""Azure Data Lake Storage"", ""Stores uploaded PDF files""],
    [""Azure Data Lake Storage"", ""called-from"", ""Logic App (Email Trigger)"", ""The logic app uploads PDF files to this storage""],
    [""Azure Data Lake Storage (PDF Container)"", ""contains"", ""Logic App (PDF Processing)"", ""Triggers the processing logic app""],
    [""Logic App (PDF Processing)"", ""part-of"", ""Logic App"", ""Processes PDF forms in the container""],
    [""Logic App (PDF Processing)"", ""calls"", ""Function App"", ""Sends location of single-page PDF file to function app for processing""],
    [""Function App"", ""called-from"", ""Logic App (PDF Processing)"", ""Receives location of single-page PDF file from logic app""],
    [""Function App"", ""contains"", ""AI Document Intelligence"", ""Uses HTTPS POST to send location of single-page PDF file""],
    [""AI Document Intelligence"", ""part-of"", ""Function App"", ""Processes PDF forms as instructed by function app""],
    [""Function App"", ""contains"", ""Azure Data Lake Storage (Split Files Container)"", ""Stores split files in this container""],
    [""Azure Data Lake Storage (Split Files Container)"", ""part-of"", ""Azure Data Lake Storage"", ""Stores split files""],
    [""Function App"", ""calls"", ""Azure Data Lake Storage (JSON Data Container)"", ""Creates JSON data file and stores it in the container""],
    [""Azure Data Lake Storage (JSON Data Container)"", ""part-of"", ""Azure Data Lake Storage"", ""Stores JSON data files""],
    [""Forms Processing Logic App"", ""called-from"", ""Azure Data Lake Storage (JSON Data Container)"", ""Receives processed response data from this storage""],
    [""Forms Processing Logic App"", ""contains"", ""Azure Cosmos DB"", ""Sends processed data to Azure Cosmos DB for saving""],
    [""Azure Cosmos DB"", ""part-of"", ""Forms Processing Logic App"", ""Stores data in a database and collections as instructed by logic app""],
    [""Power BI"", ""called-from"", ""Azure Cosmos DB"", ""Obtains data from Azure Cosmos DB for insights and dashboards""]
  ]
}
```",12.569584150012815
79,mistral-nemo,../IMAGES NEW/Azure/13 Azure Secure Research.txt,"
    Data owners upload datasets into a public blob storage account. The data is encrypted by using Microsoft-managed keys.

    Azure Data Factory uses a trigger that starts copying of the uploaded dataset to a specific location (import path) on another storage account with security controls. The storage account can only be reached through a private endpoint. Also, it's accessed by a service principal with limited permissions. Data Factory deletes the original copy making the dataset immutable.

    Researchers access the secure environment through a streaming application using Azure Virtual Desktop as a privileged jump box.

    The dataset in the secure storage account is presented to the data science VMs provisioned in a secure network environment for research work. Much of the data preparation is done on those VMs.

    The secure environment has Azure Machine Learning compute that can access the dataset through a private endpoint for users for Azure Machine Learning capabilities, such as to train, deploy, automate, and manage machine learning models. At this point, models are created that meet regulatory guidelines. All model data is de-identified by removing personal information.

    Models or de-identified data is saved to a separate location on the secure storage (export path). When new data is added to the export path, a logic app is triggered. In this architecture, the logic app is outside the secure environment because no data is sent to the logic app. Its only function is to send notification and start the manual approval process.

    The app starts an approval process requesting a review of data that is queued to be exported. The manual reviewers ensure that sensitive data isn't exported. After the review process, the data is either approved or denied.

    Note

    If an approval step is not required on exfiltration, the logic app step could be omitted.

    If the de-identified data is approved, it's sent to the Data Factory instance.

    Data Factory moves the data to the public storage account in a separate container to allow external researchers to have access to their exported data and models. Alternately, you can provision another storage account in a lower security environment.

","{""entities"": [[""datasets"", ""component"", ""Data owners upload datasets into a public blob storage account""], [""public blob storage account"", ""system"", ""Data owners upload datasets into a public blob storage account""], [""Azure Data Factory"", ""system"", ""Azure Data Factory uses a trigger that starts copying of the uploaded dataset to a specific location""], [""storage account"", ""system"", ""Azure Data Factory uses a trigger that starts copying of the uploaded dataset to a specific location (import path) on another storage account with security controls""], [""copied dataset"", ""system"", ""Azure Data Factory uses a trigger that starts copying of the uploaded dataset to a specific location (import path) on another storage account with security controls""], [""private endpoint"", ""component"", ""The storage account can only be reached through a private endpoint.""], [""service principal"", ""component"", ""Also, it's accessed by a service principal with limited permissions.""], [""streaming application"", ""component"", ""access the secure environment through a streaming application""], [""Azure Virtual Desktop"", ""component"", ""Azure Virtual Desktop as a privileged jump box""], [""data science VMs"", ""component"", ""data science VMs provisioned in a secure network environment""], [""Azure Machine Learning compute"", ""component"", ""The secure environment has Azure Machine Learning compute that can access the dataset""], [""secure network environment"", ""system"", ""data science VMs provisioned in a secure network environment""], [""machine learning models"", ""component"", ""At this point, models are created that meet regulatory guidelines""], [""de-identified data"", ""component"", ""Models or de-identified data is saved to a separate location on the secure storage (export path)""], [""logic app"", ""component"", ""When new data is added to the export path, a logic app is triggered""], [""separate container"", ""component"", ""Data Factory moves the data to the public storage account in a separate container""], [""moved data"", ""component"", ""Data Factory moves the data to the public storage account in a separate container""], [""Data owners"", ""person"", ""Data owners upload datasets into a public blob storage account""], [""Researchers"", ""person"", ""Researchers access the secure environment through a streaming application using Azure Virtual Desktop as a privileged jump box""], [""manual reviewers"", ""person"", ""The manual reviewers ensure that sensitive data isn't exported.""], [""Users"", ""person"", ""The secure environment has Azure Machine Learning compute that can access the dataset""]], ""relationships"": [[""datasets"", ""part-of"", ""public blob storage account"", ""Data owners upload datasets into a public blob storage account""], [""Data owners"", ""calls"", ""datasets"", ""Data owners upload datasets into a public blob storage account""], [""Azure Data Factory"", ""calls"", ""datasets"", ""Azure Data Factory uses a trigger that starts copying of the uploaded dataset""], [""storage account"", ""contains"", ""copied dataset"", ""opying of the uploaded dataset to a specific location (import path) on another storage account with security controls""], [""Azure Data Factory"", ""calls"", ""copied dataset"", ""Azure Data Factory uses a trigger that starts copying of the uploaded dataset to a specific location""], [""private endpoint"", ""calls"", ""storage account"", ""The storage account can only be reached through a private endpoint""], [""storage account"", ""is-called-from"", ""service principal"", ""Also, it's accessed by a service principal with limited permissions""], [""Researchers"", ""calls"", ""Azure Virtual Desktop"", "" Researchers access the secure environment through a streaming application""], [""Azure Virtual Desktop"", ""calls"", ""streaming application"", ""through a streaming application using Azure Virtual Desktop""], [""streaming application"", ""calls"", ""storage account"", ""Researchers access the secure environment through a streaming application using Azure Virtual Desktop as a privileged jump box""], [""data science VMs"", ""part-of"", ""secure network environment"", ""The dataset in the secure storage account is presented to the data science VMs""], [""data science VMs"", ""calls"", ""copied dataset"", "" The dataset in the secure storage account is presented to the data science VMs""], [""secure network environment"", ""contains"", ""Azure Machine Learning compute"", ""The secure environment has Azure Machine Learning compute that can access the dataset""], [""Azure Machine Learning compute"", ""calls"", ""Azure Machine Learning compute"", ""The secure environment has Azure Machine Learning compute that can access the dataset""], [""machine learning models"", ""part-of"", ""storage account"", ""Models or de-identified data is saved to a separate location on the secure storage (export path)""], [""machine learning models"", ""calls"", ""logic app"", ""When new data is added to the export path, a logic app is triggered""], [""logic app"", ""calls"", ""manual reviewers"", ""The app starts an approval process requesting a review of data that is queued to be exported.""], [""public blob storage account"", ""contains"", ""separate container"", ""Data Factory moves the data to the public storage account in a separate container""], [""Azure Data Factory"", ""calls"", ""de-identified data"", ""Data Factory moves the data to the public storage account in a separate container to allow external researchers to have access to their exported data and models""], [""separate container"", ""contains"", ""moved data"", ""Data Factory moves the data to the public storage account in a separate container""], [""Azure Data Factory"", ""calls"", ""moved data"", ""Data Factory moves the data to the public storage account in a separate container to allow external researchers to have access to their exported data and models""], [""Users"", ""calls"", ""Azure Machine Learning compute"", ""The secure environment has Azure Machine Learning compute that can access the dataset""]]}","{
  ""entities"": [
    [""Azure Blob Storage Account"", ""system"", ""Public storage for uploading datasets""],
    [""Microsoft-Managed Keys"", ""component"", ""Used for encrypting uploaded datasets""],
    [""Azure Data Factory"", ""system"", ""Responsible for copying and moving datasets""],
    [""Import Path"", ""component"", ""Specific location in the secure storage account""],
    [""Private Endpoint"", ""component"", ""Enables secure access to the secure storage account""],
    [""Service Principal"", ""person"", ""Has limited permissions to access the secure storage account""],
    [""Azure Virtual Desktop"", ""system"", ""Provides privileged jump box for researchers""],
    [""Data Science VMs"", ""system"", ""Provisioned in a secure network environment for research work""],
    [""Azure Machine Learning Compute"", ""system"", ""Accesses dataset through private endpoint for machine learning capabilities""],
    [""Logic App"", ""component"", ""Triggers manual approval process upon new data detection""],
    [""Manual Reviewers"", ""person"", ""Ensure that sensitive data isn't exported""]
  ],
  ""relationships"": [
    [""Azure Blob Storage Account"", ""contains"", ""Microsoft-Managed Keys""],
    [""Azure Data Factory"", ""calls"", ""Azure Blob Storage Account""],
    [""Secure Storage Account"", ""part-of"", ""Azure Data Factory""],
    [""Private Endpoint"", ""part-of"", ""Secure Storage Account""],
    [""Service Principal"", ""called-from"", ""Azure Data Factory""],
    [""Azure Virtual Desktop"", ""contains"", ""Researchers""],
    [""Data Science VMs"", ""part-of"", ""Azure Machine Learning Compute""],
    [""Logic App"", ""calls"", ""Manual Reviewers""],
    [""Approved Data/ Models"", ""called-from"", ""Logic App""],
    [""Approved Data/ Models"", ""calls"", ""Azure Data Factory""]
  ]
}","{
  ""entities"": [
    [""Azure Blob Storage Account"", ""system"", ""Public storage for uploading datasets""],
    [""Microsoft-Managed Keys"", ""component"", ""Used for encrypting uploaded datasets""],
    [""Azure Data Factory"", ""system"", ""Responsible for copying and moving datasets""],
    [""Import Path"", ""component"", ""Specific location in the secure storage account""],
    [""Private Endpoint"", ""component"", ""Enables secure access to the secure storage account""],
    [""Service Principal"", ""person"", ""Has limited permissions to access the secure storage account""],
    [""Azure Virtual Desktop"", ""system"", ""Provides privileged jump box for researchers""],
    [""Data Science VMs"", ""system"", ""Provisioned in a secure network environment for research work""],
    [""Azure Machine Learning Compute"", ""system"", ""Accesses dataset through private endpoint for machine learning capabilities""],
    [""Logic App"", ""component"", ""Triggers manual approval process upon new data detection""],
    [""Manual Reviewers"", ""person"", ""Ensure that sensitive data isn't exported""]
  ],
  ""relationships"": [
    [""Azure Blob Storage Account"", ""contains"", ""Microsoft-Managed Keys""],
    [""Azure Data Factory"", ""calls"", ""Azure Blob Storage Account""],
    [""Secure Storage Account"", ""part-of"", ""Azure Data Factory""],
    [""Private Endpoint"", ""part-of"", ""Secure Storage Account""],
    [""Service Principal"", ""called-from"", ""Azure Data Factory""],
    [""Azure Virtual Desktop"", ""contains"", ""Researchers""],
    [""Data Science VMs"", ""part-of"", ""Azure Machine Learning Compute""],
    [""Logic App"", ""calls"", ""Manual Reviewers""],
    [""Approved Data/ Models"", ""called-from"", ""Logic App""],
    [""Approved Data/ Models"", ""calls"", ""Azure Data Factory""]
  ]
}",6.657072361005703
80,mistral-nemo,../IMAGES NEW/Azure/10 Azure LoB original.txt,"
The data flows through the solution as follows:

    Supplier data stored in CDS is moved to SQL via Data Factory.
    Purchase order (PO) data stored in ERP system is sent to Azure SQL database.
    Azure Functions uses API to surface PO data monthly and creates a task for users to review.
    Power Apps retrieves data from Azure SQL Database through API.
    User reviews and updates POs in Power Apps and sends this data to suppliers through CSV export.
    Power BI reports trends in supplier status.

","{""entities"": [[""Supplier data"", ""component"", ""Supplier data stored in CDS""], [""CDS"", ""system"", "" Supplier data stored in CDS""], [""Azure SQL database"", ""system"", ""moved to SQL via Data Factory""], [""Data Factory"", ""system"", ""moved to SQL via Data Factory""], [""Purchase order (PO)"", ""system"", ""moved to SQL via Data Factory""], [""ERP system"", ""system"", ""Purchase order (PO) data stored in ERP system""], [""Azure Functions"", ""system"", ""uses API to surface PO data monthly and creates a task for users to review""], [""Power Apps"", ""system"", ""retrieves data from Azure SQL Database through API""], [""CSV export"", ""system"", ""ends this data to suppliers through CSV export""], [""User"", ""person"", "" reviews and updates POs in Power Apps""], [""suppliers"", ""person"", "" reviews and updates POs in Power Apps""]], ""relationships"": [[""Supplier data"", ""part-of"", ""CDS"", ""Supplier data stored in CDS""], [""Supplier data"", ""is-called-from"", ""Data Factory"", ""moved to SQL via Data Factory""], [""Data Factory"", ""calls"", ""Azure SQL database"", ""moved to SQL via Data Factory""], [""Purchase order (PO)"", ""part-of"", ""ERP system"", ""Purchase order (PO) data stored in ERP system""], [""Purchase order (PO)"", ""calls"", ""Azure SQL database"", ""Purchase order (PO) data stored in ERP system is sent to Azure SQL database""], [""Azure Functions"", ""calls"", ""Purchase order (PO)"", ""uses API to surface PO data monthly""], [""Azure Functions"", ""calls"", ""User"", ""creates a task for users to review""], [""Power Apps"", ""calls"", ""Azure SQL database"", ""retrieves data from Azure SQL Database through API""], [""User"", ""calls"", ""Power Apps"", ""Reviews and updates POs in Power Apps""], [""User"", ""calls"", ""CSV export"", ""sends this data to suppliers through CSV export""], [""CSV export"", ""calls"", ""suppliers"", ""sends this data to suppliers through CSV export""]]}","{
""entities"": [
  [""Supplier data"", ""system""],
  [""CDS"", ""component""],
  [""SQL"", ""component""],
  [""Data Factory"", ""component""],
  [""Purchase order data"", ""system""],
  [""ERP system"", ""component""],
  [""Azure SQL database"", ""system""],
  [""Azure Functions"", ""component""],
  [""API"", ""component""],
  [""PO data"", ""system""],
  [""Task"", ""system""],
  [""User"", ""person""],
  [""Power Apps"", ""component""],
  [""Azure SQL Database"", ""system""],
  [""CSV export"", ""component""],
  [""Supplier status trends"", ""system""],
  [""Power BI"", ""component""]
],
""relationships"": [
  [""Supplier data"", ""contains"", ""CDS""],
  [""Supplier data"", ""part-of"", ""SQL""],
  [""Purchase order data"", ""sent-to"", ""Azure SQL database""],
  [""PO data"", ""sent-from"", ""ERP system""],
  [""Azure Functions"", ""uses"", ""API""],
  [""Azure Functions"", ""creates"", ""Task""],
  [""User"", ""reviews-updates"", ""Power Apps""],
  [""User"", ""sends-data-to"", ""Supplier""],
  [""Power BI"", ""reports-on"", ""Supplier status trends""]
]
}","{
""entities"": [
  [""Supplier data"", ""system""],
  [""CDS"", ""component""],
  [""SQL"", ""component""],
  [""Data Factory"", ""component""],
  [""Purchase order data"", ""system""],
  [""ERP system"", ""component""],
  [""Azure SQL database"", ""system""],
  [""Azure Functions"", ""component""],
  [""API"", ""component""],
  [""PO data"", ""system""],
  [""Task"", ""system""],
  [""User"", ""person""],
  [""Power Apps"", ""component""],
  [""Azure SQL Database"", ""system""],
  [""CSV export"", ""component""],
  [""Supplier status trends"", ""system""],
  [""Power BI"", ""component""]
],
""relationships"": [
  [""Supplier data"", ""contains"", ""CDS""],
  [""Supplier data"", ""part-of"", ""SQL""],
  [""Purchase order data"", ""sent-to"", ""Azure SQL database""],
  [""PO data"", ""sent-from"", ""ERP system""],
  [""Azure Functions"", ""uses"", ""API""],
  [""Azure Functions"", ""creates"", ""Task""],
  [""User"", ""reviews-updates"", ""Power Apps""],
  [""User"", ""sends-data-to"", ""Supplier""],
  [""Power BI"", ""reports-on"", ""Supplier status trends""]
]
}",4.685288130014669
81,mistral-nemo,../IMAGES NEW/Azure/14 Azure Call Center Analytics.txt,"
    A phone call between an agent and a customer is recorded and stored in Azure Blob Storage. Audio files are uploaded to an Azure Storage account via a supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API.

    Azure AI Speech is used to transcribe audio files in Batch mode asynchronously with speaker diarization enabled. The transcription results are persisted in Blob Storage.

    Azure AI Language is used to detect and redact personal data in the transcript.

    For batch mode transcription and personal data detection and redaction, use the AI services Ingestion Client tool. The Ingestion Client tool uses a no-code approach for call center transcription.

    Azure OpenAI is used to process the transcript and extract entities, summarize the conversation, and analyze sentiments. The processed output is stored in Blob Storage and then analyzed and visualized by using other services. You can also store the output in a datastore for keeping track of metadata and for reporting. Use Azure OpenAI to process the stored transcription information.

    Power BI or a custom web application that's hosted by App Service is used to visualize the output. Both options provide near real-time insights. You can store this output in a customer relationship management (CRM), so agents have contextual information about why the customer called and can quickly solve potential problems. This process is fully automated, which saves the agents time and effort.

","{""entities"": [[""phone call"", ""component"", ""A phone call between an agent and a customer is recorded""], [""agent"", ""person"", ""A phone call between an agent and a customer is recorded""], [""customer"", ""person"", ""A phone call between an agent and a customer is recorded""], [""Azure Blob Storage"", ""system"", ""is recorded and stored in Azure Blob Storage""], [""Audio files"", ""system"", ""Audio files are uploaded to an Azure Storage account via a supported method""], [""supported method"", ""component"", ""Audio files are uploaded to an Azure Storage account via a supported method""], [""UI-based tool"", ""component"", ""supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""Azure Storage Explorer"", ""component"", ""supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""Storage SDK"", ""component"", ""supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""API"", ""component"", ""supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""Azure AI Speech"", ""component"", ""transcribe audio files in Batch mode asynchronously""], [""transcription results"", ""component"", ""The transcription results are persisted in Blob Storage.""], [""Azure AI Language"", ""component"", ""Azure AI Language is used to detect and redact personal data in the transcript.""], [""AI services Ingestion Client tool"", ""component"", ""For batch mode transcription and personal data detection and redaction, use the AI services Ingestion Client tool""], [""Azure OpenAI"", ""component"", ""Azure OpenAI is used to process the transcript and extract entities, summarize the conversation, and analyze sentiments.""], [""Azure OpenAI output"", ""component"", ""The processed output is stored in Blob Storage and then analyzed and visualized by using other services.""], [""other services"", ""component"", ""The processed output is stored in Blob Storage and then analyzed and visualized by using other services.""], [""App Service"", ""system"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""Power BI"", ""system"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""custom web application"", ""system"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""Azure OpenAI output 2"", ""component"", ""You can also store the output in a datastore for keeping track of metadata and for reporting""], [""datastore"", ""component"", ""You can also store the output in a datastore for keeping track of metadata and for reporting""], [""customer relationship management (CRM)"", ""system"", ""You can store this output in a customer relationship management (CRM)""], [""Azure OpenAI output 3"", ""component"", ""You can store this output in a customer relationship management (CRM)""]], ""relationships"": [[""agent"", ""calls"", ""phone call"", ""A phone call between an agent and a customer is recorded""], [""customer"", ""calls"", ""phone call"", ""A phone call between an agent and a customer is recorded""], [""phone call"", ""part-of"", ""Azure Blob Storage"", ""is recorded and stored in Azure Blob Storage""], [""Audio files"", ""part-of"", ""Azure Blob Storage"", ""Audio files are uploaded to an Azure Storage account via a supported method""], [""supported method"", ""calls"", ""Audio files"", ""Audio files are uploaded to an Azure Storage account via a supported method""], [""supported method"", ""contains"", ""UI-based tool"", ""upported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""supported method"", ""contains"", ""Azure Storage Explorer"", ""upported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""supported method"", ""contains"", ""Storage SDK"", ""upported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""supported method"", ""contains"", ""API"", ""supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""Azure AI Speech"", ""calls"", ""Audio files"", ""transcribe audio files in Batch mode asynchronously""], [""Azure Blob Storage"", ""contains"", ""transcription results"", ""The transcription results are persisted in Blob Storage.""], [""Azure AI Speech"", ""calls"", ""transcription results"", ""The transcription results are persisted in Blob Storage.""], [""Azure AI Language"", ""calls"", ""transcription results"", ""Azure AI Language is used to detect and redact personal data in the transcript.""], [""AI services Ingestion Client tool"", ""calls"", ""transcription results"", ""For batch mode transcription and personal data detection and redaction, use the AI services Ingestion Client tool""], [""Azure OpenAI"", ""calls"", ""transcription results"", ""Azure OpenAI is used to process the transcript and extract entities, summarize the conversation, and analyze sentiments.""], [""Azure OpenAI"", ""calls"", ""Azure OpenAI output"", ""The processed output is stored in Blob Storage and then analyzed and visualized by using other services.""], [""Azure Blob Storage"", ""contains"", ""Azure OpenAI output"", ""The processed output is stored in Blob Storage and then analyzed and visualized by using other services.""], [""other services"", ""calls"", ""Azure OpenAI output"", ""The processed output is stored in Blob Storage and then analyzed and visualized by using other services.""], [""Power BI"", ""part-of"", ""App Service"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""custom web application"", ""part-of"", ""App Service"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""custom web application"", ""calls"", ""Azure OpenAI output"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""Power BI"", ""calls"", ""Azure OpenAI output"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""agent"", ""calls"", ""customer relationship management (CRM)"", ""You can store this output in a customer relationship management (CRM), so agents have contextual information about why the customer called and can quickly solve potential problems""], [""Azure OpenAI output 2"", ""part-of"", ""datastore"", ""You can also store the output in a datastore for keeping track of metadata and for reporting""], [""Azure OpenAI output 3"", ""part-of"", ""customer relationship management (CRM)"", ""You can also store the output in a datastore for keeping track of metadata and for reporting""], [""Azure OpenAI output"", ""calls"", ""Azure OpenAI output 2"", ""You can also store the output in a datastore for keeping track of metadata and for reporting""], [""Azure OpenAI output"", ""calls"", ""Azure OpenAI output 3"", ""You can store this output in a customer relationship management (CRM), so agents have contextual information about why the customer called and can quickly solve potential problems""]]}","```json
{
  ""entities"": [
    [""Azure Blob Storage"", ""system""],
    [""Audio Files"", ""component""],
    [""Azure Storage Account"", ""component""],
    [""Azure AI Speech"", ""system""],
    [""AI Services Ingestion Client tool"", ""component""],
    [""Azure AI Language"", ""system""],
    [""Azure OpenAI"", ""system""],
    [""Power BI"", ""component""],
    [""App Service"", ""system""],
    [""CRM"", ""system""]
  ],
  ""relationships"": [
    [""Audio Files"", ""stored-in"", ""Azure Blob Storage""],
    [""Audio Files"", ""uploaded-to"", ""Azure Storage Account""],
    [""Azure AI Speech"", ""transcribes"", ""Audio Files""],
    [""AI Services Ingestion Client tool"", ""uses"", ""Azure AI Speech""],
    [""AI Services Ingestion Client tool"", ""uses"", ""Azure AI Language""],
    [""Azure OpenAI"", ""processes"", ""Transcription Results""],
    [""Power BI"", ""visualizes"", ""Processed Output""],
    [""App Service"", ""hosts"", ""Custom Web Application""],
    [""CRM"", ""stores"", ""Output""]
  ]
}
```","```json
{
  ""entities"": [
    [""Azure Blob Storage"", ""system""],
    [""Audio Files"", ""component""],
    [""Azure Storage Account"", ""component""],
    [""Azure AI Speech"", ""system""],
    [""AI Services Ingestion Client tool"", ""component""],
    [""Azure AI Language"", ""system""],
    [""Azure OpenAI"", ""system""],
    [""Power BI"", ""component""],
    [""App Service"", ""system""],
    [""CRM"", ""system""]
  ],
  ""relationships"": [
    [""Audio Files"", ""stored-in"", ""Azure Blob Storage""],
    [""Audio Files"", ""uploaded-to"", ""Azure Storage Account""],
    [""Azure AI Speech"", ""transcribes"", ""Audio Files""],
    [""AI Services Ingestion Client tool"", ""uses"", ""Azure AI Speech""],
    [""AI Services Ingestion Client tool"", ""uses"", ""Azure AI Language""],
    [""Azure OpenAI"", ""processes"", ""Transcription Results""],
    [""Power BI"", ""visualizes"", ""Processed Output""],
    [""App Service"", ""hosts"", ""Custom Web Application""],
    [""CRM"", ""stores"", ""Output""]
  ]
}
```",4.524188187002437
82,mistral-nemo,../IMAGES NEW/Azure/06 Azure logic-apps-data-integration.txt,"
    API Management accepts API calls in the form of HTTP requests.

    API Management securely routes the HTTP requests to Logic Apps.

    Each HTTP request triggers a run in Logic Apps:
        Logic Apps uses secured template parameters to retrieve database credentials from Azure Key Vault.
        Logic Apps uses Transport Layer Security (TLS) to send the database credentials and a database statement to the on-premises data gateway.

    The on-premises data gateway connects to a SQL Server database to run the statement.

    SQL Server stores the data and makes it available to apps that users access.

    Azure Monitor collects information on Logic Apps events and performance.

","{""entities"": [[""API Management"", ""system"", ""accepts API calls in the form of HTTP requests""], [""Logic Apps"", ""system"", ""uses secured template parameters to retrieve database credentials from Azure Key Vault""], [""on-premises data gateway"", ""system"", """"], [""SQL Server"", ""system"", ""stores the data and makes it available to apps that users access""], [""Azure Monitor"", ""system"", ""collects information on Logic Apps events and performance""], [""Azure Key Vault"", ""system"", ""database credentials""]], ""relationships"": [[""API Management"", ""calls"", ""Logic Apps"", ""routes the HTTP requests to Logic Apps""], [""Logic Apps"", ""calls"", ""Azure Key Vault"", ""Logic Apps uses secured template parameters to retrieve database credentials from Azure Key Vault""], [""Logic Apps"", ""calls"", ""on-premises data gateway"", ""send the database credentials and a database statement to the on-premises data gateway""], [""on-premises data gateway"", ""calls"", ""SQL Server"", ""connects to a SQL Server database""], [""Azure Monitor"", ""calls"", ""Logic Apps"", ""collects information on Logic Apps events and performance""]]}","{
  ""entities"": [
    [""API Management"", ""system""],
    [""Logic Apps"", ""component""],
    [""Azure Key Vault"", ""system""],
    [""on-premises data gateway"", ""component""],
    [""SQL Server database"", ""system""]
  ],
  ""relationships"": [
    [""API Management"", ""calls"", ""Logic Apps""],
    [""Logic Apps"", ""contains"", ""Azure Key Vault""],
    [""Logic Apps"", ""calls"", ""on-premises data gateway""],
    [""on-premises data gateway"", ""part-of"", ""SQL Server database""],
    [""Azure Monitor"", ""collects_from"", ""Logic Apps""]
  ]
}","{
  ""entities"": [
    [""API Management"", ""system""],
    [""Logic Apps"", ""component""],
    [""Azure Key Vault"", ""system""],
    [""on-premises data gateway"", ""component""],
    [""SQL Server database"", ""system""]
  ],
  ""relationships"": [
    [""API Management"", ""calls"", ""Logic Apps""],
    [""Logic Apps"", ""contains"", ""Azure Key Vault""],
    [""Logic Apps"", ""calls"", ""on-premises data gateway""],
    [""on-premises data gateway"", ""part-of"", ""SQL Server database""],
    [""Azure Monitor"", ""collects_from"", ""Logic Apps""]
  ]
}",2.6251307700003963
83,mistral-nemo,../IMAGES NEW/Azure/12 Azure Network Microservices original.txt,"
    Outside services and clients make a POST request to APIM, with a data body that includes patient information.
    APIM calls the CreatePatient function in the Patient API with the given patient information.
    The CreatePatient function in Patient API calls the CreateAuditRecord function in the Audit API function app to create an audit record.
    The Audit API CreateAuditRecord function creates the audit record in Azure Cosmos DB, and returns a success response to the Patient API CreatePatient function.
    The CreatePatient function creates the patient document in Azure Cosmos DB, and returns a success response to APIM.
    The outside services and clients receive the success response from APIM.

","{""entities"": [[""Outside services"", ""system"", ""Outside services and clients make a POST request to APIM""], [""clients"", ""system"", ""Outside services and clients make a POST request to APIM""], [""APIM"", ""system"", ""Outside services and clients make a POST request to APIM""], [""Patient API"", ""system"", "" The CreatePatient function in Patient API calls the CreateAuditRecord function in the Audit API function app""], [""CreatePatient function"", ""component"", "" The CreatePatient function in Patient API calls the CreateAuditRecord function in the Audit API function app""], [""Audit API function app"", ""system"", ""The CreatePatient function in Patient API calls the CreateAuditRecord function in the Audit API function app""], [""CreateAuditRecord function"", ""component"", ""CreatePatient function in Patient API calls the CreateAuditRecord function""], [""Azure Cosmos DB"", ""system"", ""The Audit API CreateAuditRecord function creates the audit record in Azure Cosmos DB, and returns a success response to the Patient API CreatePatient function""]], ""relationships"": [[""CreatePatient function"", ""part-of"", ""Patient API"", ""Reason""], [""Outside services"", ""calls"", ""APIM"", ""utside services and clients make a POST request to APIM""], [""clients"", ""calls"", ""APIM"", ""outside services and clients make a POST request to APIM""], [""APIM"", ""calls"", ""CreatePatient function"", ""APIM calls the CreatePatient function in the Patient API""], [""CreateAuditRecord function"", ""part-of"", ""Audit API function app"", ""Reason""], [""CreatePatient function"", ""calls"", ""CreateAuditRecord function"", ""CreatePatient function in Patient API calls the CreateAuditRecord function in the Audit API function app""], [""CreateAuditRecord function"", ""calls"", ""Azure Cosmos DB"", ""Audit API CreateAuditRecord function creates the audit record in Azure Cosmos DB""], [""CreateAuditRecord function"", ""calls"", ""CreatePatient function"", ""returns a success response to the Patient API CreatePatient function.""], [""CreatePatient function"", ""calls"", ""Azure Cosmos DB"", ""The CreatePatient function creates the patient document in Azure Cosmos DB""], [""CreatePatient function"", ""is-called-from"", ""APIM"", ""The CreatePatient function returns a success response to APIM""]]}","Based on the provided context, here's the extracted entities and relationships in JSON format:

```json
{
  ""entities"": [
    [""APIM"", ""system"", ""API Management""],
    [""Patient API"", ""system"", ""Handles patient-related operations""],
    [""Audit API"", ""system"", ""Handles audit record creation""],
    [""CreatePatient"", ""function"", ""Creates a new patient document""],
    [""CreateAuditRecord"", ""function"", ""Creates an audit record""],
    [""Azure Cosmos DB"", ""system"", ""NoSQL database service""]
  ],
  ""relationships"": [
    [""APIM"", ""calls"", ""CreatePatient"", ""Makes a request to create a patient""],
    [""CreatePatient"", ""called-from"", ""APIM"", ""Invoked by APIM to create a patient""],
    [""CreatePatient"", ""calls"", ""CreateAuditRecord"", ""Calls Audit API function""],
    [""CreateAuditRecord"", ""called-from"", ""CreatePatient"", ""Invoked by Patient API function""],
    [""CreateAuditRecord"", ""contains"", ""Azure Cosmos DB"", ""Creates audit record in Cosmos DB""],
    [""CreatePatient"", ""contains"", ""Azure Cosmos DB"", ""Creates patient document in Cosmos DB""]
  ]
}
```","Based on the provided context, here's the extracted entities and relationships in JSON format:

```json
{
  ""entities"": [
    [""APIM"", ""system"", ""API Management""],
    [""Patient API"", ""system"", ""Handles patient-related operations""],
    [""Audit API"", ""system"", ""Handles audit record creation""],
    [""CreatePatient"", ""function"", ""Creates a new patient document""],
    [""CreateAuditRecord"", ""function"", ""Creates an audit record""],
    [""Azure Cosmos DB"", ""system"", ""NoSQL database service""]
  ],
  ""relationships"": [
    [""APIM"", ""calls"", ""CreatePatient"", ""Makes a request to create a patient""],
    [""CreatePatient"", ""called-from"", ""APIM"", ""Invoked by APIM to create a patient""],
    [""CreatePatient"", ""calls"", ""CreateAuditRecord"", ""Calls Audit API function""],
    [""CreateAuditRecord"", ""called-from"", ""CreatePatient"", ""Invoked by Patient API function""],
    [""CreateAuditRecord"", ""contains"", ""Azure Cosmos DB"", ""Creates audit record in Cosmos DB""],
    [""CreatePatient"", ""contains"", ""Azure Cosmos DB"", ""Creates patient document in Cosmos DB""]
  ]
}
```",4.654031630983809
84,mistral-nemo,../IMAGES NEW/Azure/09 Azure protect APIs original.txt,"
    To gain access to an application, an API client authenticates by providing credentials such as username and password. The IdP is Azure AD B2C in this solution, but you can use a different one.

    The authentication request goes via Azure Front Door to Azure AD B2C, which is configured with a custom domain for sign-in. Azure AD B2C authenticates the user and returns a JSON Web Token (JWT) bearer token back to the user.

    The client triggers an event that accesses a backend API. This event could be a click of a button on a web application or on a mobile device, or a direct call to the endpoint of the backend API.

    The request goes through Azure Front Door, whose back end is mapped to the public endpoint of API Management. API Management intercepts the request and validates the bearer token against Azure AD B2C by using its validate-jwt policy. If the token isn't valid, API Management rejects the request by responding with a 401 code.

    If the token is valid, API Management forwards the request to the appropriate backend API.

    The diagram shows backend APIs running in three environments:
        App Service Environment
        Function Apps
        Azure Kubernetes Services (AKS)

    APIs running in on-premises and hybrid cloud environments can also be integrated with API Management if network connectivity is established between the APIs and API Management.

","{""entities"": [[""API client"", ""system"", ""wants to gain access to an application""], [""application"", ""system"", ""API client wants to gain access to an application""], [""Azure AD B2C"", ""system"", ""The IdP is Azure AD B2C""], [""Azure Front Door"", ""system"", ""authentication request goes via Azure Front Door to Azure AD B2C""], [""backend API"", ""system"", ""The client triggers an event that accesses a backend API""], [""Azure Front Door"", ""system"", ""The request goes through Azure Front Door, whose back end is mapped to the public endpoint of API Management.""], [""backend"", ""component"", ""Azure Front Door, whose back end""], [""API Management"", ""system"", ""API Management intercepts the request and validates the bearer token against Azure AD B2C ""], [""public endpoint"", ""system"", ""whose back end is mapped to the public endpoint of API Management""], [""User"", ""person"", ""Azure AD B2C authenticates the user and returns a JSON Web Token (JWT) bearer token back to the user""]], ""relationships"": [[""API client"", ""calls"", ""application"", """"], [""Azure Front Door"", ""calls"", ""Azure AD B2C"", ""authentication request goes via Azure Front Door to Azure AD B2C""], [""Azure AD B2C"", ""is-called-from"", ""User"", ""Azure AD B2C authenticates the user and returns a JSON Web Token (JWT) bearer token back to the user""], [""API client"", ""calls"", ""backend API"", ""The client triggers an event that accesses a backend API""], [""Azure Front Door"", ""contains"", ""backend"", ""Azure Front Door, whose back end""], [""public endpoint"", ""part-of"", ""API Management"", ""Azure Front Door, whose back end""], [""backend"", ""calls"", ""public endpoint"", ""whose back end is mapped to the public endpoint of API Management""], [""API Management"", ""calls"", ""Azure AD B2C"", ""API Management intercepts the request and validates the bearer token against Azure AD B2C""]]}","```json
{
  ""entities"": [
    [""API Client"", ""person""],
    [""Azure AD B2C"", ""system""],
    [""Azure Front Door"", ""system""],
    [""API Management"", ""system""],
    [""App Service Environment"", ""system""],
    [""Function Apps"", ""system""],
    [""Azure Kubernetes Services (AKS)"", ""system""],
    [""Backend API"", ""component""]
  ],
  ""relationships"": [
    [""API Client"", ""calls"", ""Azure Front Door""],
    [""Azure Front Door"", ""contains"", ""Azure AD B2C""],
    [""Azure AD B2C"", ""returns"", ""JWT""],
    [""API Management"", ""intercepts"", ""request""],
    [""API Management"", ""validates"", ""bearer token""],
    [""API Management"", ""rejects"", ""request""],
    [""API Management"", ""forwards"", ""Backend API""],
    [""App Service Environment"", ""runs"", ""Backend API""],
    [""Function Apps"", ""runs"", ""Backend API""],
    [""Azure Kubernetes Services (AKS)"", ""runs"", ""Backend API""]
  ]
}
```","```json
{
  ""entities"": [
    [""API Client"", ""person""],
    [""Azure AD B2C"", ""system""],
    [""Azure Front Door"", ""system""],
    [""API Management"", ""system""],
    [""App Service Environment"", ""system""],
    [""Function Apps"", ""system""],
    [""Azure Kubernetes Services (AKS)"", ""system""],
    [""Backend API"", ""component""]
  ],
  ""relationships"": [
    [""API Client"", ""calls"", ""Azure Front Door""],
    [""Azure Front Door"", ""contains"", ""Azure AD B2C""],
    [""Azure AD B2C"", ""returns"", ""JWT""],
    [""API Management"", ""intercepts"", ""request""],
    [""API Management"", ""validates"", ""bearer token""],
    [""API Management"", ""rejects"", ""request""],
    [""API Management"", ""forwards"", ""Backend API""],
    [""App Service Environment"", ""runs"", ""Backend API""],
    [""Function Apps"", ""runs"", ""Backend API""],
    [""Azure Kubernetes Services (AKS)"", ""runs"", ""Backend API""]
  ]
}
```",4.3297722509887535
85,mistral-nemo,../IMAGES NEW/TEST/08 Azure Business Processes.txt,"
The data flows through the solution as follows:

    The airline system communicates with a custom API hosted in Azure API Management.
    A custom API coordinator receives notifications and handles incoming messages from the airline system. It sends them to Power Apps, where flights are assigned to Microsoft Teams channels.
    When a user selects a flight to monitor, or when the system assigns the user to a flight, the system queues a Graph API call in an Azure Storage Account queue for further processing.
    Azure Functions runs the Graph API calls based on the incoming messages in the storage queue, sending notifications to Teams, and also streams all events to an Azure Event Hubs for further analytics.
    The airline's notification system is managed by a custom bot messaging service that employs Azure Bot Service.
    Custom bots send flight updates to users in Teams.
    An Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs, ultimately generating insightful reports with Power BI.

","{""entities"": [[""airline system"", ""system"", ""communicates with a custom API hosted in Azure API Management""], [""custom API"", ""component"", ""communicates with a custom API hosted in Azure API Management""], [""Azure API Management"", ""system"", ""communicates with a custom API hosted in Azure API Management""], [""custom API coordinator"", ""system"", ""receives notifications and handles incoming messages from the airline system""], [""Power Apps"", ""system"", ""where flights are assigned to Microsoft Teams channels""], [""Microsoft Teams channels"", ""system"", ""where flights are assigned to Microsoft Teams channels""], [""Storage Account queue"", ""system"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing.""], [""Graph API call"", ""system"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing.""], [""Azure Functions"", ""system"", ""runs the Graph API calls based on the incoming messages in the storage queue""], [""Azure Event Hubs"", ""system"", ""Azure Event Hubs for further analytics""], [""notification system"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""custom bot messaging service"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""Azure Bot Service"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""Users"", ""person"", ""selects a flight to monitor, or when the system assigns the user to a flight""], [""Azure Data Lake storage"", ""system"", ""offers long-term retention and micro-batch processing of events from Event Hubs""], [""Power BI"", ""system"", ""generating insightful reports""]], ""relationships"": [[""Azure API Management"", ""contains"", ""custom API"", ""custom API hosted in Azure API Management""], [""airline system"", ""calls"", ""custom API"", ""communicates with a custom API""], [""custom API coordinator"", ""is-called-from"", ""airline system"", ""receives notifications and handles incoming messages from the airline system""], [""Power Apps"", ""calls"", ""Microsoft Teams channels"", ""Power Apps, where flights are assigned to Microsoft Teams channels""], [""airline system"", ""calls"", ""Graph API call"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing""], [""Azure Functions"", ""calls"", ""Graph API call"", ""runs the Graph API calls based on the incoming messages in the storage queue""], [""Azure Functions"", ""calls"", ""Storage Account queue"", ""based on the incoming messages in the storage queue""], [""Azure Functions"", ""calls"", ""Microsoft Teams channels"", ""sending notifications to Teams""], [""Azure Functions"", ""calls"", ""Azure Event Hubs"", ""also streams all events to an Azure Event Hubs for further analytics""], [""notification system"", ""is-called-from"", ""custom bot messaging service"", ""managed by a custom bot messaging service""], [""custom bot messaging service"", ""calls"", ""Azure Bot Service"", ""custom bot messaging service that employs Azure Bot Service""], [""custom bot messaging service"", ""calls"", ""Microsoft Teams channels"", ""Custom bots send flight updates to users in Teams.""], [""Microsoft Teams channels"", ""calls"", ""Users"", ""Custom bots send flight updates to users in Teams.""], [""Azure Data Lake storage"", ""is-called-from"", ""Azure Event Hubs"", ""Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs""], [""Azure Data Lake storage"", ""calls"", ""Power BI"", ""Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs, ultimately generating insightful reports with Power BI""]]}","Here's the JSON response based on the provided text:

```json
{
  ""entities"": [
    [""Airline System"", ""system""],
    [""Custom API Coordinator"", ""component""],
    [""Power Apps"", ""system""],
    [""Microsoft Teams"", ""system""],
    [""Azure Storage Account Queue"", ""component""],
    [""Azure Functions"", ""component""],
    [""Azure Event Hubs"", ""system""],
    [""Azure Bot Service"", ""system""],
    [""Custom Bot Messaging Service"", ""component""],
    [""Azure Data Lake Storage"", ""system""],
    [""Power BI"", ""system""]
  ],
  ""relationships"": [
    [""Airline System"", ""calls"", ""Custom API Coordinator""],
    [""Custom API Coordinator"", ""contains"", ""Power Apps""],
    [""Power Apps"", ""part-of"", ""Microsoft Teams""],
    [""Custom API Coordinator"", ""calls"", ""Azure Storage Account Queue""],
    [""Azure Storage Account Queue"", ""called-from"", ""Custom API Coordinator""],
    [""Azure Functions"", ""calls"", ""Azure Storage Account Queue""],
    [""Azure Functions"", ""contains"", ""Azure Event Hubs""],
    [""Azure Bot Service"", ""contains"", ""Custom Bot Messaging Service""],
    [""Custom Bot Messaging Service"", ""calls"", ""Microsoft Teams""],
    [""Azure Event Hubs"", ""called-from"", ""Azure Functions""],
    [""Azure Data Lake Storage"", ""contains"", ""Azure Event Hubs""],
    [""Power BI"", ""part-of"", ""Azure Data Lake Storage""]
  ]
}
```","Here's the JSON response based on the provided text:

```json
{
  ""entities"": [
    [""Airline System"", ""system""],
    [""Custom API Coordinator"", ""component""],
    [""Power Apps"", ""system""],
    [""Microsoft Teams"", ""system""],
    [""Azure Storage Account Queue"", ""component""],
    [""Azure Functions"", ""component""],
    [""Azure Event Hubs"", ""system""],
    [""Azure Bot Service"", ""system""],
    [""Custom Bot Messaging Service"", ""component""],
    [""Azure Data Lake Storage"", ""system""],
    [""Power BI"", ""system""]
  ],
  ""relationships"": [
    [""Airline System"", ""calls"", ""Custom API Coordinator""],
    [""Custom API Coordinator"", ""contains"", ""Power Apps""],
    [""Power Apps"", ""part-of"", ""Microsoft Teams""],
    [""Custom API Coordinator"", ""calls"", ""Azure Storage Account Queue""],
    [""Azure Storage Account Queue"", ""called-from"", ""Custom API Coordinator""],
    [""Azure Functions"", ""calls"", ""Azure Storage Account Queue""],
    [""Azure Functions"", ""contains"", ""Azure Event Hubs""],
    [""Azure Bot Service"", ""contains"", ""Custom Bot Messaging Service""],
    [""Custom Bot Messaging Service"", ""calls"", ""Microsoft Teams""],
    [""Azure Event Hubs"", ""called-from"", ""Azure Functions""],
    [""Azure Data Lake Storage"", ""contains"", ""Azure Event Hubs""],
    [""Power BI"", ""part-of"", ""Azure Data Lake Storage""]
  ]
}
```",5.437048610998318
86,mistral-nemo,../IMAGES NEW/Azure/07 Azure internal APIs original.txt,"
The data flows as follows:

    Developers check in code to a GitHub repository that's connected to a CI/CD pipeline agent that's installed on an Azure VM.
    The agent pushes the build to the API application that's hosted on ILB ASE.
    Azure API Management consumes the preceding APIs via HOST headers that are specified in API Management policy.
    API Management uses the App Service Environment's DNS name for all the APIs.
    Application Gateway exposes API Management's developer and API portal.
    Azure Private DNS is used to route the traffic internally between ASE, API Management, and Application Gateway.
    External users utilize the exposed developer portal to consume the APIs via Application Gateway's public IP.

","{""entities"": [[""GitHub repository"", ""system"", """"], [""Developers"", ""person"", """"], [""External users"", ""person"", """"], [""CI/CD pipeline agent"", ""system"", """"], [""Azure VM"", ""system"", """"], [""ILB ASE"", ""system"", """"], [""API application"", ""component"", """"], [""Azure API Management"", ""system"", ""consumes the preceding APIs via HOST headers""], [""App Service Environment"", ""component"", """"], [""Application Gateway"", ""component"", ""exposes API Management's developer and API portal""], [""Developer portal"", ""component"", ""API Management's developer and API portal""], [""API portal"", ""component"", ""API Management's developer and API portal""], [""Application Gateway"", ""component"", ""exposes API Management's developer and API portal""], [""Azure Private DNS"", ""component"", ""used to route the traffic internally between ASE, API Management, and Application Gateway""]], ""relationships"": [[""Azure VM"", ""contains"", ""CI/CD pipeline agent"", ""installed on an Azure VM""], [""API application"", ""part-of"", ""ILB ASE"", ""API application that's hosted on ILB ASE""], [""GitHub repository"", ""calls"", ""CI/CD pipeline agent"", ""GitHub repository that's connected to a CI/CD pipeline agent""], [""CI/CD pipeline agent"", ""calls"", ""API application"", ""agent pushes the build to the API application""], [""Azure API Management"", ""calls"", ""App Service Environment"", ""uses the App Service Environment's DNS name for all the APIs""], [""External users"", ""calls"", ""Application Gateway"", """"], [""Application Gateway"", ""calls"", ""API application"", ""to consume the APIs via Application Gateway's public IP""], [""Azure API Management"", ""contains"", ""Developer portal"", ""API Management's developer and API portal""], [""Azure API Management"", ""contains"", ""API portal"", ""API Management's developer and API portal""], [""Application Gateway"", ""calls"", ""API portal"", ""exposes API Management's developer and API portal.""], [""Application Gateway"", ""calls"", ""Developer portal"", ""exposes API Management's developer and API portal.""], [""Azure Private DNS"", ""calls"", ""Azure API Management"", ""route the traffic internally between ASE, API Management, and Application Gateway""], [""Azure Private DNS"", ""calls"", ""Application Gateway"", ""route the traffic internally between ASE, API Management, and Application Gateway""]]}","Here's the extracted entities and relationships in JSON format:

```json
{
  ""entities"": [
    [""Developers"", ""person""],
    [""GitHub repository"", ""system""],
    [""CI/CD pipeline agent"", ""component""],
    [""Azure VM"", ""system""],
    [""API application"", ""component""],
    [""ILB ASE"", ""system""],
    [""Azure API Management"", ""system""],
    [""HOST headers"", ""component""],
    [""API Management policy"", ""component""],
    [""App Service Environment's DNS name"", ""component""],
    [""Application Gateway"", ""system""],
    [""External users"", ""person""],
    [""Developer portal"", ""component""]
  ],
  ""relationships"": [
    [""Developers"", ""checks-in"", ""GitHub repository""],
    [""CI/CD pipeline agent"", ""part-of"", ""Azure VM""],
    [""CI/CD pipeline agent"", ""pushes-to"", ""API application""],
    [""API application"", ""hosted-on"", ""ILB ASE""],
    [""Azure API Management"", ""consumes-via"", ""HOST headers""],
    [""HOST headers"", ""specified-in"", ""API Management policy""],
    [""Azure API Management"", ""uses"", ""App Service Environment's DNS name""],
    [""Application Gateway"", ""exposes"", ""Developer portal""],
    [""External users"", ""utilize"", ""Developer portal""]
  ]
}
```","Here's the extracted entities and relationships in JSON format:

```json
{
  ""entities"": [
    [""Developers"", ""person""],
    [""GitHub repository"", ""system""],
    [""CI/CD pipeline agent"", ""component""],
    [""Azure VM"", ""system""],
    [""API application"", ""component""],
    [""ILB ASE"", ""system""],
    [""Azure API Management"", ""system""],
    [""HOST headers"", ""component""],
    [""API Management policy"", ""component""],
    [""App Service Environment's DNS name"", ""component""],
    [""Application Gateway"", ""system""],
    [""External users"", ""person""],
    [""Developer portal"", ""component""]
  ],
  ""relationships"": [
    [""Developers"", ""checks-in"", ""GitHub repository""],
    [""CI/CD pipeline agent"", ""part-of"", ""Azure VM""],
    [""CI/CD pipeline agent"", ""pushes-to"", ""API application""],
    [""API application"", ""hosted-on"", ""ILB ASE""],
    [""Azure API Management"", ""consumes-via"", ""HOST headers""],
    [""HOST headers"", ""specified-in"", ""API Management policy""],
    [""Azure API Management"", ""uses"", ""App Service Environment's DNS name""],
    [""Application Gateway"", ""exposes"", ""Developer portal""],
    [""External users"", ""utilize"", ""Developer portal""]
  ]
}
```",4.97760491198278
87,mistral-nemo,../IMAGES NEW/Azure/08 Azure Business Processes.txt,"
The data flows through the solution as follows:

    The airline system communicates with a custom API hosted in Azure API Management.
    A custom API coordinator receives notifications and handles incoming messages from the airline system. It sends them to Power Apps, where flights are assigned to Microsoft Teams channels.
    When a user selects a flight to monitor, or when the system assigns the user to a flight, the system queues a Graph API call in an Azure Storage Account queue for further processing.
    Azure Functions runs the Graph API calls based on the incoming messages in the storage queue, sending notifications to Teams, and also streams all events to an Azure Event Hubs for further analytics.
    The airline's notification system is managed by a custom bot messaging service that employs Azure Bot Service.
    Custom bots send flight updates to users in Teams.
    An Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs, ultimately generating insightful reports with Power BI.

","{""entities"": [[""airline system"", ""system"", ""communicates with a custom API hosted in Azure API Management""], [""custom API"", ""component"", ""communicates with a custom API hosted in Azure API Management""], [""Azure API Management"", ""system"", ""communicates with a custom API hosted in Azure API Management""], [""custom API coordinator"", ""system"", ""receives notifications and handles incoming messages from the airline system""], [""Power Apps"", ""system"", ""where flights are assigned to Microsoft Teams channels""], [""Microsoft Teams channels"", ""system"", ""where flights are assigned to Microsoft Teams channels""], [""Storage Account queue"", ""system"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing.""], [""Graph API call"", ""system"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing.""], [""Azure Functions"", ""system"", ""runs the Graph API calls based on the incoming messages in the storage queue""], [""Azure Event Hubs"", ""system"", ""Azure Event Hubs for further analytics""], [""notification system"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""custom bot messaging service"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""Azure Bot Service"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""Users"", ""person"", ""selects a flight to monitor, or when the system assigns the user to a flight""], [""Azure Data Lake storage"", ""system"", ""offers long-term retention and micro-batch processing of events from Event Hubs""], [""Power BI"", ""system"", ""generating insightful reports""]], ""relationships"": [[""Azure API Management"", ""contains"", ""custom API"", ""custom API hosted in Azure API Management""], [""airline system"", ""calls"", ""custom API"", ""communicates with a custom API""], [""custom API coordinator"", ""is-called-from"", ""airline system"", ""receives notifications and handles incoming messages from the airline system""], [""Power Apps"", ""calls"", ""Microsoft Teams channels"", ""Power Apps, where flights are assigned to Microsoft Teams channels""], [""airline system"", ""calls"", ""Graph API call"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing""], [""Azure Functions"", ""calls"", ""Graph API call"", ""runs the Graph API calls based on the incoming messages in the storage queue""], [""Azure Functions"", ""calls"", ""Storage Account queue"", ""based on the incoming messages in the storage queue""], [""Azure Functions"", ""calls"", ""Microsoft Teams channels"", ""sending notifications to Teams""], [""Azure Functions"", ""calls"", ""Azure Event Hubs"", ""also streams all events to an Azure Event Hubs for further analytics""], [""notification system"", ""is-called-from"", ""custom bot messaging service"", ""managed by a custom bot messaging service""], [""custom bot messaging service"", ""calls"", ""Azure Bot Service"", ""custom bot messaging service that employs Azure Bot Service""], [""custom bot messaging service"", ""calls"", ""Microsoft Teams channels"", ""Custom bots send flight updates to users in Teams.""], [""Microsoft Teams channels"", ""calls"", ""Users"", ""Custom bots send flight updates to users in Teams.""], [""Azure Data Lake storage"", ""is-called-from"", ""Azure Event Hubs"", ""Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs""], [""Azure Data Lake storage"", ""calls"", ""Power BI"", ""Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs, ultimately generating insightful reports with Power BI""]]}","Here's the JSON response based on the provided text:

```json
{
  ""entities"": [
    [""Airline System"", ""system""],
    [""Custom API Coordinator"", ""component""],
    [""Power Apps"", ""system""],
    [""Microsoft Teams"", ""system""],
    [""Azure Storage Account Queue"", ""component""],
    [""Azure Functions"", ""component""],
    [""Azure Event Hubs"", ""system""],
    [""Custom Bot Messaging Service"", ""component""],
    [""Azure Bot Service"", ""system""],
    [""Azure Data Lake Storage"", ""system""],
    [""Power BI"", ""system""]
  ],
  ""relationships"": [
    [""Airline System"", ""calls"", ""Custom API Coordinator""],
    [""Custom API Coordinator"", ""contains"", ""Power Apps""],
    [""Custom API Coordinator"", ""called-from"", ""Microsoft Teams""],
    [""Azure Storage Account Queue"", ""part-of"", ""Azure Functions""],
    [""Azure Functions"", ""contains"", ""Azure Storage Account Queue""],
    [""Azure Functions"", ""calls"", ""Azure Event Hubs""],
    [""Custom Bot Messaging Service"", ""part-of"", ""Azure Bot Service""],
    [""Azure Bot Service"", ""contains"", ""Custom Bot Messaging Service""],
    [""Azure Data Lake Storage"", ""contains"", ""Power BI""]
  ]
}
```","Here's the JSON response based on the provided text:

```json
{
  ""entities"": [
    [""Airline System"", ""system""],
    [""Custom API Coordinator"", ""component""],
    [""Power Apps"", ""system""],
    [""Microsoft Teams"", ""system""],
    [""Azure Storage Account Queue"", ""component""],
    [""Azure Functions"", ""component""],
    [""Azure Event Hubs"", ""system""],
    [""Custom Bot Messaging Service"", ""component""],
    [""Azure Bot Service"", ""system""],
    [""Azure Data Lake Storage"", ""system""],
    [""Power BI"", ""system""]
  ],
  ""relationships"": [
    [""Airline System"", ""calls"", ""Custom API Coordinator""],
    [""Custom API Coordinator"", ""contains"", ""Power Apps""],
    [""Custom API Coordinator"", ""called-from"", ""Microsoft Teams""],
    [""Azure Storage Account Queue"", ""part-of"", ""Azure Functions""],
    [""Azure Functions"", ""contains"", ""Azure Storage Account Queue""],
    [""Azure Functions"", ""calls"", ""Azure Event Hubs""],
    [""Custom Bot Messaging Service"", ""part-of"", ""Azure Bot Service""],
    [""Azure Bot Service"", ""contains"", ""Custom Bot Messaging Service""],
    [""Azure Data Lake Storage"", ""contains"", ""Power BI""]
  ]
}
```",4.72849882801529
88,mistral-nemo,../IMAGES NEW/Azure/15 Azure automate-document-classification.txt,"
    The user provides a document file that the web app uploads. The file contains multiple documents of various types. It can, for instance, be a PDF or multipage TIFF file.
        The document file is stored in Azure Blob Storage.
        The web app adds a command message to a storage queue to initiate pipeline processing.

    Durable Functions orchestration is triggered by the command message. The message contains metadata that identifies the location in Blob Storage of the document file to be processed. Each Durable Functions instance processes only one document file.

    The Scan activity function calls the Computer Vision Read API, passing in the location in storage of the document to be processed. Optical character recognition (OCR) results are returned to the orchestration to be used by subsequent activities.

    The Classify activity function calls the document classifier service that's hosted in an Azure Kubernetes Service (AKS) cluster. This service uses regular expression pattern matching to identify the starting page of each known document and to calculate how many document types are contained in the document file. The types and page ranges of the documents are calculated and returned to the orchestration.



Note

Azure doesn't offer a service that can classify multiple document types in a single file. This solution uses a non-Azure service that's hosted in AKS.

The Metadata Store activity function saves the document type and page range information in an Azure Cosmos DB store.

The Indexing activity function creates a new search document in the Cognitive Search service for each identified document type and uses the Azure AI Search libraries for .NET to include in the search document the full OCR results and document information. A correlation ID is also added to the search document so that the search results can be matched with the corresponding document metadata from Azure Cosmos DB.

End users can search for documents by contents and metadata. Correlation IDs in the search result set can be used to look up document records that are in Azure Cosmos DB. The records include links to the original document file in Blob Storage.


","{""entities"": [[""web app"", ""system"", ""The user provides a document file that the web app uploads""], [""Azure Blob Storage"", ""system"", ""The document file is stored in Azure Blob Storage""], [""storage queue"", ""system"", ""the web app adds a command message to a storage queue to initiate pipeline processing""], [""Durable Functions orchestration"", ""system"", ""Durable Functions orchestration is triggered by the command message.""], [""Scan activity function"", ""component"", ""The Scan activity function calls the Computer Vision Read API.""], [""Computer Vision Read API"", ""component"", ""The Scan activity function calls the Computer Vision Read API.""], [""Classify activity function"", ""component"", ""The Classify activity function calls the document classifier service that's hosted in an Azure Kubernetes Service (AKS) cluster""], [""document classifier service"", ""component"", ""The Classify activity function calls the document classifier service that's hosted in an Azure Kubernetes Service (AKS) cluster""], [""Azure Kubernetes Service (AKS) cluster"", ""system"", ""The Classify activity function calls the document classifier service that's hosted in an Azure Kubernetes Service (AKS) cluster""], [""User"", ""person"", ""provides a document file that the web app uploads""]], ""relationships"": [[""User"", ""calls"", ""web app"", ""The user provides a document file that the web app uploads""], [""web app"", ""calls"", ""Azure Blob Storage"", ""The user provides a document file that the web app uploads.The document file is stored in Azure Blob Storage""], [""web app"", ""calls"", ""storage queue"", ""the web app adds a command message to a storage queue to initiate pipeline processing""], [""storage queue"", ""calls"", ""Durable Functions orchestration"", ""Durable Functions orchestration is triggered by the command message.""], [""Durable Functions orchestration"", ""calls"", ""Azure Blob Storage"", ""Each Durable Functions instance processes only one document file""], [""Scan activity function"", ""calls"", ""Computer Vision Read API"", ""the Scan activity function calls the Computer Vision Read API""], [""document classifier service"", ""part-of"", ""Azure Kubernetes Service (AKS) cluster"", ""document classifier service that's hosted in an Azure Kubernetes Service (AKS) cluster""], [""Classify activity function"", ""calls"", ""Scan activity function"", ""The Classify activity function calls the document classifier service""], [""Classify activity function"", ""calls"", ""Durable Functions orchestration"", ""The types and page ranges of the documents are calculated and returned to the orchestration""]]}","Based on the provided text, here's the extracted entities and their relationships in JSON format:

```json
{
  ""entities"": [
    [""User"", ""person"", ""The user provides a document file""],
    [""Document File"", ""system"", ""Contains multiple documents of various types""],
    [""Azure Blob Storage"", ""component"", ""Stores the document file""],
    [""Web App"", ""system"", ""Adds a command message to a storage queue""],
    [""Storage Queue"", ""component"", ""Used by Web App to initiate pipeline processing""],
    [""Durable Functions"", ""system"", ""Orchestrates the processing of documents""],
    [""Scan Activity Function"", ""component"", ""Calls Computer Vision Read API for OCR""],
    [""Computer Vision Read API"", ""component"", ""Returns OCR results to orchestration""],
    [""Classify Activity Function"", ""component"", ""Calls Document Classifier Service""],
    [""Document Classifier Service"", ""system"", ""Hosted in Azure Kubernetes Service (AKS)""],
    [""Metadata Store Activity Function"", ""component"", ""Saves document type and page range information in Cosmos DB""],
    [""Azure Cosmos DB"", ""component"", ""Used by Metadata Store Activity Function to store metadata""],
    [""Indexing Activity Function"", ""component"", ""Creates search documents in Cognitive Search service""],
    [""Cognitive Search Service"", ""system"", ""Uses Azure AI Search libraries for .NET""],
    [""End User"", ""person"", ""Searches for documents by contents and metadata""]
  ],
  ""relationships"": [
    [""Document File"", ""contains"", ""PDF, multipage TIFF file""],
    [""Web App"", ""calls"", ""Storage Queue""],
    [""Storage Queue"", ""called-from"", ""Web App""],
    [""Durable Functions"", ""part-of"", ""Scan Activity Function""],
    [""Durable Functions"", ""part-of"", ""Classify Activity Function""],
    [""Durable Functions"", ""part-of"", ""Metadata Store Activity Function""],
    [""Durable Functions"", ""part-of"", ""Indexing Activity Function""],
    [""Scan Activity Function"", ""calls"", ""Computer Vision Read API""],
    [""Computer Vision Read API"", ""called-from"", ""Scan Activity Function""],
    [""Classify Activity Function"", ""calls"", ""Document Classifier Service""],
    [""Document Classifier Service"", ""called-from"", ""Classify Activity Function""],
    [""Metadata Store Activity Function"", ""calls"", ""Azure Cosmos DB""],
    [""Azure Cosmos DB"", ""called-from"", ""Metadata Store Activity Function""],
    [""Indexing Activity Function"", ""calls"", ""Cognitive Search Service""],
    [""Cognitive Search Service"", ""called-from"", ""Indexing Activity Function""]
  ]
}
```","Based on the provided text, here's the extracted entities and their relationships in JSON format:

```json
{
  ""entities"": [
    [""User"", ""person"", ""The user provides a document file""],
    [""Document File"", ""system"", ""Contains multiple documents of various types""],
    [""Azure Blob Storage"", ""component"", ""Stores the document file""],
    [""Web App"", ""system"", ""Adds a command message to a storage queue""],
    [""Storage Queue"", ""component"", ""Used by Web App to initiate pipeline processing""],
    [""Durable Functions"", ""system"", ""Orchestrates the processing of documents""],
    [""Scan Activity Function"", ""component"", ""Calls Computer Vision Read API for OCR""],
    [""Computer Vision Read API"", ""component"", ""Returns OCR results to orchestration""],
    [""Classify Activity Function"", ""component"", ""Calls Document Classifier Service""],
    [""Document Classifier Service"", ""system"", ""Hosted in Azure Kubernetes Service (AKS)""],
    [""Metadata Store Activity Function"", ""component"", ""Saves document type and page range information in Cosmos DB""],
    [""Azure Cosmos DB"", ""component"", ""Used by Metadata Store Activity Function to store metadata""],
    [""Indexing Activity Function"", ""component"", ""Creates search documents in Cognitive Search service""],
    [""Cognitive Search Service"", ""system"", ""Uses Azure AI Search libraries for .NET""],
    [""End User"", ""person"", ""Searches for documents by contents and metadata""]
  ],
  ""relationships"": [
    [""Document File"", ""contains"", ""PDF, multipage TIFF file""],
    [""Web App"", ""calls"", ""Storage Queue""],
    [""Storage Queue"", ""called-from"", ""Web App""],
    [""Durable Functions"", ""part-of"", ""Scan Activity Function""],
    [""Durable Functions"", ""part-of"", ""Classify Activity Function""],
    [""Durable Functions"", ""part-of"", ""Metadata Store Activity Function""],
    [""Durable Functions"", ""part-of"", ""Indexing Activity Function""],
    [""Scan Activity Function"", ""calls"", ""Computer Vision Read API""],
    [""Computer Vision Read API"", ""called-from"", ""Scan Activity Function""],
    [""Classify Activity Function"", ""calls"", ""Document Classifier Service""],
    [""Document Classifier Service"", ""called-from"", ""Classify Activity Function""],
    [""Metadata Store Activity Function"", ""calls"", ""Azure Cosmos DB""],
    [""Azure Cosmos DB"", ""called-from"", ""Metadata Store Activity Function""],
    [""Indexing Activity Function"", ""calls"", ""Cognitive Search Service""],
    [""Cognitive Search Service"", ""called-from"", ""Indexing Activity Function""]
  ]
}
```",9.397771643998567
89,mistral-nemo,../IMAGES NEW/Azure/11 Mainframe original.txt,"
    A Connect agent component captures change logs by using mainframe or midrange native utilities and caches the logs in temporary storage.
    For mainframe systems, a publisher component on the mainframe manages data migration.
    For midrange systems, in place of the publisher, a listener component manages data migration. It's located on either a Windows or Linux machine.
    The publisher or listener moves the data from on-premises to Azure via an enhanced-security connection. The publisher or listener handles the commit and rollback of transactions for each unit of work, maintaining the integrity of data.
    The Connect Replicator Engine captures the data from the publisher or listener and applies it to the target. It distributes data for parallel processing.
    The target is a database that receives the changes via ODBC or ingests the changes via Azure Event Hubs.
    The changed data is consumed by Azure Databricks and applied to Azure data platform services.
    The Connect Controller Daemon authenticates the request and establishes the socket connection between the publisher or listener and the Replicator Engine.

","{""entities"": [[""Connect agent"", ""component"", ""captures change logs""], [""temporary storage"", ""component"", ""caches the logs in temporary storage""], [""mainframe native utilities"", ""system"", ""captures change logs by using mainframe or midrange native utilities""], [""midrange native utilities"", ""system"", ""captures change logs by using mainframe or midrange native utilities""], [""mainframe systems"", ""system"", ""For mainframe systems, a publisher component on the mainframe manages data migration.""], [""midrange systems"", ""system"", ""For midrange systems, in place of the publisher, a listener component manages data migration.""], [""publisher"", ""component"", ""For mainframe systems, a publisher component on the mainframe manages data migration.""], [""listener"", ""component"", ""For midrange systems, in place of the publisher, a listener component manages data migration.""], [""Connect Replicator Engine"", ""system"", ""captures the data from the publisher or listener and applies it to the target.""], [""on-premises"", ""system"", ""The publisher or listener moves the data from on-premises to Azure""], [""Azure"", ""system"", ""The publisher or listener moves the data from on-premises to Azure""], [""Connect Replicator Engine"", ""system"", ""The Connect Replicator Engine captures the data from the publisher or listener""], [""target"", ""system"", ""applies it to the target""], [""database"", ""system"", ""target is a database""], [""ODBC"", ""component"", ""The target is a database that receives the changes via ODBC or ingests the changes via Azure Event Hubs""], [""Azure Event Hubs"", ""component"", ""The target is a database that receives the changes via ODBC or ingests the changes via Azure Event Hubs""], [""Azure Databricks"", ""component"", ""the changed data is consumed by Azure Databricks and applied to Azure data platform services.""], [""Azure data platform services"", ""component"", ""the changed data is consumed by Azure Databricks and applied to Azure data platform services.""], [""Connect Controller Daemon"", ""component"", ""authenticates the request and establishes the socket connection between the publisher or listener and the Replicator Engine.""]], ""relationships"": [[""Connect agent"", ""calls"", ""mainframe native utilities"", ""captures change logs by using mainframe or midrange native utilities""], [""Connect agent"", ""calls"", ""midrange native utilities"", ""captures change logs by using mainframe or midrange native utilities""], [""Connect agent"", ""calls"", ""temporary storage"", ""captures change logs by using mainframe or midrange native utilities""], [""mainframe systems"", ""contains"", ""mainframe native utilities"", ""F""], [""midrange systems"", ""contains"", ""midrange native utilities"", """"], [""mainframe systems"", ""contains"", ""publisher"", ""For mainframe systems, a publisher component on the mainframe manages data migration.""], [""midrange systems"", ""contains"", ""listener"", ""For midrange systems, in place of the publisher, a listener component manages data migration.""], [""publisher"", ""calls"", ""on-premises"", ""The publisher or listener moves the data from on-premises to Azure""], [""publisher"", ""calls"", ""Azure"", ""The publisher or listener moves the data from on-premises to Azure""], [""listener"", ""calls"", ""on-premises"", ""The publisher or listener moves the data from on-premises to Azure""], [""listener"", ""calls"", ""Azure"", ""The publisher or listener moves the data from on-premises to Azure""], [""Connect Replicator Engine"", ""calls"", ""publisher"", ""captures the data from the publisher or listener and applies it to the target.""], [""Connect Replicator Engine"", ""calls"", ""listener"", ""captures the data from the publisher or listener and applies it to the target.""], [""Connect Replicator Engine"", ""calls"", ""target"", ""captures the data from the publisher or listener and applies it to the target.""], [""target"", ""contains"", ""database"", ""target is a database""], [""database"", ""is-called-from"", ""ODBC"", ""database that receives the changes via ODBC""], [""database"", ""is-called-from"", ""Azure Event Hubs"", ""ingests the changes via Azure Event Hubs""], [""database"", ""is-called-from"", ""Azure Databricks"", ""the changed data is consumed by Azure Databricks""], [""Azure Databricks"", ""calls"", ""Azure data platform services"", ""consumed by Azure Databricks and applied to Azure data platform services.""], [""Connect Controller Daemon"", ""is-called-from"", ""publisher"", ""establishes the socket connection between the publisher or listener and the Replicator Engine..""], [""Connect Controller Daemon"", ""is-called-from"", ""listener"", ""establishes the socket connection between the publisher or listener and the Replicator Engine..""], [""Connect Controller Daemon"", ""calls"", ""Connect Replicator Engine"", ""establishes the socket connection between the publisher or listener and the Replicator Engine..""]]}","```json
{
  ""entities"": [
    [""Connect Agent"", ""component"", ""Captures change logs using native utilities""],
    [""Mainframe Native Utilities"", ""system""],
    [""Midrange Native Utilities"", ""system""],
    [""Publisher Component"", ""component"", ""Manages data migration for mainframe systems""],
    [""Listener Component"", ""component"", ""Manages data migration for midrange systems""],
    [""Windows Machine"", ""system""],
    [""Linux Machine"", ""system""],
    [""Azure"", ""system""],
    [""Connect Replicator Engine"", ""component"", ""Captures data from publisher or listener and applies it to the target""],
    [""Target Database"", ""system"", ""Receives changes via ODBC or ingests changes via Azure Event Hubs""],
    [""Azure Databricks"", ""system"", ""Consumes changed data and applies it to Azure data platform services""],
    [""Connect Controller Daemon"", ""component"", ""Authenticates requests and establishes socket connections""]
  ],
  ""relationships"": [
    [""Connect Agent"", ""calls"", ""Mainframe Native Utilities""],
    [""Connect Agent"", ""calls"", ""Midrange Native Utilities""],
    [""Publisher Component"", ""part-of"", ""Mainframe Systems""],
    [""Listener Component"", ""part-of"", ""Midrange Systems""],
    [""Listener Component"", ""located-on"", ""Windows Machine""],
    [""Listener Component"", ""located-on"", ""Linux Machine""],
    [""Publisher Component"", ""moves-data-to"", ""Azure""],
    [""Listener Component"", ""moves-data-to"", ""Azure""],
    [""Connect Replicator Engine"", ""captures-from"", ""Publisher Component""],
    [""Connect Replicator Engine"", ""captures-from"", ""Listener Component""],
    [""Connect Replicator Engine"", ""applies-to"", ""Target Database""],
    [""Target Database"", ""called-from"", ""Azure Event Hubs""],
    [""Azure Databricks"", ""consumes-data-from"", ""Target Database""],
    [""Connect Controller Daemon"", ""calls"", ""Connect Replicator Engine""]
  ]
}
```","```json
{
  ""entities"": [
    [""Connect Agent"", ""component"", ""Captures change logs using native utilities""],
    [""Mainframe Native Utilities"", ""system""],
    [""Midrange Native Utilities"", ""system""],
    [""Publisher Component"", ""component"", ""Manages data migration for mainframe systems""],
    [""Listener Component"", ""component"", ""Manages data migration for midrange systems""],
    [""Windows Machine"", ""system""],
    [""Linux Machine"", ""system""],
    [""Azure"", ""system""],
    [""Connect Replicator Engine"", ""component"", ""Captures data from publisher or listener and applies it to the target""],
    [""Target Database"", ""system"", ""Receives changes via ODBC or ingests changes via Azure Event Hubs""],
    [""Azure Databricks"", ""system"", ""Consumes changed data and applies it to Azure data platform services""],
    [""Connect Controller Daemon"", ""component"", ""Authenticates requests and establishes socket connections""]
  ],
  ""relationships"": [
    [""Connect Agent"", ""calls"", ""Mainframe Native Utilities""],
    [""Connect Agent"", ""calls"", ""Midrange Native Utilities""],
    [""Publisher Component"", ""part-of"", ""Mainframe Systems""],
    [""Listener Component"", ""part-of"", ""Midrange Systems""],
    [""Listener Component"", ""located-on"", ""Windows Machine""],
    [""Listener Component"", ""located-on"", ""Linux Machine""],
    [""Publisher Component"", ""moves-data-to"", ""Azure""],
    [""Listener Component"", ""moves-data-to"", ""Azure""],
    [""Connect Replicator Engine"", ""captures-from"", ""Publisher Component""],
    [""Connect Replicator Engine"", ""captures-from"", ""Listener Component""],
    [""Connect Replicator Engine"", ""applies-to"", ""Target Database""],
    [""Target Database"", ""called-from"", ""Azure Event Hubs""],
    [""Azure Databricks"", ""consumes-data-from"", ""Target Database""],
    [""Connect Controller Daemon"", ""calls"", ""Connect Replicator Engine""]
  ]
}
```",7.319863707001787
90,mistral-nemo,../IMAGES NEW/Azure/05. azure Original.txt,"
    Backend systems. The right-hand side of the diagram shows the various backend systems that the enterprise has deployed or relies on. These systems might include SaaS systems, other Azure services, or web services that expose REST or SOAP endpoints.

    Azure Logic Apps. In this architecture, logic apps are triggered by HTTP requests. You can also nest workflows for more complex orchestration. Logic Apps uses connectors to integrate with commonly used services. Logic Apps offers hundreds of connectors, and you can create custom connectors.

    Azure API Management. API Management consists of two related components:

        API gateway. The API gateway accepts HTTP calls and routes them to the backend.

        Developer portal. Each instance of Azure API Management provides access to a developer portal. This portal gives your developers access to documentation and code samples for calling the APIs. You can also test APIs in the developer portal.

    Azure DNS. Azure DNS provides name resolution by using the Azure infrastructure. By hosting your domains in Azure, you can manage your DNS records by using the same credentials, APIs, tools, and billing that you use for your other Azure services. To use a custom domain name, such as contoso.com, create DNS records that map the custom domain name to the IP address. For more information, see Configure a custom domain name in API Management.

    Microsoft Entra ID. Use Microsoft Entra ID to authenticate clients that call the API gateway. Microsoft Entra ID supports the OpenID Connect (OIDC) protocol. Clients obtain an access token from Microsoft Entra ID, and API Gateway validates the token to authorize the request. If you use the Standard or Premium tier of API Management, Microsoft Entra ID can also help secure access to the developer portal.

","{""entities"": [[""Backend systems"", ""system"", ""various backend systems that the enterprise has deployed or relies on""], [""SaaS systems"", ""component"", ""SaaS systems""], [""other Azure services"", ""component"", ""other Azure services""], [""web services"", ""component"", ""expose REST or SOAP endpoints""], [""Azure Logic Apps"", ""system"", ""Logic Apps uses connectors to integrate with commonly used services""], [""Azure API Management"", ""system"", ""Logic Apps uses connectors to integrate with commonly used services""], [""API gateway"", ""component"", ""The API gateway accepts HTTP calls and routes them to the backend""], [""Developer portal"", ""component"", ""This portal gives your developers access to documentation and code samples for calling the APIs""], [""Azure DNS"", ""system"", ""Azure DNS provides name resolution by using the Azure infrastructure""], [""Microsoft Entra ID"", ""system"", ""Use Microsoft Entra ID to authenticate clients that call the API gateway""], [""clients"", ""system"", ""clients that call the API gateway""], [""developers"", ""person"", ""accesses documentation and code samples""]], ""relationships"": [[""Backend systems"", ""contains"", ""SaaS systems"", ""These systems might include ""], [""Backend systems"", ""contains"", ""web services"", ""These systems might include ""], [""Backend systems"", ""contains"", ""other Azure services"", ""These systems might include ""], [""web services"", ""contains"", ""SaaS systems"", ""These systems might include ""], [""Azure API Management"", ""contains"", ""API gateway"", ""API Management consists of two related components""], [""Azure API Management"", ""contains"", ""Developer portal"", ""API Management consists of two related components""], [""clients"", ""calls"", ""API gateway"", ""clients that call the API gateway""], [""clients"", ""calls"", ""Microsoft Entra ID"", ""Clients obtain an access token from Microsoft Entra ID""], [""developers"", ""calls"", ""Developer portal"", ""This portal gives your developers access to documentation and code samples for calling the APIs. You can also test APIs in the developer portal""]]}","```json
{
  ""entities"": [
    [""Azure Logic Apps"", ""system""],
    [""Azure API Management"", ""system""],
    [""API gateway"", ""component""],
    [""Developer portal"", ""component""],
    [""Azure DNS"", ""system""],
    [""Microsoft Entra ID"", ""system""]
  ],
  ""relationships"": [
    [""Logic Apps"", ""contains"", ""workflows"", ""For more complex orchestration""],
    [""API Management"", ""contains"", ""API gateway""],
    [""API Management"", ""contains"", ""Developer portal""],
    [""Azure DNS"", ""part-of"", ""Azure""],
    [""Microsoft Entra ID"", ""calls"", ""API gateway""]
  ]
}
```","```json
{
  ""entities"": [
    [""Azure Logic Apps"", ""system""],
    [""Azure API Management"", ""system""],
    [""API gateway"", ""component""],
    [""Developer portal"", ""component""],
    [""Azure DNS"", ""system""],
    [""Microsoft Entra ID"", ""system""]
  ],
  ""relationships"": [
    [""Logic Apps"", ""contains"", ""workflows"", ""For more complex orchestration""],
    [""API Management"", ""contains"", ""API gateway""],
    [""API Management"", ""contains"", ""Developer portal""],
    [""Azure DNS"", ""part-of"", ""Azure""],
    [""Microsoft Entra ID"", ""calls"", ""API gateway""]
  ]
}
```",2.951413822011091
91,mistral-nemo,../IMAGES NEW/Azure/11 Mainframe original.txt,"
    A Connect agent component captures change logs by using mainframe or midrange native utilities and caches the logs in temporary storage.
    For mainframe systems, a publisher component on the mainframe manages data migration.
    For midrange systems, in place of the publisher, a listener component manages data migration. It's located on either a Windows or Linux machine.
    The publisher or listener moves the data from on-premises to Azure via an enhanced-security connection. The publisher or listener handles the commit and rollback of transactions for each unit of work, maintaining the integrity of data.
    The Connect Replicator Engine captures the data from the publisher or listener and applies it to the target. It distributes data for parallel processing.
    The target is a database that receives the changes via ODBC or ingests the changes via Azure Event Hubs.
    The changed data is consumed by Azure Databricks and applied to Azure data platform services.
    The Connect Controller Daemon authenticates the request and establishes the socket connection between the publisher or listener and the Replicator Engine.

","{""entities"": [[""Connect agent"", ""component"", ""captures change logs""], [""temporary storage"", ""component"", ""caches the logs in temporary storage""], [""mainframe native utilities"", ""system"", ""captures change logs by using mainframe or midrange native utilities""], [""midrange native utilities"", ""system"", ""captures change logs by using mainframe or midrange native utilities""], [""mainframe systems"", ""system"", ""For mainframe systems, a publisher component on the mainframe manages data migration.""], [""midrange systems"", ""system"", ""For midrange systems, in place of the publisher, a listener component manages data migration.""], [""publisher"", ""component"", ""For mainframe systems, a publisher component on the mainframe manages data migration.""], [""listener"", ""component"", ""For midrange systems, in place of the publisher, a listener component manages data migration.""], [""Connect Replicator Engine"", ""system"", ""captures the data from the publisher or listener and applies it to the target.""], [""on-premises"", ""system"", ""The publisher or listener moves the data from on-premises to Azure""], [""Azure"", ""system"", ""The publisher or listener moves the data from on-premises to Azure""], [""Connect Replicator Engine"", ""system"", ""The Connect Replicator Engine captures the data from the publisher or listener""], [""target"", ""system"", ""applies it to the target""], [""database"", ""system"", ""target is a database""], [""ODBC"", ""component"", ""The target is a database that receives the changes via ODBC or ingests the changes via Azure Event Hubs""], [""Azure Event Hubs"", ""component"", ""The target is a database that receives the changes via ODBC or ingests the changes via Azure Event Hubs""], [""Azure Databricks"", ""component"", ""the changed data is consumed by Azure Databricks and applied to Azure data platform services.""], [""Azure data platform services"", ""component"", ""the changed data is consumed by Azure Databricks and applied to Azure data platform services.""], [""Connect Controller Daemon"", ""component"", ""authenticates the request and establishes the socket connection between the publisher or listener and the Replicator Engine.""]], ""relationships"": [[""Connect agent"", ""calls"", ""mainframe native utilities"", ""captures change logs by using mainframe or midrange native utilities""], [""Connect agent"", ""calls"", ""midrange native utilities"", ""captures change logs by using mainframe or midrange native utilities""], [""Connect agent"", ""calls"", ""temporary storage"", ""captures change logs by using mainframe or midrange native utilities""], [""mainframe systems"", ""contains"", ""mainframe native utilities"", ""F""], [""midrange systems"", ""contains"", ""midrange native utilities"", """"], [""mainframe systems"", ""contains"", ""publisher"", ""For mainframe systems, a publisher component on the mainframe manages data migration.""], [""midrange systems"", ""contains"", ""listener"", ""For midrange systems, in place of the publisher, a listener component manages data migration.""], [""publisher"", ""calls"", ""on-premises"", ""The publisher or listener moves the data from on-premises to Azure""], [""publisher"", ""calls"", ""Azure"", ""The publisher or listener moves the data from on-premises to Azure""], [""listener"", ""calls"", ""on-premises"", ""The publisher or listener moves the data from on-premises to Azure""], [""listener"", ""calls"", ""Azure"", ""The publisher or listener moves the data from on-premises to Azure""], [""Connect Replicator Engine"", ""calls"", ""publisher"", ""captures the data from the publisher or listener and applies it to the target.""], [""Connect Replicator Engine"", ""calls"", ""listener"", ""captures the data from the publisher or listener and applies it to the target.""], [""Connect Replicator Engine"", ""calls"", ""target"", ""captures the data from the publisher or listener and applies it to the target.""], [""target"", ""contains"", ""database"", ""target is a database""], [""database"", ""is-called-from"", ""ODBC"", ""database that receives the changes via ODBC""], [""database"", ""is-called-from"", ""Azure Event Hubs"", ""ingests the changes via Azure Event Hubs""], [""database"", ""is-called-from"", ""Azure Databricks"", ""the changed data is consumed by Azure Databricks""], [""Azure Databricks"", ""calls"", ""Azure data platform services"", ""consumed by Azure Databricks and applied to Azure data platform services.""], [""Connect Controller Daemon"", ""is-called-from"", ""publisher"", ""establishes the socket connection between the publisher or listener and the Replicator Engine..""], [""Connect Controller Daemon"", ""is-called-from"", ""listener"", ""establishes the socket connection between the publisher or listener and the Replicator Engine..""], [""Connect Controller Daemon"", ""calls"", ""Connect Replicator Engine"", ""establishes the socket connection between the publisher or listener and the Replicator Engine..""]]}","{
  ""entities"": [
    [""Connect Agent Component"", ""component"", ""Captures change logs""],
    [""Mainframe Native Utilities"", ""system"", ""Provides utilities for mainframe systems""],
    [""Midrange Systems"", ""system"", ""Supports midrange systems""],
    [""Publisher Component"", ""component"", ""Manages data migration for mainframe systems""],
    [""Listener Component"", ""component"", ""Manages data migration for midrange systems""],
    [""Windows/Linux Machine"", ""system"", ""Hosts the listener component""],
    [""Azure"", ""system"", ""Receives migrated data from on-premises systems""],
    [""Enhanced-Security Connection"", ""component"", ""Secures data migration between on-premises and Azure""],
    [""Connect Replicator Engine"", ""component"", ""Captures data from publisher or listener and applies it to the target""],
    [""Target Database"", ""system"", ""Receives changes via ODBC or Azure Event Hubs""],
    [""Azure Databricks"", ""system"", ""Consumes changed data and applies it to Azure data platform services""],
    [""Connect Controller Daemon"", ""component"", ""Authenticates requests and establishes socket connections""]
  ],
  ""relationships"": [
    [""Connect Agent Component"", ""contains"", ""Mainframe Native Utilities""],
    [""Connect Agent Component"", ""contains"", ""Midrange Systems""],
    [""Publisher Component"", ""part-of"", ""Mainframe Systems""],
    [""Listener Component"", ""part-of"", ""Midrange Systems""],
    [""Listener Component"", ""located-on"", ""Windows/Linux Machine""],
    [""Publisher Component"", ""calls"", ""Enhanced-Security Connection""],
    [""Listener Component"", ""calls"", ""Enhanced-Security Connection""],
    [""Enhanced-Security Connection"", ""called-from"", ""Azure""],
    [""Connect Replicator Engine"", ""contains"", ""Publisher Component""],
    [""Connect Replicator Engine"", ""contains"", ""Listener Component""],
    [""Connect Replicator Engine"", ""calls"", ""Target Database""],
    [""Target Database"", ""part-of"", ""Azure Databricks""],
    [""Connect Controller Daemon"", ""authenticates"", ""Connect Agent Component""]
  ]
}","{
  ""entities"": [
    [""Connect Agent Component"", ""component"", ""Captures change logs""],
    [""Mainframe Native Utilities"", ""system"", ""Provides utilities for mainframe systems""],
    [""Midrange Systems"", ""system"", ""Supports midrange systems""],
    [""Publisher Component"", ""component"", ""Manages data migration for mainframe systems""],
    [""Listener Component"", ""component"", ""Manages data migration for midrange systems""],
    [""Windows/Linux Machine"", ""system"", ""Hosts the listener component""],
    [""Azure"", ""system"", ""Receives migrated data from on-premises systems""],
    [""Enhanced-Security Connection"", ""component"", ""Secures data migration between on-premises and Azure""],
    [""Connect Replicator Engine"", ""component"", ""Captures data from publisher or listener and applies it to the target""],
    [""Target Database"", ""system"", ""Receives changes via ODBC or Azure Event Hubs""],
    [""Azure Databricks"", ""system"", ""Consumes changed data and applies it to Azure data platform services""],
    [""Connect Controller Daemon"", ""component"", ""Authenticates requests and establishes socket connections""]
  ],
  ""relationships"": [
    [""Connect Agent Component"", ""contains"", ""Mainframe Native Utilities""],
    [""Connect Agent Component"", ""contains"", ""Midrange Systems""],
    [""Publisher Component"", ""part-of"", ""Mainframe Systems""],
    [""Listener Component"", ""part-of"", ""Midrange Systems""],
    [""Listener Component"", ""located-on"", ""Windows/Linux Machine""],
    [""Publisher Component"", ""calls"", ""Enhanced-Security Connection""],
    [""Listener Component"", ""calls"", ""Enhanced-Security Connection""],
    [""Enhanced-Security Connection"", ""called-from"", ""Azure""],
    [""Connect Replicator Engine"", ""contains"", ""Publisher Component""],
    [""Connect Replicator Engine"", ""contains"", ""Listener Component""],
    [""Connect Replicator Engine"", ""calls"", ""Target Database""],
    [""Target Database"", ""part-of"", ""Azure Databricks""],
    [""Connect Controller Daemon"", ""authenticates"", ""Connect Agent Component""]
  ]
}",7.719597056013299
92,mistral-nemo,../IMAGES NEW/Azure/05. azure Original.txt,"
    Backend systems. The right-hand side of the diagram shows the various backend systems that the enterprise has deployed or relies on. These systems might include SaaS systems, other Azure services, or web services that expose REST or SOAP endpoints.

    Azure Logic Apps. In this architecture, logic apps are triggered by HTTP requests. You can also nest workflows for more complex orchestration. Logic Apps uses connectors to integrate with commonly used services. Logic Apps offers hundreds of connectors, and you can create custom connectors.

    Azure API Management. API Management consists of two related components:

        API gateway. The API gateway accepts HTTP calls and routes them to the backend.

        Developer portal. Each instance of Azure API Management provides access to a developer portal. This portal gives your developers access to documentation and code samples for calling the APIs. You can also test APIs in the developer portal.

    Azure DNS. Azure DNS provides name resolution by using the Azure infrastructure. By hosting your domains in Azure, you can manage your DNS records by using the same credentials, APIs, tools, and billing that you use for your other Azure services. To use a custom domain name, such as contoso.com, create DNS records that map the custom domain name to the IP address. For more information, see Configure a custom domain name in API Management.

    Microsoft Entra ID. Use Microsoft Entra ID to authenticate clients that call the API gateway. Microsoft Entra ID supports the OpenID Connect (OIDC) protocol. Clients obtain an access token from Microsoft Entra ID, and API Gateway validates the token to authorize the request. If you use the Standard or Premium tier of API Management, Microsoft Entra ID can also help secure access to the developer portal.

","{""entities"": [[""Backend systems"", ""system"", ""various backend systems that the enterprise has deployed or relies on""], [""SaaS systems"", ""component"", ""SaaS systems""], [""other Azure services"", ""component"", ""other Azure services""], [""web services"", ""component"", ""expose REST or SOAP endpoints""], [""Azure Logic Apps"", ""system"", ""Logic Apps uses connectors to integrate with commonly used services""], [""Azure API Management"", ""system"", ""Logic Apps uses connectors to integrate with commonly used services""], [""API gateway"", ""component"", ""The API gateway accepts HTTP calls and routes them to the backend""], [""Developer portal"", ""component"", ""This portal gives your developers access to documentation and code samples for calling the APIs""], [""Azure DNS"", ""system"", ""Azure DNS provides name resolution by using the Azure infrastructure""], [""Microsoft Entra ID"", ""system"", ""Use Microsoft Entra ID to authenticate clients that call the API gateway""], [""clients"", ""system"", ""clients that call the API gateway""], [""developers"", ""person"", ""accesses documentation and code samples""]], ""relationships"": [[""Backend systems"", ""contains"", ""SaaS systems"", ""These systems might include ""], [""Backend systems"", ""contains"", ""web services"", ""These systems might include ""], [""Backend systems"", ""contains"", ""other Azure services"", ""These systems might include ""], [""web services"", ""contains"", ""SaaS systems"", ""These systems might include ""], [""Azure API Management"", ""contains"", ""API gateway"", ""API Management consists of two related components""], [""Azure API Management"", ""contains"", ""Developer portal"", ""API Management consists of two related components""], [""clients"", ""calls"", ""API gateway"", ""clients that call the API gateway""], [""clients"", ""calls"", ""Microsoft Entra ID"", ""Clients obtain an access token from Microsoft Entra ID""], [""developers"", ""calls"", ""Developer portal"", ""This portal gives your developers access to documentation and code samples for calling the APIs. You can also test APIs in the developer portal""]]}","Here's the JSON response based on the provided context:

```json
{
  ""entities"": [
    [""Azure Logic Apps"", ""system"", ""A workflow orchestration service that triggers actions based on events.""],
    [""API gateway"", ""component"", ""Accepts HTTP calls and routes them to the backend.""],
    [""Developer portal"", ""component"", ""Provides access to documentation, code samples, and API testing for developers.""],
    [""Azure DNS"", ""system"", ""A Domain Name System service that provides name resolution using Azure infrastructure.""],
    [""Microsoft Entra ID"", ""system"", ""An identity management system supporting OpenID Connect (OIDC) protocol for authentication and authorization.""]
  ],
  ""relationships"": [
    [""API gateway"", ""part-of"", ""Azure API Management"", ""The API gateway is a component of Azure API Management""],
    [""Developer portal"", ""part-of"", ""Azure API Management"", ""The developer portal is a component of Azure API Management""],
    [""Azure Logic Apps"", ""contains"", ""workflows"", ""Logic Apps contains workflows for complex orchestration""],
    [""Microsoft Entra ID"", ""calls"", ""API gateway"", ""Microsoft Entra ID secures access to the API gateway""],
    [""Azure DNS"", ""called-from"", ""custom domain name"", ""Azure DNS is called from custom domain names to map them to IP addresses""]
  ]
}
```","Here's the JSON response based on the provided context:

```json
{
  ""entities"": [
    [""Azure Logic Apps"", ""system"", ""A workflow orchestration service that triggers actions based on events.""],
    [""API gateway"", ""component"", ""Accepts HTTP calls and routes them to the backend.""],
    [""Developer portal"", ""component"", ""Provides access to documentation, code samples, and API testing for developers.""],
    [""Azure DNS"", ""system"", ""A Domain Name System service that provides name resolution using Azure infrastructure.""],
    [""Microsoft Entra ID"", ""system"", ""An identity management system supporting OpenID Connect (OIDC) protocol for authentication and authorization.""]
  ],
  ""relationships"": [
    [""API gateway"", ""part-of"", ""Azure API Management"", ""The API gateway is a component of Azure API Management""],
    [""Developer portal"", ""part-of"", ""Azure API Management"", ""The developer portal is a component of Azure API Management""],
    [""Azure Logic Apps"", ""contains"", ""workflows"", ""Logic Apps contains workflows for complex orchestration""],
    [""Microsoft Entra ID"", ""calls"", ""API gateway"", ""Microsoft Entra ID secures access to the API gateway""],
    [""Azure DNS"", ""called-from"", ""custom domain name"", ""Azure DNS is called from custom domain names to map them to IP addresses""]
  ]
}
```",5.202971049002372
93,mistral-nemo,../IMAGES NEW/Azure/06 Azure logic-apps-data-integration.txt,"
    API Management accepts API calls in the form of HTTP requests.

    API Management securely routes the HTTP requests to Logic Apps.

    Each HTTP request triggers a run in Logic Apps:
        Logic Apps uses secured template parameters to retrieve database credentials from Azure Key Vault.
        Logic Apps uses Transport Layer Security (TLS) to send the database credentials and a database statement to the on-premises data gateway.

    The on-premises data gateway connects to a SQL Server database to run the statement.

    SQL Server stores the data and makes it available to apps that users access.

    Azure Monitor collects information on Logic Apps events and performance.

","{""entities"": [[""API Management"", ""system"", ""accepts API calls in the form of HTTP requests""], [""Logic Apps"", ""system"", ""uses secured template parameters to retrieve database credentials from Azure Key Vault""], [""on-premises data gateway"", ""system"", """"], [""SQL Server"", ""system"", ""stores the data and makes it available to apps that users access""], [""Azure Monitor"", ""system"", ""collects information on Logic Apps events and performance""], [""Azure Key Vault"", ""system"", ""database credentials""]], ""relationships"": [[""API Management"", ""calls"", ""Logic Apps"", ""routes the HTTP requests to Logic Apps""], [""Logic Apps"", ""calls"", ""Azure Key Vault"", ""Logic Apps uses secured template parameters to retrieve database credentials from Azure Key Vault""], [""Logic Apps"", ""calls"", ""on-premises data gateway"", ""send the database credentials and a database statement to the on-premises data gateway""], [""on-premises data gateway"", ""calls"", ""SQL Server"", ""connects to a SQL Server database""], [""Azure Monitor"", ""calls"", ""Logic Apps"", ""collects information on Logic Apps events and performance""]]}","```json
{
  ""entities"": [
    [""API Management"", ""system"", ""Handles HTTP requests and securely routes them.""],
    [""Logic Apps"", ""system"", ""Triggers runs for HTTP requests, retrieves credentials, sends data to gateway.""],
    [""Azure Key Vault"", ""component"", ""Stores database credentials securely.""],
    [""on-premises data gateway"", ""component"", ""Connects to SQL Server database and runs statements.""],
    [""SQL Server database"", ""system"", ""Stores data and makes it available to apps.""],
    [""Azure Monitor"", ""system"", ""Collects information on Logic Apps events and performance.""]
  ],
  ""relationships"": [
    [""API Management"", ""calls"", ""Logic Apps""],
    [""Logic Apps"", ""called-from"", ""API Management""],
    [""Logic Apps"", ""contains"", ""Azure Key Vault""],
    [""Logic Apps"", ""calls"", ""on-premises data gateway""],
    [""on-premises data gateway"", ""part-of"", ""SQL Server database""],
    [""SQL Server database"", ""contains"", ""on-premises data gateway""],
    [""Logic Apps"", ""called-from"", ""Azure Monitor""]
  ]
}
```","```json
{
  ""entities"": [
    [""API Management"", ""system"", ""Handles HTTP requests and securely routes them.""],
    [""Logic Apps"", ""system"", ""Triggers runs for HTTP requests, retrieves credentials, sends data to gateway.""],
    [""Azure Key Vault"", ""component"", ""Stores database credentials securely.""],
    [""on-premises data gateway"", ""component"", ""Connects to SQL Server database and runs statements.""],
    [""SQL Server database"", ""system"", ""Stores data and makes it available to apps.""],
    [""Azure Monitor"", ""system"", ""Collects information on Logic Apps events and performance.""]
  ],
  ""relationships"": [
    [""API Management"", ""calls"", ""Logic Apps""],
    [""Logic Apps"", ""called-from"", ""API Management""],
    [""Logic Apps"", ""contains"", ""Azure Key Vault""],
    [""Logic Apps"", ""calls"", ""on-premises data gateway""],
    [""on-premises data gateway"", ""part-of"", ""SQL Server database""],
    [""SQL Server database"", ""contains"", ""on-premises data gateway""],
    [""Logic Apps"", ""called-from"", ""Azure Monitor""]
  ]
}
```",4.483192765008425
94,mistral-nemo,../IMAGES NEW/Azure/13 Azure Secure Research.txt,"
    Data owners upload datasets into a public blob storage account. The data is encrypted by using Microsoft-managed keys.

    Azure Data Factory uses a trigger that starts copying of the uploaded dataset to a specific location (import path) on another storage account with security controls. The storage account can only be reached through a private endpoint. Also, it's accessed by a service principal with limited permissions. Data Factory deletes the original copy making the dataset immutable.

    Researchers access the secure environment through a streaming application using Azure Virtual Desktop as a privileged jump box.

    The dataset in the secure storage account is presented to the data science VMs provisioned in a secure network environment for research work. Much of the data preparation is done on those VMs.

    The secure environment has Azure Machine Learning compute that can access the dataset through a private endpoint for users for Azure Machine Learning capabilities, such as to train, deploy, automate, and manage machine learning models. At this point, models are created that meet regulatory guidelines. All model data is de-identified by removing personal information.

    Models or de-identified data is saved to a separate location on the secure storage (export path). When new data is added to the export path, a logic app is triggered. In this architecture, the logic app is outside the secure environment because no data is sent to the logic app. Its only function is to send notification and start the manual approval process.

    The app starts an approval process requesting a review of data that is queued to be exported. The manual reviewers ensure that sensitive data isn't exported. After the review process, the data is either approved or denied.

    Note

    If an approval step is not required on exfiltration, the logic app step could be omitted.

    If the de-identified data is approved, it's sent to the Data Factory instance.

    Data Factory moves the data to the public storage account in a separate container to allow external researchers to have access to their exported data and models. Alternately, you can provision another storage account in a lower security environment.

","{""entities"": [[""datasets"", ""component"", ""Data owners upload datasets into a public blob storage account""], [""public blob storage account"", ""system"", ""Data owners upload datasets into a public blob storage account""], [""Azure Data Factory"", ""system"", ""Azure Data Factory uses a trigger that starts copying of the uploaded dataset to a specific location""], [""storage account"", ""system"", ""Azure Data Factory uses a trigger that starts copying of the uploaded dataset to a specific location (import path) on another storage account with security controls""], [""copied dataset"", ""system"", ""Azure Data Factory uses a trigger that starts copying of the uploaded dataset to a specific location (import path) on another storage account with security controls""], [""private endpoint"", ""component"", ""The storage account can only be reached through a private endpoint.""], [""service principal"", ""component"", ""Also, it's accessed by a service principal with limited permissions.""], [""streaming application"", ""component"", ""access the secure environment through a streaming application""], [""Azure Virtual Desktop"", ""component"", ""Azure Virtual Desktop as a privileged jump box""], [""data science VMs"", ""component"", ""data science VMs provisioned in a secure network environment""], [""Azure Machine Learning compute"", ""component"", ""The secure environment has Azure Machine Learning compute that can access the dataset""], [""secure network environment"", ""system"", ""data science VMs provisioned in a secure network environment""], [""machine learning models"", ""component"", ""At this point, models are created that meet regulatory guidelines""], [""de-identified data"", ""component"", ""Models or de-identified data is saved to a separate location on the secure storage (export path)""], [""logic app"", ""component"", ""When new data is added to the export path, a logic app is triggered""], [""separate container"", ""component"", ""Data Factory moves the data to the public storage account in a separate container""], [""moved data"", ""component"", ""Data Factory moves the data to the public storage account in a separate container""], [""Data owners"", ""person"", ""Data owners upload datasets into a public blob storage account""], [""Researchers"", ""person"", ""Researchers access the secure environment through a streaming application using Azure Virtual Desktop as a privileged jump box""], [""manual reviewers"", ""person"", ""The manual reviewers ensure that sensitive data isn't exported.""], [""Users"", ""person"", ""The secure environment has Azure Machine Learning compute that can access the dataset""]], ""relationships"": [[""datasets"", ""part-of"", ""public blob storage account"", ""Data owners upload datasets into a public blob storage account""], [""Data owners"", ""calls"", ""datasets"", ""Data owners upload datasets into a public blob storage account""], [""Azure Data Factory"", ""calls"", ""datasets"", ""Azure Data Factory uses a trigger that starts copying of the uploaded dataset""], [""storage account"", ""contains"", ""copied dataset"", ""opying of the uploaded dataset to a specific location (import path) on another storage account with security controls""], [""Azure Data Factory"", ""calls"", ""copied dataset"", ""Azure Data Factory uses a trigger that starts copying of the uploaded dataset to a specific location""], [""private endpoint"", ""calls"", ""storage account"", ""The storage account can only be reached through a private endpoint""], [""storage account"", ""is-called-from"", ""service principal"", ""Also, it's accessed by a service principal with limited permissions""], [""Researchers"", ""calls"", ""Azure Virtual Desktop"", "" Researchers access the secure environment through a streaming application""], [""Azure Virtual Desktop"", ""calls"", ""streaming application"", ""through a streaming application using Azure Virtual Desktop""], [""streaming application"", ""calls"", ""storage account"", ""Researchers access the secure environment through a streaming application using Azure Virtual Desktop as a privileged jump box""], [""data science VMs"", ""part-of"", ""secure network environment"", ""The dataset in the secure storage account is presented to the data science VMs""], [""data science VMs"", ""calls"", ""copied dataset"", "" The dataset in the secure storage account is presented to the data science VMs""], [""secure network environment"", ""contains"", ""Azure Machine Learning compute"", ""The secure environment has Azure Machine Learning compute that can access the dataset""], [""Azure Machine Learning compute"", ""calls"", ""Azure Machine Learning compute"", ""The secure environment has Azure Machine Learning compute that can access the dataset""], [""machine learning models"", ""part-of"", ""storage account"", ""Models or de-identified data is saved to a separate location on the secure storage (export path)""], [""machine learning models"", ""calls"", ""logic app"", ""When new data is added to the export path, a logic app is triggered""], [""logic app"", ""calls"", ""manual reviewers"", ""The app starts an approval process requesting a review of data that is queued to be exported.""], [""public blob storage account"", ""contains"", ""separate container"", ""Data Factory moves the data to the public storage account in a separate container""], [""Azure Data Factory"", ""calls"", ""de-identified data"", ""Data Factory moves the data to the public storage account in a separate container to allow external researchers to have access to their exported data and models""], [""separate container"", ""contains"", ""moved data"", ""Data Factory moves the data to the public storage account in a separate container""], [""Azure Data Factory"", ""calls"", ""moved data"", ""Data Factory moves the data to the public storage account in a separate container to allow external researchers to have access to their exported data and models""], [""Users"", ""calls"", ""Azure Machine Learning compute"", ""The secure environment has Azure Machine Learning compute that can access the dataset""]]}","{
  ""entities"": [
    [""Azure Blob Storage"", ""system"", ""Public blob storage for data upload.""],
    [""Microsoft-managed keys"", ""component"", ""Used to encrypt data.""],
    [""Azure Data Factory"", ""system"", ""Copies uploaded datasets and deletes original copies.""],
    [""Trigger"", ""component"", ""Starts copying of dataset by Azure Data Factory.""],
    [""Import Path"", ""component"", ""Specific location in secure storage account for copied dataset.""],
    [""Secure Storage Account"", ""system"", ""Accessible through private endpoint with service principal access.""],
    [""Private Endpoint"", ""component"", ""Enables secure access to storage account.""],
    [""Service Principal"", ""person"", ""Has limited permissions to access secure storage account.""],
    [""Azure Virtual Desktop"", ""system"", ""Provides privileged jump box for researchers' access.""],
    [""Streaming Application"", ""component"", ""Accesses secure environment through Azure Virtual Desktop.""],
    [""Researchers"", ""person"", ""Access secure environment for data preparation on Data Science VMs.""],
    [""Data Science VMs"", ""system"", ""Provisioned in secure network environment for research work.""],
    [""Azure Machine Learning compute"", ""component"", ""Accesses dataset through private endpoint.""],
    [""Machine Learning Models"", ""component"", ""Created and managed using Azure Machine Learning capabilities.""],
    [""De-identified Data"", ""component"", ""Data with personal information removed.""],
    [""Export Path"", ""component"", ""Separate location on secure storage for saving models or de-identified data.""],
    [""Logic App"", ""system"", ""Triggers approval process when new data is added to export path.""],
    [""Approval Process"", ""component"", ""Manual review of queued data before exporting.""],
    [""Data Reviewers"", ""person"", ""Ensure sensitive data isn't exported in approval process.""],
    [""Public Storage Account"", ""system"", ""Separate container for external access to exported data and models.""]
  ],
  ""relationships"": [
    [""Azure Blob Storage"", ""contains"", ""Microsoft-managed keys""],
    [""Azure Data Factory"", ""calls"", ""Trigger""],
    [""Secure Storage Account"", ""contains"", ""Import Path""],
    [""Secure Storage Account"", ""contains"", ""Export Path""],
    [""Azure Virtual Desktop"", ""called-from"", ""Streaming Application""],
    [""Data Science VMs"", ""part-of"", ""Azure Machine Learning compute""],
    [""Logic App"", ""called-from"", ""Approval Process""],
    [""Public Storage Account"", ""calls"", ""Export Path""]
  ]
}","{
  ""entities"": [
    [""Azure Blob Storage"", ""system"", ""Public blob storage for data upload.""],
    [""Microsoft-managed keys"", ""component"", ""Used to encrypt data.""],
    [""Azure Data Factory"", ""system"", ""Copies uploaded datasets and deletes original copies.""],
    [""Trigger"", ""component"", ""Starts copying of dataset by Azure Data Factory.""],
    [""Import Path"", ""component"", ""Specific location in secure storage account for copied dataset.""],
    [""Secure Storage Account"", ""system"", ""Accessible through private endpoint with service principal access.""],
    [""Private Endpoint"", ""component"", ""Enables secure access to storage account.""],
    [""Service Principal"", ""person"", ""Has limited permissions to access secure storage account.""],
    [""Azure Virtual Desktop"", ""system"", ""Provides privileged jump box for researchers' access.""],
    [""Streaming Application"", ""component"", ""Accesses secure environment through Azure Virtual Desktop.""],
    [""Researchers"", ""person"", ""Access secure environment for data preparation on Data Science VMs.""],
    [""Data Science VMs"", ""system"", ""Provisioned in secure network environment for research work.""],
    [""Azure Machine Learning compute"", ""component"", ""Accesses dataset through private endpoint.""],
    [""Machine Learning Models"", ""component"", ""Created and managed using Azure Machine Learning capabilities.""],
    [""De-identified Data"", ""component"", ""Data with personal information removed.""],
    [""Export Path"", ""component"", ""Separate location on secure storage for saving models or de-identified data.""],
    [""Logic App"", ""system"", ""Triggers approval process when new data is added to export path.""],
    [""Approval Process"", ""component"", ""Manual review of queued data before exporting.""],
    [""Data Reviewers"", ""person"", ""Ensure sensitive data isn't exported in approval process.""],
    [""Public Storage Account"", ""system"", ""Separate container for external access to exported data and models.""]
  ],
  ""relationships"": [
    [""Azure Blob Storage"", ""contains"", ""Microsoft-managed keys""],
    [""Azure Data Factory"", ""calls"", ""Trigger""],
    [""Secure Storage Account"", ""contains"", ""Import Path""],
    [""Secure Storage Account"", ""contains"", ""Export Path""],
    [""Azure Virtual Desktop"", ""called-from"", ""Streaming Application""],
    [""Data Science VMs"", ""part-of"", ""Azure Machine Learning compute""],
    [""Logic App"", ""called-from"", ""Approval Process""],
    [""Public Storage Account"", ""calls"", ""Export Path""]
  ]
}",9.074491681996733
95,mistral-nemo,../IMAGES NEW/Azure/14 Azure Call Center Analytics.txt,"
    A phone call between an agent and a customer is recorded and stored in Azure Blob Storage. Audio files are uploaded to an Azure Storage account via a supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API.

    Azure AI Speech is used to transcribe audio files in Batch mode asynchronously with speaker diarization enabled. The transcription results are persisted in Blob Storage.

    Azure AI Language is used to detect and redact personal data in the transcript.

    For batch mode transcription and personal data detection and redaction, use the AI services Ingestion Client tool. The Ingestion Client tool uses a no-code approach for call center transcription.

    Azure OpenAI is used to process the transcript and extract entities, summarize the conversation, and analyze sentiments. The processed output is stored in Blob Storage and then analyzed and visualized by using other services. You can also store the output in a datastore for keeping track of metadata and for reporting. Use Azure OpenAI to process the stored transcription information.

    Power BI or a custom web application that's hosted by App Service is used to visualize the output. Both options provide near real-time insights. You can store this output in a customer relationship management (CRM), so agents have contextual information about why the customer called and can quickly solve potential problems. This process is fully automated, which saves the agents time and effort.

","{""entities"": [[""phone call"", ""component"", ""A phone call between an agent and a customer is recorded""], [""agent"", ""person"", ""A phone call between an agent and a customer is recorded""], [""customer"", ""person"", ""A phone call between an agent and a customer is recorded""], [""Azure Blob Storage"", ""system"", ""is recorded and stored in Azure Blob Storage""], [""Audio files"", ""system"", ""Audio files are uploaded to an Azure Storage account via a supported method""], [""supported method"", ""component"", ""Audio files are uploaded to an Azure Storage account via a supported method""], [""UI-based tool"", ""component"", ""supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""Azure Storage Explorer"", ""component"", ""supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""Storage SDK"", ""component"", ""supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""API"", ""component"", ""supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""Azure AI Speech"", ""component"", ""transcribe audio files in Batch mode asynchronously""], [""transcription results"", ""component"", ""The transcription results are persisted in Blob Storage.""], [""Azure AI Language"", ""component"", ""Azure AI Language is used to detect and redact personal data in the transcript.""], [""AI services Ingestion Client tool"", ""component"", ""For batch mode transcription and personal data detection and redaction, use the AI services Ingestion Client tool""], [""Azure OpenAI"", ""component"", ""Azure OpenAI is used to process the transcript and extract entities, summarize the conversation, and analyze sentiments.""], [""Azure OpenAI output"", ""component"", ""The processed output is stored in Blob Storage and then analyzed and visualized by using other services.""], [""other services"", ""component"", ""The processed output is stored in Blob Storage and then analyzed and visualized by using other services.""], [""App Service"", ""system"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""Power BI"", ""system"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""custom web application"", ""system"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""Azure OpenAI output 2"", ""component"", ""You can also store the output in a datastore for keeping track of metadata and for reporting""], [""datastore"", ""component"", ""You can also store the output in a datastore for keeping track of metadata and for reporting""], [""customer relationship management (CRM)"", ""system"", ""You can store this output in a customer relationship management (CRM)""], [""Azure OpenAI output 3"", ""component"", ""You can store this output in a customer relationship management (CRM)""]], ""relationships"": [[""agent"", ""calls"", ""phone call"", ""A phone call between an agent and a customer is recorded""], [""customer"", ""calls"", ""phone call"", ""A phone call between an agent and a customer is recorded""], [""phone call"", ""part-of"", ""Azure Blob Storage"", ""is recorded and stored in Azure Blob Storage""], [""Audio files"", ""part-of"", ""Azure Blob Storage"", ""Audio files are uploaded to an Azure Storage account via a supported method""], [""supported method"", ""calls"", ""Audio files"", ""Audio files are uploaded to an Azure Storage account via a supported method""], [""supported method"", ""contains"", ""UI-based tool"", ""upported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""supported method"", ""contains"", ""Azure Storage Explorer"", ""upported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""supported method"", ""contains"", ""Storage SDK"", ""upported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""supported method"", ""contains"", ""API"", ""supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""Azure AI Speech"", ""calls"", ""Audio files"", ""transcribe audio files in Batch mode asynchronously""], [""Azure Blob Storage"", ""contains"", ""transcription results"", ""The transcription results are persisted in Blob Storage.""], [""Azure AI Speech"", ""calls"", ""transcription results"", ""The transcription results are persisted in Blob Storage.""], [""Azure AI Language"", ""calls"", ""transcription results"", ""Azure AI Language is used to detect and redact personal data in the transcript.""], [""AI services Ingestion Client tool"", ""calls"", ""transcription results"", ""For batch mode transcription and personal data detection and redaction, use the AI services Ingestion Client tool""], [""Azure OpenAI"", ""calls"", ""transcription results"", ""Azure OpenAI is used to process the transcript and extract entities, summarize the conversation, and analyze sentiments.""], [""Azure OpenAI"", ""calls"", ""Azure OpenAI output"", ""The processed output is stored in Blob Storage and then analyzed and visualized by using other services.""], [""Azure Blob Storage"", ""contains"", ""Azure OpenAI output"", ""The processed output is stored in Blob Storage and then analyzed and visualized by using other services.""], [""other services"", ""calls"", ""Azure OpenAI output"", ""The processed output is stored in Blob Storage and then analyzed and visualized by using other services.""], [""Power BI"", ""part-of"", ""App Service"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""custom web application"", ""part-of"", ""App Service"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""custom web application"", ""calls"", ""Azure OpenAI output"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""Power BI"", ""calls"", ""Azure OpenAI output"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""agent"", ""calls"", ""customer relationship management (CRM)"", ""You can store this output in a customer relationship management (CRM), so agents have contextual information about why the customer called and can quickly solve potential problems""], [""Azure OpenAI output 2"", ""part-of"", ""datastore"", ""You can also store the output in a datastore for keeping track of metadata and for reporting""], [""Azure OpenAI output 3"", ""part-of"", ""customer relationship management (CRM)"", ""You can also store the output in a datastore for keeping track of metadata and for reporting""], [""Azure OpenAI output"", ""calls"", ""Azure OpenAI output 2"", ""You can also store the output in a datastore for keeping track of metadata and for reporting""], [""Azure OpenAI output"", ""calls"", ""Azure OpenAI output 3"", ""You can store this output in a customer relationship management (CRM), so agents have contextual information about why the customer called and can quickly solve potential problems""]]}","Here's the extracted entities and relationships in JSON format:

```json
{
  ""entities"": [
    [""Azure Blob Storage"", ""system""],
    [""Audio files"", ""component""],
    [""Azure Storage account"", ""system""],
    [""Azure Storage Explorer"", ""component""],
    [""Storage SDK or API"", ""component""],
    [""Azure AI Speech"", ""system""],
    [""Batch mode"", ""component""],
    [""Speaker diarization"", ""component""],
    [""Azure AI Language"", ""system""],
    [""Personal data"", ""entity""],
    [""AI services Ingestion Client tool"", ""component""],
    [""No-code approach"", ""component""],
    [""Azure OpenAI"", ""system""],
    [""Entities"", ""entity""],
    [""Summarization"", ""component""],
    [""Sentiment analysis"", ""component""],
    [""Blob Storage"", ""system""],
    [""Metadata"", ""entity""],
    [""Reporting"", ""entity""],
    [""Power BI"", ""system""],
    [""App Service"", ""system""],
    [""Web application"", ""component""],
    [""Real-time insights"", ""component""],
    [""CRM"", ""system""]
  ],
  ""relationships"": [
    [""Azure Blob Storage"", ""contains"", ""Audio files""],
    [""Azure Storage account"", ""part-of"", ""Azure Blob Storage""],
    [""Azure AI Speech"", ""calls"", ""Batch mode""],
    [""Batch mode"", ""called-from"", ""Azure AI Speech""],
    [""Azure AI Language"", ""calls"", ""Personal data""],
    [""Personal data"", ""called-from"", ""Azure AI Language""],
    [""AI services Ingestion Client tool"", ""part-of"", ""Azure AI Speech""],
    [""Azure AI Speech"", ""contains"", ""AI services Ingestion Client tool""],
    [""Azure OpenAI"", ""calls"", ""Entities""],
    [""Entities"", ""called-from"", ""Azure OpenAI""],
    [""Azure OpenAI"", ""calls"", ""Summarization""],
    [""Summarization"", ""called-from"", ""Azure OpenAI""],
    [""Azure OpenAI"", ""calls"", ""Sentiment analysis""],
    [""Sentiment analysis"", ""called-from"", ""Azure OpenAI""],
    [""Blob Storage"", ""contains"", ""Metadata""],
    [""Metadata"", ""part-of"", ""Blob Storage""],
    [""Blob Storage"", ""contains"", ""Reporting""],
    [""Reporting"", ""part-of"", ""Blob Storage""],
    [""Power BI"", ""calls"", ""Real-time insights""],
    [""Real-time insights"", ""called-from"", ""Power BI""],
    [""App Service"", ""contains"", ""Web application""],
    [""Web application"", ""part-of"", ""App Service""],
    [""CRM"", ""contains"", ""Real-time insights""]
  ]
}
```","Here's the extracted entities and relationships in JSON format:

```json
{
  ""entities"": [
    [""Azure Blob Storage"", ""system""],
    [""Audio files"", ""component""],
    [""Azure Storage account"", ""system""],
    [""Azure Storage Explorer"", ""component""],
    [""Storage SDK or API"", ""component""],
    [""Azure AI Speech"", ""system""],
    [""Batch mode"", ""component""],
    [""Speaker diarization"", ""component""],
    [""Azure AI Language"", ""system""],
    [""Personal data"", ""entity""],
    [""AI services Ingestion Client tool"", ""component""],
    [""No-code approach"", ""component""],
    [""Azure OpenAI"", ""system""],
    [""Entities"", ""entity""],
    [""Summarization"", ""component""],
    [""Sentiment analysis"", ""component""],
    [""Blob Storage"", ""system""],
    [""Metadata"", ""entity""],
    [""Reporting"", ""entity""],
    [""Power BI"", ""system""],
    [""App Service"", ""system""],
    [""Web application"", ""component""],
    [""Real-time insights"", ""component""],
    [""CRM"", ""system""]
  ],
  ""relationships"": [
    [""Azure Blob Storage"", ""contains"", ""Audio files""],
    [""Azure Storage account"", ""part-of"", ""Azure Blob Storage""],
    [""Azure AI Speech"", ""calls"", ""Batch mode""],
    [""Batch mode"", ""called-from"", ""Azure AI Speech""],
    [""Azure AI Language"", ""calls"", ""Personal data""],
    [""Personal data"", ""called-from"", ""Azure AI Language""],
    [""AI services Ingestion Client tool"", ""part-of"", ""Azure AI Speech""],
    [""Azure AI Speech"", ""contains"", ""AI services Ingestion Client tool""],
    [""Azure OpenAI"", ""calls"", ""Entities""],
    [""Entities"", ""called-from"", ""Azure OpenAI""],
    [""Azure OpenAI"", ""calls"", ""Summarization""],
    [""Summarization"", ""called-from"", ""Azure OpenAI""],
    [""Azure OpenAI"", ""calls"", ""Sentiment analysis""],
    [""Sentiment analysis"", ""called-from"", ""Azure OpenAI""],
    [""Blob Storage"", ""contains"", ""Metadata""],
    [""Metadata"", ""part-of"", ""Blob Storage""],
    [""Blob Storage"", ""contains"", ""Reporting""],
    [""Reporting"", ""part-of"", ""Blob Storage""],
    [""Power BI"", ""calls"", ""Real-time insights""],
    [""Real-time insights"", ""called-from"", ""Power BI""],
    [""App Service"", ""contains"", ""Web application""],
    [""Web application"", ""part-of"", ""App Service""],
    [""CRM"", ""contains"", ""Real-time insights""]
  ]
}
```",9.213326922006672
96,mistral-nemo,../IMAGES NEW/Azure/08 Azure Business Processes.txt,"
The data flows through the solution as follows:

    The airline system communicates with a custom API hosted in Azure API Management.
    A custom API coordinator receives notifications and handles incoming messages from the airline system. It sends them to Power Apps, where flights are assigned to Microsoft Teams channels.
    When a user selects a flight to monitor, or when the system assigns the user to a flight, the system queues a Graph API call in an Azure Storage Account queue for further processing.
    Azure Functions runs the Graph API calls based on the incoming messages in the storage queue, sending notifications to Teams, and also streams all events to an Azure Event Hubs for further analytics.
    The airline's notification system is managed by a custom bot messaging service that employs Azure Bot Service.
    Custom bots send flight updates to users in Teams.
    An Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs, ultimately generating insightful reports with Power BI.

","{""entities"": [[""airline system"", ""system"", ""communicates with a custom API hosted in Azure API Management""], [""custom API"", ""component"", ""communicates with a custom API hosted in Azure API Management""], [""Azure API Management"", ""system"", ""communicates with a custom API hosted in Azure API Management""], [""custom API coordinator"", ""system"", ""receives notifications and handles incoming messages from the airline system""], [""Power Apps"", ""system"", ""where flights are assigned to Microsoft Teams channels""], [""Microsoft Teams channels"", ""system"", ""where flights are assigned to Microsoft Teams channels""], [""Storage Account queue"", ""system"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing.""], [""Graph API call"", ""system"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing.""], [""Azure Functions"", ""system"", ""runs the Graph API calls based on the incoming messages in the storage queue""], [""Azure Event Hubs"", ""system"", ""Azure Event Hubs for further analytics""], [""notification system"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""custom bot messaging service"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""Azure Bot Service"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""Users"", ""person"", ""selects a flight to monitor, or when the system assigns the user to a flight""], [""Azure Data Lake storage"", ""system"", ""offers long-term retention and micro-batch processing of events from Event Hubs""], [""Power BI"", ""system"", ""generating insightful reports""]], ""relationships"": [[""Azure API Management"", ""contains"", ""custom API"", ""custom API hosted in Azure API Management""], [""airline system"", ""calls"", ""custom API"", ""communicates with a custom API""], [""custom API coordinator"", ""is-called-from"", ""airline system"", ""receives notifications and handles incoming messages from the airline system""], [""Power Apps"", ""calls"", ""Microsoft Teams channels"", ""Power Apps, where flights are assigned to Microsoft Teams channels""], [""airline system"", ""calls"", ""Graph API call"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing""], [""Azure Functions"", ""calls"", ""Graph API call"", ""runs the Graph API calls based on the incoming messages in the storage queue""], [""Azure Functions"", ""calls"", ""Storage Account queue"", ""based on the incoming messages in the storage queue""], [""Azure Functions"", ""calls"", ""Microsoft Teams channels"", ""sending notifications to Teams""], [""Azure Functions"", ""calls"", ""Azure Event Hubs"", ""also streams all events to an Azure Event Hubs for further analytics""], [""notification system"", ""is-called-from"", ""custom bot messaging service"", ""managed by a custom bot messaging service""], [""custom bot messaging service"", ""calls"", ""Azure Bot Service"", ""custom bot messaging service that employs Azure Bot Service""], [""custom bot messaging service"", ""calls"", ""Microsoft Teams channels"", ""Custom bots send flight updates to users in Teams.""], [""Microsoft Teams channels"", ""calls"", ""Users"", ""Custom bots send flight updates to users in Teams.""], [""Azure Data Lake storage"", ""is-called-from"", ""Azure Event Hubs"", ""Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs""], [""Azure Data Lake storage"", ""calls"", ""Power BI"", ""Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs, ultimately generating insightful reports with Power BI""]]}","Based on the provided context, here's the extracted entities and relationships in JSON format:

```json
{
  ""entities"": [
    [""Airline System"", ""system""],
    [""Custom API Coordinator"", ""component""],
    [""Power Apps"", ""system""],
    [""Microsoft Teams"", ""system""],
    [""Azure Storage Account Queue"", ""system""],
    [""Azure Functions"", ""system""],
    [""Azure Event Hubs"", ""system""],
    [""Custom Bot Messaging Service"", ""system""],
    [""Azure Data Lake Storage"", ""system""],
    [""Power BI"", ""system""]
  ],
  ""relationships"": [
    [""Airline System"", ""calls"", ""Custom API Coordinator""],
    [""Custom API Coordinator"", ""sends-to"", ""Power Apps""],
    [""Power Apps"", ""assigns-flights-to"", ""Microsoft Teams""],
    [""Azure Storage Account Queue"", ""queues-calls-for"", ""Azure Functions""],
    [""Azure Functions"", ""runs-calls-on-behalf-of"", ""Airline System""],
    [""Azure Functions"", ""streams-events-to"", ""Azure Event Hubs""],
    [""Custom Bot Messaging Service"", ""uses"", ""Azure Bot Service""],
    [""Custom Bot Messaging Service"", ""sends-updates-to"", ""Microsoft Teams""],
    [""Azure Event Hubs"", ""generates-reports-with"", ""Power BI""]
  ]
}
```

I've assumed the following relationships based on the text:

- ""calls"": Initiated by Airline System to Custom API Coordinator
- ""sends-to"": From Custom API Coordinator to Power Apps
- ""assigns-flights-to"": From Power Apps to Microsoft Teams
- ""queues-calls-for"": From Azure Storage Account Queue to Azure Functions (inferred as a part-of relationship)
- ""runs-calls-on-behalf-of"": From Azure Functions on behalf of Airline System (inferred from the queue processing)
- ""streams-events-to"": From Azure Functions to Azure Event Hubs
- ""uses"": From Custom Bot Messaging Service to Azure Bot Service
- ""sends-updates-to"": From Custom Bot Messaging Service to Microsoft Teams
- ""generates-reports-with"": From Azure Event Hubs with Power BI","Based on the provided context, here's the extracted entities and relationships in JSON format:

```json
{
  ""entities"": [
    [""Airline System"", ""system""],
    [""Custom API Coordinator"", ""component""],
    [""Power Apps"", ""system""],
    [""Microsoft Teams"", ""system""],
    [""Azure Storage Account Queue"", ""system""],
    [""Azure Functions"", ""system""],
    [""Azure Event Hubs"", ""system""],
    [""Custom Bot Messaging Service"", ""system""],
    [""Azure Data Lake Storage"", ""system""],
    [""Power BI"", ""system""]
  ],
  ""relationships"": [
    [""Airline System"", ""calls"", ""Custom API Coordinator""],
    [""Custom API Coordinator"", ""sends-to"", ""Power Apps""],
    [""Power Apps"", ""assigns-flights-to"", ""Microsoft Teams""],
    [""Azure Storage Account Queue"", ""queues-calls-for"", ""Azure Functions""],
    [""Azure Functions"", ""runs-calls-on-behalf-of"", ""Airline System""],
    [""Azure Functions"", ""streams-events-to"", ""Azure Event Hubs""],
    [""Custom Bot Messaging Service"", ""uses"", ""Azure Bot Service""],
    [""Custom Bot Messaging Service"", ""sends-updates-to"", ""Microsoft Teams""],
    [""Azure Event Hubs"", ""generates-reports-with"", ""Power BI""]
  ]
}
```

I've assumed the following relationships based on the text:

- ""calls"": Initiated by Airline System to Custom API Coordinator
- ""sends-to"": From Custom API Coordinator to Power Apps
- ""assigns-flights-to"": From Power Apps to Microsoft Teams
- ""queues-calls-for"": From Azure Storage Account Queue to Azure Functions (inferred as a part-of relationship)
- ""runs-calls-on-behalf-of"": From Azure Functions on behalf of Airline System (inferred from the queue processing)
- ""streams-events-to"": From Azure Functions to Azure Event Hubs
- ""uses"": From Custom Bot Messaging Service to Azure Bot Service
- ""sends-updates-to"": From Custom Bot Messaging Service to Microsoft Teams
- ""generates-reports-with"": From Azure Event Hubs with Power BI",7.5591829949989915
97,mistral-nemo,../IMAGES NEW/Azure/07 Azure internal APIs original.txt,"
The data flows as follows:

    Developers check in code to a GitHub repository that's connected to a CI/CD pipeline agent that's installed on an Azure VM.
    The agent pushes the build to the API application that's hosted on ILB ASE.
    Azure API Management consumes the preceding APIs via HOST headers that are specified in API Management policy.
    API Management uses the App Service Environment's DNS name for all the APIs.
    Application Gateway exposes API Management's developer and API portal.
    Azure Private DNS is used to route the traffic internally between ASE, API Management, and Application Gateway.
    External users utilize the exposed developer portal to consume the APIs via Application Gateway's public IP.

","{""entities"": [[""GitHub repository"", ""system"", """"], [""Developers"", ""person"", """"], [""External users"", ""person"", """"], [""CI/CD pipeline agent"", ""system"", """"], [""Azure VM"", ""system"", """"], [""ILB ASE"", ""system"", """"], [""API application"", ""component"", """"], [""Azure API Management"", ""system"", ""consumes the preceding APIs via HOST headers""], [""App Service Environment"", ""component"", """"], [""Application Gateway"", ""component"", ""exposes API Management's developer and API portal""], [""Developer portal"", ""component"", ""API Management's developer and API portal""], [""API portal"", ""component"", ""API Management's developer and API portal""], [""Application Gateway"", ""component"", ""exposes API Management's developer and API portal""], [""Azure Private DNS"", ""component"", ""used to route the traffic internally between ASE, API Management, and Application Gateway""]], ""relationships"": [[""Azure VM"", ""contains"", ""CI/CD pipeline agent"", ""installed on an Azure VM""], [""API application"", ""part-of"", ""ILB ASE"", ""API application that's hosted on ILB ASE""], [""GitHub repository"", ""calls"", ""CI/CD pipeline agent"", ""GitHub repository that's connected to a CI/CD pipeline agent""], [""CI/CD pipeline agent"", ""calls"", ""API application"", ""agent pushes the build to the API application""], [""Azure API Management"", ""calls"", ""App Service Environment"", ""uses the App Service Environment's DNS name for all the APIs""], [""External users"", ""calls"", ""Application Gateway"", """"], [""Application Gateway"", ""calls"", ""API application"", ""to consume the APIs via Application Gateway's public IP""], [""Azure API Management"", ""contains"", ""Developer portal"", ""API Management's developer and API portal""], [""Azure API Management"", ""contains"", ""API portal"", ""API Management's developer and API portal""], [""Application Gateway"", ""calls"", ""API portal"", ""exposes API Management's developer and API portal.""], [""Application Gateway"", ""calls"", ""Developer portal"", ""exposes API Management's developer and API portal.""], [""Azure Private DNS"", ""calls"", ""Azure API Management"", ""route the traffic internally between ASE, API Management, and Application Gateway""], [""Azure Private DNS"", ""calls"", ""Application Gateway"", ""route the traffic internally between ASE, API Management, and Application Gateway""]]}","Here's the extracted entities and relationships in JSON format:

```json
{
  ""entities"": [
    [""Developers"", ""person""],
    [""GitHub"", ""system""],
    [""CI/CD pipeline agent"", ""component""],
    [""Azure VM"", ""system""],
    [""API application"", ""component""],
    [""ILB ASE"", ""system""],
    [""Azure API Management"", ""system""],
    [""HOST headers"", ""component""],
    [""App Service Environment"", ""system""],
    [""Application Gateway"", ""system""],
    [""Azure Private DNS"", ""system""],
    [""External users"", ""person""]
  ],
  ""relationships"": [
    [""Developers"", ""check-in"", ""GitHub"", ""Checking in code""],
    [""CI/CD pipeline agent"", ""part-of"", ""Azure VM"", ""Installed on Azure VM""],
    [""CI/CD pipeline agent"", ""pushes-to"", ""API application"", ""Pushing build to API application""],
    [""API application"", ""part-of"", ""ILB ASE"", ""Hosted on ILB ASE""],
    [""Azure API Management"", ""consumes-via"", ""HOST headers"", ""Consuming APIs via HOST headers""],
    [""Azure API Management"", ""uses"", ""App Service Environment"", ""Using App Service Environment's DNS name for APIs""],
    [""Application Gateway"", ""exposes"", ""Azure API Management"", ""Exposing developer and API portal""],
    [""Azure Private DNS"", ""routes-between"", ""ASE, API Management, Application Gateway"", ""Routing traffic internally""]
  ]
}
```","Here's the extracted entities and relationships in JSON format:

```json
{
  ""entities"": [
    [""Developers"", ""person""],
    [""GitHub"", ""system""],
    [""CI/CD pipeline agent"", ""component""],
    [""Azure VM"", ""system""],
    [""API application"", ""component""],
    [""ILB ASE"", ""system""],
    [""Azure API Management"", ""system""],
    [""HOST headers"", ""component""],
    [""App Service Environment"", ""system""],
    [""Application Gateway"", ""system""],
    [""Azure Private DNS"", ""system""],
    [""External users"", ""person""]
  ],
  ""relationships"": [
    [""Developers"", ""check-in"", ""GitHub"", ""Checking in code""],
    [""CI/CD pipeline agent"", ""part-of"", ""Azure VM"", ""Installed on Azure VM""],
    [""CI/CD pipeline agent"", ""pushes-to"", ""API application"", ""Pushing build to API application""],
    [""API application"", ""part-of"", ""ILB ASE"", ""Hosted on ILB ASE""],
    [""Azure API Management"", ""consumes-via"", ""HOST headers"", ""Consuming APIs via HOST headers""],
    [""Azure API Management"", ""uses"", ""App Service Environment"", ""Using App Service Environment's DNS name for APIs""],
    [""Application Gateway"", ""exposes"", ""Azure API Management"", ""Exposing developer and API portal""],
    [""Azure Private DNS"", ""routes-between"", ""ASE, API Management, Application Gateway"", ""Routing traffic internally""]
  ]
}
```",5.53830520901829
98,mistral-nemo,../IMAGES NEW/Azure/16 Azure automate-pdf-forms.txt,"
    A designated Outlook email account receives PDF files as attachments. The arrival of an email triggers a logic app to process the email. The logic app is built by using the capabilities of Azure Logic Apps.
    The logic app uploads the PDF files to a container in Azure Data Lake Storage.
    You can also manually or programmatically upload PDF files to the same PDF container.
    The arrival of a PDF file in the PDF container triggers another logic app to process the PDF forms that are in the PDF file.
    The logic app sends the location of the PDF file to a function app for processing. The function app is built by using the capabilities of Azure Functions.
    The function app receives the location of the file and takes these actions:
        It splits the file into single pages if the file has multiple pages. Each page contains one independent form. Split files are saved to a second container in Data Lake Storage.
        It uses HTTPS POST, an Azure REST API, to send the location of the single-page PDF file to AI Document Intelligence for processing. When Azure AI Document Intelligence completes its processing, it sends a response back to the function app, which places the information into a data structure.
        It creates a JSON data file that contains the response data and stores the file to a third container in Data Lake Storage.
    The forms processing logic app receives the processed response data.
    The forms processing logic app sends the processed data to Azure Cosmos DB, which saves the data in a database and in collections.
    Power BI obtains the data from Azure Cosmos DB and provides insights and dashboards.
    You can implement further processing as needed on the data that's in Azure Cosmos DB.

","{""entities"": [[""designated Outlook email account"", ""component"", ""A designated Outlook email account receives PDF files as attachments""], [""logic app"", ""component"", ""The arrival of an email triggers a logic app to process the email.""], [""Azure Logic Apps"", ""system"", ""The logic app is built by using the capabilities of Azure Logic Apps.""], [""Container"", ""component"", ""The logic app uploads the PDF files to a container in Azure Data Lake Storage""], [""Azure Data Lake Storage"", ""system"", ""The logic app uploads the PDF files to a container in Azure Data Lake Storage""], [""logic app 2"", ""system"", ""The arrival of a PDF file in the PDF container triggers another logic app to process the PDF forms""], [""function app"", ""component"", ""The logic app sends the location of the PDF file to a function app for processing.""], [""Azure Functions"", ""system"", ""The function app is built by using the capabilities of Azure Functions""], [""Azure REST API"", ""component"", ""It uses HTTPS POST, an Azure REST API, to send the location of the single-page PDF file""], [""Container 2"", ""component"", ""Split files are saved to a second container in Data Lake Storage""], [""AI Document Intelligence"", ""component"", ""It uses HTTPS POST, an Azure REST API, to send the location of the single-page PDF file to AI Document Intelligence for processing""], [""Container 3"", ""component"", ""JSON data file that contains the response data and stores the file to a third container in Data Lake Storage""], [""forms processing logic app"", ""component"", ""The forms processing logic app receives the processed response data""], [""Azure Cosmos DB"", ""component"", ""The forms processing logic app sends the processed data to Azure Cosmos DB""], [""database"", ""component"", ""Azure Cosmos DB, which saves the data in a database""], [""Power BI"", ""component"", ""Power BI obtains the data from Azure Cosmos DB and provides insights and dashboards""]], ""relationships"": [[""designated Outlook email account"", ""calls"", ""logic app"", ""The arrival of an email triggers a logic app to process the email.""], [""Azure Logic Apps"", ""contains"", ""logic app"", ""The logic app is built by using the capabilities of Azure Logic Apps.""], [""logic app"", ""calls"", ""Container"", ""The logic app uploads the PDF files to a container in Azure Data Lake Storage""], [""Container"", ""part-of"", ""Azure Data Lake Storage"", ""container in Azure Data Lake Storage""], [""Container"", ""calls"", ""logic app 2"", ""The arrival of a PDF file in the PDF container triggers another logic app""], [""logic app"", ""calls"", ""function app"", ""The logic app sends the location of the PDF file to a function app for processing.""], [""function app"", ""part-of"", ""Azure Functions"", ""container in Azure Data Lake Storage""], [""function app"", ""calls"", ""Container 2"", ""Split files are saved to a second container in Data Lake Storage""], [""Azure Data Lake Storage"", ""contains"", ""Container 2"", ""Split files are saved to a second container in Data Lake Storage""], [""function app"", ""calls"", ""Azure REST API"", ""It uses HTTPS POST, an Azure REST API""], [""Azure REST API"", ""calls"", ""AI Document Intelligence"", ""HTTPS POST, an Azure REST API, to send the location of the single-page PDF file to AI Document Intelligence""], [""Azure Data Lake Storage"", ""contains"", ""Container 3"", ""third container in Data Lake Storage""], [""function app"", ""calls"", ""Container 3"", ""It creates a JSON data file that contains the response data and stores the file to a third container""], [""forms processing logic app"", ""calls"", ""Container 3"", ""The forms processing logic app receives the processed response data""], [""forms processing logic app"", ""calls"", ""Azure Cosmos DB"", ""The forms processing logic app sends the processed data to Azure Cosmos DB""], [""Azure Cosmos DB"", ""calls"", ""database"", ""Azure Cosmos DB, which saves the data in a database""], [""Power BI"", ""calls"", ""Azure Cosmos DB"", ""Power BI obtains the data from Azure Cosmos DB and provides insights and dashboards""]]}","Here's the JSON response based on the provided text:

```json
{
  ""entities"": [
    [""Outlook Email Account"", ""system""],
    [""Logic App (Email Trigger)"", ""component""],
    [""Azure Logic Apps"", ""system""],
    [""PDF Container"", ""component"", ""Azure Data Lake Storage container for PDF files""],
    [""Logic App (PDF Trigger)"", ""component""],
    [""Function App"", ""component""],
    [""Azure Functions"", ""system""],
    [""AI Document Intelligence"", ""component""],
    [""Single-Page PDF Container"", ""component"", ""Azure Data Lake Storage container for single-page PDF files""],
    [""Processed JSON Data Container"", ""component"", ""Azure Data Lake Storage container for processed JSON data files""],
    [""Forms Processing Logic App"", ""component""],
    [""Azure Cosmos DB"", ""system""],
    [""Power BI"", ""component""]
  ],
  ""relationships"": [
    [""Outlook Email Account"", ""calls"", ""Logic App (Email Trigger)""],
    [""Logic App (Email Trigger)"", ""contains"", ""PDF Container""],
    [""PDF Container"", ""calls"", ""Logic App (PDF Trigger)""],
    [""Logic App (PDF Trigger)"", ""part-of"", ""Azure Logic Apps""],
    [""Logic App (PDF Trigger)"", ""calls"", ""Function App""],
    [""Function App"", ""part-of"", ""Azure Functions""],
    [""Function App"", ""called-from"", ""AI Document Intelligence""],
    [""Function App"", ""contains"", ""Single-Page PDF Container""],
    [""Function App"", ""contains"", ""Processed JSON Data Container""],
    [""Forms Processing Logic App"", ""calls"", ""Azure Cosmos DB""],
    [""Azure Cosmos DB"", ""part-of"", ""Power BI""]
  ]
}
```","Here's the JSON response based on the provided text:

```json
{
  ""entities"": [
    [""Outlook Email Account"", ""system""],
    [""Logic App (Email Trigger)"", ""component""],
    [""Azure Logic Apps"", ""system""],
    [""PDF Container"", ""component"", ""Azure Data Lake Storage container for PDF files""],
    [""Logic App (PDF Trigger)"", ""component""],
    [""Function App"", ""component""],
    [""Azure Functions"", ""system""],
    [""AI Document Intelligence"", ""component""],
    [""Single-Page PDF Container"", ""component"", ""Azure Data Lake Storage container for single-page PDF files""],
    [""Processed JSON Data Container"", ""component"", ""Azure Data Lake Storage container for processed JSON data files""],
    [""Forms Processing Logic App"", ""component""],
    [""Azure Cosmos DB"", ""system""],
    [""Power BI"", ""component""]
  ],
  ""relationships"": [
    [""Outlook Email Account"", ""calls"", ""Logic App (Email Trigger)""],
    [""Logic App (Email Trigger)"", ""contains"", ""PDF Container""],
    [""PDF Container"", ""calls"", ""Logic App (PDF Trigger)""],
    [""Logic App (PDF Trigger)"", ""part-of"", ""Azure Logic Apps""],
    [""Logic App (PDF Trigger)"", ""calls"", ""Function App""],
    [""Function App"", ""part-of"", ""Azure Functions""],
    [""Function App"", ""called-from"", ""AI Document Intelligence""],
    [""Function App"", ""contains"", ""Single-Page PDF Container""],
    [""Function App"", ""contains"", ""Processed JSON Data Container""],
    [""Forms Processing Logic App"", ""calls"", ""Azure Cosmos DB""],
    [""Azure Cosmos DB"", ""part-of"", ""Power BI""]
  ]
}
```",6.259192201017868
99,mistral-nemo,../IMAGES NEW/Azure/10 Azure LoB original.txt,"
The data flows through the solution as follows:

    Supplier data stored in CDS is moved to SQL via Data Factory.
    Purchase order (PO) data stored in ERP system is sent to Azure SQL database.
    Azure Functions uses API to surface PO data monthly and creates a task for users to review.
    Power Apps retrieves data from Azure SQL Database through API.
    User reviews and updates POs in Power Apps and sends this data to suppliers through CSV export.
    Power BI reports trends in supplier status.

","{""entities"": [[""Supplier data"", ""component"", ""Supplier data stored in CDS""], [""CDS"", ""system"", "" Supplier data stored in CDS""], [""Azure SQL database"", ""system"", ""moved to SQL via Data Factory""], [""Data Factory"", ""system"", ""moved to SQL via Data Factory""], [""Purchase order (PO)"", ""system"", ""moved to SQL via Data Factory""], [""ERP system"", ""system"", ""Purchase order (PO) data stored in ERP system""], [""Azure Functions"", ""system"", ""uses API to surface PO data monthly and creates a task for users to review""], [""Power Apps"", ""system"", ""retrieves data from Azure SQL Database through API""], [""CSV export"", ""system"", ""ends this data to suppliers through CSV export""], [""User"", ""person"", "" reviews and updates POs in Power Apps""], [""suppliers"", ""person"", "" reviews and updates POs in Power Apps""]], ""relationships"": [[""Supplier data"", ""part-of"", ""CDS"", ""Supplier data stored in CDS""], [""Supplier data"", ""is-called-from"", ""Data Factory"", ""moved to SQL via Data Factory""], [""Data Factory"", ""calls"", ""Azure SQL database"", ""moved to SQL via Data Factory""], [""Purchase order (PO)"", ""part-of"", ""ERP system"", ""Purchase order (PO) data stored in ERP system""], [""Purchase order (PO)"", ""calls"", ""Azure SQL database"", ""Purchase order (PO) data stored in ERP system is sent to Azure SQL database""], [""Azure Functions"", ""calls"", ""Purchase order (PO)"", ""uses API to surface PO data monthly""], [""Azure Functions"", ""calls"", ""User"", ""creates a task for users to review""], [""Power Apps"", ""calls"", ""Azure SQL database"", ""retrieves data from Azure SQL Database through API""], [""User"", ""calls"", ""Power Apps"", ""Reviews and updates POs in Power Apps""], [""User"", ""calls"", ""CSV export"", ""sends this data to suppliers through CSV export""], [""CSV export"", ""calls"", ""suppliers"", ""sends this data to suppliers through CSV export""]]}","```json
{
  ""entities"": [
    [""Supplier data"", ""component""],
    [""CDS"", ""system""],
    [""Data Factory"", ""component""],
    [""SQL"", ""system""],
    [""PO data"", ""component""],
    [""ERP system"", ""system""],
    [""Azure SQL database"", ""system""],
    [""Azure Functions"", ""component""],
    [""API"", ""component""],
    [""Power Apps"", ""component""],
    [""User"", ""person""],
    [""CSV export"", ""component""],
    [""Power BI"", ""component""]
  ],
  ""relationships"": [
    [""Supplier data"", ""part-of"", ""CDS""],
    [""CDS"", ""contains"", ""Supplier data""],
    [""Supplier data"", ""moved-to"", ""SQL"", ""via Data Factory""],
    [""PO data"", ""sent-to"", ""Azure SQL database"", ""from ERP system""],
    [""Azure Functions"", ""uses"", ""API"", ""to surface PO data monthly""],
    [""Power Apps"", ""retrieves-data-from"", ""Azure SQL Database"", ""through API""],
    [""User"", ""reviews-updates-sends"", ""POs"", ""in Power Apps via CSV export""]
  ]
}
```","```json
{
  ""entities"": [
    [""Supplier data"", ""component""],
    [""CDS"", ""system""],
    [""Data Factory"", ""component""],
    [""SQL"", ""system""],
    [""PO data"", ""component""],
    [""ERP system"", ""system""],
    [""Azure SQL database"", ""system""],
    [""Azure Functions"", ""component""],
    [""API"", ""component""],
    [""Power Apps"", ""component""],
    [""User"", ""person""],
    [""CSV export"", ""component""],
    [""Power BI"", ""component""]
  ],
  ""relationships"": [
    [""Supplier data"", ""part-of"", ""CDS""],
    [""CDS"", ""contains"", ""Supplier data""],
    [""Supplier data"", ""moved-to"", ""SQL"", ""via Data Factory""],
    [""PO data"", ""sent-to"", ""Azure SQL database"", ""from ERP system""],
    [""Azure Functions"", ""uses"", ""API"", ""to surface PO data monthly""],
    [""Power Apps"", ""retrieves-data-from"", ""Azure SQL Database"", ""through API""],
    [""User"", ""reviews-updates-sends"", ""POs"", ""in Power Apps via CSV export""]
  ]
}
```",4.403700351016596
100,mistral-nemo,../IMAGES NEW/Azure/15 Azure automate-document-classification.txt,"
    The user provides a document file that the web app uploads. The file contains multiple documents of various types. It can, for instance, be a PDF or multipage TIFF file.
        The document file is stored in Azure Blob Storage.
        The web app adds a command message to a storage queue to initiate pipeline processing.

    Durable Functions orchestration is triggered by the command message. The message contains metadata that identifies the location in Blob Storage of the document file to be processed. Each Durable Functions instance processes only one document file.

    The Scan activity function calls the Computer Vision Read API, passing in the location in storage of the document to be processed. Optical character recognition (OCR) results are returned to the orchestration to be used by subsequent activities.

    The Classify activity function calls the document classifier service that's hosted in an Azure Kubernetes Service (AKS) cluster. This service uses regular expression pattern matching to identify the starting page of each known document and to calculate how many document types are contained in the document file. The types and page ranges of the documents are calculated and returned to the orchestration.



Note

Azure doesn't offer a service that can classify multiple document types in a single file. This solution uses a non-Azure service that's hosted in AKS.

The Metadata Store activity function saves the document type and page range information in an Azure Cosmos DB store.

The Indexing activity function creates a new search document in the Cognitive Search service for each identified document type and uses the Azure AI Search libraries for .NET to include in the search document the full OCR results and document information. A correlation ID is also added to the search document so that the search results can be matched with the corresponding document metadata from Azure Cosmos DB.

End users can search for documents by contents and metadata. Correlation IDs in the search result set can be used to look up document records that are in Azure Cosmos DB. The records include links to the original document file in Blob Storage.


","{""entities"": [[""web app"", ""system"", ""The user provides a document file that the web app uploads""], [""Azure Blob Storage"", ""system"", ""The document file is stored in Azure Blob Storage""], [""storage queue"", ""system"", ""the web app adds a command message to a storage queue to initiate pipeline processing""], [""Durable Functions orchestration"", ""system"", ""Durable Functions orchestration is triggered by the command message.""], [""Scan activity function"", ""component"", ""The Scan activity function calls the Computer Vision Read API.""], [""Computer Vision Read API"", ""component"", ""The Scan activity function calls the Computer Vision Read API.""], [""Classify activity function"", ""component"", ""The Classify activity function calls the document classifier service that's hosted in an Azure Kubernetes Service (AKS) cluster""], [""document classifier service"", ""component"", ""The Classify activity function calls the document classifier service that's hosted in an Azure Kubernetes Service (AKS) cluster""], [""Azure Kubernetes Service (AKS) cluster"", ""system"", ""The Classify activity function calls the document classifier service that's hosted in an Azure Kubernetes Service (AKS) cluster""], [""User"", ""person"", ""provides a document file that the web app uploads""]], ""relationships"": [[""User"", ""calls"", ""web app"", ""The user provides a document file that the web app uploads""], [""web app"", ""calls"", ""Azure Blob Storage"", ""The user provides a document file that the web app uploads.The document file is stored in Azure Blob Storage""], [""web app"", ""calls"", ""storage queue"", ""the web app adds a command message to a storage queue to initiate pipeline processing""], [""storage queue"", ""calls"", ""Durable Functions orchestration"", ""Durable Functions orchestration is triggered by the command message.""], [""Durable Functions orchestration"", ""calls"", ""Azure Blob Storage"", ""Each Durable Functions instance processes only one document file""], [""Scan activity function"", ""calls"", ""Computer Vision Read API"", ""the Scan activity function calls the Computer Vision Read API""], [""document classifier service"", ""part-of"", ""Azure Kubernetes Service (AKS) cluster"", ""document classifier service that's hosted in an Azure Kubernetes Service (AKS) cluster""], [""Classify activity function"", ""calls"", ""Scan activity function"", ""The Classify activity function calls the document classifier service""], [""Classify activity function"", ""calls"", ""Durable Functions orchestration"", ""The types and page ranges of the documents are calculated and returned to the orchestration""]]}","Here's the extracted information as a JSON format knowledge graph:

```json
{
  ""entities"": [
    [""User"", ""person"", ""Provides the document file""],
    [""WebApp"", ""component"", ""Handles file upload and initiates pipeline processing""],
    [""AzureBlobStorage"", ""system"", ""Stores document files""],
    [""AzureStorageQueue"", ""system"", ""Contains command messages for processing""],
    [""DurableFunctionsOrchestration"", ""component"", ""Triggers and manages activities""],
    [""ScanActivityFunction"", ""component"", ""Processes OCR using Computer Vision Read API""],
    [""ComputerVisionReadAPI"", ""component"", ""Performs optical character recognition (OCR)""],
    [""ClassifyActivityFunction"", ""component"", ""Identifies document types and page ranges""],
    [""DocumentClassifierService"", ""system"", ""Hosted in Azure Kubernetes Service (AKS), uses regular expression pattern matching""],
    [""AzureKubernetesService(AKS)"", ""system"", ""Hosts DocumentClassifierService""],
    [""MetadataStoreActivityFunction"", ""component"", ""Stores document type and page range information in Cosmos DB""],
    [""AzureCosmosDB"", ""system"", ""Stores document metadata""],
    [""IndexingActivityFunction"", ""component"", ""Creates search documents using Azure AI Search libraries for .NET""],
    [""CognitiveSearchService"", ""system"", ""Handles search functionality""],
    [""EndUser"", ""person"", ""Searches for documents by contents and metadata""]
  ],
  ""relationships"": [
    [""WebApp"", ""adds"", ""AzureStorageQueue"", ""Initiates pipeline processing""],
    [""AzureStorageQueue"", ""contains"", ""DurableFunctionsOrchestration"", ""Command messages for processing""],
    [""DurableFunctionsOrchestration"", ""calls"", ""ScanActivityFunction"", ""Triggers OCR process""],
    [""ScanActivityFunction"", ""calls"", ""ComputerVisionReadAPI"", ""Performs OCR""],
    [""DurableFunctionsOrchestration"", ""calls"", ""ClassifyActivityFunction"", ""Identifies document types and page ranges""],
    [""ClassifyActivityFunction"", ""calls"", ""DocumentClassifierService"", ""Uses regular expression pattern matching""],
    [""DocumentClassifierService"", ""part-of"", ""AzureKubernetesService(AKS)"", ""Hosted in Azure Kubernetes Service (AKS)""],
    [""DurableFunctionsOrchestration"", ""calls"", ""MetadataStoreActivityFunction"", ""Stores document metadata""],
    [""MetadataStoreActivityFunction"", ""saves"", ""AzureCosmosDB"", ""Document type and page range information""],
    [""DurableFunctionsOrchestration"", ""calls"", ""IndexingActivityFunction"", ""Creates search documents""],
    [""IndexingActivityFunction"", ""creates"", ""CognitiveSearchService"", ""Handles search functionality""],
    [""EndUser"", ""searches"", ""CognitiveSearchService"", ""Documents by contents and metadata""]
  ]
}
```","Here's the extracted information as a JSON format knowledge graph:

```json
{
  ""entities"": [
    [""User"", ""person"", ""Provides the document file""],
    [""WebApp"", ""component"", ""Handles file upload and initiates pipeline processing""],
    [""AzureBlobStorage"", ""system"", ""Stores document files""],
    [""AzureStorageQueue"", ""system"", ""Contains command messages for processing""],
    [""DurableFunctionsOrchestration"", ""component"", ""Triggers and manages activities""],
    [""ScanActivityFunction"", ""component"", ""Processes OCR using Computer Vision Read API""],
    [""ComputerVisionReadAPI"", ""component"", ""Performs optical character recognition (OCR)""],
    [""ClassifyActivityFunction"", ""component"", ""Identifies document types and page ranges""],
    [""DocumentClassifierService"", ""system"", ""Hosted in Azure Kubernetes Service (AKS), uses regular expression pattern matching""],
    [""AzureKubernetesService(AKS)"", ""system"", ""Hosts DocumentClassifierService""],
    [""MetadataStoreActivityFunction"", ""component"", ""Stores document type and page range information in Cosmos DB""],
    [""AzureCosmosDB"", ""system"", ""Stores document metadata""],
    [""IndexingActivityFunction"", ""component"", ""Creates search documents using Azure AI Search libraries for .NET""],
    [""CognitiveSearchService"", ""system"", ""Handles search functionality""],
    [""EndUser"", ""person"", ""Searches for documents by contents and metadata""]
  ],
  ""relationships"": [
    [""WebApp"", ""adds"", ""AzureStorageQueue"", ""Initiates pipeline processing""],
    [""AzureStorageQueue"", ""contains"", ""DurableFunctionsOrchestration"", ""Command messages for processing""],
    [""DurableFunctionsOrchestration"", ""calls"", ""ScanActivityFunction"", ""Triggers OCR process""],
    [""ScanActivityFunction"", ""calls"", ""ComputerVisionReadAPI"", ""Performs OCR""],
    [""DurableFunctionsOrchestration"", ""calls"", ""ClassifyActivityFunction"", ""Identifies document types and page ranges""],
    [""ClassifyActivityFunction"", ""calls"", ""DocumentClassifierService"", ""Uses regular expression pattern matching""],
    [""DocumentClassifierService"", ""part-of"", ""AzureKubernetesService(AKS)"", ""Hosted in Azure Kubernetes Service (AKS)""],
    [""DurableFunctionsOrchestration"", ""calls"", ""MetadataStoreActivityFunction"", ""Stores document metadata""],
    [""MetadataStoreActivityFunction"", ""saves"", ""AzureCosmosDB"", ""Document type and page range information""],
    [""DurableFunctionsOrchestration"", ""calls"", ""IndexingActivityFunction"", ""Creates search documents""],
    [""IndexingActivityFunction"", ""creates"", ""CognitiveSearchService"", ""Handles search functionality""],
    [""EndUser"", ""searches"", ""CognitiveSearchService"", ""Documents by contents and metadata""]
  ]
}
```",10.27975173300365
101,mistral-nemo,../IMAGES NEW/Azure/12 Azure Network Microservices original.txt,"
    Outside services and clients make a POST request to APIM, with a data body that includes patient information.
    APIM calls the CreatePatient function in the Patient API with the given patient information.
    The CreatePatient function in Patient API calls the CreateAuditRecord function in the Audit API function app to create an audit record.
    The Audit API CreateAuditRecord function creates the audit record in Azure Cosmos DB, and returns a success response to the Patient API CreatePatient function.
    The CreatePatient function creates the patient document in Azure Cosmos DB, and returns a success response to APIM.
    The outside services and clients receive the success response from APIM.

","{""entities"": [[""Outside services"", ""system"", ""Outside services and clients make a POST request to APIM""], [""clients"", ""system"", ""Outside services and clients make a POST request to APIM""], [""APIM"", ""system"", ""Outside services and clients make a POST request to APIM""], [""Patient API"", ""system"", "" The CreatePatient function in Patient API calls the CreateAuditRecord function in the Audit API function app""], [""CreatePatient function"", ""component"", "" The CreatePatient function in Patient API calls the CreateAuditRecord function in the Audit API function app""], [""Audit API function app"", ""system"", ""The CreatePatient function in Patient API calls the CreateAuditRecord function in the Audit API function app""], [""CreateAuditRecord function"", ""component"", ""CreatePatient function in Patient API calls the CreateAuditRecord function""], [""Azure Cosmos DB"", ""system"", ""The Audit API CreateAuditRecord function creates the audit record in Azure Cosmos DB, and returns a success response to the Patient API CreatePatient function""]], ""relationships"": [[""CreatePatient function"", ""part-of"", ""Patient API"", ""Reason""], [""Outside services"", ""calls"", ""APIM"", ""utside services and clients make a POST request to APIM""], [""clients"", ""calls"", ""APIM"", ""outside services and clients make a POST request to APIM""], [""APIM"", ""calls"", ""CreatePatient function"", ""APIM calls the CreatePatient function in the Patient API""], [""CreateAuditRecord function"", ""part-of"", ""Audit API function app"", ""Reason""], [""CreatePatient function"", ""calls"", ""CreateAuditRecord function"", ""CreatePatient function in Patient API calls the CreateAuditRecord function in the Audit API function app""], [""CreateAuditRecord function"", ""calls"", ""Azure Cosmos DB"", ""Audit API CreateAuditRecord function creates the audit record in Azure Cosmos DB""], [""CreateAuditRecord function"", ""calls"", ""CreatePatient function"", ""returns a success response to the Patient API CreatePatient function.""], [""CreatePatient function"", ""calls"", ""Azure Cosmos DB"", ""The CreatePatient function creates the patient document in Azure Cosmos DB""], [""CreatePatient function"", ""is-called-from"", ""APIM"", ""The CreatePatient function returns a success response to APIM""]]}","Based on the provided text, here's the extracted entities and relationships in JSON format:

```json
{
  ""entities"": [
    [""APIM"", ""system"", ""Outside services and clients make a POST request to APIM""],
    [""Patient API"", ""system"", ""APIM calls the CreatePatient function in the Patient API""],
    [""CreatePatient"", ""function"", ""The CreatePatient function in Patient API...""],
    [""Audit API"", ""system"", ""The CreatePatient function calls the CreateAuditRecord function in the Audit API""],
    [""CreateAuditRecord"", ""function"", ""The Audit API CreateAuditRecord function...""],
    [""Azure Cosmos DB"", ""system"", ""The Audit API CreateAuditRecord function creates the audit record in Azure Cosmos DB""]
  ],
  ""relationships"": [
    [""APIM"", ""calls"", ""Patient API""],
    [""Patient API"", ""contains"", ""CreatePatient""],
    [""CreatePatient"", ""called-from"", ""APIM""],
    [""CreatePatient"", ""calls"", ""Audit API""],
    [""Audit API"", ""contains"", ""CreateAuditRecord""],
    [""CreateAuditRecord"", ""called-from"", ""CreatePatient""],
    [""Audit API"", ""creates"", ""Azure Cosmos DB""],
    [""CreatePatient"", ""creates"", ""Azure Cosmos DB""]
  ]
}
```","Based on the provided text, here's the extracted entities and relationships in JSON format:

```json
{
  ""entities"": [
    [""APIM"", ""system"", ""Outside services and clients make a POST request to APIM""],
    [""Patient API"", ""system"", ""APIM calls the CreatePatient function in the Patient API""],
    [""CreatePatient"", ""function"", ""The CreatePatient function in Patient API...""],
    [""Audit API"", ""system"", ""The CreatePatient function calls the CreateAuditRecord function in the Audit API""],
    [""CreateAuditRecord"", ""function"", ""The Audit API CreateAuditRecord function...""],
    [""Azure Cosmos DB"", ""system"", ""The Audit API CreateAuditRecord function creates the audit record in Azure Cosmos DB""]
  ],
  ""relationships"": [
    [""APIM"", ""calls"", ""Patient API""],
    [""Patient API"", ""contains"", ""CreatePatient""],
    [""CreatePatient"", ""called-from"", ""APIM""],
    [""CreatePatient"", ""calls"", ""Audit API""],
    [""Audit API"", ""contains"", ""CreateAuditRecord""],
    [""CreateAuditRecord"", ""called-from"", ""CreatePatient""],
    [""Audit API"", ""creates"", ""Azure Cosmos DB""],
    [""CreatePatient"", ""creates"", ""Azure Cosmos DB""]
  ]
}
```",4.833219200983876
102,mistral-nemo,../IMAGES NEW/Azure/09 Azure protect APIs original.txt,"
    To gain access to an application, an API client authenticates by providing credentials such as username and password. The IdP is Azure AD B2C in this solution, but you can use a different one.

    The authentication request goes via Azure Front Door to Azure AD B2C, which is configured with a custom domain for sign-in. Azure AD B2C authenticates the user and returns a JSON Web Token (JWT) bearer token back to the user.

    The client triggers an event that accesses a backend API. This event could be a click of a button on a web application or on a mobile device, or a direct call to the endpoint of the backend API.

    The request goes through Azure Front Door, whose back end is mapped to the public endpoint of API Management. API Management intercepts the request and validates the bearer token against Azure AD B2C by using its validate-jwt policy. If the token isn't valid, API Management rejects the request by responding with a 401 code.

    If the token is valid, API Management forwards the request to the appropriate backend API.

    The diagram shows backend APIs running in three environments:
        App Service Environment
        Function Apps
        Azure Kubernetes Services (AKS)

    APIs running in on-premises and hybrid cloud environments can also be integrated with API Management if network connectivity is established between the APIs and API Management.

","{""entities"": [[""API client"", ""system"", ""wants to gain access to an application""], [""application"", ""system"", ""API client wants to gain access to an application""], [""Azure AD B2C"", ""system"", ""The IdP is Azure AD B2C""], [""Azure Front Door"", ""system"", ""authentication request goes via Azure Front Door to Azure AD B2C""], [""backend API"", ""system"", ""The client triggers an event that accesses a backend API""], [""Azure Front Door"", ""system"", ""The request goes through Azure Front Door, whose back end is mapped to the public endpoint of API Management.""], [""backend"", ""component"", ""Azure Front Door, whose back end""], [""API Management"", ""system"", ""API Management intercepts the request and validates the bearer token against Azure AD B2C ""], [""public endpoint"", ""system"", ""whose back end is mapped to the public endpoint of API Management""], [""User"", ""person"", ""Azure AD B2C authenticates the user and returns a JSON Web Token (JWT) bearer token back to the user""]], ""relationships"": [[""API client"", ""calls"", ""application"", """"], [""Azure Front Door"", ""calls"", ""Azure AD B2C"", ""authentication request goes via Azure Front Door to Azure AD B2C""], [""Azure AD B2C"", ""is-called-from"", ""User"", ""Azure AD B2C authenticates the user and returns a JSON Web Token (JWT) bearer token back to the user""], [""API client"", ""calls"", ""backend API"", ""The client triggers an event that accesses a backend API""], [""Azure Front Door"", ""contains"", ""backend"", ""Azure Front Door, whose back end""], [""public endpoint"", ""part-of"", ""API Management"", ""Azure Front Door, whose back end""], [""backend"", ""calls"", ""public endpoint"", ""whose back end is mapped to the public endpoint of API Management""], [""API Management"", ""calls"", ""Azure AD B2C"", ""API Management intercepts the request and validates the bearer token against Azure AD B2C""]]}","```json
{
  ""entities"": [
    [""API Client"", ""person""],
    [""Azure AD B2C"", ""system""],
    [""Azure Front Door"", ""component""],
    [""JSON Web Token (JWT)"", ""entity""],
    [""Backend API"", ""system""],
    [""App Service Environment"", ""system""],
    [""Function Apps"", ""system""],
    [""Azure Kubernetes Services (AKS)"", ""system""],
    [""API Management"", ""system""]
  ],
  ""relationships"": [
    [""API Client"", ""calls"", ""Azure Front Door""],
    [""Azure Front Door"", ""contains"", ""Azure AD B2C""],
    [""Azure Front Door"", ""called-from"", ""Backend API""],
    [""Backend API"", ""part-of"", ""App Service Environment""],
    [""Backend API"", ""part-of"", ""Function Apps""],
    [""Backend API"", ""part-of"", ""Azure Kubernetes Services (AKS)""],
    [""API Management"", ""contains"", ""validate-jwt policy""]
  ]
}
```","```json
{
  ""entities"": [
    [""API Client"", ""person""],
    [""Azure AD B2C"", ""system""],
    [""Azure Front Door"", ""component""],
    [""JSON Web Token (JWT)"", ""entity""],
    [""Backend API"", ""system""],
    [""App Service Environment"", ""system""],
    [""Function Apps"", ""system""],
    [""Azure Kubernetes Services (AKS)"", ""system""],
    [""API Management"", ""system""]
  ],
  ""relationships"": [
    [""API Client"", ""calls"", ""Azure Front Door""],
    [""Azure Front Door"", ""contains"", ""Azure AD B2C""],
    [""Azure Front Door"", ""called-from"", ""Backend API""],
    [""Backend API"", ""part-of"", ""App Service Environment""],
    [""Backend API"", ""part-of"", ""Function Apps""],
    [""Backend API"", ""part-of"", ""Azure Kubernetes Services (AKS)""],
    [""API Management"", ""contains"", ""validate-jwt policy""]
  ]
}
```",3.935924518009415
103,mistral-nemo,../IMAGES NEW/TEST/08 Azure Business Processes.txt,"
The data flows through the solution as follows:

    The airline system communicates with a custom API hosted in Azure API Management.
    A custom API coordinator receives notifications and handles incoming messages from the airline system. It sends them to Power Apps, where flights are assigned to Microsoft Teams channels.
    When a user selects a flight to monitor, or when the system assigns the user to a flight, the system queues a Graph API call in an Azure Storage Account queue for further processing.
    Azure Functions runs the Graph API calls based on the incoming messages in the storage queue, sending notifications to Teams, and also streams all events to an Azure Event Hubs for further analytics.
    The airline's notification system is managed by a custom bot messaging service that employs Azure Bot Service.
    Custom bots send flight updates to users in Teams.
    An Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs, ultimately generating insightful reports with Power BI.

","{""entities"": [[""airline system"", ""system"", ""communicates with a custom API hosted in Azure API Management""], [""custom API"", ""component"", ""communicates with a custom API hosted in Azure API Management""], [""Azure API Management"", ""system"", ""communicates with a custom API hosted in Azure API Management""], [""custom API coordinator"", ""system"", ""receives notifications and handles incoming messages from the airline system""], [""Power Apps"", ""system"", ""where flights are assigned to Microsoft Teams channels""], [""Microsoft Teams channels"", ""system"", ""where flights are assigned to Microsoft Teams channels""], [""Storage Account queue"", ""system"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing.""], [""Graph API call"", ""system"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing.""], [""Azure Functions"", ""system"", ""runs the Graph API calls based on the incoming messages in the storage queue""], [""Azure Event Hubs"", ""system"", ""Azure Event Hubs for further analytics""], [""notification system"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""custom bot messaging service"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""Azure Bot Service"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""Users"", ""person"", ""selects a flight to monitor, or when the system assigns the user to a flight""], [""Azure Data Lake storage"", ""system"", ""offers long-term retention and micro-batch processing of events from Event Hubs""], [""Power BI"", ""system"", ""generating insightful reports""]], ""relationships"": [[""Azure API Management"", ""contains"", ""custom API"", ""custom API hosted in Azure API Management""], [""airline system"", ""calls"", ""custom API"", ""communicates with a custom API""], [""custom API coordinator"", ""is-called-from"", ""airline system"", ""receives notifications and handles incoming messages from the airline system""], [""Power Apps"", ""calls"", ""Microsoft Teams channels"", ""Power Apps, where flights are assigned to Microsoft Teams channels""], [""airline system"", ""calls"", ""Graph API call"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing""], [""Azure Functions"", ""calls"", ""Graph API call"", ""runs the Graph API calls based on the incoming messages in the storage queue""], [""Azure Functions"", ""calls"", ""Storage Account queue"", ""based on the incoming messages in the storage queue""], [""Azure Functions"", ""calls"", ""Microsoft Teams channels"", ""sending notifications to Teams""], [""Azure Functions"", ""calls"", ""Azure Event Hubs"", ""also streams all events to an Azure Event Hubs for further analytics""], [""notification system"", ""is-called-from"", ""custom bot messaging service"", ""managed by a custom bot messaging service""], [""custom bot messaging service"", ""calls"", ""Azure Bot Service"", ""custom bot messaging service that employs Azure Bot Service""], [""custom bot messaging service"", ""calls"", ""Microsoft Teams channels"", ""Custom bots send flight updates to users in Teams.""], [""Microsoft Teams channels"", ""calls"", ""Users"", ""Custom bots send flight updates to users in Teams.""], [""Azure Data Lake storage"", ""is-called-from"", ""Azure Event Hubs"", ""Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs""], [""Azure Data Lake storage"", ""calls"", ""Power BI"", ""Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs, ultimately generating insightful reports with Power BI""]]}","{
  ""entities"": [
    [""Airline System"", ""system""],
    [""Custom API Coordinator"", ""component""],
    [""Power Apps"", ""system""],
    [""Microsoft Teams"", ""system""],
    [""Azure Storage Account Queue"", ""component""],
    [""Azure Functions"", ""component""],
    [""Azure Event Hubs"", ""system""],
    [""Azure Data Lake storage"", ""system""],
    [""Power BI"", ""system""],
    [""Custom Bot Messaging Service"", ""component""],
    [""Azure Bot Service"", ""system""]
  ],
  ""relationships"": [
    [""Airline System"", ""calls"", ""Custom API Coordinator""],
    [""Custom API Coordinator"", ""contains"", ""Microsoft Teams""],
    [""Azure Storage Account Queue"", ""part-of"", ""Azure Functions""],
    [""Azure Functions"", ""called-from"", ""Azure Storage Account Queue""],
    [""Azure Functions"", ""sends notifications to"", ""Microsoft Teams""],
    [""Azure Functions"", ""streams events to"", ""Azure Event Hubs""],
    [""Custom Bot Messaging Service"", ""contains"", ""Azure Bot Service""]
  ]
}","{
  ""entities"": [
    [""Airline System"", ""system""],
    [""Custom API Coordinator"", ""component""],
    [""Power Apps"", ""system""],
    [""Microsoft Teams"", ""system""],
    [""Azure Storage Account Queue"", ""component""],
    [""Azure Functions"", ""component""],
    [""Azure Event Hubs"", ""system""],
    [""Azure Data Lake storage"", ""system""],
    [""Power BI"", ""system""],
    [""Custom Bot Messaging Service"", ""component""],
    [""Azure Bot Service"", ""system""]
  ],
  ""relationships"": [
    [""Airline System"", ""calls"", ""Custom API Coordinator""],
    [""Custom API Coordinator"", ""contains"", ""Microsoft Teams""],
    [""Azure Storage Account Queue"", ""part-of"", ""Azure Functions""],
    [""Azure Functions"", ""called-from"", ""Azure Storage Account Queue""],
    [""Azure Functions"", ""sends notifications to"", ""Microsoft Teams""],
    [""Azure Functions"", ""streams events to"", ""Azure Event Hubs""],
    [""Custom Bot Messaging Service"", ""contains"", ""Azure Bot Service""]
  ]
}",4.086526552971918
104,mistral-nemo,../IMAGES NEW/Azure/12 Azure Network Microservices original.txt,"
    Outside services and clients make a POST request to APIM, with a data body that includes patient information.
    APIM calls the CreatePatient function in the Patient API with the given patient information.
    The CreatePatient function in Patient API calls the CreateAuditRecord function in the Audit API function app to create an audit record.
    The Audit API CreateAuditRecord function creates the audit record in Azure Cosmos DB, and returns a success response to the Patient API CreatePatient function.
    The CreatePatient function creates the patient document in Azure Cosmos DB, and returns a success response to APIM.
    The outside services and clients receive the success response from APIM.

","{""entities"": [[""Outside services"", ""system"", ""Outside services and clients make a POST request to APIM""], [""clients"", ""system"", ""Outside services and clients make a POST request to APIM""], [""APIM"", ""system"", ""Outside services and clients make a POST request to APIM""], [""Patient API"", ""system"", "" The CreatePatient function in Patient API calls the CreateAuditRecord function in the Audit API function app""], [""CreatePatient function"", ""component"", "" The CreatePatient function in Patient API calls the CreateAuditRecord function in the Audit API function app""], [""Audit API function app"", ""system"", ""The CreatePatient function in Patient API calls the CreateAuditRecord function in the Audit API function app""], [""CreateAuditRecord function"", ""component"", ""CreatePatient function in Patient API calls the CreateAuditRecord function""], [""Azure Cosmos DB"", ""system"", ""The Audit API CreateAuditRecord function creates the audit record in Azure Cosmos DB, and returns a success response to the Patient API CreatePatient function""]], ""relationships"": [[""CreatePatient function"", ""part-of"", ""Patient API"", ""Reason""], [""Outside services"", ""calls"", ""APIM"", ""utside services and clients make a POST request to APIM""], [""clients"", ""calls"", ""APIM"", ""outside services and clients make a POST request to APIM""], [""APIM"", ""calls"", ""CreatePatient function"", ""APIM calls the CreatePatient function in the Patient API""], [""CreateAuditRecord function"", ""part-of"", ""Audit API function app"", ""Reason""], [""CreatePatient function"", ""calls"", ""CreateAuditRecord function"", ""CreatePatient function in Patient API calls the CreateAuditRecord function in the Audit API function app""], [""CreateAuditRecord function"", ""calls"", ""Azure Cosmos DB"", ""Audit API CreateAuditRecord function creates the audit record in Azure Cosmos DB""], [""CreateAuditRecord function"", ""calls"", ""CreatePatient function"", ""returns a success response to the Patient API CreatePatient function.""], [""CreatePatient function"", ""calls"", ""Azure Cosmos DB"", ""The CreatePatient function creates the patient document in Azure Cosmos DB""], [""CreatePatient function"", ""is-called-from"", ""APIM"", ""The CreatePatient function returns a success response to APIM""]]}","{
  ""entities"": [
    [""APIM"", ""system"", ""External API Management service""],
    [""CreatePatient"", ""component"", ""Function in Patient API""],
    [""Patient API"", ""system"", ""Contains multiple components""],
    [""Audit API"", ""system"", ""Contains CreateAuditRecord function""],
    [""CreateAuditRecord"", ""component"", ""Function in Audit API""],
    [""Azure Cosmos DB"", ""system"", ""Data storage service""]
  ],
  ""relationships"": [
    [""APIM"", ""calls"", ""CreatePatient""],
    [""CreatePatient"", ""part-of"", ""Patient API""],
    [""CreatePatient"", ""called-from"", ""APIM""],
    [""CreatePatient"", ""calls"", ""CreateAuditRecord""],
    [""CreateAuditRecord"", ""part-of"", ""Audit API""],
    [""CreateAuditRecord"", ""contains"", ""Azure Cosmos DB""]
  ]
}","{
  ""entities"": [
    [""APIM"", ""system"", ""External API Management service""],
    [""CreatePatient"", ""component"", ""Function in Patient API""],
    [""Patient API"", ""system"", ""Contains multiple components""],
    [""Audit API"", ""system"", ""Contains CreateAuditRecord function""],
    [""CreateAuditRecord"", ""component"", ""Function in Audit API""],
    [""Azure Cosmos DB"", ""system"", ""Data storage service""]
  ],
  ""relationships"": [
    [""APIM"", ""calls"", ""CreatePatient""],
    [""CreatePatient"", ""part-of"", ""Patient API""],
    [""CreatePatient"", ""called-from"", ""APIM""],
    [""CreatePatient"", ""calls"", ""CreateAuditRecord""],
    [""CreateAuditRecord"", ""part-of"", ""Audit API""],
    [""CreateAuditRecord"", ""contains"", ""Azure Cosmos DB""]
  ]
}",3.415531763981562
105,mistral-nemo,../IMAGES NEW/TEST/08 Azure Business Processes.txt,"
The data flows through the solution as follows:

    The airline system communicates with a custom API hosted in Azure API Management.
    A custom API coordinator receives notifications and handles incoming messages from the airline system. It sends them to Power Apps, where flights are assigned to Microsoft Teams channels.
    When a user selects a flight to monitor, or when the system assigns the user to a flight, the system queues a Graph API call in an Azure Storage Account queue for further processing.
    Azure Functions runs the Graph API calls based on the incoming messages in the storage queue, sending notifications to Teams, and also streams all events to an Azure Event Hubs for further analytics.
    The airline's notification system is managed by a custom bot messaging service that employs Azure Bot Service.
    Custom bots send flight updates to users in Teams.
    An Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs, ultimately generating insightful reports with Power BI.

","{""entities"": [[""airline system"", ""system"", ""communicates with a custom API hosted in Azure API Management""], [""custom API"", ""component"", ""communicates with a custom API hosted in Azure API Management""], [""Azure API Management"", ""system"", ""communicates with a custom API hosted in Azure API Management""], [""custom API coordinator"", ""system"", ""receives notifications and handles incoming messages from the airline system""], [""Power Apps"", ""system"", ""where flights are assigned to Microsoft Teams channels""], [""Microsoft Teams channels"", ""system"", ""where flights are assigned to Microsoft Teams channels""], [""Storage Account queue"", ""system"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing.""], [""Graph API call"", ""system"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing.""], [""Azure Functions"", ""system"", ""runs the Graph API calls based on the incoming messages in the storage queue""], [""Azure Event Hubs"", ""system"", ""Azure Event Hubs for further analytics""], [""notification system"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""custom bot messaging service"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""Azure Bot Service"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""Users"", ""person"", ""selects a flight to monitor, or when the system assigns the user to a flight""], [""Azure Data Lake storage"", ""system"", ""offers long-term retention and micro-batch processing of events from Event Hubs""], [""Power BI"", ""system"", ""generating insightful reports""]], ""relationships"": [[""Azure API Management"", ""contains"", ""custom API"", ""custom API hosted in Azure API Management""], [""airline system"", ""calls"", ""custom API"", ""communicates with a custom API""], [""custom API coordinator"", ""is-called-from"", ""airline system"", ""receives notifications and handles incoming messages from the airline system""], [""Power Apps"", ""calls"", ""Microsoft Teams channels"", ""Power Apps, where flights are assigned to Microsoft Teams channels""], [""airline system"", ""calls"", ""Graph API call"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing""], [""Azure Functions"", ""calls"", ""Graph API call"", ""runs the Graph API calls based on the incoming messages in the storage queue""], [""Azure Functions"", ""calls"", ""Storage Account queue"", ""based on the incoming messages in the storage queue""], [""Azure Functions"", ""calls"", ""Microsoft Teams channels"", ""sending notifications to Teams""], [""Azure Functions"", ""calls"", ""Azure Event Hubs"", ""also streams all events to an Azure Event Hubs for further analytics""], [""notification system"", ""is-called-from"", ""custom bot messaging service"", ""managed by a custom bot messaging service""], [""custom bot messaging service"", ""calls"", ""Azure Bot Service"", ""custom bot messaging service that employs Azure Bot Service""], [""custom bot messaging service"", ""calls"", ""Microsoft Teams channels"", ""Custom bots send flight updates to users in Teams.""], [""Microsoft Teams channels"", ""calls"", ""Users"", ""Custom bots send flight updates to users in Teams.""], [""Azure Data Lake storage"", ""is-called-from"", ""Azure Event Hubs"", ""Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs""], [""Azure Data Lake storage"", ""calls"", ""Power BI"", ""Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs, ultimately generating insightful reports with Power BI""]]}","Here's the extracted entities and relationships in JSON format:

```json
{
  ""entities"": [
    [""Airline System"", ""system""],
    [""Azure API Management"", ""system""],
    [""Custom API Coordinator"", ""component""],
    [""Power Apps"", ""system""],
    [""Microsoft Teams"", ""system""],
    [""Azure Storage Account Queue"", ""system""],
    [""Azure Functions"", ""system""],
    [""Azure Event Hubs"", ""system""],
    [""Azure Data Lake Storage"", ""system""],
    [""Power BI"", ""system""],
    [""Custom Bot Messaging Service"", ""component""],
    [""Azure Bot Service"", ""system""]
  ],
  ""relationships"": [
    [""Airline System"", ""calls"", ""Azure API Management""],
    [""Custom API Coordinator"", ""part-of"", ""Azure API Management""],
    [""Custom API Coordinator"", ""contains"", ""Power Apps""],
    [""Custom API Coordinator"", ""calls"", ""Microsoft Teams""],
    [""Azure Storage Account Queue"", ""contains"", ""Graph API Call""],
    [""Azure Functions"", ""called-from"", ""Azure Storage Account Queue""],
    [""Azure Functions"", ""calls"", ""Microsoft Teams""],
    [""Azure Functions"", ""calls"", ""Azure Event Hubs""],
    [""Azure Data Lake Storage"", ""contains"", ""Events from Azure Event Hubs""],
    [""Power BI"", ""called-from"", ""Azure Data Lake Storage""],
    [""Custom Bot Messaging Service"", ""part-of"", ""Azure Bot Service""]
  ]
}
```","Here's the extracted entities and relationships in JSON format:

```json
{
  ""entities"": [
    [""Airline System"", ""system""],
    [""Azure API Management"", ""system""],
    [""Custom API Coordinator"", ""component""],
    [""Power Apps"", ""system""],
    [""Microsoft Teams"", ""system""],
    [""Azure Storage Account Queue"", ""system""],
    [""Azure Functions"", ""system""],
    [""Azure Event Hubs"", ""system""],
    [""Azure Data Lake Storage"", ""system""],
    [""Power BI"", ""system""],
    [""Custom Bot Messaging Service"", ""component""],
    [""Azure Bot Service"", ""system""]
  ],
  ""relationships"": [
    [""Airline System"", ""calls"", ""Azure API Management""],
    [""Custom API Coordinator"", ""part-of"", ""Azure API Management""],
    [""Custom API Coordinator"", ""contains"", ""Power Apps""],
    [""Custom API Coordinator"", ""calls"", ""Microsoft Teams""],
    [""Azure Storage Account Queue"", ""contains"", ""Graph API Call""],
    [""Azure Functions"", ""called-from"", ""Azure Storage Account Queue""],
    [""Azure Functions"", ""calls"", ""Microsoft Teams""],
    [""Azure Functions"", ""calls"", ""Azure Event Hubs""],
    [""Azure Data Lake Storage"", ""contains"", ""Events from Azure Event Hubs""],
    [""Power BI"", ""called-from"", ""Azure Data Lake Storage""],
    [""Custom Bot Messaging Service"", ""part-of"", ""Azure Bot Service""]
  ]
}
```",5.369376154005295
106,mistral-nemo,../IMAGES NEW/Azure/14 Azure Call Center Analytics.txt,"
    A phone call between an agent and a customer is recorded and stored in Azure Blob Storage. Audio files are uploaded to an Azure Storage account via a supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API.

    Azure AI Speech is used to transcribe audio files in Batch mode asynchronously with speaker diarization enabled. The transcription results are persisted in Blob Storage.

    Azure AI Language is used to detect and redact personal data in the transcript.

    For batch mode transcription and personal data detection and redaction, use the AI services Ingestion Client tool. The Ingestion Client tool uses a no-code approach for call center transcription.

    Azure OpenAI is used to process the transcript and extract entities, summarize the conversation, and analyze sentiments. The processed output is stored in Blob Storage and then analyzed and visualized by using other services. You can also store the output in a datastore for keeping track of metadata and for reporting. Use Azure OpenAI to process the stored transcription information.

    Power BI or a custom web application that's hosted by App Service is used to visualize the output. Both options provide near real-time insights. You can store this output in a customer relationship management (CRM), so agents have contextual information about why the customer called and can quickly solve potential problems. This process is fully automated, which saves the agents time and effort.

","{""entities"": [[""phone call"", ""component"", ""A phone call between an agent and a customer is recorded""], [""agent"", ""person"", ""A phone call between an agent and a customer is recorded""], [""customer"", ""person"", ""A phone call between an agent and a customer is recorded""], [""Azure Blob Storage"", ""system"", ""is recorded and stored in Azure Blob Storage""], [""Audio files"", ""system"", ""Audio files are uploaded to an Azure Storage account via a supported method""], [""supported method"", ""component"", ""Audio files are uploaded to an Azure Storage account via a supported method""], [""UI-based tool"", ""component"", ""supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""Azure Storage Explorer"", ""component"", ""supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""Storage SDK"", ""component"", ""supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""API"", ""component"", ""supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""Azure AI Speech"", ""component"", ""transcribe audio files in Batch mode asynchronously""], [""transcription results"", ""component"", ""The transcription results are persisted in Blob Storage.""], [""Azure AI Language"", ""component"", ""Azure AI Language is used to detect and redact personal data in the transcript.""], [""AI services Ingestion Client tool"", ""component"", ""For batch mode transcription and personal data detection and redaction, use the AI services Ingestion Client tool""], [""Azure OpenAI"", ""component"", ""Azure OpenAI is used to process the transcript and extract entities, summarize the conversation, and analyze sentiments.""], [""Azure OpenAI output"", ""component"", ""The processed output is stored in Blob Storage and then analyzed and visualized by using other services.""], [""other services"", ""component"", ""The processed output is stored in Blob Storage and then analyzed and visualized by using other services.""], [""App Service"", ""system"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""Power BI"", ""system"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""custom web application"", ""system"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""Azure OpenAI output 2"", ""component"", ""You can also store the output in a datastore for keeping track of metadata and for reporting""], [""datastore"", ""component"", ""You can also store the output in a datastore for keeping track of metadata and for reporting""], [""customer relationship management (CRM)"", ""system"", ""You can store this output in a customer relationship management (CRM)""], [""Azure OpenAI output 3"", ""component"", ""You can store this output in a customer relationship management (CRM)""]], ""relationships"": [[""agent"", ""calls"", ""phone call"", ""A phone call between an agent and a customer is recorded""], [""customer"", ""calls"", ""phone call"", ""A phone call between an agent and a customer is recorded""], [""phone call"", ""part-of"", ""Azure Blob Storage"", ""is recorded and stored in Azure Blob Storage""], [""Audio files"", ""part-of"", ""Azure Blob Storage"", ""Audio files are uploaded to an Azure Storage account via a supported method""], [""supported method"", ""calls"", ""Audio files"", ""Audio files are uploaded to an Azure Storage account via a supported method""], [""supported method"", ""contains"", ""UI-based tool"", ""upported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""supported method"", ""contains"", ""Azure Storage Explorer"", ""upported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""supported method"", ""contains"", ""Storage SDK"", ""upported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""supported method"", ""contains"", ""API"", ""supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""Azure AI Speech"", ""calls"", ""Audio files"", ""transcribe audio files in Batch mode asynchronously""], [""Azure Blob Storage"", ""contains"", ""transcription results"", ""The transcription results are persisted in Blob Storage.""], [""Azure AI Speech"", ""calls"", ""transcription results"", ""The transcription results are persisted in Blob Storage.""], [""Azure AI Language"", ""calls"", ""transcription results"", ""Azure AI Language is used to detect and redact personal data in the transcript.""], [""AI services Ingestion Client tool"", ""calls"", ""transcription results"", ""For batch mode transcription and personal data detection and redaction, use the AI services Ingestion Client tool""], [""Azure OpenAI"", ""calls"", ""transcription results"", ""Azure OpenAI is used to process the transcript and extract entities, summarize the conversation, and analyze sentiments.""], [""Azure OpenAI"", ""calls"", ""Azure OpenAI output"", ""The processed output is stored in Blob Storage and then analyzed and visualized by using other services.""], [""Azure Blob Storage"", ""contains"", ""Azure OpenAI output"", ""The processed output is stored in Blob Storage and then analyzed and visualized by using other services.""], [""other services"", ""calls"", ""Azure OpenAI output"", ""The processed output is stored in Blob Storage and then analyzed and visualized by using other services.""], [""Power BI"", ""part-of"", ""App Service"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""custom web application"", ""part-of"", ""App Service"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""custom web application"", ""calls"", ""Azure OpenAI output"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""Power BI"", ""calls"", ""Azure OpenAI output"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""agent"", ""calls"", ""customer relationship management (CRM)"", ""You can store this output in a customer relationship management (CRM), so agents have contextual information about why the customer called and can quickly solve potential problems""], [""Azure OpenAI output 2"", ""part-of"", ""datastore"", ""You can also store the output in a datastore for keeping track of metadata and for reporting""], [""Azure OpenAI output 3"", ""part-of"", ""customer relationship management (CRM)"", ""You can also store the output in a datastore for keeping track of metadata and for reporting""], [""Azure OpenAI output"", ""calls"", ""Azure OpenAI output 2"", ""You can also store the output in a datastore for keeping track of metadata and for reporting""], [""Azure OpenAI output"", ""calls"", ""Azure OpenAI output 3"", ""You can store this output in a customer relationship management (CRM), so agents have contextual information about why the customer called and can quickly solve potential problems""]]}","Here's the JSON output based on the provided context:

```json
{
  ""entities"": [
    [""Agent"", ""person"", ""A human agent in the call center""],
    [""Customer"", ""person"", ""The caller""],
    [""Azure Blob Storage"", ""system"", ""A cloud storage service for audio files and transcription results""],
    [""Azure AI Speech"", ""component"", ""An Azure service for transcribing audio files""],
    [""Azure AI Language"", ""component"", ""An Azure service for detecting and redacting personal data in text""],
    [""AI services Ingestion Client tool"", ""system"", ""A no-code tool for batch mode transcription and personal data detection and redaction""],
    [""Azure OpenAI"", ""component"", ""An Azure service for processing transcript, extracting entities, summarizing conversations, and analyzing sentiments""],
    [""Power BI"", ""system"", ""A business intelligence platform for visualizing output""],
    [""App Service"", ""system"", ""A platform as a service (PaaS) offered by Microsoft Azure to build, deploy, and scale web apps""]
  ],
  ""relationships"": [
    [""Azure Blob Storage"", ""contains"", ""Audio files""],
    [""Azure AI Speech"", ""part-of"", ""AI services Ingestion Client tool""],
    [""AI services Ingestion Client tool"", ""calls"", ""Azure AI Language""],
    [""Azure OpenAI"", ""called-from"", ""Azure Blob Storage""],
    [""Power BI"", ""contains"", ""Visualizations""],
    [""App Service"", ""contains"", ""Custom web application""]
  ]
}
```","Here's the JSON output based on the provided context:

```json
{
  ""entities"": [
    [""Agent"", ""person"", ""A human agent in the call center""],
    [""Customer"", ""person"", ""The caller""],
    [""Azure Blob Storage"", ""system"", ""A cloud storage service for audio files and transcription results""],
    [""Azure AI Speech"", ""component"", ""An Azure service for transcribing audio files""],
    [""Azure AI Language"", ""component"", ""An Azure service for detecting and redacting personal data in text""],
    [""AI services Ingestion Client tool"", ""system"", ""A no-code tool for batch mode transcription and personal data detection and redaction""],
    [""Azure OpenAI"", ""component"", ""An Azure service for processing transcript, extracting entities, summarizing conversations, and analyzing sentiments""],
    [""Power BI"", ""system"", ""A business intelligence platform for visualizing output""],
    [""App Service"", ""system"", ""A platform as a service (PaaS) offered by Microsoft Azure to build, deploy, and scale web apps""]
  ],
  ""relationships"": [
    [""Azure Blob Storage"", ""contains"", ""Audio files""],
    [""Azure AI Speech"", ""part-of"", ""AI services Ingestion Client tool""],
    [""AI services Ingestion Client tool"", ""calls"", ""Azure AI Language""],
    [""Azure OpenAI"", ""called-from"", ""Azure Blob Storage""],
    [""Power BI"", ""contains"", ""Visualizations""],
    [""App Service"", ""contains"", ""Custom web application""]
  ]
}
```",5.6350542820000555
107,mistral-nemo,../IMAGES NEW/Azure/05. azure Original.txt,"
    Backend systems. The right-hand side of the diagram shows the various backend systems that the enterprise has deployed or relies on. These systems might include SaaS systems, other Azure services, or web services that expose REST or SOAP endpoints.

    Azure Logic Apps. In this architecture, logic apps are triggered by HTTP requests. You can also nest workflows for more complex orchestration. Logic Apps uses connectors to integrate with commonly used services. Logic Apps offers hundreds of connectors, and you can create custom connectors.

    Azure API Management. API Management consists of two related components:

        API gateway. The API gateway accepts HTTP calls and routes them to the backend.

        Developer portal. Each instance of Azure API Management provides access to a developer portal. This portal gives your developers access to documentation and code samples for calling the APIs. You can also test APIs in the developer portal.

    Azure DNS. Azure DNS provides name resolution by using the Azure infrastructure. By hosting your domains in Azure, you can manage your DNS records by using the same credentials, APIs, tools, and billing that you use for your other Azure services. To use a custom domain name, such as contoso.com, create DNS records that map the custom domain name to the IP address. For more information, see Configure a custom domain name in API Management.

    Microsoft Entra ID. Use Microsoft Entra ID to authenticate clients that call the API gateway. Microsoft Entra ID supports the OpenID Connect (OIDC) protocol. Clients obtain an access token from Microsoft Entra ID, and API Gateway validates the token to authorize the request. If you use the Standard or Premium tier of API Management, Microsoft Entra ID can also help secure access to the developer portal.

","{""entities"": [[""Backend systems"", ""system"", ""various backend systems that the enterprise has deployed or relies on""], [""SaaS systems"", ""component"", ""SaaS systems""], [""other Azure services"", ""component"", ""other Azure services""], [""web services"", ""component"", ""expose REST or SOAP endpoints""], [""Azure Logic Apps"", ""system"", ""Logic Apps uses connectors to integrate with commonly used services""], [""Azure API Management"", ""system"", ""Logic Apps uses connectors to integrate with commonly used services""], [""API gateway"", ""component"", ""The API gateway accepts HTTP calls and routes them to the backend""], [""Developer portal"", ""component"", ""This portal gives your developers access to documentation and code samples for calling the APIs""], [""Azure DNS"", ""system"", ""Azure DNS provides name resolution by using the Azure infrastructure""], [""Microsoft Entra ID"", ""system"", ""Use Microsoft Entra ID to authenticate clients that call the API gateway""], [""clients"", ""system"", ""clients that call the API gateway""], [""developers"", ""person"", ""accesses documentation and code samples""]], ""relationships"": [[""Backend systems"", ""contains"", ""SaaS systems"", ""These systems might include ""], [""Backend systems"", ""contains"", ""web services"", ""These systems might include ""], [""Backend systems"", ""contains"", ""other Azure services"", ""These systems might include ""], [""web services"", ""contains"", ""SaaS systems"", ""These systems might include ""], [""Azure API Management"", ""contains"", ""API gateway"", ""API Management consists of two related components""], [""Azure API Management"", ""contains"", ""Developer portal"", ""API Management consists of two related components""], [""clients"", ""calls"", ""API gateway"", ""clients that call the API gateway""], [""clients"", ""calls"", ""Microsoft Entra ID"", ""Clients obtain an access token from Microsoft Entra ID""], [""developers"", ""calls"", ""Developer portal"", ""This portal gives your developers access to documentation and code samples for calling the APIs. You can also test APIs in the developer portal""]]}","Based on the provided context, here's the extracted entities and their relationships in JSON format:

```json
{
  ""entities"": [
    [""Azure Logic Apps"", ""system"", ""Orchestrates workflows triggered by HTTP requests, uses connectors for integration.""],
    [""API Gateway (Azure API Management)"", ""component"", ""Accepts HTTP calls, routes them to the backend.""],
    [""Developer Portal (Azure API Management)"", ""component"", ""Provides access to documentation and code samples, allows API testing.""],
    [""Azure DNS"", ""system"", ""Provides name resolution for custom domain names using Azure infrastructure.""],
    [""Microsoft Entra ID"", ""system"", ""Handles authentication for clients calling the API gateway, supports OpenID Connect protocol.""]
  ],
  ""relationships"": [
    [""API Gateway (Azure API Management)"", ""part-of"", ""Azure API Management""],
    [""Developer Portal (Azure API Management)"", ""part-of"", ""Azure API Management""],
    [""Azure Logic Apps"", ""contains"", ""Workflow""],
    [""API Gateway (Azure API Management)"", ""calls"", ""Backend Systems""],
    [""Microsoft Entra ID"", ""called-from"", ""API Gateway (Azure API Management)""]
  ]
}
```","Based on the provided context, here's the extracted entities and their relationships in JSON format:

```json
{
  ""entities"": [
    [""Azure Logic Apps"", ""system"", ""Orchestrates workflows triggered by HTTP requests, uses connectors for integration.""],
    [""API Gateway (Azure API Management)"", ""component"", ""Accepts HTTP calls, routes them to the backend.""],
    [""Developer Portal (Azure API Management)"", ""component"", ""Provides access to documentation and code samples, allows API testing.""],
    [""Azure DNS"", ""system"", ""Provides name resolution for custom domain names using Azure infrastructure.""],
    [""Microsoft Entra ID"", ""system"", ""Handles authentication for clients calling the API gateway, supports OpenID Connect protocol.""]
  ],
  ""relationships"": [
    [""API Gateway (Azure API Management)"", ""part-of"", ""Azure API Management""],
    [""Developer Portal (Azure API Management)"", ""part-of"", ""Azure API Management""],
    [""Azure Logic Apps"", ""contains"", ""Workflow""],
    [""API Gateway (Azure API Management)"", ""calls"", ""Backend Systems""],
    [""Microsoft Entra ID"", ""called-from"", ""API Gateway (Azure API Management)""]
  ]
}
```",4.611282852012664
108,mistral-nemo,../IMAGES NEW/Azure/16 Azure automate-pdf-forms.txt,"
    A designated Outlook email account receives PDF files as attachments. The arrival of an email triggers a logic app to process the email. The logic app is built by using the capabilities of Azure Logic Apps.
    The logic app uploads the PDF files to a container in Azure Data Lake Storage.
    You can also manually or programmatically upload PDF files to the same PDF container.
    The arrival of a PDF file in the PDF container triggers another logic app to process the PDF forms that are in the PDF file.
    The logic app sends the location of the PDF file to a function app for processing. The function app is built by using the capabilities of Azure Functions.
    The function app receives the location of the file and takes these actions:
        It splits the file into single pages if the file has multiple pages. Each page contains one independent form. Split files are saved to a second container in Data Lake Storage.
        It uses HTTPS POST, an Azure REST API, to send the location of the single-page PDF file to AI Document Intelligence for processing. When Azure AI Document Intelligence completes its processing, it sends a response back to the function app, which places the information into a data structure.
        It creates a JSON data file that contains the response data and stores the file to a third container in Data Lake Storage.
    The forms processing logic app receives the processed response data.
    The forms processing logic app sends the processed data to Azure Cosmos DB, which saves the data in a database and in collections.
    Power BI obtains the data from Azure Cosmos DB and provides insights and dashboards.
    You can implement further processing as needed on the data that's in Azure Cosmos DB.

","{""entities"": [[""designated Outlook email account"", ""component"", ""A designated Outlook email account receives PDF files as attachments""], [""logic app"", ""component"", ""The arrival of an email triggers a logic app to process the email.""], [""Azure Logic Apps"", ""system"", ""The logic app is built by using the capabilities of Azure Logic Apps.""], [""Container"", ""component"", ""The logic app uploads the PDF files to a container in Azure Data Lake Storage""], [""Azure Data Lake Storage"", ""system"", ""The logic app uploads the PDF files to a container in Azure Data Lake Storage""], [""logic app 2"", ""system"", ""The arrival of a PDF file in the PDF container triggers another logic app to process the PDF forms""], [""function app"", ""component"", ""The logic app sends the location of the PDF file to a function app for processing.""], [""Azure Functions"", ""system"", ""The function app is built by using the capabilities of Azure Functions""], [""Azure REST API"", ""component"", ""It uses HTTPS POST, an Azure REST API, to send the location of the single-page PDF file""], [""Container 2"", ""component"", ""Split files are saved to a second container in Data Lake Storage""], [""AI Document Intelligence"", ""component"", ""It uses HTTPS POST, an Azure REST API, to send the location of the single-page PDF file to AI Document Intelligence for processing""], [""Container 3"", ""component"", ""JSON data file that contains the response data and stores the file to a third container in Data Lake Storage""], [""forms processing logic app"", ""component"", ""The forms processing logic app receives the processed response data""], [""Azure Cosmos DB"", ""component"", ""The forms processing logic app sends the processed data to Azure Cosmos DB""], [""database"", ""component"", ""Azure Cosmos DB, which saves the data in a database""], [""Power BI"", ""component"", ""Power BI obtains the data from Azure Cosmos DB and provides insights and dashboards""]], ""relationships"": [[""designated Outlook email account"", ""calls"", ""logic app"", ""The arrival of an email triggers a logic app to process the email.""], [""Azure Logic Apps"", ""contains"", ""logic app"", ""The logic app is built by using the capabilities of Azure Logic Apps.""], [""logic app"", ""calls"", ""Container"", ""The logic app uploads the PDF files to a container in Azure Data Lake Storage""], [""Container"", ""part-of"", ""Azure Data Lake Storage"", ""container in Azure Data Lake Storage""], [""Container"", ""calls"", ""logic app 2"", ""The arrival of a PDF file in the PDF container triggers another logic app""], [""logic app"", ""calls"", ""function app"", ""The logic app sends the location of the PDF file to a function app for processing.""], [""function app"", ""part-of"", ""Azure Functions"", ""container in Azure Data Lake Storage""], [""function app"", ""calls"", ""Container 2"", ""Split files are saved to a second container in Data Lake Storage""], [""Azure Data Lake Storage"", ""contains"", ""Container 2"", ""Split files are saved to a second container in Data Lake Storage""], [""function app"", ""calls"", ""Azure REST API"", ""It uses HTTPS POST, an Azure REST API""], [""Azure REST API"", ""calls"", ""AI Document Intelligence"", ""HTTPS POST, an Azure REST API, to send the location of the single-page PDF file to AI Document Intelligence""], [""Azure Data Lake Storage"", ""contains"", ""Container 3"", ""third container in Data Lake Storage""], [""function app"", ""calls"", ""Container 3"", ""It creates a JSON data file that contains the response data and stores the file to a third container""], [""forms processing logic app"", ""calls"", ""Container 3"", ""The forms processing logic app receives the processed response data""], [""forms processing logic app"", ""calls"", ""Azure Cosmos DB"", ""The forms processing logic app sends the processed data to Azure Cosmos DB""], [""Azure Cosmos DB"", ""calls"", ""database"", ""Azure Cosmos DB, which saves the data in a database""], [""Power BI"", ""calls"", ""Azure Cosmos DB"", ""Power BI obtains the data from Azure Cosmos DB and provides insights and dashboards""]]}","{
  ""entities"": [
    [""Outlook Email Account"", ""system""],
    [""Azure Logic Apps (Logic App 1)"", ""system""],
    [""Azure Data Lake Storage (PDF Container)"", ""system""],
    [""Azure Logic Apps (Logic App 2)"", ""system""],
    [""Azure Functions (Function App)"", ""system""],
    [""AI Document Intelligence"", ""component""],
    [""Azure Cosmos DB"", ""system""]
  ],
  ""relationships"": [
    [""Outlook Email Account"", ""triggers"", ""Azure Logic Apps (Logic App 1)""],
    [""Azure Logic Apps (Logic App 1)"", ""contains"", ""PDF Container""],
    [""PDF Container"", ""contains"", ""Azure Logic Apps (Logic App 2)""],
    [""Azure Logic Apps (Logic App 2)"", ""sends_to"", ""Azure Functions (Function App)""],
    [""Azure Functions (Function App)"", ""calls"", ""AI Document Intelligence""],
    [""Azure Functions (Function App)"", ""stores_in"", ""PDF Container""],
    [""Azure Functions (Function App)"", ""stores_in"", ""Azure Data Lake Storage (JSON Container)""],
    [""Azure Logic Apps (Logic App 2)"", ""retrieves_from"", ""Azure Functions (Function App)""],
    [""Azure Logic Apps (Logic App 2)"", ""sends_to"", ""Azure Cosmos DB""]
  ]
}","{
  ""entities"": [
    [""Outlook Email Account"", ""system""],
    [""Azure Logic Apps (Logic App 1)"", ""system""],
    [""Azure Data Lake Storage (PDF Container)"", ""system""],
    [""Azure Logic Apps (Logic App 2)"", ""system""],
    [""Azure Functions (Function App)"", ""system""],
    [""AI Document Intelligence"", ""component""],
    [""Azure Cosmos DB"", ""system""]
  ],
  ""relationships"": [
    [""Outlook Email Account"", ""triggers"", ""Azure Logic Apps (Logic App 1)""],
    [""Azure Logic Apps (Logic App 1)"", ""contains"", ""PDF Container""],
    [""PDF Container"", ""contains"", ""Azure Logic Apps (Logic App 2)""],
    [""Azure Logic Apps (Logic App 2)"", ""sends_to"", ""Azure Functions (Function App)""],
    [""Azure Functions (Function App)"", ""calls"", ""AI Document Intelligence""],
    [""Azure Functions (Function App)"", ""stores_in"", ""PDF Container""],
    [""Azure Functions (Function App)"", ""stores_in"", ""Azure Data Lake Storage (JSON Container)""],
    [""Azure Logic Apps (Logic App 2)"", ""retrieves_from"", ""Azure Functions (Function App)""],
    [""Azure Logic Apps (Logic App 2)"", ""sends_to"", ""Azure Cosmos DB""]
  ]
}",4.9342017579765525
109,mistral-nemo,../IMAGES NEW/Azure/13 Azure Secure Research.txt,"
    Data owners upload datasets into a public blob storage account. The data is encrypted by using Microsoft-managed keys.

    Azure Data Factory uses a trigger that starts copying of the uploaded dataset to a specific location (import path) on another storage account with security controls. The storage account can only be reached through a private endpoint. Also, it's accessed by a service principal with limited permissions. Data Factory deletes the original copy making the dataset immutable.

    Researchers access the secure environment through a streaming application using Azure Virtual Desktop as a privileged jump box.

    The dataset in the secure storage account is presented to the data science VMs provisioned in a secure network environment for research work. Much of the data preparation is done on those VMs.

    The secure environment has Azure Machine Learning compute that can access the dataset through a private endpoint for users for Azure Machine Learning capabilities, such as to train, deploy, automate, and manage machine learning models. At this point, models are created that meet regulatory guidelines. All model data is de-identified by removing personal information.

    Models or de-identified data is saved to a separate location on the secure storage (export path). When new data is added to the export path, a logic app is triggered. In this architecture, the logic app is outside the secure environment because no data is sent to the logic app. Its only function is to send notification and start the manual approval process.

    The app starts an approval process requesting a review of data that is queued to be exported. The manual reviewers ensure that sensitive data isn't exported. After the review process, the data is either approved or denied.

    Note

    If an approval step is not required on exfiltration, the logic app step could be omitted.

    If the de-identified data is approved, it's sent to the Data Factory instance.

    Data Factory moves the data to the public storage account in a separate container to allow external researchers to have access to their exported data and models. Alternately, you can provision another storage account in a lower security environment.

","{""entities"": [[""datasets"", ""component"", ""Data owners upload datasets into a public blob storage account""], [""public blob storage account"", ""system"", ""Data owners upload datasets into a public blob storage account""], [""Azure Data Factory"", ""system"", ""Azure Data Factory uses a trigger that starts copying of the uploaded dataset to a specific location""], [""storage account"", ""system"", ""Azure Data Factory uses a trigger that starts copying of the uploaded dataset to a specific location (import path) on another storage account with security controls""], [""copied dataset"", ""system"", ""Azure Data Factory uses a trigger that starts copying of the uploaded dataset to a specific location (import path) on another storage account with security controls""], [""private endpoint"", ""component"", ""The storage account can only be reached through a private endpoint.""], [""service principal"", ""component"", ""Also, it's accessed by a service principal with limited permissions.""], [""streaming application"", ""component"", ""access the secure environment through a streaming application""], [""Azure Virtual Desktop"", ""component"", ""Azure Virtual Desktop as a privileged jump box""], [""data science VMs"", ""component"", ""data science VMs provisioned in a secure network environment""], [""Azure Machine Learning compute"", ""component"", ""The secure environment has Azure Machine Learning compute that can access the dataset""], [""secure network environment"", ""system"", ""data science VMs provisioned in a secure network environment""], [""machine learning models"", ""component"", ""At this point, models are created that meet regulatory guidelines""], [""de-identified data"", ""component"", ""Models or de-identified data is saved to a separate location on the secure storage (export path)""], [""logic app"", ""component"", ""When new data is added to the export path, a logic app is triggered""], [""separate container"", ""component"", ""Data Factory moves the data to the public storage account in a separate container""], [""moved data"", ""component"", ""Data Factory moves the data to the public storage account in a separate container""], [""Data owners"", ""person"", ""Data owners upload datasets into a public blob storage account""], [""Researchers"", ""person"", ""Researchers access the secure environment through a streaming application using Azure Virtual Desktop as a privileged jump box""], [""manual reviewers"", ""person"", ""The manual reviewers ensure that sensitive data isn't exported.""], [""Users"", ""person"", ""The secure environment has Azure Machine Learning compute that can access the dataset""]], ""relationships"": [[""datasets"", ""part-of"", ""public blob storage account"", ""Data owners upload datasets into a public blob storage account""], [""Data owners"", ""calls"", ""datasets"", ""Data owners upload datasets into a public blob storage account""], [""Azure Data Factory"", ""calls"", ""datasets"", ""Azure Data Factory uses a trigger that starts copying of the uploaded dataset""], [""storage account"", ""contains"", ""copied dataset"", ""opying of the uploaded dataset to a specific location (import path) on another storage account with security controls""], [""Azure Data Factory"", ""calls"", ""copied dataset"", ""Azure Data Factory uses a trigger that starts copying of the uploaded dataset to a specific location""], [""private endpoint"", ""calls"", ""storage account"", ""The storage account can only be reached through a private endpoint""], [""storage account"", ""is-called-from"", ""service principal"", ""Also, it's accessed by a service principal with limited permissions""], [""Researchers"", ""calls"", ""Azure Virtual Desktop"", "" Researchers access the secure environment through a streaming application""], [""Azure Virtual Desktop"", ""calls"", ""streaming application"", ""through a streaming application using Azure Virtual Desktop""], [""streaming application"", ""calls"", ""storage account"", ""Researchers access the secure environment through a streaming application using Azure Virtual Desktop as a privileged jump box""], [""data science VMs"", ""part-of"", ""secure network environment"", ""The dataset in the secure storage account is presented to the data science VMs""], [""data science VMs"", ""calls"", ""copied dataset"", "" The dataset in the secure storage account is presented to the data science VMs""], [""secure network environment"", ""contains"", ""Azure Machine Learning compute"", ""The secure environment has Azure Machine Learning compute that can access the dataset""], [""Azure Machine Learning compute"", ""calls"", ""Azure Machine Learning compute"", ""The secure environment has Azure Machine Learning compute that can access the dataset""], [""machine learning models"", ""part-of"", ""storage account"", ""Models or de-identified data is saved to a separate location on the secure storage (export path)""], [""machine learning models"", ""calls"", ""logic app"", ""When new data is added to the export path, a logic app is triggered""], [""logic app"", ""calls"", ""manual reviewers"", ""The app starts an approval process requesting a review of data that is queued to be exported.""], [""public blob storage account"", ""contains"", ""separate container"", ""Data Factory moves the data to the public storage account in a separate container""], [""Azure Data Factory"", ""calls"", ""de-identified data"", ""Data Factory moves the data to the public storage account in a separate container to allow external researchers to have access to their exported data and models""], [""separate container"", ""contains"", ""moved data"", ""Data Factory moves the data to the public storage account in a separate container""], [""Azure Data Factory"", ""calls"", ""moved data"", ""Data Factory moves the data to the public storage account in a separate container to allow external researchers to have access to their exported data and models""], [""Users"", ""calls"", ""Azure Machine Learning compute"", ""The secure environment has Azure Machine Learning compute that can access the dataset""]]}","Based on the provided context, here's the extracted entities and relationships in JSON format:

```json
{
  ""entities"": [
    [""Data Owners"", ""person""],
    [""Azure Blob Storage Account (Public)"", ""system""],
    [""Azure Data Factory"", ""component""],
    [""Specific Location (Import Path)"", ""component""],
    [""Another Storage Account (Private)"", ""system""],
    [""Service Principal"", ""person""],
    [""Streaming Application"", ""component""],
    [""Azure Virtual Desktop"", ""component""],
    [""Data Science VMs"", ""system""],
    [""Secure Network Environment"", ""system""],
    [""Azure Machine Learning Compute"", ""component""],
    [""Models/De-identified Data"", ""component""],
    [""Separate Location (Export Path)"", ""component""],
    [""Logic App"", ""component""],
    [""Manual Reviewers"", ""person""],
    [""External Researchers"", ""person""],
    [""Another Storage Account (Public)"", ""system""]
  ],
  ""relationships"": [
    [""Data Owners"", ""uploads"", ""Azure Blob Storage Account (Public)""],
    [""Azure Data Factory"", ""contains"", ""Specific Location (Import Path)""],
    [""Azure Data Factory"", ""uses"", ""Trigger""],
    [""Azure Data Factory"", ""deletes"", ""Original Copy""],
    [""Another Storage Account (Private)"", ""part-of"", ""Secure Environment""],
    [""Another Storage Account (Private)"", ""accessed-by"", ""Service Principal""],
    [""Streaming Application"", ""uses"", ""Azure Virtual Desktop""],
    [""Data Science VMs"", ""presented-by"", ""Dataset""],
    [""Data Science VMs"", ""located-in"", ""Secure Network Environment""],
    [""Azure Machine Learning Compute"", ""accesses"", ""Dataset""],
    [""Models/De-identified Data"", ""saved-to"", ""Separate Location (Export Path)""],
    [""Logic App"", ""triggered-by"", ""New Data Addition""],
    [""Logic App"", ""starts"", ""Approval Process""],
    [""Manual Reviewers"", ""ensure"", ""No Sensitive Data Exfiltration""],
    [""Approved Data/Models"", ""sent-to"", ""Azure Data Factory""],
    [""Azure Data Factory"", ""moves"", ""Data/Models"", ""Another Storage Account (Public)""]
  ]
}
```","Based on the provided context, here's the extracted entities and relationships in JSON format:

```json
{
  ""entities"": [
    [""Data Owners"", ""person""],
    [""Azure Blob Storage Account (Public)"", ""system""],
    [""Azure Data Factory"", ""component""],
    [""Specific Location (Import Path)"", ""component""],
    [""Another Storage Account (Private)"", ""system""],
    [""Service Principal"", ""person""],
    [""Streaming Application"", ""component""],
    [""Azure Virtual Desktop"", ""component""],
    [""Data Science VMs"", ""system""],
    [""Secure Network Environment"", ""system""],
    [""Azure Machine Learning Compute"", ""component""],
    [""Models/De-identified Data"", ""component""],
    [""Separate Location (Export Path)"", ""component""],
    [""Logic App"", ""component""],
    [""Manual Reviewers"", ""person""],
    [""External Researchers"", ""person""],
    [""Another Storage Account (Public)"", ""system""]
  ],
  ""relationships"": [
    [""Data Owners"", ""uploads"", ""Azure Blob Storage Account (Public)""],
    [""Azure Data Factory"", ""contains"", ""Specific Location (Import Path)""],
    [""Azure Data Factory"", ""uses"", ""Trigger""],
    [""Azure Data Factory"", ""deletes"", ""Original Copy""],
    [""Another Storage Account (Private)"", ""part-of"", ""Secure Environment""],
    [""Another Storage Account (Private)"", ""accessed-by"", ""Service Principal""],
    [""Streaming Application"", ""uses"", ""Azure Virtual Desktop""],
    [""Data Science VMs"", ""presented-by"", ""Dataset""],
    [""Data Science VMs"", ""located-in"", ""Secure Network Environment""],
    [""Azure Machine Learning Compute"", ""accesses"", ""Dataset""],
    [""Models/De-identified Data"", ""saved-to"", ""Separate Location (Export Path)""],
    [""Logic App"", ""triggered-by"", ""New Data Addition""],
    [""Logic App"", ""starts"", ""Approval Process""],
    [""Manual Reviewers"", ""ensure"", ""No Sensitive Data Exfiltration""],
    [""Approved Data/Models"", ""sent-to"", ""Azure Data Factory""],
    [""Azure Data Factory"", ""moves"", ""Data/Models"", ""Another Storage Account (Public)""]
  ]
}
```",7.916450096992776
110,mistral-nemo,../IMAGES NEW/Azure/08 Azure Business Processes.txt,"
The data flows through the solution as follows:

    The airline system communicates with a custom API hosted in Azure API Management.
    A custom API coordinator receives notifications and handles incoming messages from the airline system. It sends them to Power Apps, where flights are assigned to Microsoft Teams channels.
    When a user selects a flight to monitor, or when the system assigns the user to a flight, the system queues a Graph API call in an Azure Storage Account queue for further processing.
    Azure Functions runs the Graph API calls based on the incoming messages in the storage queue, sending notifications to Teams, and also streams all events to an Azure Event Hubs for further analytics.
    The airline's notification system is managed by a custom bot messaging service that employs Azure Bot Service.
    Custom bots send flight updates to users in Teams.
    An Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs, ultimately generating insightful reports with Power BI.

","{""entities"": [[""airline system"", ""system"", ""communicates with a custom API hosted in Azure API Management""], [""custom API"", ""component"", ""communicates with a custom API hosted in Azure API Management""], [""Azure API Management"", ""system"", ""communicates with a custom API hosted in Azure API Management""], [""custom API coordinator"", ""system"", ""receives notifications and handles incoming messages from the airline system""], [""Power Apps"", ""system"", ""where flights are assigned to Microsoft Teams channels""], [""Microsoft Teams channels"", ""system"", ""where flights are assigned to Microsoft Teams channels""], [""Storage Account queue"", ""system"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing.""], [""Graph API call"", ""system"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing.""], [""Azure Functions"", ""system"", ""runs the Graph API calls based on the incoming messages in the storage queue""], [""Azure Event Hubs"", ""system"", ""Azure Event Hubs for further analytics""], [""notification system"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""custom bot messaging service"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""Azure Bot Service"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""Users"", ""person"", ""selects a flight to monitor, or when the system assigns the user to a flight""], [""Azure Data Lake storage"", ""system"", ""offers long-term retention and micro-batch processing of events from Event Hubs""], [""Power BI"", ""system"", ""generating insightful reports""]], ""relationships"": [[""Azure API Management"", ""contains"", ""custom API"", ""custom API hosted in Azure API Management""], [""airline system"", ""calls"", ""custom API"", ""communicates with a custom API""], [""custom API coordinator"", ""is-called-from"", ""airline system"", ""receives notifications and handles incoming messages from the airline system""], [""Power Apps"", ""calls"", ""Microsoft Teams channels"", ""Power Apps, where flights are assigned to Microsoft Teams channels""], [""airline system"", ""calls"", ""Graph API call"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing""], [""Azure Functions"", ""calls"", ""Graph API call"", ""runs the Graph API calls based on the incoming messages in the storage queue""], [""Azure Functions"", ""calls"", ""Storage Account queue"", ""based on the incoming messages in the storage queue""], [""Azure Functions"", ""calls"", ""Microsoft Teams channels"", ""sending notifications to Teams""], [""Azure Functions"", ""calls"", ""Azure Event Hubs"", ""also streams all events to an Azure Event Hubs for further analytics""], [""notification system"", ""is-called-from"", ""custom bot messaging service"", ""managed by a custom bot messaging service""], [""custom bot messaging service"", ""calls"", ""Azure Bot Service"", ""custom bot messaging service that employs Azure Bot Service""], [""custom bot messaging service"", ""calls"", ""Microsoft Teams channels"", ""Custom bots send flight updates to users in Teams.""], [""Microsoft Teams channels"", ""calls"", ""Users"", ""Custom bots send flight updates to users in Teams.""], [""Azure Data Lake storage"", ""is-called-from"", ""Azure Event Hubs"", ""Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs""], [""Azure Data Lake storage"", ""calls"", ""Power BI"", ""Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs, ultimately generating insightful reports with Power BI""]]}","{
  ""entities"": [
    [""Airline System"", ""system""],
    [""Azure API Management"", ""system""],
    [""Custom API Coordinator"", ""component""],
    [""Power Apps"", ""system""],
    [""Microsoft Teams"", ""system""],
    [""Azure Storage Account"", ""system""],
    [""Azure Functions"", ""component""],
    [""Graph API"", ""component""],
    [""Azure Event Hubs"", ""system""],
    [""Azure Data Lake storage"", ""system""],
    [""Custom Bot Messaging Service"", ""system""],
    [""Azure Bot Service"", ""system""]
  ],
  ""relationships"": [
    [""Airline System"", ""calls"", ""Azure API Management""],
    [""Custom API Coordinator"", ""part-of"", ""Azure API Management""],
    [""Custom API Coordinator"", ""contains"", ""Power Apps""],
    [""Power Apps"", ""contains"", ""Microsoft Teams""],
    [""Custom API Coordinator"", ""calls"", ""Azure Storage Account""],
    [""Azure Storage Account"", ""contains"", ""Graph API""],
    [""Graph API"", ""called-from"", ""Azure Functions""],
    [""Azure Functions"", ""part-of"", ""Azure Storage Account""],
    [""Azure Functions"", ""contains"", ""Graph API""],
    [""Azure Functions"", ""calls"", ""Azure Event Hubs""],
    [""Custom Bot Messaging Service"", ""part-of"", ""Azure Bot Service""],
    [""Azure Bot Service"", ""contains"", ""Microsoft Teams""]
  ]
}","{
  ""entities"": [
    [""Airline System"", ""system""],
    [""Azure API Management"", ""system""],
    [""Custom API Coordinator"", ""component""],
    [""Power Apps"", ""system""],
    [""Microsoft Teams"", ""system""],
    [""Azure Storage Account"", ""system""],
    [""Azure Functions"", ""component""],
    [""Graph API"", ""component""],
    [""Azure Event Hubs"", ""system""],
    [""Azure Data Lake storage"", ""system""],
    [""Custom Bot Messaging Service"", ""system""],
    [""Azure Bot Service"", ""system""]
  ],
  ""relationships"": [
    [""Airline System"", ""calls"", ""Azure API Management""],
    [""Custom API Coordinator"", ""part-of"", ""Azure API Management""],
    [""Custom API Coordinator"", ""contains"", ""Power Apps""],
    [""Power Apps"", ""contains"", ""Microsoft Teams""],
    [""Custom API Coordinator"", ""calls"", ""Azure Storage Account""],
    [""Azure Storage Account"", ""contains"", ""Graph API""],
    [""Graph API"", ""called-from"", ""Azure Functions""],
    [""Azure Functions"", ""part-of"", ""Azure Storage Account""],
    [""Azure Functions"", ""contains"", ""Graph API""],
    [""Azure Functions"", ""calls"", ""Azure Event Hubs""],
    [""Custom Bot Messaging Service"", ""part-of"", ""Azure Bot Service""],
    [""Azure Bot Service"", ""contains"", ""Microsoft Teams""]
  ]
}",5.1339306849986315
111,mistral-nemo,../IMAGES NEW/Azure/10 Azure LoB original.txt,"
The data flows through the solution as follows:

    Supplier data stored in CDS is moved to SQL via Data Factory.
    Purchase order (PO) data stored in ERP system is sent to Azure SQL database.
    Azure Functions uses API to surface PO data monthly and creates a task for users to review.
    Power Apps retrieves data from Azure SQL Database through API.
    User reviews and updates POs in Power Apps and sends this data to suppliers through CSV export.
    Power BI reports trends in supplier status.

","{""entities"": [[""Supplier data"", ""component"", ""Supplier data stored in CDS""], [""CDS"", ""system"", "" Supplier data stored in CDS""], [""Azure SQL database"", ""system"", ""moved to SQL via Data Factory""], [""Data Factory"", ""system"", ""moved to SQL via Data Factory""], [""Purchase order (PO)"", ""system"", ""moved to SQL via Data Factory""], [""ERP system"", ""system"", ""Purchase order (PO) data stored in ERP system""], [""Azure Functions"", ""system"", ""uses API to surface PO data monthly and creates a task for users to review""], [""Power Apps"", ""system"", ""retrieves data from Azure SQL Database through API""], [""CSV export"", ""system"", ""ends this data to suppliers through CSV export""], [""User"", ""person"", "" reviews and updates POs in Power Apps""], [""suppliers"", ""person"", "" reviews and updates POs in Power Apps""]], ""relationships"": [[""Supplier data"", ""part-of"", ""CDS"", ""Supplier data stored in CDS""], [""Supplier data"", ""is-called-from"", ""Data Factory"", ""moved to SQL via Data Factory""], [""Data Factory"", ""calls"", ""Azure SQL database"", ""moved to SQL via Data Factory""], [""Purchase order (PO)"", ""part-of"", ""ERP system"", ""Purchase order (PO) data stored in ERP system""], [""Purchase order (PO)"", ""calls"", ""Azure SQL database"", ""Purchase order (PO) data stored in ERP system is sent to Azure SQL database""], [""Azure Functions"", ""calls"", ""Purchase order (PO)"", ""uses API to surface PO data monthly""], [""Azure Functions"", ""calls"", ""User"", ""creates a task for users to review""], [""Power Apps"", ""calls"", ""Azure SQL database"", ""retrieves data from Azure SQL Database through API""], [""User"", ""calls"", ""Power Apps"", ""Reviews and updates POs in Power Apps""], [""User"", ""calls"", ""CSV export"", ""sends this data to suppliers through CSV export""], [""CSV export"", ""calls"", ""suppliers"", ""sends this data to suppliers through CSV export""]]}","```json
{
  ""entities"": [
    [""Supplier"", ""system""],
    [""CDS"", ""component"", ""Supplier data storage""],
    [""Data Factory"", ""component"", ""Moves supplier data to SQL""],
    [""SQL"", ""component"", ""Stores supplier data""],
    [""ERP system"", ""system""],
    [""Azure SQL database"", ""system""],
    [""Purchase order (PO) data"", ""component"", ""Stored in ERP and sent to Azure SQL""],
    [""Azure Functions"", ""component"", ""Surfaces PO data monthly""],
    [""Power Apps"", ""component"", ""Retrieves data from Azure SQL Database, updates POs and sends them to suppliers""],
    [""Power BI"", ""component"", ""Reports trends in supplier status""]
  ],
  ""relationships"": [
    [""CDS"", ""contains"", ""Supplier""],
    [""ERP system"", ""calls"", ""Azure SQL database""],
    [""Azure Functions"", ""called-from"", ""Azure SQL database""],
    [""Azure Functions"", ""calls"", ""Power Apps""],
    [""Power Apps"", ""part-of"", ""Azure Functions""],
    [""Power BI"", ""called-from"", ""Azure SQL database""]
  ]
}
```","```json
{
  ""entities"": [
    [""Supplier"", ""system""],
    [""CDS"", ""component"", ""Supplier data storage""],
    [""Data Factory"", ""component"", ""Moves supplier data to SQL""],
    [""SQL"", ""component"", ""Stores supplier data""],
    [""ERP system"", ""system""],
    [""Azure SQL database"", ""system""],
    [""Purchase order (PO) data"", ""component"", ""Stored in ERP and sent to Azure SQL""],
    [""Azure Functions"", ""component"", ""Surfaces PO data monthly""],
    [""Power Apps"", ""component"", ""Retrieves data from Azure SQL Database, updates POs and sends them to suppliers""],
    [""Power BI"", ""component"", ""Reports trends in supplier status""]
  ],
  ""relationships"": [
    [""CDS"", ""contains"", ""Supplier""],
    [""ERP system"", ""calls"", ""Azure SQL database""],
    [""Azure Functions"", ""called-from"", ""Azure SQL database""],
    [""Azure Functions"", ""calls"", ""Power Apps""],
    [""Power Apps"", ""part-of"", ""Azure Functions""],
    [""Power BI"", ""called-from"", ""Azure SQL database""]
  ]
}
```",4.369954506983049
112,mistral-nemo,../IMAGES NEW/Azure/15 Azure automate-document-classification.txt,"
    The user provides a document file that the web app uploads. The file contains multiple documents of various types. It can, for instance, be a PDF or multipage TIFF file.
        The document file is stored in Azure Blob Storage.
        The web app adds a command message to a storage queue to initiate pipeline processing.

    Durable Functions orchestration is triggered by the command message. The message contains metadata that identifies the location in Blob Storage of the document file to be processed. Each Durable Functions instance processes only one document file.

    The Scan activity function calls the Computer Vision Read API, passing in the location in storage of the document to be processed. Optical character recognition (OCR) results are returned to the orchestration to be used by subsequent activities.

    The Classify activity function calls the document classifier service that's hosted in an Azure Kubernetes Service (AKS) cluster. This service uses regular expression pattern matching to identify the starting page of each known document and to calculate how many document types are contained in the document file. The types and page ranges of the documents are calculated and returned to the orchestration.



Note

Azure doesn't offer a service that can classify multiple document types in a single file. This solution uses a non-Azure service that's hosted in AKS.

The Metadata Store activity function saves the document type and page range information in an Azure Cosmos DB store.

The Indexing activity function creates a new search document in the Cognitive Search service for each identified document type and uses the Azure AI Search libraries for .NET to include in the search document the full OCR results and document information. A correlation ID is also added to the search document so that the search results can be matched with the corresponding document metadata from Azure Cosmos DB.

End users can search for documents by contents and metadata. Correlation IDs in the search result set can be used to look up document records that are in Azure Cosmos DB. The records include links to the original document file in Blob Storage.


","{""entities"": [[""web app"", ""system"", ""The user provides a document file that the web app uploads""], [""Azure Blob Storage"", ""system"", ""The document file is stored in Azure Blob Storage""], [""storage queue"", ""system"", ""the web app adds a command message to a storage queue to initiate pipeline processing""], [""Durable Functions orchestration"", ""system"", ""Durable Functions orchestration is triggered by the command message.""], [""Scan activity function"", ""component"", ""The Scan activity function calls the Computer Vision Read API.""], [""Computer Vision Read API"", ""component"", ""The Scan activity function calls the Computer Vision Read API.""], [""Classify activity function"", ""component"", ""The Classify activity function calls the document classifier service that's hosted in an Azure Kubernetes Service (AKS) cluster""], [""document classifier service"", ""component"", ""The Classify activity function calls the document classifier service that's hosted in an Azure Kubernetes Service (AKS) cluster""], [""Azure Kubernetes Service (AKS) cluster"", ""system"", ""The Classify activity function calls the document classifier service that's hosted in an Azure Kubernetes Service (AKS) cluster""], [""User"", ""person"", ""provides a document file that the web app uploads""]], ""relationships"": [[""User"", ""calls"", ""web app"", ""The user provides a document file that the web app uploads""], [""web app"", ""calls"", ""Azure Blob Storage"", ""The user provides a document file that the web app uploads.The document file is stored in Azure Blob Storage""], [""web app"", ""calls"", ""storage queue"", ""the web app adds a command message to a storage queue to initiate pipeline processing""], [""storage queue"", ""calls"", ""Durable Functions orchestration"", ""Durable Functions orchestration is triggered by the command message.""], [""Durable Functions orchestration"", ""calls"", ""Azure Blob Storage"", ""Each Durable Functions instance processes only one document file""], [""Scan activity function"", ""calls"", ""Computer Vision Read API"", ""the Scan activity function calls the Computer Vision Read API""], [""document classifier service"", ""part-of"", ""Azure Kubernetes Service (AKS) cluster"", ""document classifier service that's hosted in an Azure Kubernetes Service (AKS) cluster""], [""Classify activity function"", ""calls"", ""Scan activity function"", ""The Classify activity function calls the document classifier service""], [""Classify activity function"", ""calls"", ""Durable Functions orchestration"", ""The types and page ranges of the documents are calculated and returned to the orchestration""]]}","Here's the JSON response based on the provided text:

```json
{
  ""entities"": [
    [""WebApp"", ""system"", ""The user provides a document file that the web app uploads.""],
    [""AzureBlobStorage"", ""component"", ""The document file is stored in Azure Blob Storage.""],
    [""StorageQueue"", ""component"", ""The web app adds a command message to a storage queue.""],
    [""DurableFunctionsOrchestration"", ""system"", ""Durable Functions orchestration is triggered by the command message.""],
    [""ScanActivityFunction"", ""component"", ""The Scan activity function calls...""],
    [""ComputerVisionReadAPI"", ""component"", ""...the Computer Vision Read API...""],
    [""ClassifyActivityFunction"", ""component"", ""The Classify activity function calls...""],
    [""DocumentClassifierService"", ""system"", ""...the document classifier service hosted in AKS.""],
    [""AzureKubernetesServiceAKS"", ""system"", ""An Azure Kubernetes Service (AKS) cluster.""],
    [""MetadataStoreActivityFunction"", ""component"", ""The Metadata Store activity function saves...""],
    [""AzureCosmosDB"", ""system"", ""...in an Azure Cosmos DB store.""],
    [""IndexingActivityFunction"", ""component"", ""The Indexing activity function creates...""],
    [""CognitiveSearchService"", ""system"", ""...a new search document in the Cognitive Search service.""],
    [""EndUsers"", ""person"", ""End users can search for documents by contents and metadata.""],
    [""AzureAI_search_libraries"", ""component"", ""The Azure AI Search libraries for .NET""]
  ],
  ""relationships"": [
    [""WebApp"", ""calls"", ""AzureBlobStorage""],
    [""AzureBlobStorage"", ""contains"", ""document file""],
    [""WebApp"", ""adds"", ""StorageQueue""],
    [""DurableFunctionsOrchestration"", ""part-of"", ""WebApp""],
    [""DurableFunctionsOrchestration"", ""contains"", ""ScanActivityFunction""],
    [""ScanActivityFunction"", ""calls"", ""ComputerVisionReadAPI""],
    [""ClassifyActivityFunction"", ""called-from"", ""DurableFunctionsOrchestration""],
    [""ClassifyActivityFunction"", ""part-of"", ""AzureKubernetesServiceAKS""],
    [""AzureKubernetesServiceAKS"", ""contains"", ""DocumentClassifierService""],
    [""MetadataStoreActivityFunction"", ""called-from"", ""DurableFunctionsOrchestration""],
    [""MetadataStoreActivityFunction"", ""part-of"", ""AzureCosmosDB""],
    [""AzureCosmosDB"", ""contains"", ""document type and page range information""],
    [""IndexingActivityFunction"", ""called-from"", ""DurableFunctionsOrchestration""],
    [""EndUsers"", ""searches"", ""CognitiveSearchService""],
    [""CognitiveSearchService"", ""contains"", ""search documents""]
  ]
}
```","Here's the JSON response based on the provided text:

```json
{
  ""entities"": [
    [""WebApp"", ""system"", ""The user provides a document file that the web app uploads.""],
    [""AzureBlobStorage"", ""component"", ""The document file is stored in Azure Blob Storage.""],
    [""StorageQueue"", ""component"", ""The web app adds a command message to a storage queue.""],
    [""DurableFunctionsOrchestration"", ""system"", ""Durable Functions orchestration is triggered by the command message.""],
    [""ScanActivityFunction"", ""component"", ""The Scan activity function calls...""],
    [""ComputerVisionReadAPI"", ""component"", ""...the Computer Vision Read API...""],
    [""ClassifyActivityFunction"", ""component"", ""The Classify activity function calls...""],
    [""DocumentClassifierService"", ""system"", ""...the document classifier service hosted in AKS.""],
    [""AzureKubernetesServiceAKS"", ""system"", ""An Azure Kubernetes Service (AKS) cluster.""],
    [""MetadataStoreActivityFunction"", ""component"", ""The Metadata Store activity function saves...""],
    [""AzureCosmosDB"", ""system"", ""...in an Azure Cosmos DB store.""],
    [""IndexingActivityFunction"", ""component"", ""The Indexing activity function creates...""],
    [""CognitiveSearchService"", ""system"", ""...a new search document in the Cognitive Search service.""],
    [""EndUsers"", ""person"", ""End users can search for documents by contents and metadata.""],
    [""AzureAI_search_libraries"", ""component"", ""The Azure AI Search libraries for .NET""]
  ],
  ""relationships"": [
    [""WebApp"", ""calls"", ""AzureBlobStorage""],
    [""AzureBlobStorage"", ""contains"", ""document file""],
    [""WebApp"", ""adds"", ""StorageQueue""],
    [""DurableFunctionsOrchestration"", ""part-of"", ""WebApp""],
    [""DurableFunctionsOrchestration"", ""contains"", ""ScanActivityFunction""],
    [""ScanActivityFunction"", ""calls"", ""ComputerVisionReadAPI""],
    [""ClassifyActivityFunction"", ""called-from"", ""DurableFunctionsOrchestration""],
    [""ClassifyActivityFunction"", ""part-of"", ""AzureKubernetesServiceAKS""],
    [""AzureKubernetesServiceAKS"", ""contains"", ""DocumentClassifierService""],
    [""MetadataStoreActivityFunction"", ""called-from"", ""DurableFunctionsOrchestration""],
    [""MetadataStoreActivityFunction"", ""part-of"", ""AzureCosmosDB""],
    [""AzureCosmosDB"", ""contains"", ""document type and page range information""],
    [""IndexingActivityFunction"", ""called-from"", ""DurableFunctionsOrchestration""],
    [""EndUsers"", ""searches"", ""CognitiveSearchService""],
    [""CognitiveSearchService"", ""contains"", ""search documents""]
  ]
}
```",9.957980541978031
113,mistral-nemo,../IMAGES NEW/Azure/11 Mainframe original.txt,"
    A Connect agent component captures change logs by using mainframe or midrange native utilities and caches the logs in temporary storage.
    For mainframe systems, a publisher component on the mainframe manages data migration.
    For midrange systems, in place of the publisher, a listener component manages data migration. It's located on either a Windows or Linux machine.
    The publisher or listener moves the data from on-premises to Azure via an enhanced-security connection. The publisher or listener handles the commit and rollback of transactions for each unit of work, maintaining the integrity of data.
    The Connect Replicator Engine captures the data from the publisher or listener and applies it to the target. It distributes data for parallel processing.
    The target is a database that receives the changes via ODBC or ingests the changes via Azure Event Hubs.
    The changed data is consumed by Azure Databricks and applied to Azure data platform services.
    The Connect Controller Daemon authenticates the request and establishes the socket connection between the publisher or listener and the Replicator Engine.

","{""entities"": [[""Connect agent"", ""component"", ""captures change logs""], [""temporary storage"", ""component"", ""caches the logs in temporary storage""], [""mainframe native utilities"", ""system"", ""captures change logs by using mainframe or midrange native utilities""], [""midrange native utilities"", ""system"", ""captures change logs by using mainframe or midrange native utilities""], [""mainframe systems"", ""system"", ""For mainframe systems, a publisher component on the mainframe manages data migration.""], [""midrange systems"", ""system"", ""For midrange systems, in place of the publisher, a listener component manages data migration.""], [""publisher"", ""component"", ""For mainframe systems, a publisher component on the mainframe manages data migration.""], [""listener"", ""component"", ""For midrange systems, in place of the publisher, a listener component manages data migration.""], [""Connect Replicator Engine"", ""system"", ""captures the data from the publisher or listener and applies it to the target.""], [""on-premises"", ""system"", ""The publisher or listener moves the data from on-premises to Azure""], [""Azure"", ""system"", ""The publisher or listener moves the data from on-premises to Azure""], [""Connect Replicator Engine"", ""system"", ""The Connect Replicator Engine captures the data from the publisher or listener""], [""target"", ""system"", ""applies it to the target""], [""database"", ""system"", ""target is a database""], [""ODBC"", ""component"", ""The target is a database that receives the changes via ODBC or ingests the changes via Azure Event Hubs""], [""Azure Event Hubs"", ""component"", ""The target is a database that receives the changes via ODBC or ingests the changes via Azure Event Hubs""], [""Azure Databricks"", ""component"", ""the changed data is consumed by Azure Databricks and applied to Azure data platform services.""], [""Azure data platform services"", ""component"", ""the changed data is consumed by Azure Databricks and applied to Azure data platform services.""], [""Connect Controller Daemon"", ""component"", ""authenticates the request and establishes the socket connection between the publisher or listener and the Replicator Engine.""]], ""relationships"": [[""Connect agent"", ""calls"", ""mainframe native utilities"", ""captures change logs by using mainframe or midrange native utilities""], [""Connect agent"", ""calls"", ""midrange native utilities"", ""captures change logs by using mainframe or midrange native utilities""], [""Connect agent"", ""calls"", ""temporary storage"", ""captures change logs by using mainframe or midrange native utilities""], [""mainframe systems"", ""contains"", ""mainframe native utilities"", ""F""], [""midrange systems"", ""contains"", ""midrange native utilities"", """"], [""mainframe systems"", ""contains"", ""publisher"", ""For mainframe systems, a publisher component on the mainframe manages data migration.""], [""midrange systems"", ""contains"", ""listener"", ""For midrange systems, in place of the publisher, a listener component manages data migration.""], [""publisher"", ""calls"", ""on-premises"", ""The publisher or listener moves the data from on-premises to Azure""], [""publisher"", ""calls"", ""Azure"", ""The publisher or listener moves the data from on-premises to Azure""], [""listener"", ""calls"", ""on-premises"", ""The publisher or listener moves the data from on-premises to Azure""], [""listener"", ""calls"", ""Azure"", ""The publisher or listener moves the data from on-premises to Azure""], [""Connect Replicator Engine"", ""calls"", ""publisher"", ""captures the data from the publisher or listener and applies it to the target.""], [""Connect Replicator Engine"", ""calls"", ""listener"", ""captures the data from the publisher or listener and applies it to the target.""], [""Connect Replicator Engine"", ""calls"", ""target"", ""captures the data from the publisher or listener and applies it to the target.""], [""target"", ""contains"", ""database"", ""target is a database""], [""database"", ""is-called-from"", ""ODBC"", ""database that receives the changes via ODBC""], [""database"", ""is-called-from"", ""Azure Event Hubs"", ""ingests the changes via Azure Event Hubs""], [""database"", ""is-called-from"", ""Azure Databricks"", ""the changed data is consumed by Azure Databricks""], [""Azure Databricks"", ""calls"", ""Azure data platform services"", ""consumed by Azure Databricks and applied to Azure data platform services.""], [""Connect Controller Daemon"", ""is-called-from"", ""publisher"", ""establishes the socket connection between the publisher or listener and the Replicator Engine..""], [""Connect Controller Daemon"", ""is-called-from"", ""listener"", ""establishes the socket connection between the publisher or listener and the Replicator Engine..""], [""Connect Controller Daemon"", ""calls"", ""Connect Replicator Engine"", ""establishes the socket connection between the publisher or listener and the Replicator Engine..""]]}","{
  ""entities"": [
    [""Connect Agent"", ""component"", ""Captures change logs""],
    [""Mainframe Native Utilities"", ""system"", ""Used by Connect Agent""],
    [""Midrange Native Utilities"", ""system"", ""Used by Connect Agent""],
    [""Publisher Component"", ""component"", ""Manages data migration for mainframe systems""],
    [""Listener Component"", ""component"", ""Manages data migration for midrange systems""],
    [""Windows/Linux Machine"", ""system"", ""Location of Listener Component""],
    [""Azure Event Hubs"", ""system"", ""Receives changes from target database""],
    [""ODBC"", ""system"", ""Used by target database to receive changes""],
    [""Connect Replicator Engine"", ""component"", ""Captures data from publisher/listener and applies it to target""],
    [""Target Database"", ""system"", ""Receives changes via ODBC or Azure Event Hubs""],
    [""Azure Databricks"", ""system"", ""Consumes changed data and applies it to Azure data platform services""],
    [""Connect Controller Daemon"", ""component"", ""Authenticates requests and establishes socket connection""]
  ],
  ""relationships"": [
    [""Connect Agent"", ""contains"", ""Mainframe Native Utilities""],
    [""Connect Agent"", ""contains"", ""Midrange Native Utilities""],
    [""Publisher Component"", ""part-of"", ""Connect Agent""],
    [""Listener Component"", ""part-of"", ""Connect Agent""],
    [""Listener Component"", ""calls"", ""Windows/Linux Machine""],
    [""Publisher/Listener"", ""calls"", ""Azure""],
    [""Connect Replicator Engine"", ""contains"", ""Target Database""],
    [""Connect Controller Daemon"", ""called-from"", ""Publisher Component""],
    [""Connect Controller Daemon"", ""called-from"", ""Listener Component""]
  ]
}","{
  ""entities"": [
    [""Connect Agent"", ""component"", ""Captures change logs""],
    [""Mainframe Native Utilities"", ""system"", ""Used by Connect Agent""],
    [""Midrange Native Utilities"", ""system"", ""Used by Connect Agent""],
    [""Publisher Component"", ""component"", ""Manages data migration for mainframe systems""],
    [""Listener Component"", ""component"", ""Manages data migration for midrange systems""],
    [""Windows/Linux Machine"", ""system"", ""Location of Listener Component""],
    [""Azure Event Hubs"", ""system"", ""Receives changes from target database""],
    [""ODBC"", ""system"", ""Used by target database to receive changes""],
    [""Connect Replicator Engine"", ""component"", ""Captures data from publisher/listener and applies it to target""],
    [""Target Database"", ""system"", ""Receives changes via ODBC or Azure Event Hubs""],
    [""Azure Databricks"", ""system"", ""Consumes changed data and applies it to Azure data platform services""],
    [""Connect Controller Daemon"", ""component"", ""Authenticates requests and establishes socket connection""]
  ],
  ""relationships"": [
    [""Connect Agent"", ""contains"", ""Mainframe Native Utilities""],
    [""Connect Agent"", ""contains"", ""Midrange Native Utilities""],
    [""Publisher Component"", ""part-of"", ""Connect Agent""],
    [""Listener Component"", ""part-of"", ""Connect Agent""],
    [""Listener Component"", ""calls"", ""Windows/Linux Machine""],
    [""Publisher/Listener"", ""calls"", ""Azure""],
    [""Connect Replicator Engine"", ""contains"", ""Target Database""],
    [""Connect Controller Daemon"", ""called-from"", ""Publisher Component""],
    [""Connect Controller Daemon"", ""called-from"", ""Listener Component""]
  ]
}",6.396257454005536
114,mistral-nemo,../IMAGES NEW/Azure/09 Azure protect APIs original.txt,"
    To gain access to an application, an API client authenticates by providing credentials such as username and password. The IdP is Azure AD B2C in this solution, but you can use a different one.

    The authentication request goes via Azure Front Door to Azure AD B2C, which is configured with a custom domain for sign-in. Azure AD B2C authenticates the user and returns a JSON Web Token (JWT) bearer token back to the user.

    The client triggers an event that accesses a backend API. This event could be a click of a button on a web application or on a mobile device, or a direct call to the endpoint of the backend API.

    The request goes through Azure Front Door, whose back end is mapped to the public endpoint of API Management. API Management intercepts the request and validates the bearer token against Azure AD B2C by using its validate-jwt policy. If the token isn't valid, API Management rejects the request by responding with a 401 code.

    If the token is valid, API Management forwards the request to the appropriate backend API.

    The diagram shows backend APIs running in three environments:
        App Service Environment
        Function Apps
        Azure Kubernetes Services (AKS)

    APIs running in on-premises and hybrid cloud environments can also be integrated with API Management if network connectivity is established between the APIs and API Management.

","{""entities"": [[""API client"", ""system"", ""wants to gain access to an application""], [""application"", ""system"", ""API client wants to gain access to an application""], [""Azure AD B2C"", ""system"", ""The IdP is Azure AD B2C""], [""Azure Front Door"", ""system"", ""authentication request goes via Azure Front Door to Azure AD B2C""], [""backend API"", ""system"", ""The client triggers an event that accesses a backend API""], [""Azure Front Door"", ""system"", ""The request goes through Azure Front Door, whose back end is mapped to the public endpoint of API Management.""], [""backend"", ""component"", ""Azure Front Door, whose back end""], [""API Management"", ""system"", ""API Management intercepts the request and validates the bearer token against Azure AD B2C ""], [""public endpoint"", ""system"", ""whose back end is mapped to the public endpoint of API Management""], [""User"", ""person"", ""Azure AD B2C authenticates the user and returns a JSON Web Token (JWT) bearer token back to the user""]], ""relationships"": [[""API client"", ""calls"", ""application"", """"], [""Azure Front Door"", ""calls"", ""Azure AD B2C"", ""authentication request goes via Azure Front Door to Azure AD B2C""], [""Azure AD B2C"", ""is-called-from"", ""User"", ""Azure AD B2C authenticates the user and returns a JSON Web Token (JWT) bearer token back to the user""], [""API client"", ""calls"", ""backend API"", ""The client triggers an event that accesses a backend API""], [""Azure Front Door"", ""contains"", ""backend"", ""Azure Front Door, whose back end""], [""public endpoint"", ""part-of"", ""API Management"", ""Azure Front Door, whose back end""], [""backend"", ""calls"", ""public endpoint"", ""whose back end is mapped to the public endpoint of API Management""], [""API Management"", ""calls"", ""Azure AD B2C"", ""API Management intercepts the request and validates the bearer token against Azure AD B2C""]]}","Here's the extracted entities and relationships in the requested JSON format:

```json
{
  ""entities"": [
    [""API Client"", ""person""],
    [""Azure AD B2C"", ""system""],
    [""Azure Front Door"", ""component""],
    [""JSON Web Token (JWT)"", ""entity""],
    [""Backend API"", ""component""],
    [""App Service Environment"", ""system""],
    [""Function Apps"", ""system""],
    [""Azure Kubernetes Services (AKS)"", ""system""],
    [""API Management"", ""system""]
  ],
  ""relationships"": [
    [""API Client"", ""calls"", ""Azure Front Door"", ""to authenticate and retrieve JWT""],
    [""Azure AD B2C"", ""contains"", ""custom domain for sign-in""],
    [""Azure Front Door"", ""called-from"", ""API Client"", ""for authentication request""],
    [""Azure Front Door"", ""calls"", ""Azure AD B2C"", ""to validate user credentials""],
    [""Azure Front Door"", ""part-of"", ""Azure AD B2C"", ""for authentication process""],
    [""Azure AD B2C"", ""contains"", ""validate-jwt policy""],
    [""Azure Front Door"", ""called-from"", ""API Management"", ""for API requests""],
    [""API Management"", ""contains"", ""validate-jwt policy""],
    [""API Management"", ""calls"", ""Backend API"", ""if token is valid""],
    [""Backend API"", ""part-of"", ""App Service Environment""],
    [""Backend API"", ""part-of"", ""Function Apps""],
    [""Backend API"", ""part-of"", ""Azure Kubernetes Services (AKS)""]
  ]
}
```","Here's the extracted entities and relationships in the requested JSON format:

```json
{
  ""entities"": [
    [""API Client"", ""person""],
    [""Azure AD B2C"", ""system""],
    [""Azure Front Door"", ""component""],
    [""JSON Web Token (JWT)"", ""entity""],
    [""Backend API"", ""component""],
    [""App Service Environment"", ""system""],
    [""Function Apps"", ""system""],
    [""Azure Kubernetes Services (AKS)"", ""system""],
    [""API Management"", ""system""]
  ],
  ""relationships"": [
    [""API Client"", ""calls"", ""Azure Front Door"", ""to authenticate and retrieve JWT""],
    [""Azure AD B2C"", ""contains"", ""custom domain for sign-in""],
    [""Azure Front Door"", ""called-from"", ""API Client"", ""for authentication request""],
    [""Azure Front Door"", ""calls"", ""Azure AD B2C"", ""to validate user credentials""],
    [""Azure Front Door"", ""part-of"", ""Azure AD B2C"", ""for authentication process""],
    [""Azure AD B2C"", ""contains"", ""validate-jwt policy""],
    [""Azure Front Door"", ""called-from"", ""API Management"", ""for API requests""],
    [""API Management"", ""contains"", ""validate-jwt policy""],
    [""API Management"", ""calls"", ""Backend API"", ""if token is valid""],
    [""Backend API"", ""part-of"", ""App Service Environment""],
    [""Backend API"", ""part-of"", ""Function Apps""],
    [""Backend API"", ""part-of"", ""Azure Kubernetes Services (AKS)""]
  ]
}
```",5.891058523993706
115,mistral-nemo,../IMAGES NEW/Azure/07 Azure internal APIs original.txt,"
The data flows as follows:

    Developers check in code to a GitHub repository that's connected to a CI/CD pipeline agent that's installed on an Azure VM.
    The agent pushes the build to the API application that's hosted on ILB ASE.
    Azure API Management consumes the preceding APIs via HOST headers that are specified in API Management policy.
    API Management uses the App Service Environment's DNS name for all the APIs.
    Application Gateway exposes API Management's developer and API portal.
    Azure Private DNS is used to route the traffic internally between ASE, API Management, and Application Gateway.
    External users utilize the exposed developer portal to consume the APIs via Application Gateway's public IP.

","{""entities"": [[""GitHub repository"", ""system"", """"], [""Developers"", ""person"", """"], [""External users"", ""person"", """"], [""CI/CD pipeline agent"", ""system"", """"], [""Azure VM"", ""system"", """"], [""ILB ASE"", ""system"", """"], [""API application"", ""component"", """"], [""Azure API Management"", ""system"", ""consumes the preceding APIs via HOST headers""], [""App Service Environment"", ""component"", """"], [""Application Gateway"", ""component"", ""exposes API Management's developer and API portal""], [""Developer portal"", ""component"", ""API Management's developer and API portal""], [""API portal"", ""component"", ""API Management's developer and API portal""], [""Application Gateway"", ""component"", ""exposes API Management's developer and API portal""], [""Azure Private DNS"", ""component"", ""used to route the traffic internally between ASE, API Management, and Application Gateway""]], ""relationships"": [[""Azure VM"", ""contains"", ""CI/CD pipeline agent"", ""installed on an Azure VM""], [""API application"", ""part-of"", ""ILB ASE"", ""API application that's hosted on ILB ASE""], [""GitHub repository"", ""calls"", ""CI/CD pipeline agent"", ""GitHub repository that's connected to a CI/CD pipeline agent""], [""CI/CD pipeline agent"", ""calls"", ""API application"", ""agent pushes the build to the API application""], [""Azure API Management"", ""calls"", ""App Service Environment"", ""uses the App Service Environment's DNS name for all the APIs""], [""External users"", ""calls"", ""Application Gateway"", """"], [""Application Gateway"", ""calls"", ""API application"", ""to consume the APIs via Application Gateway's public IP""], [""Azure API Management"", ""contains"", ""Developer portal"", ""API Management's developer and API portal""], [""Azure API Management"", ""contains"", ""API portal"", ""API Management's developer and API portal""], [""Application Gateway"", ""calls"", ""API portal"", ""exposes API Management's developer and API portal.""], [""Application Gateway"", ""calls"", ""Developer portal"", ""exposes API Management's developer and API portal.""], [""Azure Private DNS"", ""calls"", ""Azure API Management"", ""route the traffic internally between ASE, API Management, and Application Gateway""], [""Azure Private DNS"", ""calls"", ""Application Gateway"", ""route the traffic internally between ASE, API Management, and Application Gateway""]]}","{
  ""entities"": [
    [""Developers"", ""person"", ""Users who check in code""],
    [""GitHub repository"", ""system"", ""Where developers push their changes""],
    [""CI/CD pipeline agent"", ""component"", ""Installed on Azure VM to handle build processes""],
    [""Azure VM"", ""system"", ""Hosts the CI/CD agent""],
    [""API application"", ""component"", ""Hosted on ILB ASE, consumes builds from CI/CD pipeline""],
    [""ILB ASE"", ""system"", ""Internal load balancer application service environment""],
    [""Azure API Management"", ""system"", ""Consumes APIs via HOST headers, uses App Service Environment's DNS name for all APIs""],
    [""App Service Environment"", ""system"", ""Hosts the API application and provides DNS name""],
    [""Application Gateway"", ""component"", ""Exposes API Management's developer and API portal""],
    [""Azure Private DNS"", ""system"", ""Routes traffic internally between ASE, API Management, and Application Gateway""],
    [""External users"", ""person"", ""Users who consume APIs via Application Gateway's public IP""]
  ],
  ""relationships"": [
    [""Developers"", ""checks-in"", ""GitHub repository"", ""Developers push code to the GitHub repository""],
    [""CI/CD pipeline agent"", ""part-of"", ""Azure VM"", ""The agent is installed on the Azure VM""],
    [""CI/CD pipeline agent"", ""pushes-to"", ""API application"", ""Agent pushes builds to the API application""],
    [""Azure API Management"", ""uses"", ""App Service Environment"", ""Uses App Service Environment's DNS name for APIs""],
    [""Application Gateway"", ""exposes"", ""Azure Private DNS"", ""Exposes API Management via Azure Private DNS""],
    [""External users"", ""consumes-via"", ""Application Gateway"", ""Users consume APIs via Application Gateway""]
  ]
}","{
  ""entities"": [
    [""Developers"", ""person"", ""Users who check in code""],
    [""GitHub repository"", ""system"", ""Where developers push their changes""],
    [""CI/CD pipeline agent"", ""component"", ""Installed on Azure VM to handle build processes""],
    [""Azure VM"", ""system"", ""Hosts the CI/CD agent""],
    [""API application"", ""component"", ""Hosted on ILB ASE, consumes builds from CI/CD pipeline""],
    [""ILB ASE"", ""system"", ""Internal load balancer application service environment""],
    [""Azure API Management"", ""system"", ""Consumes APIs via HOST headers, uses App Service Environment's DNS name for all APIs""],
    [""App Service Environment"", ""system"", ""Hosts the API application and provides DNS name""],
    [""Application Gateway"", ""component"", ""Exposes API Management's developer and API portal""],
    [""Azure Private DNS"", ""system"", ""Routes traffic internally between ASE, API Management, and Application Gateway""],
    [""External users"", ""person"", ""Users who consume APIs via Application Gateway's public IP""]
  ],
  ""relationships"": [
    [""Developers"", ""checks-in"", ""GitHub repository"", ""Developers push code to the GitHub repository""],
    [""CI/CD pipeline agent"", ""part-of"", ""Azure VM"", ""The agent is installed on the Azure VM""],
    [""CI/CD pipeline agent"", ""pushes-to"", ""API application"", ""Agent pushes builds to the API application""],
    [""Azure API Management"", ""uses"", ""App Service Environment"", ""Uses App Service Environment's DNS name for APIs""],
    [""Application Gateway"", ""exposes"", ""Azure Private DNS"", ""Exposes API Management via Azure Private DNS""],
    [""External users"", ""consumes-via"", ""Application Gateway"", ""Users consume APIs via Application Gateway""]
  ]
}",6.473594930022955
116,mistral-nemo,../IMAGES NEW/Azure/06 Azure logic-apps-data-integration.txt,"
    API Management accepts API calls in the form of HTTP requests.

    API Management securely routes the HTTP requests to Logic Apps.

    Each HTTP request triggers a run in Logic Apps:
        Logic Apps uses secured template parameters to retrieve database credentials from Azure Key Vault.
        Logic Apps uses Transport Layer Security (TLS) to send the database credentials and a database statement to the on-premises data gateway.

    The on-premises data gateway connects to a SQL Server database to run the statement.

    SQL Server stores the data and makes it available to apps that users access.

    Azure Monitor collects information on Logic Apps events and performance.

","{""entities"": [[""API Management"", ""system"", ""accepts API calls in the form of HTTP requests""], [""Logic Apps"", ""system"", ""uses secured template parameters to retrieve database credentials from Azure Key Vault""], [""on-premises data gateway"", ""system"", """"], [""SQL Server"", ""system"", ""stores the data and makes it available to apps that users access""], [""Azure Monitor"", ""system"", ""collects information on Logic Apps events and performance""], [""Azure Key Vault"", ""system"", ""database credentials""]], ""relationships"": [[""API Management"", ""calls"", ""Logic Apps"", ""routes the HTTP requests to Logic Apps""], [""Logic Apps"", ""calls"", ""Azure Key Vault"", ""Logic Apps uses secured template parameters to retrieve database credentials from Azure Key Vault""], [""Logic Apps"", ""calls"", ""on-premises data gateway"", ""send the database credentials and a database statement to the on-premises data gateway""], [""on-premises data gateway"", ""calls"", ""SQL Server"", ""connects to a SQL Server database""], [""Azure Monitor"", ""calls"", ""Logic Apps"", ""collects information on Logic Apps events and performance""]]}","{
  ""entities"": [
    [""API Management"", ""system""],
    [""Logic Apps"", ""component""],
    [""Azure Key Vault"", ""component""],
    [""On-premises Data Gateway"", ""component""],
    [""SQL Server Database"", ""component""],
    [""Azure Monitor"", ""component""]
  ],
  ""relationships"": [
    [""API Management"", ""calls"", ""Logic Apps""],
    [""Logic Apps"", ""uses"", ""Azure Key Vault""],
    [""Logic Apps"", ""sends to"", ""On-premises Data Gateway""],
    [""On-premises Data Gateway"", ""connects to"", ""SQL Server Database""],
    [""SQL Server Database"", ""stores data for"", ""API Management""]
  ]
}","{
  ""entities"": [
    [""API Management"", ""system""],
    [""Logic Apps"", ""component""],
    [""Azure Key Vault"", ""component""],
    [""On-premises Data Gateway"", ""component""],
    [""SQL Server Database"", ""component""],
    [""Azure Monitor"", ""component""]
  ],
  ""relationships"": [
    [""API Management"", ""calls"", ""Logic Apps""],
    [""Logic Apps"", ""uses"", ""Azure Key Vault""],
    [""Logic Apps"", ""sends to"", ""On-premises Data Gateway""],
    [""On-premises Data Gateway"", ""connects to"", ""SQL Server Database""],
    [""SQL Server Database"", ""stores data for"", ""API Management""]
  ]
}",2.9038051160168834
117,mistral-nemo,../IMAGES NEW/Azure/08 Azure Business Processes.txt,"
The data flows through the solution as follows:

    The airline system communicates with a custom API hosted in Azure API Management.
    A custom API coordinator receives notifications and handles incoming messages from the airline system. It sends them to Power Apps, where flights are assigned to Microsoft Teams channels.
    When a user selects a flight to monitor, or when the system assigns the user to a flight, the system queues a Graph API call in an Azure Storage Account queue for further processing.
    Azure Functions runs the Graph API calls based on the incoming messages in the storage queue, sending notifications to Teams, and also streams all events to an Azure Event Hubs for further analytics.
    The airline's notification system is managed by a custom bot messaging service that employs Azure Bot Service.
    Custom bots send flight updates to users in Teams.
    An Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs, ultimately generating insightful reports with Power BI.

","{""entities"": [[""airline system"", ""system"", ""communicates with a custom API hosted in Azure API Management""], [""custom API"", ""component"", ""communicates with a custom API hosted in Azure API Management""], [""Azure API Management"", ""system"", ""communicates with a custom API hosted in Azure API Management""], [""custom API coordinator"", ""system"", ""receives notifications and handles incoming messages from the airline system""], [""Power Apps"", ""system"", ""where flights are assigned to Microsoft Teams channels""], [""Microsoft Teams channels"", ""system"", ""where flights are assigned to Microsoft Teams channels""], [""Storage Account queue"", ""system"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing.""], [""Graph API call"", ""system"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing.""], [""Azure Functions"", ""system"", ""runs the Graph API calls based on the incoming messages in the storage queue""], [""Azure Event Hubs"", ""system"", ""Azure Event Hubs for further analytics""], [""notification system"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""custom bot messaging service"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""Azure Bot Service"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""Users"", ""person"", ""selects a flight to monitor, or when the system assigns the user to a flight""], [""Azure Data Lake storage"", ""system"", ""offers long-term retention and micro-batch processing of events from Event Hubs""], [""Power BI"", ""system"", ""generating insightful reports""]], ""relationships"": [[""Azure API Management"", ""contains"", ""custom API"", ""custom API hosted in Azure API Management""], [""airline system"", ""calls"", ""custom API"", ""communicates with a custom API""], [""custom API coordinator"", ""is-called-from"", ""airline system"", ""receives notifications and handles incoming messages from the airline system""], [""Power Apps"", ""calls"", ""Microsoft Teams channels"", ""Power Apps, where flights are assigned to Microsoft Teams channels""], [""airline system"", ""calls"", ""Graph API call"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing""], [""Azure Functions"", ""calls"", ""Graph API call"", ""runs the Graph API calls based on the incoming messages in the storage queue""], [""Azure Functions"", ""calls"", ""Storage Account queue"", ""based on the incoming messages in the storage queue""], [""Azure Functions"", ""calls"", ""Microsoft Teams channels"", ""sending notifications to Teams""], [""Azure Functions"", ""calls"", ""Azure Event Hubs"", ""also streams all events to an Azure Event Hubs for further analytics""], [""notification system"", ""is-called-from"", ""custom bot messaging service"", ""managed by a custom bot messaging service""], [""custom bot messaging service"", ""calls"", ""Azure Bot Service"", ""custom bot messaging service that employs Azure Bot Service""], [""custom bot messaging service"", ""calls"", ""Microsoft Teams channels"", ""Custom bots send flight updates to users in Teams.""], [""Microsoft Teams channels"", ""calls"", ""Users"", ""Custom bots send flight updates to users in Teams.""], [""Azure Data Lake storage"", ""is-called-from"", ""Azure Event Hubs"", ""Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs""], [""Azure Data Lake storage"", ""calls"", ""Power BI"", ""Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs, ultimately generating insightful reports with Power BI""]]}","```json
{
  ""entities"": [
    [""Airline System"", ""system""],
    [""Azure API Management"", ""system""],
    [""Custom API Coordinator"", ""component""],
    [""Power Apps"", ""system""],
    [""Microsoft Teams"", ""system""],
    [""Azure Storage Account"", ""system""],
    [""Azure Functions"", ""component""],
    [""Graph API"", ""component""],
    [""Azure Event Hubs"", ""system""],
    [""Azure Data Lake storage"", ""system""],
    [""Power BI"", ""system""],
    [""Custom Bot Messaging Service"", ""component""],
    [""Azure Bot Service"", ""system""]
  ],
  ""relationships"": [
    [""Airline System"", ""calls"", ""Azure API Management""],
    [""Custom API Coordinator"", ""part-of"", ""Airline System""],
    [""Custom API Coordinator"", ""contains"", ""Graph API""],
    [""Power Apps"", ""contains"", ""Microsoft Teams""],
    [""Azure Storage Account"", ""contains"", ""Azure Functions""],
    [""Azure Functions"", ""calls"", ""Graph API""],
    [""Azure Functions"", ""called-from"", ""Azure Storage Account""],
    [""Azure Functions"", ""calls"", ""Azure Event Hubs""],
    [""Custom Bot Messaging Service"", ""part-of"", ""Airline System""],
    [""Azure Data Lake storage"", ""contains"", ""Power BI""]
  ]
}
```","```json
{
  ""entities"": [
    [""Airline System"", ""system""],
    [""Azure API Management"", ""system""],
    [""Custom API Coordinator"", ""component""],
    [""Power Apps"", ""system""],
    [""Microsoft Teams"", ""system""],
    [""Azure Storage Account"", ""system""],
    [""Azure Functions"", ""component""],
    [""Graph API"", ""component""],
    [""Azure Event Hubs"", ""system""],
    [""Azure Data Lake storage"", ""system""],
    [""Power BI"", ""system""],
    [""Custom Bot Messaging Service"", ""component""],
    [""Azure Bot Service"", ""system""]
  ],
  ""relationships"": [
    [""Airline System"", ""calls"", ""Azure API Management""],
    [""Custom API Coordinator"", ""part-of"", ""Airline System""],
    [""Custom API Coordinator"", ""contains"", ""Graph API""],
    [""Power Apps"", ""contains"", ""Microsoft Teams""],
    [""Azure Storage Account"", ""contains"", ""Azure Functions""],
    [""Azure Functions"", ""calls"", ""Graph API""],
    [""Azure Functions"", ""called-from"", ""Azure Storage Account""],
    [""Azure Functions"", ""calls"", ""Azure Event Hubs""],
    [""Custom Bot Messaging Service"", ""part-of"", ""Airline System""],
    [""Azure Data Lake storage"", ""contains"", ""Power BI""]
  ]
}
```",4.94443010300165
118,mistral-nemo,../IMAGES NEW/Azure/06 Azure logic-apps-data-integration.txt,"
    API Management accepts API calls in the form of HTTP requests.

    API Management securely routes the HTTP requests to Logic Apps.

    Each HTTP request triggers a run in Logic Apps:
        Logic Apps uses secured template parameters to retrieve database credentials from Azure Key Vault.
        Logic Apps uses Transport Layer Security (TLS) to send the database credentials and a database statement to the on-premises data gateway.

    The on-premises data gateway connects to a SQL Server database to run the statement.

    SQL Server stores the data and makes it available to apps that users access.

    Azure Monitor collects information on Logic Apps events and performance.

","{""entities"": [[""API Management"", ""system"", ""accepts API calls in the form of HTTP requests""], [""Logic Apps"", ""system"", ""uses secured template parameters to retrieve database credentials from Azure Key Vault""], [""on-premises data gateway"", ""system"", """"], [""SQL Server"", ""system"", ""stores the data and makes it available to apps that users access""], [""Azure Monitor"", ""system"", ""collects information on Logic Apps events and performance""], [""Azure Key Vault"", ""system"", ""database credentials""]], ""relationships"": [[""API Management"", ""calls"", ""Logic Apps"", ""routes the HTTP requests to Logic Apps""], [""Logic Apps"", ""calls"", ""Azure Key Vault"", ""Logic Apps uses secured template parameters to retrieve database credentials from Azure Key Vault""], [""Logic Apps"", ""calls"", ""on-premises data gateway"", ""send the database credentials and a database statement to the on-premises data gateway""], [""on-premises data gateway"", ""calls"", ""SQL Server"", ""connects to a SQL Server database""], [""Azure Monitor"", ""calls"", ""Logic Apps"", ""collects information on Logic Apps events and performance""]]}","```json
{
  ""entities"": [
    [""API Management"", ""system""],
    [""Logic Apps"", ""system""],
    [""HTTP requests"", ""component""],
    [""Azure Key Vault"", ""component""],
    [""on-premises data gateway"", ""component""],
    [""SQL Server database"", ""system""],
    [""Azure Monitor"", ""system""]
  ],
  ""relationships"": [
    [""API Management"", ""calls"", ""Logic Apps""],
    [""Logic Apps"", ""contains"", ""HTTP requests""],
    [""Logic Apps"", ""uses"", ""Azure Key Vault""],
    [""Logic Apps"", ""uses"", ""on-premises data gateway""],
    [""on-premises data gateway"", ""part-of"", ""SQL Server database""],
    [""SQL Server database"", ""stores"", ""data""],
    [""Azure Monitor"", ""collects"", ""Logic Apps""]
  ]
}
```","```json
{
  ""entities"": [
    [""API Management"", ""system""],
    [""Logic Apps"", ""system""],
    [""HTTP requests"", ""component""],
    [""Azure Key Vault"", ""component""],
    [""on-premises data gateway"", ""component""],
    [""SQL Server database"", ""system""],
    [""Azure Monitor"", ""system""]
  ],
  ""relationships"": [
    [""API Management"", ""calls"", ""Logic Apps""],
    [""Logic Apps"", ""contains"", ""HTTP requests""],
    [""Logic Apps"", ""uses"", ""Azure Key Vault""],
    [""Logic Apps"", ""uses"", ""on-premises data gateway""],
    [""on-premises data gateway"", ""part-of"", ""SQL Server database""],
    [""SQL Server database"", ""stores"", ""data""],
    [""Azure Monitor"", ""collects"", ""Logic Apps""]
  ]
}
```",3.4265632320020813
119,mistral-nemo,../IMAGES NEW/Azure/09 Azure protect APIs original.txt,"
    To gain access to an application, an API client authenticates by providing credentials such as username and password. The IdP is Azure AD B2C in this solution, but you can use a different one.

    The authentication request goes via Azure Front Door to Azure AD B2C, which is configured with a custom domain for sign-in. Azure AD B2C authenticates the user and returns a JSON Web Token (JWT) bearer token back to the user.

    The client triggers an event that accesses a backend API. This event could be a click of a button on a web application or on a mobile device, or a direct call to the endpoint of the backend API.

    The request goes through Azure Front Door, whose back end is mapped to the public endpoint of API Management. API Management intercepts the request and validates the bearer token against Azure AD B2C by using its validate-jwt policy. If the token isn't valid, API Management rejects the request by responding with a 401 code.

    If the token is valid, API Management forwards the request to the appropriate backend API.

    The diagram shows backend APIs running in three environments:
        App Service Environment
        Function Apps
        Azure Kubernetes Services (AKS)

    APIs running in on-premises and hybrid cloud environments can also be integrated with API Management if network connectivity is established between the APIs and API Management.

","{""entities"": [[""API client"", ""system"", ""wants to gain access to an application""], [""application"", ""system"", ""API client wants to gain access to an application""], [""Azure AD B2C"", ""system"", ""The IdP is Azure AD B2C""], [""Azure Front Door"", ""system"", ""authentication request goes via Azure Front Door to Azure AD B2C""], [""backend API"", ""system"", ""The client triggers an event that accesses a backend API""], [""Azure Front Door"", ""system"", ""The request goes through Azure Front Door, whose back end is mapped to the public endpoint of API Management.""], [""backend"", ""component"", ""Azure Front Door, whose back end""], [""API Management"", ""system"", ""API Management intercepts the request and validates the bearer token against Azure AD B2C ""], [""public endpoint"", ""system"", ""whose back end is mapped to the public endpoint of API Management""], [""User"", ""person"", ""Azure AD B2C authenticates the user and returns a JSON Web Token (JWT) bearer token back to the user""]], ""relationships"": [[""API client"", ""calls"", ""application"", """"], [""Azure Front Door"", ""calls"", ""Azure AD B2C"", ""authentication request goes via Azure Front Door to Azure AD B2C""], [""Azure AD B2C"", ""is-called-from"", ""User"", ""Azure AD B2C authenticates the user and returns a JSON Web Token (JWT) bearer token back to the user""], [""API client"", ""calls"", ""backend API"", ""The client triggers an event that accesses a backend API""], [""Azure Front Door"", ""contains"", ""backend"", ""Azure Front Door, whose back end""], [""public endpoint"", ""part-of"", ""API Management"", ""Azure Front Door, whose back end""], [""backend"", ""calls"", ""public endpoint"", ""whose back end is mapped to the public endpoint of API Management""], [""API Management"", ""calls"", ""Azure AD B2C"", ""API Management intercepts the request and validates the bearer token against Azure AD B2C""]]}","Here's the JSON response based on the provided text:

```json
{
  ""entities"": [
    [""API Client"", ""component"", ""Authenticates with username and password""],
    [""Azure AD B2C"", ""system"", ""Handles user authentication and returns JWT tokens""],
    [""Azure Front Door"", ""system"", ""Routes requests to Azure AD B2C and API Management""],
    [""JSON Web Token (JWT)"", ""component"", ""Bearer token returned by Azure AD B2C""],
    [""API Management"", ""system"", ""Validates JWT tokens, intercepts requests, forwards to backend APIs""],
    [""App Service Environment"", ""system"", ""Runs some backend APIs""],
    [""Function Apps"", ""system"", ""Runs some backend APIs""],
    [""Azure Kubernetes Services (AKS)"", ""system"", ""Runs some backend APIs""],
    [""On-premises/Hybrid Cloud APIs"", ""system"", ""Can be integrated with API Management if network connectivity is established""]
  ],
  ""relationships"": [
    [""API Client"", ""calls"", ""Azure AD B2C"", ""Provides credentials for authentication""],
    [""Azure AD B2C"", ""contains"", ""JSON Web Token (JWT)"", ""Returns JWT token after successful authentication""],
    [""Azure Front Door"", ""contains"", ""Azure AD B2C"", ""Routes requests to Azure AD B2C""],
    [""Azure Front Door"", ""contains"", ""API Management"", ""Routes requests to API Management""],
    [""API Management"", ""validates"", ""JSON Web Token (JWT)"", ""Validates JWT token against Azure AD B2C""],
    [""API Management"", ""called-from"", ""Azure Front Door"", ""Receives requests from Azure Front Door""],
    [""API Management"", ""part-of"", ""App Service Environment"", ""Runs some backend APIs""],
    [""API Management"", ""part-of"", ""Function Apps"", ""Runs some backend APIs""],
    [""API Management"", ""part-of"", ""Azure Kubernetes Services (AKS)"", ""Runs some backend APIs""],
    [""API Management"", ""can-integrate-with"", ""On-premises/Hybrid Cloud APIs"", ""Can integrate if network connectivity is established""]
  ]
}
```","Here's the JSON response based on the provided text:

```json
{
  ""entities"": [
    [""API Client"", ""component"", ""Authenticates with username and password""],
    [""Azure AD B2C"", ""system"", ""Handles user authentication and returns JWT tokens""],
    [""Azure Front Door"", ""system"", ""Routes requests to Azure AD B2C and API Management""],
    [""JSON Web Token (JWT)"", ""component"", ""Bearer token returned by Azure AD B2C""],
    [""API Management"", ""system"", ""Validates JWT tokens, intercepts requests, forwards to backend APIs""],
    [""App Service Environment"", ""system"", ""Runs some backend APIs""],
    [""Function Apps"", ""system"", ""Runs some backend APIs""],
    [""Azure Kubernetes Services (AKS)"", ""system"", ""Runs some backend APIs""],
    [""On-premises/Hybrid Cloud APIs"", ""system"", ""Can be integrated with API Management if network connectivity is established""]
  ],
  ""relationships"": [
    [""API Client"", ""calls"", ""Azure AD B2C"", ""Provides credentials for authentication""],
    [""Azure AD B2C"", ""contains"", ""JSON Web Token (JWT)"", ""Returns JWT token after successful authentication""],
    [""Azure Front Door"", ""contains"", ""Azure AD B2C"", ""Routes requests to Azure AD B2C""],
    [""Azure Front Door"", ""contains"", ""API Management"", ""Routes requests to API Management""],
    [""API Management"", ""validates"", ""JSON Web Token (JWT)"", ""Validates JWT token against Azure AD B2C""],
    [""API Management"", ""called-from"", ""Azure Front Door"", ""Receives requests from Azure Front Door""],
    [""API Management"", ""part-of"", ""App Service Environment"", ""Runs some backend APIs""],
    [""API Management"", ""part-of"", ""Function Apps"", ""Runs some backend APIs""],
    [""API Management"", ""part-of"", ""Azure Kubernetes Services (AKS)"", ""Runs some backend APIs""],
    [""API Management"", ""can-integrate-with"", ""On-premises/Hybrid Cloud APIs"", ""Can integrate if network connectivity is established""]
  ]
}
```",7.693052001995966
120,mistral-nemo,../IMAGES NEW/TEST/08 Azure Business Processes.txt,"
The data flows through the solution as follows:

    The airline system communicates with a custom API hosted in Azure API Management.
    A custom API coordinator receives notifications and handles incoming messages from the airline system. It sends them to Power Apps, where flights are assigned to Microsoft Teams channels.
    When a user selects a flight to monitor, or when the system assigns the user to a flight, the system queues a Graph API call in an Azure Storage Account queue for further processing.
    Azure Functions runs the Graph API calls based on the incoming messages in the storage queue, sending notifications to Teams, and also streams all events to an Azure Event Hubs for further analytics.
    The airline's notification system is managed by a custom bot messaging service that employs Azure Bot Service.
    Custom bots send flight updates to users in Teams.
    An Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs, ultimately generating insightful reports with Power BI.

","{""entities"": [[""airline system"", ""system"", ""communicates with a custom API hosted in Azure API Management""], [""custom API"", ""component"", ""communicates with a custom API hosted in Azure API Management""], [""Azure API Management"", ""system"", ""communicates with a custom API hosted in Azure API Management""], [""custom API coordinator"", ""system"", ""receives notifications and handles incoming messages from the airline system""], [""Power Apps"", ""system"", ""where flights are assigned to Microsoft Teams channels""], [""Microsoft Teams channels"", ""system"", ""where flights are assigned to Microsoft Teams channels""], [""Storage Account queue"", ""system"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing.""], [""Graph API call"", ""system"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing.""], [""Azure Functions"", ""system"", ""runs the Graph API calls based on the incoming messages in the storage queue""], [""Azure Event Hubs"", ""system"", ""Azure Event Hubs for further analytics""], [""notification system"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""custom bot messaging service"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""Azure Bot Service"", ""system"", ""managed by a custom bot messaging service that employs Azure Bot Service""], [""Users"", ""person"", ""selects a flight to monitor, or when the system assigns the user to a flight""], [""Azure Data Lake storage"", ""system"", ""offers long-term retention and micro-batch processing of events from Event Hubs""], [""Power BI"", ""system"", ""generating insightful reports""]], ""relationships"": [[""Azure API Management"", ""contains"", ""custom API"", ""custom API hosted in Azure API Management""], [""airline system"", ""calls"", ""custom API"", ""communicates with a custom API""], [""custom API coordinator"", ""is-called-from"", ""airline system"", ""receives notifications and handles incoming messages from the airline system""], [""Power Apps"", ""calls"", ""Microsoft Teams channels"", ""Power Apps, where flights are assigned to Microsoft Teams channels""], [""airline system"", ""calls"", ""Graph API call"", "" the system queues a Graph API call in an Azure Storage Account queue for further processing""], [""Azure Functions"", ""calls"", ""Graph API call"", ""runs the Graph API calls based on the incoming messages in the storage queue""], [""Azure Functions"", ""calls"", ""Storage Account queue"", ""based on the incoming messages in the storage queue""], [""Azure Functions"", ""calls"", ""Microsoft Teams channels"", ""sending notifications to Teams""], [""Azure Functions"", ""calls"", ""Azure Event Hubs"", ""also streams all events to an Azure Event Hubs for further analytics""], [""notification system"", ""is-called-from"", ""custom bot messaging service"", ""managed by a custom bot messaging service""], [""custom bot messaging service"", ""calls"", ""Azure Bot Service"", ""custom bot messaging service that employs Azure Bot Service""], [""custom bot messaging service"", ""calls"", ""Microsoft Teams channels"", ""Custom bots send flight updates to users in Teams.""], [""Microsoft Teams channels"", ""calls"", ""Users"", ""Custom bots send flight updates to users in Teams.""], [""Azure Data Lake storage"", ""is-called-from"", ""Azure Event Hubs"", ""Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs""], [""Azure Data Lake storage"", ""calls"", ""Power BI"", ""Azure Data Lake storage offers long-term retention and micro-batch processing of events from Event Hubs, ultimately generating insightful reports with Power BI""]]}","{
  ""entities"": [
    [""Airline System"", ""system""],
    [""Azure API Management"", ""system""],
    [""Custom API Coordinator"", ""component""],
    [""Power Apps"", ""system""],
    [""Microsoft Teams"", ""system""],
    [""Azure Storage Account"", ""system""],
    [""Azure Functions"", ""system""],
    [""Azure Event Hubs"", ""system""],
    [""Custom Bot Messaging Service"", ""system""],
    [""Azure Bot Service"", ""system""],
    [""Azure Data Lake storage"", ""system""],
    [""Power BI"", ""system""]
  ],
  ""relationships"": [
    [""Airline System"", ""communicates-with"", ""Azure API Management""],
    [""Custom API Coordinator"", ""sends-to"", ""Power Apps""],
    [""Power Apps"", ""assigns-flights-to"", ""Microsoft Teams""],
    [""Airline System"", ""queues-Graph-API-calls-in"", ""Azure Storage Account""],
    [""Azure Functions"", ""runs-Graph-API-calls-based-on"", ""Azure Storage Account""],
    [""Azure Functions"", ""sends-notifications-to"", ""Microsoft Teams""],
    [""Azure Functions"", ""streams-events-to"", ""Azure Event Hubs""],
    [""Custom Bot Messaging Service"", ""uses"", ""Azure Bot Service""],
    [""Custom Bot Messaging Service"", ""sends-flight-updates-to-users-in"", ""Microsoft Teams""],
    [""Azure Data Lake storage"", ""offers-long-term-retention-and-processing-of"", ""events from Azure Event Hubs""],
    [""Power BI"", ""generates-reports-from"", ""Azure Data Lake storage""]
  ]
}","{
  ""entities"": [
    [""Airline System"", ""system""],
    [""Azure API Management"", ""system""],
    [""Custom API Coordinator"", ""component""],
    [""Power Apps"", ""system""],
    [""Microsoft Teams"", ""system""],
    [""Azure Storage Account"", ""system""],
    [""Azure Functions"", ""system""],
    [""Azure Event Hubs"", ""system""],
    [""Custom Bot Messaging Service"", ""system""],
    [""Azure Bot Service"", ""system""],
    [""Azure Data Lake storage"", ""system""],
    [""Power BI"", ""system""]
  ],
  ""relationships"": [
    [""Airline System"", ""communicates-with"", ""Azure API Management""],
    [""Custom API Coordinator"", ""sends-to"", ""Power Apps""],
    [""Power Apps"", ""assigns-flights-to"", ""Microsoft Teams""],
    [""Airline System"", ""queues-Graph-API-calls-in"", ""Azure Storage Account""],
    [""Azure Functions"", ""runs-Graph-API-calls-based-on"", ""Azure Storage Account""],
    [""Azure Functions"", ""sends-notifications-to"", ""Microsoft Teams""],
    [""Azure Functions"", ""streams-events-to"", ""Azure Event Hubs""],
    [""Custom Bot Messaging Service"", ""uses"", ""Azure Bot Service""],
    [""Custom Bot Messaging Service"", ""sends-flight-updates-to-users-in"", ""Microsoft Teams""],
    [""Azure Data Lake storage"", ""offers-long-term-retention-and-processing-of"", ""events from Azure Event Hubs""],
    [""Power BI"", ""generates-reports-from"", ""Azure Data Lake storage""]
  ]
}",5.621023724990664
121,mistral-nemo,../IMAGES NEW/Azure/16 Azure automate-pdf-forms.txt,"
    A designated Outlook email account receives PDF files as attachments. The arrival of an email triggers a logic app to process the email. The logic app is built by using the capabilities of Azure Logic Apps.
    The logic app uploads the PDF files to a container in Azure Data Lake Storage.
    You can also manually or programmatically upload PDF files to the same PDF container.
    The arrival of a PDF file in the PDF container triggers another logic app to process the PDF forms that are in the PDF file.
    The logic app sends the location of the PDF file to a function app for processing. The function app is built by using the capabilities of Azure Functions.
    The function app receives the location of the file and takes these actions:
        It splits the file into single pages if the file has multiple pages. Each page contains one independent form. Split files are saved to a second container in Data Lake Storage.
        It uses HTTPS POST, an Azure REST API, to send the location of the single-page PDF file to AI Document Intelligence for processing. When Azure AI Document Intelligence completes its processing, it sends a response back to the function app, which places the information into a data structure.
        It creates a JSON data file that contains the response data and stores the file to a third container in Data Lake Storage.
    The forms processing logic app receives the processed response data.
    The forms processing logic app sends the processed data to Azure Cosmos DB, which saves the data in a database and in collections.
    Power BI obtains the data from Azure Cosmos DB and provides insights and dashboards.
    You can implement further processing as needed on the data that's in Azure Cosmos DB.

","{""entities"": [[""designated Outlook email account"", ""component"", ""A designated Outlook email account receives PDF files as attachments""], [""logic app"", ""component"", ""The arrival of an email triggers a logic app to process the email.""], [""Azure Logic Apps"", ""system"", ""The logic app is built by using the capabilities of Azure Logic Apps.""], [""Container"", ""component"", ""The logic app uploads the PDF files to a container in Azure Data Lake Storage""], [""Azure Data Lake Storage"", ""system"", ""The logic app uploads the PDF files to a container in Azure Data Lake Storage""], [""logic app 2"", ""system"", ""The arrival of a PDF file in the PDF container triggers another logic app to process the PDF forms""], [""function app"", ""component"", ""The logic app sends the location of the PDF file to a function app for processing.""], [""Azure Functions"", ""system"", ""The function app is built by using the capabilities of Azure Functions""], [""Azure REST API"", ""component"", ""It uses HTTPS POST, an Azure REST API, to send the location of the single-page PDF file""], [""Container 2"", ""component"", ""Split files are saved to a second container in Data Lake Storage""], [""AI Document Intelligence"", ""component"", ""It uses HTTPS POST, an Azure REST API, to send the location of the single-page PDF file to AI Document Intelligence for processing""], [""Container 3"", ""component"", ""JSON data file that contains the response data and stores the file to a third container in Data Lake Storage""], [""forms processing logic app"", ""component"", ""The forms processing logic app receives the processed response data""], [""Azure Cosmos DB"", ""component"", ""The forms processing logic app sends the processed data to Azure Cosmos DB""], [""database"", ""component"", ""Azure Cosmos DB, which saves the data in a database""], [""Power BI"", ""component"", ""Power BI obtains the data from Azure Cosmos DB and provides insights and dashboards""]], ""relationships"": [[""designated Outlook email account"", ""calls"", ""logic app"", ""The arrival of an email triggers a logic app to process the email.""], [""Azure Logic Apps"", ""contains"", ""logic app"", ""The logic app is built by using the capabilities of Azure Logic Apps.""], [""logic app"", ""calls"", ""Container"", ""The logic app uploads the PDF files to a container in Azure Data Lake Storage""], [""Container"", ""part-of"", ""Azure Data Lake Storage"", ""container in Azure Data Lake Storage""], [""Container"", ""calls"", ""logic app 2"", ""The arrival of a PDF file in the PDF container triggers another logic app""], [""logic app"", ""calls"", ""function app"", ""The logic app sends the location of the PDF file to a function app for processing.""], [""function app"", ""part-of"", ""Azure Functions"", ""container in Azure Data Lake Storage""], [""function app"", ""calls"", ""Container 2"", ""Split files are saved to a second container in Data Lake Storage""], [""Azure Data Lake Storage"", ""contains"", ""Container 2"", ""Split files are saved to a second container in Data Lake Storage""], [""function app"", ""calls"", ""Azure REST API"", ""It uses HTTPS POST, an Azure REST API""], [""Azure REST API"", ""calls"", ""AI Document Intelligence"", ""HTTPS POST, an Azure REST API, to send the location of the single-page PDF file to AI Document Intelligence""], [""Azure Data Lake Storage"", ""contains"", ""Container 3"", ""third container in Data Lake Storage""], [""function app"", ""calls"", ""Container 3"", ""It creates a JSON data file that contains the response data and stores the file to a third container""], [""forms processing logic app"", ""calls"", ""Container 3"", ""The forms processing logic app receives the processed response data""], [""forms processing logic app"", ""calls"", ""Azure Cosmos DB"", ""The forms processing logic app sends the processed data to Azure Cosmos DB""], [""Azure Cosmos DB"", ""calls"", ""database"", ""Azure Cosmos DB, which saves the data in a database""], [""Power BI"", ""calls"", ""Azure Cosmos DB"", ""Power BI obtains the data from Azure Cosmos DB and provides insights and dashboards""]]}","Here's the extracted entities and relationships in the JSON format:

```json
{
  ""entities"": [
    [""Outlook Email Account"", ""system""],
    [""Azure Logic Apps"", ""system""],
    [""Azure Data Lake Storage"", ""system""],
    [""PDF Container"", ""component"", ""A container for PDF files in Azure Data Lake Storage""],
    [""Logic App (Email Trigger)"", ""component"", ""Triggers when an email arrives""],
    [""Logic App (File Trigger)"", ""component"", ""Triggers when a file arrives in the PDF container""],
    [""Azure Functions"", ""system""],
    [""Function App"", ""component"", ""Processes PDF files and interacts with Azure AI Document Intelligence""],
    [""AI Document Intelligence"", ""component"", ""Processes PDF forms using an HTTPS POST API""],
    [""PDF Page Container"", ""component"", ""A container for processed PDF pages in Azure Data Lake Storage""],
    [""Processed JSON File Container"", ""component"", ""A container for processed JSON files in Azure Data Lake Storage""],
    [""Azure Cosmos DB"", ""system""]
  ],
  ""relationships"": [
    [""Outlook Email Account"", ""contains"", ""Logic App (Email Trigger)""],
    [""Azure Logic Apps"", ""contains"", ""Logic App (Email Trigger)""],
    [""PDF Container"", ""part-of"", ""Azure Data Lake Storage""],
    [""Logic App (File Trigger)"", ""calls"", ""Function App""],
    [""Function App"", ""called-from"", ""Logic App (File Trigger)""],
    [""Function App"", ""contains"", ""AI Document Intelligence""],
    [""AI Document Intelligence"", ""called-from"", ""Function App""],
    [""PDF Page Container"", ""part-of"", ""Azure Data Lake Storage""],
    [""Processed JSON File Container"", ""part-of"", ""Azure Data Lake Storage""],
    [""Logic App (File Trigger)"", ""calls"", ""Azure Cosmos DB""],
    [""Azure Functions"", ""contains"", ""Function App""]
  ]
}
```","Here's the extracted entities and relationships in the JSON format:

```json
{
  ""entities"": [
    [""Outlook Email Account"", ""system""],
    [""Azure Logic Apps"", ""system""],
    [""Azure Data Lake Storage"", ""system""],
    [""PDF Container"", ""component"", ""A container for PDF files in Azure Data Lake Storage""],
    [""Logic App (Email Trigger)"", ""component"", ""Triggers when an email arrives""],
    [""Logic App (File Trigger)"", ""component"", ""Triggers when a file arrives in the PDF container""],
    [""Azure Functions"", ""system""],
    [""Function App"", ""component"", ""Processes PDF files and interacts with Azure AI Document Intelligence""],
    [""AI Document Intelligence"", ""component"", ""Processes PDF forms using an HTTPS POST API""],
    [""PDF Page Container"", ""component"", ""A container for processed PDF pages in Azure Data Lake Storage""],
    [""Processed JSON File Container"", ""component"", ""A container for processed JSON files in Azure Data Lake Storage""],
    [""Azure Cosmos DB"", ""system""]
  ],
  ""relationships"": [
    [""Outlook Email Account"", ""contains"", ""Logic App (Email Trigger)""],
    [""Azure Logic Apps"", ""contains"", ""Logic App (Email Trigger)""],
    [""PDF Container"", ""part-of"", ""Azure Data Lake Storage""],
    [""Logic App (File Trigger)"", ""calls"", ""Function App""],
    [""Function App"", ""called-from"", ""Logic App (File Trigger)""],
    [""Function App"", ""contains"", ""AI Document Intelligence""],
    [""AI Document Intelligence"", ""called-from"", ""Function App""],
    [""PDF Page Container"", ""part-of"", ""Azure Data Lake Storage""],
    [""Processed JSON File Container"", ""part-of"", ""Azure Data Lake Storage""],
    [""Logic App (File Trigger)"", ""calls"", ""Azure Cosmos DB""],
    [""Azure Functions"", ""contains"", ""Function App""]
  ]
}
```",6.773268780001672
122,mistral-nemo,../IMAGES NEW/Azure/07 Azure internal APIs original.txt,"
The data flows as follows:

    Developers check in code to a GitHub repository that's connected to a CI/CD pipeline agent that's installed on an Azure VM.
    The agent pushes the build to the API application that's hosted on ILB ASE.
    Azure API Management consumes the preceding APIs via HOST headers that are specified in API Management policy.
    API Management uses the App Service Environment's DNS name for all the APIs.
    Application Gateway exposes API Management's developer and API portal.
    Azure Private DNS is used to route the traffic internally between ASE, API Management, and Application Gateway.
    External users utilize the exposed developer portal to consume the APIs via Application Gateway's public IP.

","{""entities"": [[""GitHub repository"", ""system"", """"], [""Developers"", ""person"", """"], [""External users"", ""person"", """"], [""CI/CD pipeline agent"", ""system"", """"], [""Azure VM"", ""system"", """"], [""ILB ASE"", ""system"", """"], [""API application"", ""component"", """"], [""Azure API Management"", ""system"", ""consumes the preceding APIs via HOST headers""], [""App Service Environment"", ""component"", """"], [""Application Gateway"", ""component"", ""exposes API Management's developer and API portal""], [""Developer portal"", ""component"", ""API Management's developer and API portal""], [""API portal"", ""component"", ""API Management's developer and API portal""], [""Application Gateway"", ""component"", ""exposes API Management's developer and API portal""], [""Azure Private DNS"", ""component"", ""used to route the traffic internally between ASE, API Management, and Application Gateway""]], ""relationships"": [[""Azure VM"", ""contains"", ""CI/CD pipeline agent"", ""installed on an Azure VM""], [""API application"", ""part-of"", ""ILB ASE"", ""API application that's hosted on ILB ASE""], [""GitHub repository"", ""calls"", ""CI/CD pipeline agent"", ""GitHub repository that's connected to a CI/CD pipeline agent""], [""CI/CD pipeline agent"", ""calls"", ""API application"", ""agent pushes the build to the API application""], [""Azure API Management"", ""calls"", ""App Service Environment"", ""uses the App Service Environment's DNS name for all the APIs""], [""External users"", ""calls"", ""Application Gateway"", """"], [""Application Gateway"", ""calls"", ""API application"", ""to consume the APIs via Application Gateway's public IP""], [""Azure API Management"", ""contains"", ""Developer portal"", ""API Management's developer and API portal""], [""Azure API Management"", ""contains"", ""API portal"", ""API Management's developer and API portal""], [""Application Gateway"", ""calls"", ""API portal"", ""exposes API Management's developer and API portal.""], [""Application Gateway"", ""calls"", ""Developer portal"", ""exposes API Management's developer and API portal.""], [""Azure Private DNS"", ""calls"", ""Azure API Management"", ""route the traffic internally between ASE, API Management, and Application Gateway""], [""Azure Private DNS"", ""calls"", ""Application Gateway"", ""route the traffic internally between ASE, API Management, and Application Gateway""]]}","```json
{
  ""entities"": [
    [""Developers"", ""person""],
    [""GitHub repository"", ""system""],
    [""CI/CD pipeline agent"", ""component""],
    [""Azure VM"", ""system""],
    [""API application"", ""component""],
    [""ILB ASE"", ""system""],
    [""Azure API Management"", ""system""],
    [""HOST headers"", ""component""],
    [""App Service Environment"", ""system""],
    [""DNS name"", ""component""],
    [""Application Gateway"", ""system""],
    [""developer portal"", ""component""],
    [""APIs"", ""component""],
    [""External users"", ""person""]
  ],
  ""relationships"": [
    [""Developers"", ""check in code to"", ""GitHub repository""],
    [""GitHub repository"", ""connected to"", ""CI/CD pipeline agent""],
    [""CI/CD pipeline agent"", ""installed on"", ""Azure VM""],
    [""CI/CD pipeline agent"", ""pushes the build to"", ""API application""],
    [""API application"", ""hosted on"", ""ILB ASE""],
    [""Azure API Management"", ""consumes the APIs via HOST headers that are specified in API Management policy""],
    [""Azure API Management"", ""uses the DNS name for all the APIs"", ""App Service Environment""],
    [""Application Gateway"", ""exposes developer portal and APIs of"", ""Azure API Management""],
    [""External users"", ""utilize the exposed developer portal to consume the APIs via Application Gateway's public IP""]
  ]
}
```","```json
{
  ""entities"": [
    [""Developers"", ""person""],
    [""GitHub repository"", ""system""],
    [""CI/CD pipeline agent"", ""component""],
    [""Azure VM"", ""system""],
    [""API application"", ""component""],
    [""ILB ASE"", ""system""],
    [""Azure API Management"", ""system""],
    [""HOST headers"", ""component""],
    [""App Service Environment"", ""system""],
    [""DNS name"", ""component""],
    [""Application Gateway"", ""system""],
    [""developer portal"", ""component""],
    [""APIs"", ""component""],
    [""External users"", ""person""]
  ],
  ""relationships"": [
    [""Developers"", ""check in code to"", ""GitHub repository""],
    [""GitHub repository"", ""connected to"", ""CI/CD pipeline agent""],
    [""CI/CD pipeline agent"", ""installed on"", ""Azure VM""],
    [""CI/CD pipeline agent"", ""pushes the build to"", ""API application""],
    [""API application"", ""hosted on"", ""ILB ASE""],
    [""Azure API Management"", ""consumes the APIs via HOST headers that are specified in API Management policy""],
    [""Azure API Management"", ""uses the DNS name for all the APIs"", ""App Service Environment""],
    [""Application Gateway"", ""exposes developer portal and APIs of"", ""Azure API Management""],
    [""External users"", ""utilize the exposed developer portal to consume the APIs via Application Gateway's public IP""]
  ]
}
```",5.249825985985808
123,mistral-nemo,../IMAGES NEW/Azure/13 Azure Secure Research.txt,"
    Data owners upload datasets into a public blob storage account. The data is encrypted by using Microsoft-managed keys.

    Azure Data Factory uses a trigger that starts copying of the uploaded dataset to a specific location (import path) on another storage account with security controls. The storage account can only be reached through a private endpoint. Also, it's accessed by a service principal with limited permissions. Data Factory deletes the original copy making the dataset immutable.

    Researchers access the secure environment through a streaming application using Azure Virtual Desktop as a privileged jump box.

    The dataset in the secure storage account is presented to the data science VMs provisioned in a secure network environment for research work. Much of the data preparation is done on those VMs.

    The secure environment has Azure Machine Learning compute that can access the dataset through a private endpoint for users for Azure Machine Learning capabilities, such as to train, deploy, automate, and manage machine learning models. At this point, models are created that meet regulatory guidelines. All model data is de-identified by removing personal information.

    Models or de-identified data is saved to a separate location on the secure storage (export path). When new data is added to the export path, a logic app is triggered. In this architecture, the logic app is outside the secure environment because no data is sent to the logic app. Its only function is to send notification and start the manual approval process.

    The app starts an approval process requesting a review of data that is queued to be exported. The manual reviewers ensure that sensitive data isn't exported. After the review process, the data is either approved or denied.

    Note

    If an approval step is not required on exfiltration, the logic app step could be omitted.

    If the de-identified data is approved, it's sent to the Data Factory instance.

    Data Factory moves the data to the public storage account in a separate container to allow external researchers to have access to their exported data and models. Alternately, you can provision another storage account in a lower security environment.

","{""entities"": [[""datasets"", ""component"", ""Data owners upload datasets into a public blob storage account""], [""public blob storage account"", ""system"", ""Data owners upload datasets into a public blob storage account""], [""Azure Data Factory"", ""system"", ""Azure Data Factory uses a trigger that starts copying of the uploaded dataset to a specific location""], [""storage account"", ""system"", ""Azure Data Factory uses a trigger that starts copying of the uploaded dataset to a specific location (import path) on another storage account with security controls""], [""copied dataset"", ""system"", ""Azure Data Factory uses a trigger that starts copying of the uploaded dataset to a specific location (import path) on another storage account with security controls""], [""private endpoint"", ""component"", ""The storage account can only be reached through a private endpoint.""], [""service principal"", ""component"", ""Also, it's accessed by a service principal with limited permissions.""], [""streaming application"", ""component"", ""access the secure environment through a streaming application""], [""Azure Virtual Desktop"", ""component"", ""Azure Virtual Desktop as a privileged jump box""], [""data science VMs"", ""component"", ""data science VMs provisioned in a secure network environment""], [""Azure Machine Learning compute"", ""component"", ""The secure environment has Azure Machine Learning compute that can access the dataset""], [""secure network environment"", ""system"", ""data science VMs provisioned in a secure network environment""], [""machine learning models"", ""component"", ""At this point, models are created that meet regulatory guidelines""], [""de-identified data"", ""component"", ""Models or de-identified data is saved to a separate location on the secure storage (export path)""], [""logic app"", ""component"", ""When new data is added to the export path, a logic app is triggered""], [""separate container"", ""component"", ""Data Factory moves the data to the public storage account in a separate container""], [""moved data"", ""component"", ""Data Factory moves the data to the public storage account in a separate container""], [""Data owners"", ""person"", ""Data owners upload datasets into a public blob storage account""], [""Researchers"", ""person"", ""Researchers access the secure environment through a streaming application using Azure Virtual Desktop as a privileged jump box""], [""manual reviewers"", ""person"", ""The manual reviewers ensure that sensitive data isn't exported.""], [""Users"", ""person"", ""The secure environment has Azure Machine Learning compute that can access the dataset""]], ""relationships"": [[""datasets"", ""part-of"", ""public blob storage account"", ""Data owners upload datasets into a public blob storage account""], [""Data owners"", ""calls"", ""datasets"", ""Data owners upload datasets into a public blob storage account""], [""Azure Data Factory"", ""calls"", ""datasets"", ""Azure Data Factory uses a trigger that starts copying of the uploaded dataset""], [""storage account"", ""contains"", ""copied dataset"", ""opying of the uploaded dataset to a specific location (import path) on another storage account with security controls""], [""Azure Data Factory"", ""calls"", ""copied dataset"", ""Azure Data Factory uses a trigger that starts copying of the uploaded dataset to a specific location""], [""private endpoint"", ""calls"", ""storage account"", ""The storage account can only be reached through a private endpoint""], [""storage account"", ""is-called-from"", ""service principal"", ""Also, it's accessed by a service principal with limited permissions""], [""Researchers"", ""calls"", ""Azure Virtual Desktop"", "" Researchers access the secure environment through a streaming application""], [""Azure Virtual Desktop"", ""calls"", ""streaming application"", ""through a streaming application using Azure Virtual Desktop""], [""streaming application"", ""calls"", ""storage account"", ""Researchers access the secure environment through a streaming application using Azure Virtual Desktop as a privileged jump box""], [""data science VMs"", ""part-of"", ""secure network environment"", ""The dataset in the secure storage account is presented to the data science VMs""], [""data science VMs"", ""calls"", ""copied dataset"", "" The dataset in the secure storage account is presented to the data science VMs""], [""secure network environment"", ""contains"", ""Azure Machine Learning compute"", ""The secure environment has Azure Machine Learning compute that can access the dataset""], [""Azure Machine Learning compute"", ""calls"", ""Azure Machine Learning compute"", ""The secure environment has Azure Machine Learning compute that can access the dataset""], [""machine learning models"", ""part-of"", ""storage account"", ""Models or de-identified data is saved to a separate location on the secure storage (export path)""], [""machine learning models"", ""calls"", ""logic app"", ""When new data is added to the export path, a logic app is triggered""], [""logic app"", ""calls"", ""manual reviewers"", ""The app starts an approval process requesting a review of data that is queued to be exported.""], [""public blob storage account"", ""contains"", ""separate container"", ""Data Factory moves the data to the public storage account in a separate container""], [""Azure Data Factory"", ""calls"", ""de-identified data"", ""Data Factory moves the data to the public storage account in a separate container to allow external researchers to have access to their exported data and models""], [""separate container"", ""contains"", ""moved data"", ""Data Factory moves the data to the public storage account in a separate container""], [""Azure Data Factory"", ""calls"", ""moved data"", ""Data Factory moves the data to the public storage account in a separate container to allow external researchers to have access to their exported data and models""], [""Users"", ""calls"", ""Azure Machine Learning compute"", ""The secure environment has Azure Machine Learning compute that can access the dataset""]]}","```json
{
  ""entities"": [
    [""Azure Blob Storage"", ""system""],
    [""Microsoft-Managed Keys"", ""component""],
    [""Azure Data Factory"", ""system""],
    [""Trigger"", ""component""],
    [""Import Path"", ""component""],
    [""Private Endpoint"", ""component""],
    [""Service Principal"", ""person""],
    [""Secure Environment"", ""system""],
    [""Streaming Application"", ""component""],
    [""Azure Virtual Desktop"", ""component""],
    [""Data Science VMs"", ""system""],
    [""Azure Machine Learning Compute"", ""system""],
    [""Logic App"", ""system""],
    [""Manual Reviewers"", ""person""],
    [""Public Storage Account"", ""system""],
    [""External Researchers"", ""person""]
  ],
  ""relationships"": [
    [""Azure Blob Storage"", ""contains"", ""Microsoft-Managed Keys""],
    [""Azure Data Factory"", ""calls"", ""Trigger""],
    [""Secure Environment"", ""contains"", ""Data Science VMs""],
    [""Secure Environment"", ""contains"", ""Azure Machine Learning Compute""],
    [""Azure Machine Learning Compute"", ""called-from"", ""Data Science VMs""],
    [""Secure Storage"", ""part-of"", ""Export Path""],
    [""Logic App"", ""calls"", ""Manual Reviewers""],
    [""Public Storage Account"", ""contains"", ""External Researchers""]
  ]
}
```","```json
{
  ""entities"": [
    [""Azure Blob Storage"", ""system""],
    [""Microsoft-Managed Keys"", ""component""],
    [""Azure Data Factory"", ""system""],
    [""Trigger"", ""component""],
    [""Import Path"", ""component""],
    [""Private Endpoint"", ""component""],
    [""Service Principal"", ""person""],
    [""Secure Environment"", ""system""],
    [""Streaming Application"", ""component""],
    [""Azure Virtual Desktop"", ""component""],
    [""Data Science VMs"", ""system""],
    [""Azure Machine Learning Compute"", ""system""],
    [""Logic App"", ""system""],
    [""Manual Reviewers"", ""person""],
    [""Public Storage Account"", ""system""],
    [""External Researchers"", ""person""]
  ],
  ""relationships"": [
    [""Azure Blob Storage"", ""contains"", ""Microsoft-Managed Keys""],
    [""Azure Data Factory"", ""calls"", ""Trigger""],
    [""Secure Environment"", ""contains"", ""Data Science VMs""],
    [""Secure Environment"", ""contains"", ""Azure Machine Learning Compute""],
    [""Azure Machine Learning Compute"", ""called-from"", ""Data Science VMs""],
    [""Secure Storage"", ""part-of"", ""Export Path""],
    [""Logic App"", ""calls"", ""Manual Reviewers""],
    [""Public Storage Account"", ""contains"", ""External Researchers""]
  ]
}
```",4.845952909992775
124,mistral-nemo,../IMAGES NEW/Azure/05. azure Original.txt,"
    Backend systems. The right-hand side of the diagram shows the various backend systems that the enterprise has deployed or relies on. These systems might include SaaS systems, other Azure services, or web services that expose REST or SOAP endpoints.

    Azure Logic Apps. In this architecture, logic apps are triggered by HTTP requests. You can also nest workflows for more complex orchestration. Logic Apps uses connectors to integrate with commonly used services. Logic Apps offers hundreds of connectors, and you can create custom connectors.

    Azure API Management. API Management consists of two related components:

        API gateway. The API gateway accepts HTTP calls and routes them to the backend.

        Developer portal. Each instance of Azure API Management provides access to a developer portal. This portal gives your developers access to documentation and code samples for calling the APIs. You can also test APIs in the developer portal.

    Azure DNS. Azure DNS provides name resolution by using the Azure infrastructure. By hosting your domains in Azure, you can manage your DNS records by using the same credentials, APIs, tools, and billing that you use for your other Azure services. To use a custom domain name, such as contoso.com, create DNS records that map the custom domain name to the IP address. For more information, see Configure a custom domain name in API Management.

    Microsoft Entra ID. Use Microsoft Entra ID to authenticate clients that call the API gateway. Microsoft Entra ID supports the OpenID Connect (OIDC) protocol. Clients obtain an access token from Microsoft Entra ID, and API Gateway validates the token to authorize the request. If you use the Standard or Premium tier of API Management, Microsoft Entra ID can also help secure access to the developer portal.

","{""entities"": [[""Backend systems"", ""system"", ""various backend systems that the enterprise has deployed or relies on""], [""SaaS systems"", ""component"", ""SaaS systems""], [""other Azure services"", ""component"", ""other Azure services""], [""web services"", ""component"", ""expose REST or SOAP endpoints""], [""Azure Logic Apps"", ""system"", ""Logic Apps uses connectors to integrate with commonly used services""], [""Azure API Management"", ""system"", ""Logic Apps uses connectors to integrate with commonly used services""], [""API gateway"", ""component"", ""The API gateway accepts HTTP calls and routes them to the backend""], [""Developer portal"", ""component"", ""This portal gives your developers access to documentation and code samples for calling the APIs""], [""Azure DNS"", ""system"", ""Azure DNS provides name resolution by using the Azure infrastructure""], [""Microsoft Entra ID"", ""system"", ""Use Microsoft Entra ID to authenticate clients that call the API gateway""], [""clients"", ""system"", ""clients that call the API gateway""], [""developers"", ""person"", ""accesses documentation and code samples""]], ""relationships"": [[""Backend systems"", ""contains"", ""SaaS systems"", ""These systems might include ""], [""Backend systems"", ""contains"", ""web services"", ""These systems might include ""], [""Backend systems"", ""contains"", ""other Azure services"", ""These systems might include ""], [""web services"", ""contains"", ""SaaS systems"", ""These systems might include ""], [""Azure API Management"", ""contains"", ""API gateway"", ""API Management consists of two related components""], [""Azure API Management"", ""contains"", ""Developer portal"", ""API Management consists of two related components""], [""clients"", ""calls"", ""API gateway"", ""clients that call the API gateway""], [""clients"", ""calls"", ""Microsoft Entra ID"", ""Clients obtain an access token from Microsoft Entra ID""], [""developers"", ""calls"", ""Developer portal"", ""This portal gives your developers access to documentation and code samples for calling the APIs. You can also test APIs in the developer portal""]]}","{
  ""entities"": [
    [""Azure Logic Apps"", ""system"", ""A workflow automation service that triggers actions based on events or schedules.""],
    [""Azure API Management"", ""system"", ""A system for publishing APIs to developers, consumers, and employees securely and at scale.""],
    [""API gateway"", ""component"", ""Accepts HTTP calls and routes them to the backend.""],
    [""Developer portal"", ""component"", ""Provides access to documentation and code samples for calling the APIs, also allows API testing.""],
    [""Azure DNS"", ""system"", ""A Domain Name System (DNS) service for hosting domains and managing DNS records.""],
    [""Microsoft Entra ID"", ""system"", ""An identity management system that supports OpenID Connect protocol for authentication""]
  ],
  ""relationships"": [
    [""Azure Logic Apps"", ""calls"", ""Azure API Management""],
    [""API gateway"", ""part-of"", ""Azure API Management""],
    [""Developer portal"", ""part-of"", ""Azure API Management""],
    [""Azure DNS"", ""contains"", ""contoso.com""],
    [""Microsoft Entra ID"", ""called-from"", ""Azure API Management""]
  ]
}","{
  ""entities"": [
    [""Azure Logic Apps"", ""system"", ""A workflow automation service that triggers actions based on events or schedules.""],
    [""Azure API Management"", ""system"", ""A system for publishing APIs to developers, consumers, and employees securely and at scale.""],
    [""API gateway"", ""component"", ""Accepts HTTP calls and routes them to the backend.""],
    [""Developer portal"", ""component"", ""Provides access to documentation and code samples for calling the APIs, also allows API testing.""],
    [""Azure DNS"", ""system"", ""A Domain Name System (DNS) service for hosting domains and managing DNS records.""],
    [""Microsoft Entra ID"", ""system"", ""An identity management system that supports OpenID Connect protocol for authentication""]
  ],
  ""relationships"": [
    [""Azure Logic Apps"", ""calls"", ""Azure API Management""],
    [""API gateway"", ""part-of"", ""Azure API Management""],
    [""Developer portal"", ""part-of"", ""Azure API Management""],
    [""Azure DNS"", ""contains"", ""contoso.com""],
    [""Microsoft Entra ID"", ""called-from"", ""Azure API Management""]
  ]
}",4.4008631100005005
125,mistral-nemo,../IMAGES NEW/Azure/15 Azure automate-document-classification.txt,"
    The user provides a document file that the web app uploads. The file contains multiple documents of various types. It can, for instance, be a PDF or multipage TIFF file.
        The document file is stored in Azure Blob Storage.
        The web app adds a command message to a storage queue to initiate pipeline processing.

    Durable Functions orchestration is triggered by the command message. The message contains metadata that identifies the location in Blob Storage of the document file to be processed. Each Durable Functions instance processes only one document file.

    The Scan activity function calls the Computer Vision Read API, passing in the location in storage of the document to be processed. Optical character recognition (OCR) results are returned to the orchestration to be used by subsequent activities.

    The Classify activity function calls the document classifier service that's hosted in an Azure Kubernetes Service (AKS) cluster. This service uses regular expression pattern matching to identify the starting page of each known document and to calculate how many document types are contained in the document file. The types and page ranges of the documents are calculated and returned to the orchestration.



Note

Azure doesn't offer a service that can classify multiple document types in a single file. This solution uses a non-Azure service that's hosted in AKS.

The Metadata Store activity function saves the document type and page range information in an Azure Cosmos DB store.

The Indexing activity function creates a new search document in the Cognitive Search service for each identified document type and uses the Azure AI Search libraries for .NET to include in the search document the full OCR results and document information. A correlation ID is also added to the search document so that the search results can be matched with the corresponding document metadata from Azure Cosmos DB.

End users can search for documents by contents and metadata. Correlation IDs in the search result set can be used to look up document records that are in Azure Cosmos DB. The records include links to the original document file in Blob Storage.


","{""entities"": [[""web app"", ""system"", ""The user provides a document file that the web app uploads""], [""Azure Blob Storage"", ""system"", ""The document file is stored in Azure Blob Storage""], [""storage queue"", ""system"", ""the web app adds a command message to a storage queue to initiate pipeline processing""], [""Durable Functions orchestration"", ""system"", ""Durable Functions orchestration is triggered by the command message.""], [""Scan activity function"", ""component"", ""The Scan activity function calls the Computer Vision Read API.""], [""Computer Vision Read API"", ""component"", ""The Scan activity function calls the Computer Vision Read API.""], [""Classify activity function"", ""component"", ""The Classify activity function calls the document classifier service that's hosted in an Azure Kubernetes Service (AKS) cluster""], [""document classifier service"", ""component"", ""The Classify activity function calls the document classifier service that's hosted in an Azure Kubernetes Service (AKS) cluster""], [""Azure Kubernetes Service (AKS) cluster"", ""system"", ""The Classify activity function calls the document classifier service that's hosted in an Azure Kubernetes Service (AKS) cluster""], [""User"", ""person"", ""provides a document file that the web app uploads""]], ""relationships"": [[""User"", ""calls"", ""web app"", ""The user provides a document file that the web app uploads""], [""web app"", ""calls"", ""Azure Blob Storage"", ""The user provides a document file that the web app uploads.The document file is stored in Azure Blob Storage""], [""web app"", ""calls"", ""storage queue"", ""the web app adds a command message to a storage queue to initiate pipeline processing""], [""storage queue"", ""calls"", ""Durable Functions orchestration"", ""Durable Functions orchestration is triggered by the command message.""], [""Durable Functions orchestration"", ""calls"", ""Azure Blob Storage"", ""Each Durable Functions instance processes only one document file""], [""Scan activity function"", ""calls"", ""Computer Vision Read API"", ""the Scan activity function calls the Computer Vision Read API""], [""document classifier service"", ""part-of"", ""Azure Kubernetes Service (AKS) cluster"", ""document classifier service that's hosted in an Azure Kubernetes Service (AKS) cluster""], [""Classify activity function"", ""calls"", ""Scan activity function"", ""The Classify activity function calls the document classifier service""], [""Classify activity function"", ""calls"", ""Durable Functions orchestration"", ""The types and page ranges of the documents are calculated and returned to the orchestration""]]}","```json
{
  ""entities"": [
    [""User"", ""person"", ""The user provides a document file""],
    [""Web App"", ""system"", ""The web app uploads the document file and initiates pipeline processing""],
    [""Azure Blob Storage"", ""component"", ""Stores the document file""],
    [""Storage Queue"", ""component"", ""Used by the web app to initiate pipeline processing""],
    [""Durable Functions Orchestration"", ""system"", ""Triggered by the command message""],
    [""Scan Activity Function"", ""component"", ""Calls Computer Vision Read API for OCR results""],
    [""Computer Vision Read API"", ""component"", ""Performs optical character recognition""],
    [""Classify Activity Function"", ""component"", ""Identifies document types and page ranges""],
    [""Document Classifier Service"", ""system"", ""Hosted in Azure Kubernetes Service (AKS)""],
    [""Azure Kubernetes Service (AKS)"", ""system"", ""Hosts the document classifier service""],
    [""Metadata Store Activity Function"", ""component"", ""Saves document type and page range information in Cosmos DB""],
    [""Azure Cosmos DB store"", ""component"", ""Stores document type and page range information""],
    [""Indexing Activity Function"", ""component"", ""Creates search documents using Azure AI Search libraries""],
    [""Cognitive Search service"", ""system"", ""Used for creating search documents""],
    [""End User"", ""person"", ""Searches for documents by contents and metadata""]
  ],
  ""relationships"": [
    [""User"", ""calls"", ""Web App"", ""The user provides a document file that the web app uploads""],
    [""Web App"", ""contains"", ""Azure Blob Storage"", ""The document file is stored in Azure Blob Storage""],
    [""Web App"", ""adds"", ""Storage Queue"", ""The web app adds a command message to initiate pipeline processing""],
    [""Storage Queue"", ""calls"", ""Durable Functions Orchestration"", ""The orchestration is triggered by the command message""],
    [""Durable Functions Orchestration"", ""contains"", ""Scan Activity Function"", ""Each instance processes one document file""],
    [""Scan Activity Function"", ""calls"", ""Computer Vision Read API"", ""OCR results are returned to the orchestration""],
    [""Durable Functions Orchestration"", ""contains"", ""Classify Activity Function"", ""The function identifies document types and page ranges""],
    [""Classify Activity Function"", ""called-from"", ""Document Classifier Service"", ""The service uses regular expression pattern matching""],
    [""Document Classifier Service"", ""part-of"", ""Azure Kubernetes Service (AKS)"", ""Hosted in AKS""],
    [""Durable Functions Orchestration"", ""contains"", ""Metadata Store Activity Function"", ""The function saves information in Cosmos DB""],
    [""Metadata Store Activity Function"", ""called-from"", ""Azure Cosmos DB store"", ""Stores document type and page range information""],
    [""Durable Functions Orchestration"", ""contains"", ""Indexing Activity Function"", ""Creates search documents using Azure AI Search libraries""],
    [""Indexing Activity Function"", ""called-from"", ""Cognitive Search service"", ""Used for creating search documents""],
    [""End User"", ""searches"", ""Cognitive Search service"", ""Searches for documents by contents and metadata""]
  ]
}
```","```json
{
  ""entities"": [
    [""User"", ""person"", ""The user provides a document file""],
    [""Web App"", ""system"", ""The web app uploads the document file and initiates pipeline processing""],
    [""Azure Blob Storage"", ""component"", ""Stores the document file""],
    [""Storage Queue"", ""component"", ""Used by the web app to initiate pipeline processing""],
    [""Durable Functions Orchestration"", ""system"", ""Triggered by the command message""],
    [""Scan Activity Function"", ""component"", ""Calls Computer Vision Read API for OCR results""],
    [""Computer Vision Read API"", ""component"", ""Performs optical character recognition""],
    [""Classify Activity Function"", ""component"", ""Identifies document types and page ranges""],
    [""Document Classifier Service"", ""system"", ""Hosted in Azure Kubernetes Service (AKS)""],
    [""Azure Kubernetes Service (AKS)"", ""system"", ""Hosts the document classifier service""],
    [""Metadata Store Activity Function"", ""component"", ""Saves document type and page range information in Cosmos DB""],
    [""Azure Cosmos DB store"", ""component"", ""Stores document type and page range information""],
    [""Indexing Activity Function"", ""component"", ""Creates search documents using Azure AI Search libraries""],
    [""Cognitive Search service"", ""system"", ""Used for creating search documents""],
    [""End User"", ""person"", ""Searches for documents by contents and metadata""]
  ],
  ""relationships"": [
    [""User"", ""calls"", ""Web App"", ""The user provides a document file that the web app uploads""],
    [""Web App"", ""contains"", ""Azure Blob Storage"", ""The document file is stored in Azure Blob Storage""],
    [""Web App"", ""adds"", ""Storage Queue"", ""The web app adds a command message to initiate pipeline processing""],
    [""Storage Queue"", ""calls"", ""Durable Functions Orchestration"", ""The orchestration is triggered by the command message""],
    [""Durable Functions Orchestration"", ""contains"", ""Scan Activity Function"", ""Each instance processes one document file""],
    [""Scan Activity Function"", ""calls"", ""Computer Vision Read API"", ""OCR results are returned to the orchestration""],
    [""Durable Functions Orchestration"", ""contains"", ""Classify Activity Function"", ""The function identifies document types and page ranges""],
    [""Classify Activity Function"", ""called-from"", ""Document Classifier Service"", ""The service uses regular expression pattern matching""],
    [""Document Classifier Service"", ""part-of"", ""Azure Kubernetes Service (AKS)"", ""Hosted in AKS""],
    [""Durable Functions Orchestration"", ""contains"", ""Metadata Store Activity Function"", ""The function saves information in Cosmos DB""],
    [""Metadata Store Activity Function"", ""called-from"", ""Azure Cosmos DB store"", ""Stores document type and page range information""],
    [""Durable Functions Orchestration"", ""contains"", ""Indexing Activity Function"", ""Creates search documents using Azure AI Search libraries""],
    [""Indexing Activity Function"", ""called-from"", ""Cognitive Search service"", ""Used for creating search documents""],
    [""End User"", ""searches"", ""Cognitive Search service"", ""Searches for documents by contents and metadata""]
  ]
}
```",11.243592115992215
126,mistral-nemo,../IMAGES NEW/Azure/14 Azure Call Center Analytics.txt,"
    A phone call between an agent and a customer is recorded and stored in Azure Blob Storage. Audio files are uploaded to an Azure Storage account via a supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API.

    Azure AI Speech is used to transcribe audio files in Batch mode asynchronously with speaker diarization enabled. The transcription results are persisted in Blob Storage.

    Azure AI Language is used to detect and redact personal data in the transcript.

    For batch mode transcription and personal data detection and redaction, use the AI services Ingestion Client tool. The Ingestion Client tool uses a no-code approach for call center transcription.

    Azure OpenAI is used to process the transcript and extract entities, summarize the conversation, and analyze sentiments. The processed output is stored in Blob Storage and then analyzed and visualized by using other services. You can also store the output in a datastore for keeping track of metadata and for reporting. Use Azure OpenAI to process the stored transcription information.

    Power BI or a custom web application that's hosted by App Service is used to visualize the output. Both options provide near real-time insights. You can store this output in a customer relationship management (CRM), so agents have contextual information about why the customer called and can quickly solve potential problems. This process is fully automated, which saves the agents time and effort.

","{""entities"": [[""phone call"", ""component"", ""A phone call between an agent and a customer is recorded""], [""agent"", ""person"", ""A phone call between an agent and a customer is recorded""], [""customer"", ""person"", ""A phone call between an agent and a customer is recorded""], [""Azure Blob Storage"", ""system"", ""is recorded and stored in Azure Blob Storage""], [""Audio files"", ""system"", ""Audio files are uploaded to an Azure Storage account via a supported method""], [""supported method"", ""component"", ""Audio files are uploaded to an Azure Storage account via a supported method""], [""UI-based tool"", ""component"", ""supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""Azure Storage Explorer"", ""component"", ""supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""Storage SDK"", ""component"", ""supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""API"", ""component"", ""supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""Azure AI Speech"", ""component"", ""transcribe audio files in Batch mode asynchronously""], [""transcription results"", ""component"", ""The transcription results are persisted in Blob Storage.""], [""Azure AI Language"", ""component"", ""Azure AI Language is used to detect and redact personal data in the transcript.""], [""AI services Ingestion Client tool"", ""component"", ""For batch mode transcription and personal data detection and redaction, use the AI services Ingestion Client tool""], [""Azure OpenAI"", ""component"", ""Azure OpenAI is used to process the transcript and extract entities, summarize the conversation, and analyze sentiments.""], [""Azure OpenAI output"", ""component"", ""The processed output is stored in Blob Storage and then analyzed and visualized by using other services.""], [""other services"", ""component"", ""The processed output is stored in Blob Storage and then analyzed and visualized by using other services.""], [""App Service"", ""system"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""Power BI"", ""system"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""custom web application"", ""system"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""Azure OpenAI output 2"", ""component"", ""You can also store the output in a datastore for keeping track of metadata and for reporting""], [""datastore"", ""component"", ""You can also store the output in a datastore for keeping track of metadata and for reporting""], [""customer relationship management (CRM)"", ""system"", ""You can store this output in a customer relationship management (CRM)""], [""Azure OpenAI output 3"", ""component"", ""You can store this output in a customer relationship management (CRM)""]], ""relationships"": [[""agent"", ""calls"", ""phone call"", ""A phone call between an agent and a customer is recorded""], [""customer"", ""calls"", ""phone call"", ""A phone call between an agent and a customer is recorded""], [""phone call"", ""part-of"", ""Azure Blob Storage"", ""is recorded and stored in Azure Blob Storage""], [""Audio files"", ""part-of"", ""Azure Blob Storage"", ""Audio files are uploaded to an Azure Storage account via a supported method""], [""supported method"", ""calls"", ""Audio files"", ""Audio files are uploaded to an Azure Storage account via a supported method""], [""supported method"", ""contains"", ""UI-based tool"", ""upported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""supported method"", ""contains"", ""Azure Storage Explorer"", ""upported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""supported method"", ""contains"", ""Storage SDK"", ""upported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""supported method"", ""contains"", ""API"", ""supported method, such as the UI-based tool, Azure Storage Explorer, or a Storage SDK or API""], [""Azure AI Speech"", ""calls"", ""Audio files"", ""transcribe audio files in Batch mode asynchronously""], [""Azure Blob Storage"", ""contains"", ""transcription results"", ""The transcription results are persisted in Blob Storage.""], [""Azure AI Speech"", ""calls"", ""transcription results"", ""The transcription results are persisted in Blob Storage.""], [""Azure AI Language"", ""calls"", ""transcription results"", ""Azure AI Language is used to detect and redact personal data in the transcript.""], [""AI services Ingestion Client tool"", ""calls"", ""transcription results"", ""For batch mode transcription and personal data detection and redaction, use the AI services Ingestion Client tool""], [""Azure OpenAI"", ""calls"", ""transcription results"", ""Azure OpenAI is used to process the transcript and extract entities, summarize the conversation, and analyze sentiments.""], [""Azure OpenAI"", ""calls"", ""Azure OpenAI output"", ""The processed output is stored in Blob Storage and then analyzed and visualized by using other services.""], [""Azure Blob Storage"", ""contains"", ""Azure OpenAI output"", ""The processed output is stored in Blob Storage and then analyzed and visualized by using other services.""], [""other services"", ""calls"", ""Azure OpenAI output"", ""The processed output is stored in Blob Storage and then analyzed and visualized by using other services.""], [""Power BI"", ""part-of"", ""App Service"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""custom web application"", ""part-of"", ""App Service"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""custom web application"", ""calls"", ""Azure OpenAI output"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""Power BI"", ""calls"", ""Azure OpenAI output"", ""Power BI or a custom web application that's hosted by App Service is used to visualize the output.""], [""agent"", ""calls"", ""customer relationship management (CRM)"", ""You can store this output in a customer relationship management (CRM), so agents have contextual information about why the customer called and can quickly solve potential problems""], [""Azure OpenAI output 2"", ""part-of"", ""datastore"", ""You can also store the output in a datastore for keeping track of metadata and for reporting""], [""Azure OpenAI output 3"", ""part-of"", ""customer relationship management (CRM)"", ""You can also store the output in a datastore for keeping track of metadata and for reporting""], [""Azure OpenAI output"", ""calls"", ""Azure OpenAI output 2"", ""You can also store the output in a datastore for keeping track of metadata and for reporting""], [""Azure OpenAI output"", ""calls"", ""Azure OpenAI output 3"", ""You can store this output in a customer relationship management (CRM), so agents have contextual information about why the customer called and can quickly solve potential problems""]]}","{
  ""entities"": [
    [""Azure Blob Storage"", ""system""],
    [""Audio files"", ""component""],
    [""Azure AI Speech"", ""system""],
    [""Blob Storage"", ""component""],
    [""Azure Language"", ""system""],
    [""AI services Ingestion Client tool"", ""component""],
    [""Azure OpenAI"", ""system""],
    [""Power BI"", ""component""],
    [""App Service"", ""system""]
  ],
  ""relationships"": [
    [""Audio files"", ""stored-in"", ""Azure Blob Storage""],
    [""Azure AI Speech"", ""uses"", ""Blob Storage""],
    [""Azure Language"", ""uses"", ""AI services Ingestion Client tool""],
    [""Azure OpenAI"", ""processes"", ""transcription information""],
    [""Power BI"", ""visualizes"", ""processed output""],
    [""App Service"", ""hosts"", ""custom web application""]
  ]
}","{
  ""entities"": [
    [""Azure Blob Storage"", ""system""],
    [""Audio files"", ""component""],
    [""Azure AI Speech"", ""system""],
    [""Blob Storage"", ""component""],
    [""Azure Language"", ""system""],
    [""AI services Ingestion Client tool"", ""component""],
    [""Azure OpenAI"", ""system""],
    [""Power BI"", ""component""],
    [""App Service"", ""system""]
  ],
  ""relationships"": [
    [""Audio files"", ""stored-in"", ""Azure Blob Storage""],
    [""Azure AI Speech"", ""uses"", ""Blob Storage""],
    [""Azure Language"", ""uses"", ""AI services Ingestion Client tool""],
    [""Azure OpenAI"", ""processes"", ""transcription information""],
    [""Power BI"", ""visualizes"", ""processed output""],
    [""App Service"", ""hosts"", ""custom web application""]
  ]
}",3.525144345010631
127,mistral-nemo,../IMAGES NEW/Azure/12 Azure Network Microservices original.txt,"
    Outside services and clients make a POST request to APIM, with a data body that includes patient information.
    APIM calls the CreatePatient function in the Patient API with the given patient information.
    The CreatePatient function in Patient API calls the CreateAuditRecord function in the Audit API function app to create an audit record.
    The Audit API CreateAuditRecord function creates the audit record in Azure Cosmos DB, and returns a success response to the Patient API CreatePatient function.
    The CreatePatient function creates the patient document in Azure Cosmos DB, and returns a success response to APIM.
    The outside services and clients receive the success response from APIM.

","{""entities"": [[""Outside services"", ""system"", ""Outside services and clients make a POST request to APIM""], [""clients"", ""system"", ""Outside services and clients make a POST request to APIM""], [""APIM"", ""system"", ""Outside services and clients make a POST request to APIM""], [""Patient API"", ""system"", "" The CreatePatient function in Patient API calls the CreateAuditRecord function in the Audit API function app""], [""CreatePatient function"", ""component"", "" The CreatePatient function in Patient API calls the CreateAuditRecord function in the Audit API function app""], [""Audit API function app"", ""system"", ""The CreatePatient function in Patient API calls the CreateAuditRecord function in the Audit API function app""], [""CreateAuditRecord function"", ""component"", ""CreatePatient function in Patient API calls the CreateAuditRecord function""], [""Azure Cosmos DB"", ""system"", ""The Audit API CreateAuditRecord function creates the audit record in Azure Cosmos DB, and returns a success response to the Patient API CreatePatient function""]], ""relationships"": [[""CreatePatient function"", ""part-of"", ""Patient API"", ""Reason""], [""Outside services"", ""calls"", ""APIM"", ""utside services and clients make a POST request to APIM""], [""clients"", ""calls"", ""APIM"", ""outside services and clients make a POST request to APIM""], [""APIM"", ""calls"", ""CreatePatient function"", ""APIM calls the CreatePatient function in the Patient API""], [""CreateAuditRecord function"", ""part-of"", ""Audit API function app"", ""Reason""], [""CreatePatient function"", ""calls"", ""CreateAuditRecord function"", ""CreatePatient function in Patient API calls the CreateAuditRecord function in the Audit API function app""], [""CreateAuditRecord function"", ""calls"", ""Azure Cosmos DB"", ""Audit API CreateAuditRecord function creates the audit record in Azure Cosmos DB""], [""CreateAuditRecord function"", ""calls"", ""CreatePatient function"", ""returns a success response to the Patient API CreatePatient function.""], [""CreatePatient function"", ""calls"", ""Azure Cosmos DB"", ""The CreatePatient function creates the patient document in Azure Cosmos DB""], [""CreatePatient function"", ""is-called-from"", ""APIM"", ""The CreatePatient function returns a success response to APIM""]]}","```json
{
  ""entities"": [
    [""APIM"", ""system"", ""Application Programming Interface Management""],
    [""Patient_API"", ""system"", ""Patient Application Programming Interface""],
    [""Audit_API"", ""system"", ""Audit Application Programming Interface""],
    [""Azure_Cosmos_DB"", ""system"", ""Azure Cosmos Database""],
    [""CreatePatient"", ""function"", ""Function to create patient""],
    [""CreateAuditRecord"", ""function"", ""Function to create audit record""],
    [""Outside_Services_Clients"", ""person"", ""External clients and services""]
  ],
  ""relationships"": [
    [""Outside_Services_Clients"", ""calls"", ""APIM"", ""Make a POST request""],
    [""APIM"", ""calls"", ""CreatePatient"", ""Call the CreatePatient function""],
    [""CreatePatient"", ""called-from"", ""APIM"", ""Called by APIM""],
    [""CreatePatient"", ""calls"", ""Azure_Cosmos_DB"", ""Create patient document""],
    [""Azure_Cosmos_DB"", ""contains"", ""CreatePatient"", ""Contains the create patient operation""],
    [""CreateAuditRecord"", ""called-from"", ""CreatePatient"", ""Called by CreatePatient function""],
    [""CreateAuditRecord"", ""calls"", ""Azure_Cosmos_DB"", ""Create audit record""],
    [""Azure_Cosmos_DB"", ""contains"", ""CreateAuditRecord"", ""Contains the create audit record operation""],
    [""APIM"", ""called-from"", ""Outside_Services_Clients"", ""Receives success response from clients""]
  ]
}
```","```json
{
  ""entities"": [
    [""APIM"", ""system"", ""Application Programming Interface Management""],
    [""Patient_API"", ""system"", ""Patient Application Programming Interface""],
    [""Audit_API"", ""system"", ""Audit Application Programming Interface""],
    [""Azure_Cosmos_DB"", ""system"", ""Azure Cosmos Database""],
    [""CreatePatient"", ""function"", ""Function to create patient""],
    [""CreateAuditRecord"", ""function"", ""Function to create audit record""],
    [""Outside_Services_Clients"", ""person"", ""External clients and services""]
  ],
  ""relationships"": [
    [""Outside_Services_Clients"", ""calls"", ""APIM"", ""Make a POST request""],
    [""APIM"", ""calls"", ""CreatePatient"", ""Call the CreatePatient function""],
    [""CreatePatient"", ""called-from"", ""APIM"", ""Called by APIM""],
    [""CreatePatient"", ""calls"", ""Azure_Cosmos_DB"", ""Create patient document""],
    [""Azure_Cosmos_DB"", ""contains"", ""CreatePatient"", ""Contains the create patient operation""],
    [""CreateAuditRecord"", ""called-from"", ""CreatePatient"", ""Called by CreatePatient function""],
    [""CreateAuditRecord"", ""calls"", ""Azure_Cosmos_DB"", ""Create audit record""],
    [""Azure_Cosmos_DB"", ""contains"", ""CreateAuditRecord"", ""Contains the create audit record operation""],
    [""APIM"", ""called-from"", ""Outside_Services_Clients"", ""Receives success response from clients""]
  ]
}
```",5.422022824001033
128,mistral-nemo,../IMAGES NEW/Azure/10 Azure LoB original.txt,"
The data flows through the solution as follows:

    Supplier data stored in CDS is moved to SQL via Data Factory.
    Purchase order (PO) data stored in ERP system is sent to Azure SQL database.
    Azure Functions uses API to surface PO data monthly and creates a task for users to review.
    Power Apps retrieves data from Azure SQL Database through API.
    User reviews and updates POs in Power Apps and sends this data to suppliers through CSV export.
    Power BI reports trends in supplier status.

","{""entities"": [[""Supplier data"", ""component"", ""Supplier data stored in CDS""], [""CDS"", ""system"", "" Supplier data stored in CDS""], [""Azure SQL database"", ""system"", ""moved to SQL via Data Factory""], [""Data Factory"", ""system"", ""moved to SQL via Data Factory""], [""Purchase order (PO)"", ""system"", ""moved to SQL via Data Factory""], [""ERP system"", ""system"", ""Purchase order (PO) data stored in ERP system""], [""Azure Functions"", ""system"", ""uses API to surface PO data monthly and creates a task for users to review""], [""Power Apps"", ""system"", ""retrieves data from Azure SQL Database through API""], [""CSV export"", ""system"", ""ends this data to suppliers through CSV export""], [""User"", ""person"", "" reviews and updates POs in Power Apps""], [""suppliers"", ""person"", "" reviews and updates POs in Power Apps""]], ""relationships"": [[""Supplier data"", ""part-of"", ""CDS"", ""Supplier data stored in CDS""], [""Supplier data"", ""is-called-from"", ""Data Factory"", ""moved to SQL via Data Factory""], [""Data Factory"", ""calls"", ""Azure SQL database"", ""moved to SQL via Data Factory""], [""Purchase order (PO)"", ""part-of"", ""ERP system"", ""Purchase order (PO) data stored in ERP system""], [""Purchase order (PO)"", ""calls"", ""Azure SQL database"", ""Purchase order (PO) data stored in ERP system is sent to Azure SQL database""], [""Azure Functions"", ""calls"", ""Purchase order (PO)"", ""uses API to surface PO data monthly""], [""Azure Functions"", ""calls"", ""User"", ""creates a task for users to review""], [""Power Apps"", ""calls"", ""Azure SQL database"", ""retrieves data from Azure SQL Database through API""], [""User"", ""calls"", ""Power Apps"", ""Reviews and updates POs in Power Apps""], [""User"", ""calls"", ""CSV export"", ""sends this data to suppliers through CSV export""], [""CSV export"", ""calls"", ""suppliers"", ""sends this data to suppliers through CSV export""]]}","{
  ""entities"": [
    [""Supplier"", ""system""],
    [""CDS"", ""component""],
    [""Data Factory"", ""component""],
    [""SQL"", ""system""],
    [""ERP"", ""system""],
    [""Azure SQL Database"", ""system""],
    [""Azure Functions"", ""component""],
    [""API"", ""component""],
    [""PO"", ""component""],
    [""Power Apps"", ""component""],
    [""CSV export"", ""component""],
    [""Power BI"", ""component""]
  ],
  ""relationships"": [
    [""Supplier"", ""stores data in"", ""CDS""],
    [""Data Factory"", ""moves data to"", ""SQL""],
    [""ERP"", ""sends data to"", ""Azure SQL Database""],
    [""Azure Functions"", ""uses API to surface"", ""PO""],
    [""Azure Functions"", ""creates task for users to review"", ""PO""],
    [""Power Apps"", ""retrieves data from"", ""Azure SQL Database""],
    [""User"", ""reviews and updates"", ""PO""],
    [""Power Apps"", ""sends data to suppliers through"", ""CSV export""],
    [""Power BI"", ""reports trends in supplier status""]
  ]
}","{
  ""entities"": [
    [""Supplier"", ""system""],
    [""CDS"", ""component""],
    [""Data Factory"", ""component""],
    [""SQL"", ""system""],
    [""ERP"", ""system""],
    [""Azure SQL Database"", ""system""],
    [""Azure Functions"", ""component""],
    [""API"", ""component""],
    [""PO"", ""component""],
    [""Power Apps"", ""component""],
    [""CSV export"", ""component""],
    [""Power BI"", ""component""]
  ],
  ""relationships"": [
    [""Supplier"", ""stores data in"", ""CDS""],
    [""Data Factory"", ""moves data to"", ""SQL""],
    [""ERP"", ""sends data to"", ""Azure SQL Database""],
    [""Azure Functions"", ""uses API to surface"", ""PO""],
    [""Azure Functions"", ""creates task for users to review"", ""PO""],
    [""Power Apps"", ""retrieves data from"", ""Azure SQL Database""],
    [""User"", ""reviews and updates"", ""PO""],
    [""Power Apps"", ""sends data to suppliers through"", ""CSV export""],
    [""Power BI"", ""reports trends in supplier status""]
  ]
}",4.340195185999619
129,mistral-nemo,../IMAGES NEW/Azure/11 Mainframe original.txt,"
    A Connect agent component captures change logs by using mainframe or midrange native utilities and caches the logs in temporary storage.
    For mainframe systems, a publisher component on the mainframe manages data migration.
    For midrange systems, in place of the publisher, a listener component manages data migration. It's located on either a Windows or Linux machine.
    The publisher or listener moves the data from on-premises to Azure via an enhanced-security connection. The publisher or listener handles the commit and rollback of transactions for each unit of work, maintaining the integrity of data.
    The Connect Replicator Engine captures the data from the publisher or listener and applies it to the target. It distributes data for parallel processing.
    The target is a database that receives the changes via ODBC or ingests the changes via Azure Event Hubs.
    The changed data is consumed by Azure Databricks and applied to Azure data platform services.
    The Connect Controller Daemon authenticates the request and establishes the socket connection between the publisher or listener and the Replicator Engine.

","{""entities"": [[""Connect agent"", ""component"", ""captures change logs""], [""temporary storage"", ""component"", ""caches the logs in temporary storage""], [""mainframe native utilities"", ""system"", ""captures change logs by using mainframe or midrange native utilities""], [""midrange native utilities"", ""system"", ""captures change logs by using mainframe or midrange native utilities""], [""mainframe systems"", ""system"", ""For mainframe systems, a publisher component on the mainframe manages data migration.""], [""midrange systems"", ""system"", ""For midrange systems, in place of the publisher, a listener component manages data migration.""], [""publisher"", ""component"", ""For mainframe systems, a publisher component on the mainframe manages data migration.""], [""listener"", ""component"", ""For midrange systems, in place of the publisher, a listener component manages data migration.""], [""Connect Replicator Engine"", ""system"", ""captures the data from the publisher or listener and applies it to the target.""], [""on-premises"", ""system"", ""The publisher or listener moves the data from on-premises to Azure""], [""Azure"", ""system"", ""The publisher or listener moves the data from on-premises to Azure""], [""Connect Replicator Engine"", ""system"", ""The Connect Replicator Engine captures the data from the publisher or listener""], [""target"", ""system"", ""applies it to the target""], [""database"", ""system"", ""target is a database""], [""ODBC"", ""component"", ""The target is a database that receives the changes via ODBC or ingests the changes via Azure Event Hubs""], [""Azure Event Hubs"", ""component"", ""The target is a database that receives the changes via ODBC or ingests the changes via Azure Event Hubs""], [""Azure Databricks"", ""component"", ""the changed data is consumed by Azure Databricks and applied to Azure data platform services.""], [""Azure data platform services"", ""component"", ""the changed data is consumed by Azure Databricks and applied to Azure data platform services.""], [""Connect Controller Daemon"", ""component"", ""authenticates the request and establishes the socket connection between the publisher or listener and the Replicator Engine.""]], ""relationships"": [[""Connect agent"", ""calls"", ""mainframe native utilities"", ""captures change logs by using mainframe or midrange native utilities""], [""Connect agent"", ""calls"", ""midrange native utilities"", ""captures change logs by using mainframe or midrange native utilities""], [""Connect agent"", ""calls"", ""temporary storage"", ""captures change logs by using mainframe or midrange native utilities""], [""mainframe systems"", ""contains"", ""mainframe native utilities"", ""F""], [""midrange systems"", ""contains"", ""midrange native utilities"", """"], [""mainframe systems"", ""contains"", ""publisher"", ""For mainframe systems, a publisher component on the mainframe manages data migration.""], [""midrange systems"", ""contains"", ""listener"", ""For midrange systems, in place of the publisher, a listener component manages data migration.""], [""publisher"", ""calls"", ""on-premises"", ""The publisher or listener moves the data from on-premises to Azure""], [""publisher"", ""calls"", ""Azure"", ""The publisher or listener moves the data from on-premises to Azure""], [""listener"", ""calls"", ""on-premises"", ""The publisher or listener moves the data from on-premises to Azure""], [""listener"", ""calls"", ""Azure"", ""The publisher or listener moves the data from on-premises to Azure""], [""Connect Replicator Engine"", ""calls"", ""publisher"", ""captures the data from the publisher or listener and applies it to the target.""], [""Connect Replicator Engine"", ""calls"", ""listener"", ""captures the data from the publisher or listener and applies it to the target.""], [""Connect Replicator Engine"", ""calls"", ""target"", ""captures the data from the publisher or listener and applies it to the target.""], [""target"", ""contains"", ""database"", ""target is a database""], [""database"", ""is-called-from"", ""ODBC"", ""database that receives the changes via ODBC""], [""database"", ""is-called-from"", ""Azure Event Hubs"", ""ingests the changes via Azure Event Hubs""], [""database"", ""is-called-from"", ""Azure Databricks"", ""the changed data is consumed by Azure Databricks""], [""Azure Databricks"", ""calls"", ""Azure data platform services"", ""consumed by Azure Databricks and applied to Azure data platform services.""], [""Connect Controller Daemon"", ""is-called-from"", ""publisher"", ""establishes the socket connection between the publisher or listener and the Replicator Engine..""], [""Connect Controller Daemon"", ""is-called-from"", ""listener"", ""establishes the socket connection between the publisher or listener and the Replicator Engine..""], [""Connect Controller Daemon"", ""calls"", ""Connect Replicator Engine"", ""establishes the socket connection between the publisher or listener and the Replicator Engine..""]]}","{
  ""entities"": [
    [""Connect agent component"", ""component"", ""Captures change logs from mainframe or midrange systems""],
    [""Publisher component"", ""component"", ""Manages data migration for mainframe systems""],
    [""Listener component"", ""component"", ""Manages data migration for midrange systems""],
    [""Replicator Engine"", ""system"", ""Captures data from publisher or listener and applies it to the target""],
    [""Connect Controller Daemon"", ""component"", ""Authenticates requests and establishes socket connections""],
    [""Target database"", ""system"", ""Receives changes via ODBC or Azure Event Hubs""],
    [""Azure Databricks"", ""system"", ""Consumes changed data and applies it to Azure data platform services""],
    [""Mainframe system"", ""system"", ""Source of change logs for Connect agent component""],
    [""Midrange system"", ""system"", ""Source of change logs for Connect agent component""]
  ],
  ""relationships"": [
    [""Connect agent component"", ""part-of"", ""Replicator Engine""],
    [""Publisher component"", ""calls"", ""Replicator Engine""],
    [""Listener component"", ""called-from"", ""Replicator Engine""],
    [""Connect Controller Daemon"", ""calls"", ""Replicator Engine""],
    [""Replicator Engine"", ""contains"", ""Target database""],
    [""Target database"", ""part-of"", ""Azure Databricks""]
  ]
}","{
  ""entities"": [
    [""Connect agent component"", ""component"", ""Captures change logs from mainframe or midrange systems""],
    [""Publisher component"", ""component"", ""Manages data migration for mainframe systems""],
    [""Listener component"", ""component"", ""Manages data migration for midrange systems""],
    [""Replicator Engine"", ""system"", ""Captures data from publisher or listener and applies it to the target""],
    [""Connect Controller Daemon"", ""component"", ""Authenticates requests and establishes socket connections""],
    [""Target database"", ""system"", ""Receives changes via ODBC or Azure Event Hubs""],
    [""Azure Databricks"", ""system"", ""Consumes changed data and applies it to Azure data platform services""],
    [""Mainframe system"", ""system"", ""Source of change logs for Connect agent component""],
    [""Midrange system"", ""system"", ""Source of change logs for Connect agent component""]
  ],
  ""relationships"": [
    [""Connect agent component"", ""part-of"", ""Replicator Engine""],
    [""Publisher component"", ""calls"", ""Replicator Engine""],
    [""Listener component"", ""called-from"", ""Replicator Engine""],
    [""Connect Controller Daemon"", ""calls"", ""Replicator Engine""],
    [""Replicator Engine"", ""contains"", ""Target database""],
    [""Target database"", ""part-of"", ""Azure Databricks""]
  ]
}",5.276658471993869
